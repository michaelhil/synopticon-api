{
  "timestamp": "2025-08-27T09:15:09.544Z",
  "version": "0.5.8",
  "overall": {
    "passed": false,
    "score": 0
  },
  "checks": [
    {
      "name": "ESLint Strict",
      "passed": false,
      "exitCode": 1,
      "duration": 786,
      "output": "[{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/examples/shared/component-integration.js\",\"messages\":[{\"ruleId\":\"max-lines-per-function\",\"severity\":1,\"message\":\"Arrow function has too many lines (363). Maximum allowed is 200.\",\"line\":30,\"column\":50,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"exceed\",\"endLine\":392,\"endColumn\":2}],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":1,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Enhanced Component Integration System\\n * Provides robust component lifecycle management and error handling\\n */\\n\\n// Component states\\nexport const ComponentState = {\\n  UNINITIALIZED: 'uninitialized',\\n  INITIALIZING: 'initializing', \\n  INITIALIZED: 'initialized',\\n  STARTING: 'starting',\\n  RUNNING: 'running',\\n  STOPPING: 'stopping',\\n  STOPPED: 'stopped',\\n  ERROR: 'error',\\n  RECOVERING: 'recovering'\\n};\\n\\n// Error types\\nexport const ErrorType = {\\n  INITIALIZATION_ERROR: 'initialization_error',\\n  RUNTIME_ERROR: 'runtime_error',\\n  NETWORK_ERROR: 'network_error',\\n  PERMISSION_ERROR: 'permission_error',\\n  RESOURCE_ERROR: 'resource_error',\\n  VALIDATION_ERROR: 'validation_error'\\n};\\n\\n// Component integration manager\\nexport const createComponentIntegrationManager = (config = {}) => {\\n  const state = {\\n    components: new Map(),\\n    dependencies: new Map(),\\n    eventBus: createEventBus(),\\n    retryConfig: {\\n      maxRetries: config.maxRetries || 3,\\n      retryDelay: config.retryDelay || 1000,\\n      backoffMultiplier: config.backoffMultiplier || 2\\n    },\\n    globalErrorHandlers: []\\n  };\\n\\n  // Register a component with dependencies\\n  const registerComponent = (name, componentFactory, options = {}) => {\\n    const component = {\\n      name,\\n      factory: componentFactory,\\n      instance: null,\\n      state: ComponentState.UNINITIALIZED,\\n      dependencies: options.dependencies || [],\\n      optional: options.optional || false,\\n      retryCount: 0,\\n      lastError: null,\\n      config: options.config || {},\\n      onStateChange: options.onStateChange || (() => {}),\\n      onError: options.onError || (() => {})\\n    };\\n\\n    state.components.set(name, component);\\n    \\n    // Register dependencies\\n    if (component.dependencies.length > 0) {\\n      state.dependencies.set(name, component.dependencies);\\n    }\\n\\n    console.log(`📦 Registered component: ${name} with ${component.dependencies.length} dependencies`);\\n    return component;\\n  };\\n\\n  // Initialize a single component with error handling\\n  const initializeComponent = async (name) => {\\n    const component = state.components.get(name);\\n    if (!component) {\\n      throw new Error(`Component ${name} not found`);\\n    }\\n\\n    if (component.state === ComponentState.INITIALIZED) {\\n      return component.instance;\\n    }\\n\\n    try {\\n      setComponentState(component, ComponentState.INITIALIZING);\\n\\n      // Check dependencies first\\n      const dependenciesReady = await checkDependencies(name);\\n      if (!dependenciesReady && !component.optional) {\\n        throw new Error(`Dependencies not ready for component ${name}`);\\n      }\\n\\n      // Initialize the component\\n      component.instance = await component.factory(component.config);\\n      \\n      // Call initialize if available\\n      if (component.instance?.initialize) {\\n        await component.instance.initialize();\\n      }\\n\\n      setComponentState(component, ComponentState.INITIALIZED);\\n      state.eventBus.emit('component:initialized', { name, component });\\n      \\n      console.log(`✅ Initialized component: ${name}`);\\n      return component.instance;\\n\\n    } catch (error) {\\n      await handleComponentError(component, error, ErrorType.INITIALIZATION_ERROR);\\n      throw error;\\n    }\\n  };\\n\\n  // Initialize all components in dependency order\\n  const initializeAll = async () => {\\n    console.log('🚀 Initializing all components...');\\n    const initOrder = getInitializationOrder();\\n    const results = {};\\n\\n    for (const componentName of initOrder) {\\n      try {\\n        results[componentName] = await initializeComponent(componentName);\\n      } catch (error) {\\n        console.error(`Failed to initialize ${componentName}:`, error.message);\\n        \\n        const component = state.components.get(componentName);\\n        if (!component.optional) {\\n          throw new Error(`Critical component ${componentName} failed to initialize`);\\n        }\\n        \\n        results[componentName] = null;\\n      }\\n    }\\n\\n    return results;\\n  };\\n\\n  // Get component initialization order based on dependencies\\n  const getInitializationOrder = () => {\\n    const visited = new Set();\\n    const visiting = new Set();\\n    const order = [];\\n\\n    const visit = (name) => {\\n      if (visiting.has(name)) {\\n        throw new Error(`Circular dependency detected involving ${name}`);\\n      }\\n      if (visited.has(name)) return;\\n\\n      visiting.add(name);\\n      \\n      const deps = state.dependencies.get(name) || [];\\n      for (const dep of deps) {\\n        if (state.components.has(dep)) {\\n          visit(dep);\\n        }\\n      }\\n      \\n      visiting.delete(name);\\n      visited.add(name);\\n      order.push(name);\\n    };\\n\\n    for (const name of state.components.keys()) {\\n      visit(name);\\n    }\\n\\n    return order;\\n  };\\n\\n  // Check if component dependencies are ready\\n  const checkDependencies = async (componentName) => {\\n    const deps = state.dependencies.get(componentName) || [];\\n    \\n    for (const depName of deps) {\\n      const depComponent = state.components.get(depName);\\n      if (!depComponent || depComponent.state !== ComponentState.INITIALIZED) {\\n        console.warn(`Dependency ${depName} not ready for ${componentName}`);\\n        return false;\\n      }\\n    }\\n    \\n    return true;\\n  };\\n\\n  // Set component state and notify listeners\\n  const setComponentState = (component, newState) => {\\n    const oldState = component.state;\\n    component.state = newState;\\n    \\n    component.onStateChange(newState, oldState);\\n    state.eventBus.emit('component:stateChanged', {\\n      name: component.name,\\n      state: newState,\\n      oldState\\n    });\\n  };\\n\\n  // Handle component errors with retry logic\\n  const handleComponentError = async (component, error, errorType) => {\\n    component.lastError = { error, type: errorType, timestamp: Date.now() };\\n    \\n    console.error(`❌ Component ${component.name} error (${errorType}):`, error.message);\\n    \\n    // Notify component-specific error handler\\n    component.onError(error, errorType);\\n    \\n    // Notify global error handlers\\n    state.globalErrorHandlers.forEach(handler => {\\n      try {\\n        handler(component.name, error, errorType);\\n      } catch (handlerError) {\\n        console.error('Error handler failed:', handlerError);\\n      }\\n    });\\n\\n    // Emit error event\\n    state.eventBus.emit('component:error', {\\n      name: component.name,\\n      error,\\n      type: errorType\\n    });\\n\\n    // Attempt recovery if configured\\n    if (shouldRetry(component, errorType)) {\\n      await attemptRecovery(component);\\n    } else {\\n      setComponentState(component, ComponentState.ERROR);\\n    }\\n  };\\n\\n  // Determine if component should retry\\n  const shouldRetry = (component, errorType) => {\\n    if (component.retryCount >= state.retryConfig.maxRetries) {\\n      return false;\\n    }\\n\\n    // Don't retry certain error types\\n    const nonRetryableErrors = [\\n      ErrorType.PERMISSION_ERROR,\\n      ErrorType.VALIDATION_ERROR\\n    ];\\n    \\n    return !nonRetryableErrors.includes(errorType);\\n  };\\n\\n  // Attempt component recovery\\n  const attemptRecovery = async (component) => {\\n    setComponentState(component, ComponentState.RECOVERING);\\n    component.retryCount++;\\n\\n    const delay = state.retryConfig.retryDelay * \\n      Math.pow(state.retryConfig.backoffMultiplier, component.retryCount - 1);\\n    \\n    console.log(`🔄 Attempting recovery for ${component.name} (attempt ${component.retryCount}) in ${delay}ms`);\\n    \\n    await new Promise(resolve => setTimeout(resolve, delay));\\n\\n    try {\\n      // Reset component state\\n      if (component.instance?.cleanup) {\\n        await component.instance.cleanup();\\n      }\\n      component.instance = null;\\n      \\n      // Reinitialize\\n      await initializeComponent(component.name);\\n      component.retryCount = 0; // Reset on success\\n      \\n    } catch (error) {\\n      await handleComponentError(component, error, ErrorType.RUNTIME_ERROR);\\n    }\\n  };\\n\\n  // Start a component\\n  const startComponent = async (name) => {\\n    const component = state.components.get(name);\\n    if (!component?.instance) {\\n      throw new Error(`Component ${name} not initialized`);\\n    }\\n\\n    if (component.state === ComponentState.RUNNING) {\\n      return component.instance;\\n    }\\n\\n    try {\\n      setComponentState(component, ComponentState.STARTING);\\n      \\n      if (component.instance.start) {\\n        await component.instance.start();\\n      }\\n      \\n      setComponentState(component, ComponentState.RUNNING);\\n      state.eventBus.emit('component:started', { name, component });\\n      \\n      return component.instance;\\n      \\n    } catch (error) {\\n      await handleComponentError(component, error, ErrorType.RUNTIME_ERROR);\\n      throw error;\\n    }\\n  };\\n\\n  // Stop a component\\n  const stopComponent = async (name) => {\\n    const component = state.components.get(name);\\n    if (!component?.instance) {\\n      return;\\n    }\\n\\n    try {\\n      setComponentState(component, ComponentState.STOPPING);\\n      \\n      if (component.instance.stop) {\\n        await component.instance.stop();\\n      }\\n      \\n      setComponentState(component, ComponentState.STOPPED);\\n      state.eventBus.emit('component:stopped', { name, component });\\n      \\n    } catch (error) {\\n      await handleComponentError(component, error, ErrorType.RUNTIME_ERROR);\\n    }\\n  };\\n\\n  // Get component by name\\n  const getComponent = (name) => {\\n    const component = state.components.get(name);\\n    return component?.instance || null;\\n  };\\n\\n  // Get component state\\n  const getComponentState = (name) => {\\n    const component = state.components.get(name);\\n    return component?.state || ComponentState.UNINITIALIZED;\\n  };\\n\\n  // Get all component states\\n  const getAllStates = () => {\\n    const states = {};\\n    for (const [name, component] of state.components) {\\n      states[name] = {\\n        state: component.state,\\n        retryCount: component.retryCount,\\n        lastError: component.lastError\\n      };\\n    }\\n    return states;\\n  };\\n\\n  // Add global error handler\\n  const addErrorHandler = (handler) => {\\n    state.globalErrorHandlers.push(handler);\\n    return () => {\\n      const index = state.globalErrorHandlers.indexOf(handler);\\n      if (index !== -1) state.globalErrorHandlers.splice(index, 1);\\n    };\\n  };\\n\\n  // Cleanup all components\\n  const cleanup = async () => {\\n    console.log('🧹 Cleaning up all components...');\\n    \\n    const componentNames = Array.from(state.components.keys()).reverse();\\n    \\n    for (const name of componentNames) {\\n      try {\\n        await stopComponent(name);\\n        const component = state.components.get(name);\\n        if (component?.instance?.cleanup) {\\n          await component.instance.cleanup();\\n        }\\n      } catch (error) {\\n        console.error(`Failed to cleanup ${name}:`, error);\\n      }\\n    }\\n    \\n    state.components.clear();\\n    state.dependencies.clear();\\n  };\\n\\n  return {\\n    registerComponent,\\n    initializeComponent,\\n    initializeAll,\\n    startComponent,\\n    stopComponent,\\n    getComponent,\\n    getComponentState,\\n    getAllStates,\\n    addErrorHandler,\\n    cleanup,\\n    on: state.eventBus.on.bind(state.eventBus),\\n    emit: state.eventBus.emit.bind(state.eventBus)\\n  };\\n};\\n\\n// Simple event bus implementation\\nconst createEventBus = () => {\\n  const events = new Map();\\n\\n  return {\\n    on: (event, callback) => {\\n      if (!events.has(event)) {\\n        events.set(event, []);\\n      }\\n      events.get(event).push(callback);\\n      \\n      return () => {\\n        const callbacks = events.get(event);\\n        if (callbacks) {\\n          const index = callbacks.indexOf(callback);\\n          if (index !== -1) callbacks.splice(index, 1);\\n        }\\n      };\\n    },\\n\\n    emit: (event, data) => {\\n      const callbacks = events.get(event) || [];\\n      callbacks.forEach(callback => {\\n        try {\\n          callback(data);\\n        } catch (error) {\\n          console.error(`Event callback error for ${event}:`, error);\\n        }\\n      });\\n    }\\n  };\\n};\\n\\n// Enhanced component factory wrapper\\nexport const createEnhancedComponent = (baseFactory, options = {}) => {\\n  return async (config) => {\\n    const component = await baseFactory(config);\\n    \\n    // Add error boundary wrapper\\n    const withErrorBoundary = (method) => {\\n      const originalMethod = component[method];\\n      if (typeof originalMethod === 'function') {\\n        component[method] = async (...args) => {\\n          try {\\n            return await originalMethod.call(component, ...args);\\n          } catch (error) {\\n            console.error(`Error in ${method}:`, error);\\n            \\n            // Emit error event if component has event system\\n            if (component.emit) {\\n              component.emit('error', { method, error, args });\\n            }\\n            \\n            // Re-throw for upstream handling\\n            throw error;\\n          }\\n        };\\n      }\\n    };\\n\\n    // Wrap common methods with error boundaries\\n    ['initialize', 'start', 'stop', 'process', 'update'].forEach(withErrorBoundary);\\n    \\n    // Add health check capability\\n    component.healthCheck = async () => {\\n      try {\\n        if (component.isHealthy) {\\n          return await component.isHealthy();\\n        }\\n        return { \\n          status: 'healthy', \\n          timestamp: Date.now(),\\n          retryCount: options.retryCount,\\n          healthCheckInterval: options.healthCheckInterval\\n        };\\n      } catch (error) {\\n        return { \\n          status: 'unhealthy', \\n          error: error.message, \\n          timestamp: Date.now(),\\n          retryCount: options.retryCount\\n        };\\n      }\\n    };\\n\\n    // Add graceful shutdown\\n    const originalCleanup = component.cleanup;\\n    component.cleanup = async () => {\\n      try {\\n        if (originalCleanup) {\\n          await originalCleanup.call(component);\\n        }\\n      } catch (error) {\\n        console.warn('Cleanup error (non-critical):', error);\\n      }\\n    };\\n\\n    return component;\\n  };\\n};\\n\\n// Utility for creating resilient components\\nexport const createResilientComponent = (factory, resilientOptions = {}) => {\\n  return createEnhancedComponent(factory, {\\n    retryCount: resilientOptions.retryCount || 3,\\n    retryDelay: resilientOptions.retryDelay || 1000,\\n    healthCheckInterval: resilientOptions.healthCheckInterval || 30000,\\n    ...resilientOptions\\n  });\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/examples/shared/demo-integration-example.js\",\"messages\":[{\"ruleId\":\"max-lines-per-function\",\"severity\":1,\"message\":\"Arrow function has too many lines (388). Maximum allowed is 200.\",\"line\":11,\"column\":46,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"exceed\",\"endLine\":398,\"endColumn\":2},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '-'. Use parentheses to clarify the intended order of operations.\",\"line\":188,\"column\":21,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":188,\"endColumn\":22},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '-'. Use parentheses to clarify the intended order of operations.\",\"line\":188,\"column\":41,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":188,\"endColumn\":42},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '-'. Use parentheses to clarify the intended order of operations.\",\"line\":189,\"column\":21,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":189,\"endColumn\":22},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '-'. Use parentheses to clarify the intended order of operations.\",\"line\":189,\"column\":42,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":189,\"endColumn\":43}],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":5,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Demo Integration Example\\n * Shows how to integrate the new component system with demo pages\\n */\\n\\nimport { createLifecycleManager } from './lifecycle-manager.js';\\nimport { createStateManager } from './state-manager.js';\\nimport { createResilientDemo } from './error-boundaries.js';\\n\\n// Example integration for MediaPipe demo\\nexport const createIntegratedMediaPipeDemo = (config = {}) => {\\n  // Create managers with config overrides\\n  const stateManager = createStateManager({\\n    enableHistory: config.enableHistory ?? true,\\n    enablePersistence: config.enablePersistence ?? true,\\n    persistenceKey: config.persistenceKey ?? 'mediapipe-demo-state'\\n  });\\n\\n  const lifecycleManager = createLifecycleManager({\\n    enableMetrics: config.enableMetrics ?? true,\\n    timeout: config.timeout ?? 10000\\n  });\\n\\n\\n  // Define component factories with error handling\\n  const createCameraComponent = createResilientDemo(async (componentConfig) => {\\n    const camera = {\\n      stream: null,\\n      isActive: false,\\n      \\n      async initialize() {\\n        try {\\n          if (!navigator.mediaDevices?.getUserMedia) {\\n            throw new Error('Camera API not supported');\\n          }\\n          console.log('📸 Camera component initialized');\\n          return true;\\n        } catch (error) {\\n          console.error('Camera initialization failed:', error);\\n          throw error;\\n        }\\n      },\\n\\n      async start() {\\n        try {\\n          this.stream = await navigator.mediaDevices.getUserMedia({\\n            video: { \\n              width: componentConfig?.video?.width || 640, \\n              height: componentConfig?.video?.height || 480 \\n            }\\n          });\\n          this.isActive = true;\\n          stateManager.setState('camera.active', true);\\n          console.log('📸 Camera started');\\n          return this.stream;\\n        } catch (error) {\\n          stateManager.setState('camera.error', error.message);\\n          throw error;\\n        }\\n      },\\n\\n      async stop() {\\n        if (this.stream) {\\n          this.stream.getTracks().forEach(track => track.stop());\\n          this.stream = null;\\n        }\\n        this.isActive = false;\\n        stateManager.setState('camera.active', false);\\n        console.log('📸 Camera stopped');\\n      },\\n\\n      async cleanup() {\\n        await this.stop();\\n        console.log('📸 Camera cleaned up');\\n      }\\n    };\\n\\n    return camera;\\n  }, {\\n    name: 'CameraComponent',\\n    severity: 'high'\\n  });\\n\\n  const createMediaPipeComponent = createResilientDemo(async (componentConfig) => {\\n    const mediapipe = {\\n      faceMesh: null,\\n      isProcessing: false,\\n      \\n      async initialize() {\\n        try {\\n          // In real implementation, this would initialize MediaPipe\\n          console.log('🔍 MediaPipe component initialized');\\n          stateManager.setState('mediapipe.ready', true);\\n          return true;\\n        } catch (error) {\\n          stateManager.setState('mediapipe.error', error.message);\\n          throw error;\\n        }\\n      },\\n\\n      async start() {\\n        this.isProcessing = true;\\n        stateManager.setState('mediapipe.processing', true);\\n        console.log('🔍 MediaPipe started');\\n      },\\n\\n      async process(videoFrame) {\\n        if (!this.isProcessing) return null;\\n        \\n        // In a real implementation, we would process the videoFrame\\n        // For now, we're mocking but could log frame info\\n        if (componentConfig?.debug && videoFrame) {\\n          console.log('Processing video frame:', { \\n            timestamp: videoFrame.timestamp || Date.now(),\\n            width: videoFrame.width,\\n            height: videoFrame.height \\n          });\\n        }\\n        \\n        // Mock face detection results\\n        const results = {\\n          landmarks: Array(componentConfig?.landmarkCount || 468).fill().map(() => ({ x: Math.random(), y: Math.random(), z: Math.random() })),\\n          confidence: componentConfig?.confidence || 0.95,\\n          timestamp: Date.now()\\n        };\\n        \\n        stateManager.setState('mediapipe.lastResults', results);\\n        return results;\\n      },\\n\\n      async stop() {\\n        this.isProcessing = false;\\n        stateManager.setState('mediapipe.processing', false);\\n        console.log('🔍 MediaPipe stopped');\\n      },\\n\\n      async cleanup() {\\n        await this.stop();\\n        stateManager.setState('mediapipe.ready', false);\\n        console.log('🔍 MediaPipe cleaned up');\\n      }\\n    };\\n\\n    return mediapipe;\\n  }, {\\n    name: 'MediaPipeComponent',\\n    severity: 'high'\\n  });\\n\\n  const createVisualizationComponent = createResilientDemo(async (componentConfig) => {\\n    const visualization = {\\n      canvas: null,\\n      ctx: null,\\n      \\n      async initialize() {\\n        const canvasId = componentConfig?.canvasId || 'demo-canvas';\\n        this.canvas = document.getElementById(canvasId) || document.createElement('canvas');\\n        this.ctx = this.canvas.getContext('2d');\\n        \\n        if (componentConfig?.canvasSize) {\\n          this.canvas.width = componentConfig.canvasSize.width;\\n          this.canvas.height = componentConfig.canvasSize.height;\\n        }\\n        \\n        console.log('🎨 Visualization component initialized');\\n        return true;\\n      },\\n\\n      async start() {\\n        stateManager.setState('visualization.active', true);\\n        console.log('🎨 Visualization started');\\n      },\\n\\n      async render(landmarks, videoElement) {\\n        if (!this.ctx || !landmarks) return;\\n        \\n        this.ctx.clearRect(0, 0, this.canvas.width, this.canvas.height);\\n        \\n        // Draw video frame if provided\\n        if (videoElement && componentConfig?.showVideo) {\\n          this.ctx.drawImage(videoElement, 0, 0, this.canvas.width, this.canvas.height);\\n        }\\n        \\n        // Draw landmarks\\n        this.ctx.fillStyle = componentConfig?.landmarkColor || 'red';\\n        landmarks.forEach(point => {\\n          this.ctx.fillRect(\\n            point.x * this.canvas.width - 2,\\n            point.y * this.canvas.height - 2,\\n            4, 4\\n          );\\n        });\\n        \\n        stateManager.updateState('visualization.stats', stats => ({\\n          ...stats,\\n          framesRendered: (stats?.framesRendered || 0) + 1,\\n          lastRender: Date.now()\\n        }));\\n      },\\n\\n      async stop() {\\n        stateManager.setState('visualization.active', false);\\n        console.log('🎨 Visualization stopped');\\n      },\\n\\n      async cleanup() {\\n        if (this.ctx) {\\n          this.ctx.clearRect(0, 0, this.canvas.width, this.canvas.height);\\n        }\\n        console.log('🎨 Visualization cleaned up');\\n      }\\n    };\\n\\n    return visualization;\\n  }, {\\n    name: 'VisualizationComponent',\\n    severity: 'medium'\\n  });\\n\\n  // Register components with dependencies\\n  lifecycleManager.registerComponent('camera', createCameraComponent, {\\n    required: true,\\n    autoStart: true\\n  });\\n\\n  lifecycleManager.registerComponent('mediapipe', createMediaPipeComponent, {\\n    dependencies: ['camera'],\\n    required: true,\\n    autoStart: true\\n  });\\n\\n  lifecycleManager.registerComponent('visualization', createVisualizationComponent, {\\n    dependencies: ['mediapipe'],\\n    required: false,\\n    autoStart: true\\n  });\\n\\n  // Add lifecycle hooks\\n  lifecycleManager.addGlobalHook('afterInit', ({ component, state: componentState }) => {\\n    console.log(`✅ ${component} initialized successfully`, componentState);\\n    stateManager.updateState('components.status', status => ({\\n      ...status,\\n      [component]: 'initialized'\\n    }));\\n  });\\n\\n  lifecycleManager.addGlobalHook('onError', ({ component, error }) => {\\n    console.error(`❌ ${component} error:`, error);\\n    stateManager.updateState('components.errors', errors => ({\\n      ...errors,\\n      [component]: { message: error.message, timestamp: Date.now() }\\n    }));\\n  });\\n\\n  // Create main demo controller\\n  const demoController = {\\n    isRunning: false,\\n    animationFrame: null,\\n\\n    async initialize() {\\n      console.log('🚀 Initializing integrated MediaPipe demo...');\\n      \\n      // Initialize state\\n      stateManager.setState('demo.status', 'initializing');\\n      stateManager.setState('components.status', {});\\n      stateManager.setState('components.errors', {});\\n      \\n      try {\\n        const components = await lifecycleManager.initializeAll();\\n        console.log('✅ All components initialized');\\n        stateManager.setState('demo.status', 'ready');\\n        return components;\\n      } catch (error) {\\n        stateManager.setState('demo.status', 'error');\\n        stateManager.setState('demo.error', error.message);\\n        throw error;\\n      }\\n    },\\n\\n    async start() {\\n      if (this.isRunning) return;\\n      \\n      try {\\n        console.log('🚀 Starting demo...');\\n        stateManager.setState('demo.status', 'starting');\\n        \\n        await lifecycleManager.startAll();\\n        \\n        this.isRunning = true;\\n        stateManager.setState('demo.status', 'running');\\n        stateManager.setState('demo.startTime', Date.now());\\n        \\n        // Start processing loop\\n        this.startProcessingLoop();\\n        \\n        console.log('✅ Demo started successfully');\\n      } catch (error) {\\n        stateManager.setState('demo.status', 'error');\\n        stateManager.setState('demo.error', error.message);\\n        throw error;\\n      }\\n    },\\n\\n    startProcessingLoop() {\\n      const processFrame = async () => {\\n        if (!this.isRunning) return;\\n        \\n        try {\\n          const camera = lifecycleManager.getComponent('camera');\\n          const mediapipe = lifecycleManager.getComponent('mediapipe');\\n          const visualization = lifecycleManager.getComponent('visualization');\\n          \\n          if (camera && mediapipe && visualization && camera.stream) {\\n            // Process current video frame\\n            const results = await mediapipe.process(camera.stream);\\n            \\n            if (results) {\\n              await visualization.render(results.landmarks);\\n              \\n              // Update performance metrics\\n              stateManager.updateState('demo.metrics', metrics => ({\\n                ...metrics,\\n                fps: this.calculateFPS(),\\n                processedFrames: (metrics?.processedFrames || 0) + 1,\\n                lastUpdate: Date.now()\\n              }));\\n            }\\n          }\\n        } catch (error) {\\n          console.error('Processing loop error:', error);\\n          stateManager.updateState('demo.processingErrors', count => (count || 0) + 1);\\n        }\\n        \\n        this.animationFrame = requestAnimationFrame(processFrame);\\n      };\\n      \\n      this.animationFrame = requestAnimationFrame(processFrame);\\n    },\\n\\n    calculateFPS() {\\n      const metrics = stateManager.getState('demo.metrics', {});\\n      const now = Date.now();\\n      const lastUpdate = metrics.lastUpdate || now;\\n      const timeDiff = now - lastUpdate;\\n      \\n      return timeDiff > 0 ? Math.round(1000 / timeDiff) : 0;\\n    },\\n\\n    async stop() {\\n      if (!this.isRunning) return;\\n      \\n      console.log('⏹️ Stopping demo...');\\n      this.isRunning = false;\\n      stateManager.setState('demo.status', 'stopping');\\n      \\n      if (this.animationFrame) {\\n        cancelAnimationFrame(this.animationFrame);\\n        this.animationFrame = null;\\n      }\\n      \\n      await lifecycleManager.stopAll();\\n      \\n      stateManager.setState('demo.status', 'stopped');\\n      console.log('✅ Demo stopped');\\n    },\\n\\n    async cleanup() {\\n      await this.stop();\\n      await lifecycleManager.cleanupAll();\\n      stateManager.resetState();\\n      console.log('🧹 Demo cleaned up');\\n    },\\n\\n    getStatus() {\\n      return {\\n        isRunning: this.isRunning,\\n        state: stateManager.getState('demo.status'),\\n        components: lifecycleManager.getStatus(),\\n        metrics: stateManager.getState('demo.metrics', {}),\\n        errors: stateManager.getState('components.errors', {})\\n      };\\n    }\\n  };\\n\\n  // Subscribe to state changes for debugging\\n  stateManager.subscribe('demo.status', (status, oldStatus) => {\\n    console.log(`Demo status: ${oldStatus} → ${status}`);\\n  });\\n\\n  stateManager.subscribe('components.errors', (errors) => {\\n    const errorCount = Object.keys(errors).length;\\n    if (errorCount > 0) {\\n      console.warn(`Component errors detected: ${errorCount}`);\\n    }\\n  });\\n\\n  return demoController;\\n};\\n\\n// Example usage in demo page\\nexport const initializeDemo = async () => {\\n  try {\\n    console.log('🎬 Starting integrated demo initialization...');\\n    \\n    const demo = createIntegratedMediaPipeDemo();\\n    \\n    // Initialize the demo\\n    await demo.initialize();\\n    \\n    // Start the demo\\n    await demo.start();\\n    \\n    console.log('🎉 Demo is now running with enhanced integration!');\\n    \\n    // Return demo controller for manual control\\n    window.demoController = demo;\\n    \\n    return demo;\\n    \\n  } catch (error) {\\n    console.error('❌ Demo initialization failed:', error);\\n    \\n    // Show error to user\\n    const errorElement = document.getElementById('error-display');\\n    if (errorElement) {\\n      errorElement.textContent = `Demo initialization failed: ${error.message}`;\\n      errorElement.style.display = 'block';\\n    }\\n    \\n    throw error;\\n  }\\n};\\n\\n// Auto-initialize when DOM is ready\\nif (typeof document !== 'undefined') {\\n  if (document.readyState === 'loading') {\\n    document.addEventListener('DOMContentLoaded', initializeDemo);\\n  } else {\\n    initializeDemo();\\n  }\\n}\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/examples/shared/error-boundaries.js\",\"messages\":[{\"ruleId\":\"max-lines-per-function\",\"severity\":1,\"message\":\"Arrow function has too many lines (336). Maximum allowed is 200.\",\"line\":24,\"column\":36,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"exceed\",\"endLine\":359,\"endColumn\":2}],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":1,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Error Boundary and Fallback System\\n * Provides comprehensive error handling for demo page components\\n */\\n\\n// Error recovery strategies\\nexport const RecoveryStrategy = {\\n  RETRY: 'retry',\\n  FALLBACK: 'fallback', \\n  GRACEFUL_DEGRADATION: 'graceful_degradation',\\n  USER_INTERVENTION: 'user_intervention',\\n  RESTART: 'restart'\\n};\\n\\n// Error severity levels\\nexport const ErrorSeverity = {\\n  LOW: 'low',\\n  MEDIUM: 'medium',\\n  HIGH: 'high',\\n  CRITICAL: 'critical'\\n};\\n\\n// Create error boundary wrapper for components\\nexport const createErrorBoundary = (config = {}) => {\\n  const state = {\\n    errorHistory: [],\\n    recoveryAttempts: new Map(),\\n    fallbackComponents: new Map(),\\n    errorHandlers: new Map(),\\n    maxRetries: config.maxRetries || 3,\\n    retryDelay: config.retryDelay || 1000,\\n    onError: config.onError || console.error\\n  };\\n\\n  // Wrap a component with error boundary\\n  const wrapComponent = (componentFactory, options = {}) => {\\n    const componentName = options.name || 'UnnamedComponent';\\n    const recoveryStrategy = options.recoveryStrategy || RecoveryStrategy.RETRY;\\n    const fallbackFactory = options.fallback;\\n    const errorSeverity = options.severity || ErrorSeverity.MEDIUM;\\n\\n    return async (config) => {\\n      try {\\n        const component = await componentFactory(config);\\n        return createProtectedComponent(component, {\\n          name: componentName,\\n          recoveryStrategy,\\n          fallbackFactory,\\n          errorSeverity,\\n          ...options\\n        });\\n      } catch (error) {\\n        return handleComponentCreationError(error, {\\n          name: componentName,\\n          fallbackFactory,\\n          config\\n        });\\n      }\\n    };\\n  };\\n\\n  // Create protected component wrapper\\n  const createProtectedComponent = (component, options) => {\\n    const protectedMethods = {};\\n    \\n    // Wrap all component methods with error handling\\n    Object.keys(component).forEach(methodName => {\\n      if (typeof component[methodName] === 'function') {\\n        protectedMethods[methodName] = createProtectedMethod(\\n          component[methodName].bind(component),\\n          methodName,\\n          options\\n        );\\n      } else {\\n        protectedMethods[methodName] = component[methodName];\\n      }\\n    });\\n\\n    // Add error boundary specific methods\\n    protectedMethods.getErrorHistory = () => state.errorHistory.filter(e => e.component === options.name);\\n    protectedMethods.clearErrors = () => {\\n      state.errorHistory = state.errorHistory.filter(e => e.component !== options.name);\\n      state.recoveryAttempts.delete(options.name);\\n    };\\n    protectedMethods.isHealthy = () => {\\n      const recentErrors = state.errorHistory\\n        .filter(e => e.component === options.name)\\n        .filter(e => Date.now() - e.timestamp < 60000); // Last minute\\n      return recentErrors.length === 0;\\n    };\\n\\n    return protectedMethods;\\n  };\\n\\n  // Create protected method wrapper\\n  const createProtectedMethod = (method, methodName, options) => {\\n    return async (...args) => {\\n      const startTime = Date.now();\\n      const attemptKey = `${options.name}:${methodName}`;\\n      \\n      try {\\n        const result = await method(...args);\\n        \\n        // Reset retry count on success\\n        state.recoveryAttempts.delete(attemptKey);\\n        \\n        return result;\\n      } catch (error) {\\n        return handleMethodError(error, {\\n          ...options,\\n          methodName,\\n          attemptKey,\\n          args,\\n          startTime,\\n          method\\n        });\\n      }\\n    };\\n  };\\n\\n  // Handle method execution errors\\n  const handleMethodError = async (error, context) => {\\n    const errorRecord = {\\n      component: context.name,\\n      method: context.methodName,\\n      error: error.message,\\n      stack: error.stack,\\n      timestamp: Date.now(),\\n      severity: context.errorSeverity,\\n      args: context.args\\n    };\\n\\n    state.errorHistory.push(errorRecord);\\n    state.onError(error, context);\\n\\n    // Check retry attempts\\n    const currentAttempts = state.recoveryAttempts.get(context.attemptKey) || 0;\\n    \\n    if (currentAttempts < state.maxRetries && shouldRetry(error, context)) {\\n      return attemptRecovery(error, context, currentAttempts + 1);\\n    }\\n\\n    // Apply fallback strategy\\n    return applyFallbackStrategy(error, context);\\n  };\\n\\n  // Handle component creation errors\\n  const handleComponentCreationError = async (error, context) => {\\n    state.errorHistory.push({\\n      component: context.name,\\n      method: 'constructor',\\n      error: error.message,\\n      timestamp: Date.now(),\\n      severity: ErrorSeverity.HIGH\\n    });\\n\\n    if (context.fallbackFactory) {\\n      console.warn(`Component ${context.name} failed to initialize, using fallback`);\\n      try {\\n        return await context.fallbackFactory(context.config);\\n      } catch (fallbackError) {\\n        console.error(`Fallback for ${context.name} also failed:`, fallbackError);\\n        return createNullComponent(context.name);\\n      }\\n    }\\n\\n    return createNullComponent(context.name);\\n  };\\n\\n  // Determine if error should trigger retry\\n  const shouldRetry = (error, context) => {\\n    // Don't retry certain error types\\n    const nonRetryableErrors = [\\n      'PermissionDeniedError',\\n      'NotSupportedError',\\n      'SecurityError',\\n      'InvalidAccessError'\\n    ];\\n\\n    const errorName = error.name || error.constructor.name;\\n    if (nonRetryableErrors.includes(errorName)) {\\n      return false;\\n    }\\n\\n    // Don't retry critical severity errors\\n    if (context.errorSeverity === ErrorSeverity.CRITICAL) {\\n      return false;\\n    }\\n\\n    return true;\\n  };\\n\\n  // Attempt error recovery\\n  const attemptRecovery = async (error, context, attemptNumber) => {\\n    state.recoveryAttempts.set(context.attemptKey, attemptNumber);\\n    \\n    const delay = state.retryDelay * Math.pow(2, attemptNumber - 1);\\n    console.log(`🔄 Retrying ${context.name}:${context.methodName} (attempt ${attemptNumber}) in ${delay}ms`);\\n    \\n    await new Promise(resolve => setTimeout(resolve, delay));\\n    \\n    // Try to re-execute the method\\n    try {\\n      return await context.method(...context.args);\\n    } catch (retryError) {\\n      // If we've exhausted retries, apply fallback\\n      const currentAttempts = state.recoveryAttempts.get(context.attemptKey) || 0;\\n      if (currentAttempts >= state.maxRetries) {\\n        return applyFallbackStrategy(retryError, context);\\n      } else {\\n        throw retryError;\\n      }\\n    }\\n  };\\n\\n  // Apply fallback strategy based on configuration\\n  const applyFallbackStrategy = (error, context) => {\\n    switch (context.recoveryStrategy) {\\n      case RecoveryStrategy.FALLBACK:\\n        return applyFallbackComponent(error, context);\\n      \\n      case RecoveryStrategy.GRACEFUL_DEGRADATION:\\n        return applyGracefulDegradation(error, context);\\n      \\n      case RecoveryStrategy.USER_INTERVENTION:\\n        return requireUserIntervention(error, context);\\n      \\n      default:\\n        console.error(`${context.name}:${context.methodName} failed after ${state.maxRetries} attempts`);\\n        throw error;\\n    }\\n  };\\n\\n  // Apply fallback component\\n  const applyFallbackComponent = (error, context) => {\\n    const fallbackKey = `${context.name}:${context.methodName}`;\\n    if (state.fallbackComponents.has(fallbackKey)) {\\n      console.log(`Using fallback for ${context.name}:${context.methodName}`);\\n      return state.fallbackComponents.get(fallbackKey);\\n    }\\n    \\n    // Return safe default based on method name\\n    return getSafeDefault(context.methodName);\\n  };\\n\\n  // Apply graceful degradation\\n  const applyGracefulDegradation = (error, context) => {\\n    console.warn(`${context.name}:${context.methodName} degraded due to error:`, error.message);\\n    \\n    // Return degraded functionality based on method type\\n    switch (context.methodName) {\\n      case 'start':\\n      case 'initialize':\\n        return { status: 'degraded', error: error.message };\\n      \\n      case 'process':\\n      case 'analyze':\\n        return { result: null, error: error.message, degraded: true };\\n      \\n      case 'update':\\n        return false; // Skip update\\n      \\n      default:\\n        return null;\\n    }\\n  };\\n\\n  // Require user intervention\\n  const requireUserIntervention = (error, context) => {\\n    const interventionNeeded = {\\n      component: context.name,\\n      method: context.methodName,\\n      error: error.message,\\n      timestamp: Date.now(),\\n      requiresIntervention: true\\n    };\\n\\n    // Emit event for UI to handle\\n    if (typeof window !== 'undefined' && window.dispatchEvent) {\\n      window.dispatchEvent(new CustomEvent('componentInterventionRequired', {\\n        detail: interventionNeeded\\n      }));\\n    }\\n\\n    throw new Error(`User intervention required for ${context.name}:${context.methodName}`);\\n  };\\n\\n  // Get safe default return value\\n  const getSafeDefault = (methodName) => {\\n    const defaults = {\\n      start: false,\\n      stop: true,\\n      initialize: false,\\n      cleanup: true,\\n      process: null,\\n      analyze: { result: null, error: 'Service unavailable' },\\n      update: false,\\n      render: '',\\n      connect: false,\\n      disconnect: true\\n    };\\n\\n    return defaults[methodName] || null;\\n  };\\n\\n  // Create null object component\\n  const createNullComponent = (name) => ({\\n    name: `${name}(null)`,\\n    initialize: () => Promise.resolve(false),\\n    start: () => Promise.resolve(false),\\n    stop: () => Promise.resolve(true),\\n    cleanup: () => Promise.resolve(true),\\n    process: () => Promise.resolve(null),\\n    isHealthy: () => false,\\n    getStatus: () => ({ status: 'failed', message: 'Component failed to initialize' })\\n  });\\n\\n  // Register fallback component for specific method\\n  const registerFallback = (componentName, methodName, fallbackValue) => {\\n    const key = `${componentName}:${methodName}`;\\n    state.fallbackComponents.set(key, fallbackValue);\\n  };\\n\\n  // Get error statistics\\n  const getErrorStats = () => {\\n    const now = Date.now();\\n    const recent = state.errorHistory.filter(e => now - e.timestamp < 300000); // 5 minutes\\n    \\n    const stats = {\\n      total: state.errorHistory.length,\\n      recent: recent.length,\\n      byComponent: {},\\n      bySeverity: {},\\n      recentByComponent: {}\\n    };\\n\\n    state.errorHistory.forEach(error => {\\n      stats.byComponent[error.component] = (stats.byComponent[error.component] || 0) + 1;\\n      stats.bySeverity[error.severity] = (stats.bySeverity[error.severity] || 0) + 1;\\n    });\\n\\n    recent.forEach(error => {\\n      stats.recentByComponent[error.component] = (stats.recentByComponent[error.component] || 0) + 1;\\n    });\\n\\n    return stats;\\n  };\\n\\n  return {\\n    wrapComponent,\\n    registerFallback,\\n    getErrorStats,\\n    getErrorHistory: () => [...state.errorHistory],\\n    clearErrors: () => {\\n      state.errorHistory.length = 0;\\n      state.recoveryAttempts.clear();\\n    }\\n  };\\n};\\n\\n// Default error boundary instance\\nexport const defaultErrorBoundary = createErrorBoundary({\\n  maxRetries: 3,\\n  retryDelay: 1000,\\n  onError: (error, context) => {\\n    console.error(`[${context.name}:${context.methodName}] Error:`, error);\\n  }\\n});\\n\\n// Utility to create resilient demo components\\nexport const createResilientDemo = (demoFactory, options = {}) => {\\n  return defaultErrorBoundary.wrapComponent(demoFactory, {\\n    name: options.name || 'DemoComponent',\\n    recoveryStrategy: RecoveryStrategy.GRACEFUL_DEGRADATION,\\n    severity: ErrorSeverity.MEDIUM,\\n    fallback: options.fallback,\\n    ...options\\n  });\\n};\\n\\n// Global error handler for unhandled promise rejections\\nif (typeof window !== 'undefined') {\\n  window.addEventListener('unhandledrejection', (event) => {\\n    console.error('Unhandled promise rejection:', event.reason);\\n    \\n    // Try to prevent the default browser error handling\\n    event.preventDefault();\\n    \\n    // Emit custom event for demo pages to handle\\n    window.dispatchEvent(new CustomEvent('demoError', {\\n      detail: {\\n        type: 'unhandledRejection',\\n        error: event.reason,\\n        timestamp: Date.now()\\n      }\\n    }));\\n  });\\n\\n  window.addEventListener('error', (event) => {\\n    console.error('Global error:', event.error);\\n    \\n    window.dispatchEvent(new CustomEvent('demoError', {\\n      detail: {\\n        type: 'globalError',\\n        error: event.error,\\n        message: event.message,\\n        filename: event.filename,\\n        lineno: event.lineno,\\n        timestamp: Date.now()\\n      }\\n    }));\\n  });\\n}\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/examples/shared/lifecycle-bulk-operations.js\",\"messages\":[],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/examples/shared/lifecycle-helpers.js\",\"messages\":[],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/examples/shared/lifecycle-manager.js\",\"messages\":[{\"ruleId\":\"max-lines-per-function\",\"severity\":1,\"message\":\"Arrow function has too many lines (423). Maximum allowed is 200.\",\"line\":48,\"column\":39,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"exceed\",\"endLine\":470,\"endColumn\":2},{\"ruleId\":\"consistent-return\",\"severity\":1,\"message\":\"Expected to return a value at the end of async arrow function.\",\"line\":250,\"column\":39,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"missingReturn\",\"endLine\":250,\"endColumn\":41}],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":2,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Enhanced Component Lifecycle Management\\n * Provides comprehensive lifecycle orchestration for demo components\\n */\\n\\nimport { ComponentState } from './component-integration.js';\\nimport { ErrorSeverity, RecoveryStrategy, createErrorBoundary } from './error-boundaries.js';\\nimport { calculateExecutionOrder } from './lifecycle-helpers.js';\\nimport { \\n  createCleanupAllOperation,\\n  createInitializeAllOperation, \\n  createStartAllOperation,\\n  createStopAllOperation\\n} from './lifecycle-bulk-operations.js';\\n\\n// Lifecycle phases\\nexport const LifecyclePhase = {\\n  PRE_INIT: 'pre_init',\\n  INIT: 'init', \\n  POST_INIT: 'post_init',\\n  PRE_START: 'pre_start',\\n  START: 'start',\\n  POST_START: 'post_start',\\n  RUNNING: 'running',\\n  PRE_STOP: 'pre_stop',\\n  STOP: 'stop',\\n  POST_STOP: 'post_stop',\\n  PRE_CLEANUP: 'pre_cleanup',\\n  CLEANUP: 'cleanup',\\n  POST_CLEANUP: 'post_cleanup'\\n};\\n\\n// Lifecycle hooks\\nexport const LifecycleHook = {\\n  BEFORE_INIT: 'beforeInit',\\n  AFTER_INIT: 'afterInit',\\n  BEFORE_START: 'beforeStart', \\n  AFTER_START: 'afterStart',\\n  BEFORE_STOP: 'beforeStop',\\n  AFTER_STOP: 'afterStop',\\n  BEFORE_CLEANUP: 'beforeCleanup',\\n  AFTER_CLEANUP: 'afterCleanup',\\n  ON_ERROR: 'onError',\\n  ON_STATE_CHANGE: 'onStateChange'\\n};\\n\\n// Create enhanced lifecycle manager\\nexport const createLifecycleManager = (config = {}) => {\\n  const state = {\\n    components: new Map(),\\n    lifecycleHooks: new Map(),\\n    dependencyGraph: new Map(),\\n    executionOrder: [],\\n    globalHooks: new Map(),\\n    metrics: {\\n      totalComponents: 0,\\n      successfulInits: 0,\\n      failedInits: 0,\\n      averageInitTime: 0,\\n      totalRuntime: 0\\n    },\\n    options: {\\n      enableMetrics: config.enableMetrics !== false,\\n      enableHooks: config.enableHooks !== false,\\n      strictMode: config.strictMode || false,\\n      timeout: config.timeout || 30000,\\n      ...config\\n    }\\n  };\\n\\n  const errorBoundary = createErrorBoundary({\\n    maxRetries: 3,\\n    retryDelay: 1000,\\n    onError: (error, context) => recordError(error, context)\\n  });\\n\\n  // Register component with lifecycle management\\n  const registerComponent = (name, factory, options = {}) => {\\n    const componentConfig = {\\n      name,\\n      factory,\\n      instance: null,\\n      state: ComponentState.UNINITIALIZED,\\n      dependencies: options.dependencies || [],\\n      hooks: new Map(),\\n      metadata: {\\n        registeredAt: Date.now(),\\n        initTime: null,\\n        startTime: null,\\n        totalRuntime: 0,\\n        restartCount: 0,\\n        errorCount: 0\\n      },\\n      options: {\\n        required: options.required !== false,\\n        timeout: options.timeout || state.options.timeout,\\n        enableMetrics: options.enableMetrics !== false,\\n        autoStart: options.autoStart || false,\\n        restartOnError: options.restartOnError || false,\\n        maxRestarts: options.maxRestarts || 3,\\n        ...options\\n      }\\n    };\\n\\n    // Wrap factory with error boundary\\n    componentConfig.factory = errorBoundary.wrapComponent(factory, {\\n      name,\\n      severity: options.required ? ErrorSeverity.HIGH : ErrorSeverity.MEDIUM,\\n      recoveryStrategy: RecoveryStrategy.GRACEFUL_DEGRADATION\\n    });\\n\\n    state.components.set(name, componentConfig);\\n    state.metrics.totalComponents++;\\n\\n    // Register component-specific hooks\\n    Object.values(LifecycleHook).forEach(hook => {\\n      if (options[hook]) {\\n        addComponentHook(name, hook, options[hook]);\\n      }\\n    });\\n\\n    console.log(`📦 Registered component: ${name} (${componentConfig.options.required ? 'required' : 'optional'})`);\\n    return componentConfig;\\n  };\\n\\n  // Add lifecycle hook for specific component\\n  const addComponentHook = (componentName, hook, callback) => {\\n    const component = state.components.get(componentName);\\n    if (!component) {\\n      throw new Error(`Component ${componentName} not found`);\\n    }\\n\\n    if (!component.hooks.has(hook)) {\\n      component.hooks.set(hook, []);\\n    }\\n    component.hooks.get(hook).push(callback);\\n  };\\n\\n  // Add global lifecycle hook\\n  const addGlobalHook = (hook, callback) => {\\n    if (!state.globalHooks.has(hook)) {\\n      state.globalHooks.set(hook, []);\\n    }\\n    state.globalHooks.get(hook).push(callback);\\n  };\\n\\n  // Execute hooks for component\\n  const executeHooks = async (componentName, hook, context = {}) => {\\n    if (!state.options.enableHooks) return;\\n\\n    const component = state.components.get(componentName);\\n    const hooks = [];\\n\\n    // Add global hooks\\n    if (state.globalHooks.has(hook)) {\\n      hooks.push(...state.globalHooks.get(hook));\\n    }\\n\\n    // Add component-specific hooks\\n    if (component?.hooks.has(hook)) {\\n      hooks.push(...component.hooks.get(hook));\\n    }\\n\\n    // Execute hooks in sequence\\n    for (const hookCallback of hooks) {\\n      try {\\n        await hookCallback({\\n          component: componentName,\\n          hook,\\n          state: component?.state,\\n          instance: component?.instance,\\n          ...context\\n        });\\n      } catch (error) {\\n        console.error(`Hook ${hook} failed for ${componentName}:`, error);\\n        if (state.options.strictMode) {\\n          throw error;\\n        }\\n      }\\n    }\\n  };\\n\\n  // Initialize component with full lifecycle\\n  const initializeComponent = async (name) => {\\n    const component = state.components.get(name);\\n    if (!component) {\\n      throw new Error(`Component ${name} not found`);\\n    }\\n\\n    if (component.state >= ComponentState.INITIALIZED) {\\n      return component.instance;\\n    }\\n\\n    const startTime = Date.now();\\n\\n    try {\\n      // Pre-initialization phase\\n      await executeHooks(name, LifecycleHook.BEFORE_INIT, { phase: LifecyclePhase.PRE_INIT });\\n      updateComponentState(component, ComponentState.INITIALIZING);\\n\\n      // Check dependencies\\n      await ensureDependencies(name);\\n\\n      // Initialize with timeout\\n      const initPromise = component.factory(component.options.config || {});\\n      const timeoutPromise = new Promise((_, reject) => \\n        setTimeout(() => reject(new Error(`Initialization timeout for ${name}`)), component.options.timeout)\\n      );\\n\\n      component.instance = await Promise.race([initPromise, timeoutPromise]);\\n\\n      // Call component's initialize method if available\\n      if (component.instance?.initialize) {\\n        await component.instance.initialize();\\n      }\\n\\n      // Post-initialization phase\\n      updateComponentState(component, ComponentState.INITIALIZED);\\n      component.metadata.initTime = Date.now() - startTime;\\n      state.metrics.successfulInits++;\\n\\n      await executeHooks(name, LifecycleHook.AFTER_INIT, { \\n        phase: LifecyclePhase.POST_INIT,\\n        initTime: component.metadata.initTime\\n      });\\n\\n      // Auto-start if configured\\n      if (component.options.autoStart) {\\n        await startComponent(name);\\n      }\\n\\n      console.log(`✅ Initialized ${name} in ${component.metadata.initTime}ms`);\\n      return component.instance;\\n\\n    } catch (error) {\\n      state.metrics.failedInits++;\\n      component.metadata.errorCount++;\\n      recordError(error, { component: name, phase: 'initialization' });\\n\\n      if (component.options.required) {\\n        throw error;\\n      }\\n\\n      console.warn(`⚠️ Optional component ${name} failed to initialize:`, error.message);\\n      return null;\\n    }\\n  };\\n\\n  // Start component with lifecycle hooks\\n  const startComponent = async (name) => {\\n    const component = state.components.get(name);\\n    if (!component?.instance) {\\n      throw new Error(`Component ${name} not initialized`);\\n    }\\n\\n    if (component.state === ComponentState.RUNNING) {\\n      return component.instance;\\n    }\\n\\n    try {\\n      await executeHooks(name, LifecycleHook.BEFORE_START, { phase: LifecyclePhase.PRE_START });\\n      updateComponentState(component, ComponentState.STARTING);\\n\\n      const startTime = Date.now();\\n      \\n      if (component.instance.start) {\\n        await component.instance.start();\\n      }\\n\\n      updateComponentState(component, ComponentState.RUNNING);\\n      component.metadata.startTime = startTime;\\n\\n      await executeHooks(name, LifecycleHook.AFTER_START, { phase: LifecyclePhase.POST_START });\\n\\n      console.log(`🚀 Started ${name}`);\\n      return component.instance;\\n\\n    } catch (error) {\\n      component.metadata.errorCount++;\\n      \\n      if (component.options.restartOnError && \\n          component.metadata.restartCount < component.options.maxRestarts) {\\n        await attemptRestart(name);\\n      } else {\\n        updateComponentState(component, ComponentState.ERROR);\\n        throw error;\\n      }\\n    }\\n  };\\n\\n  // Stop component with lifecycle hooks\\n  const stopComponent = async (name) => {\\n    const component = state.components.get(name);\\n    if (!component?.instance) {\\n      return;\\n    }\\n\\n    try {\\n      await executeHooks(name, LifecycleHook.BEFORE_STOP, { phase: LifecyclePhase.PRE_STOP });\\n      updateComponentState(component, ComponentState.STOPPING);\\n\\n      if (component.instance.stop) {\\n        await component.instance.stop();\\n      }\\n\\n      // Update runtime metrics\\n      if (component.metadata.startTime) {\\n        const runtime = Date.now() - component.metadata.startTime;\\n        component.metadata.totalRuntime += runtime;\\n        state.metrics.totalRuntime += runtime;\\n      }\\n\\n      updateComponentState(component, ComponentState.STOPPED);\\n      await executeHooks(name, LifecycleHook.AFTER_STOP, { phase: LifecyclePhase.POST_STOP });\\n\\n      console.log(`⏹️ Stopped ${name}`);\\n\\n    } catch (error) {\\n      console.error(`Error stopping ${name}:`, error);\\n      updateComponentState(component, ComponentState.ERROR);\\n    }\\n  };\\n\\n  // Cleanup component with lifecycle hooks\\n  const cleanupComponent = async (name) => {\\n    const component = state.components.get(name);\\n    if (!component) return;\\n\\n    try {\\n      await executeHooks(name, LifecycleHook.BEFORE_CLEANUP, { phase: LifecyclePhase.PRE_CLEANUP });\\n\\n      if (component.instance?.cleanup) {\\n        await component.instance.cleanup();\\n      }\\n\\n      component.instance = null;\\n      updateComponentState(component, ComponentState.UNINITIALIZED);\\n\\n      await executeHooks(name, LifecycleHook.AFTER_CLEANUP, { phase: LifecyclePhase.POST_CLEANUP });\\n\\n      console.log(`🧹 Cleaned up ${name}`);\\n\\n    } catch (error) {\\n      console.error(`Error cleaning up ${name}:`, error);\\n    }\\n  };\\n\\n  // Restart component\\n  const restartComponent = async (name) => {\\n    await stopComponent(name);\\n    await cleanupComponent(name);\\n    await initializeComponent(name);\\n    return startComponent(name);\\n  };\\n\\n  // Attempt automatic restart\\n  const attemptRestart = async (name) => {\\n    const component = state.components.get(name);\\n    component.metadata.restartCount++;\\n\\n    console.log(`🔄 Restarting ${name} (attempt ${component.metadata.restartCount})`);\\n\\n    try {\\n      await restartComponent(name);\\n      console.log(`✅ Successfully restarted ${name}`);\\n    } catch (error) {\\n      console.error(`❌ Failed to restart ${name}:`, error);\\n      updateComponentState(component, ComponentState.ERROR);\\n    }\\n  };\\n\\n  // Ensure dependencies are ready\\n  const ensureDependencies = async (componentName) => {\\n    const component = state.components.get(componentName);\\n    \\n    for (const depName of component.dependencies) {\\n      const dependency = state.components.get(depName);\\n      \\n      if (!dependency) {\\n        throw new Error(`Dependency ${depName} not found for ${componentName}`);\\n      }\\n      \\n      if (dependency.state < ComponentState.INITIALIZED) {\\n        await initializeComponent(depName);\\n      }\\n    }\\n  };\\n\\n  // Update component state with notifications\\n  const updateComponentState = (component, newState) => {\\n    const oldState = component.state;\\n    component.state = newState;\\n\\n    executeHooks(component.name, LifecycleHook.ON_STATE_CHANGE, {\\n      oldState,\\n      newState,\\n      timestamp: Date.now()\\n    }).catch(error => console.error('State change hook error:', error));\\n  };\\n\\n  // Record error for metrics\\n  const recordError = (error, context) => {\\n    const component = state.components.get(context.component);\\n    if (component) {\\n      component.metadata.errorCount++;\\n    }\\n\\n    executeHooks(context.component, LifecycleHook.ON_ERROR, {\\n      error,\\n      context,\\n      timestamp: Date.now()\\n    }).catch(hookError => console.error('Error hook failed:', hookError));\\n  };\\n\\n  // Initialize all components in dependency order\\n  const initializeAll = createInitializeAllOperation(state, initializeComponent);\\n\\n  // Start all initialized components\\n  const startAll = createStartAllOperation(state, startComponent);\\n\\n  // Stop all running components\\n  const stopAll = createStopAllOperation(state, stopComponent);\\n\\n  // Cleanup all components\\n  const cleanupAll = createCleanupAllOperation(state, cleanupComponent);\\n\\n  // Calculate execution order based on dependencies\\n  const getExecutionOrder = () => {\\n    if (state.executionOrder.length === 0) {\\n      state.executionOrder = calculateExecutionOrder(state.components);\\n    }\\n    return state.executionOrder;\\n  };\\n\\n\\n  // Get comprehensive status\\n  const getStatus = () => ({\\n    components: Object.fromEntries(\\n      [...state.components.entries()].map(([name, comp]) => [\\n        name,\\n        {\\n          state: comp.state,\\n          metadata: comp.metadata,\\n          isRequired: comp.options.required,\\n          dependencies: comp.dependencies\\n        }\\n      ])\\n    ),\\n    metrics: { ...state.metrics },\\n    executionOrder: getExecutionOrder()\\n  });\\n\\n  return {\\n    registerComponent,\\n    addComponentHook,\\n    addGlobalHook,\\n    initializeComponent,\\n    startComponent,\\n    stopComponent,\\n    cleanupComponent,\\n    restartComponent,\\n    initializeAll,\\n    startAll,\\n    stopAll,\\n    cleanupAll,\\n    getStatus,\\n    getComponent: (name) => state.components.get(name)?.instance,\\n    getComponentState: (name) => state.components.get(name)?.state || ComponentState.UNINITIALIZED\\n  };\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/examples/shared/lifecycle-operations.js\",\"messages\":[],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/examples/shared/state-helpers.js\",\"messages\":[],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/examples/shared/state-manager.js\",\"messages\":[],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/examples/shared/state-operations.js\",\"messages\":[{\"ruleId\":\"max-params\",\"severity\":1,\"message\":\"Arrow function has too many parameters (7). Maximum allowed is 6.\",\"line\":24,\"column\":3,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"exceed\",\"endLine\":24,\"endColumn\":5},{\"ruleId\":\"max-params\",\"severity\":1,\"message\":\"Arrow function has too many parameters (7). Maximum allowed is 6.\",\"line\":85,\"column\":3,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"exceed\",\"endLine\":85,\"endColumn\":5},{\"ruleId\":\"max-params\",\"severity\":1,\"message\":\"Arrow function has too many parameters (7). Maximum allowed is 6.\",\"line\":205,\"column\":3,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"exceed\",\"endLine\":205,\"endColumn\":5}],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":3,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * State Manager Operations\\n * Core state operations extracted for better organization\\n */\\n\\n// State update types\\nexport const StateUpdateType = {\\n  SET: 'set',\\n  UPDATE: 'update',\\n  DELETE: 'delete',\\n  BATCH: 'batch',\\n  ASYNC: 'async'\\n};\\n\\n// Create setState operation\\nexport const createSetOperation = (\\n  store, \\n  historyManager, \\n  subscriptionManager, \\n  persistenceManager, \\n  timerManager,\\n  applyMiddlewares,\\n  options = {}\\n) => (key, value, operationOptions = {}) => {\\n  const oldValue = store.get(key);\\n  const updateType = StateUpdateType.SET;\\n  \\n  // Apply middlewares\\n  const context = { key, value, oldValue, type: updateType, options: operationOptions };\\n  const processedValue = applyMiddlewares(context);\\n  \\n  // Update store\\n  store.set(key, processedValue);\\n  \\n  // Add to history\\n  if (options.enableHistory) {\\n    historyManager.push({\\n      type: updateType,\\n      key,\\n      oldValue,\\n      newValue: processedValue,\\n      options: operationOptions\\n    });\\n  }\\n  \\n  // Notify subscribers\\n  subscriptionManager.notify(key, {\\n    key,\\n    value: processedValue,\\n    oldValue,\\n    type: updateType\\n  });\\n  \\n  // Global notification\\n  subscriptionManager.notifyAll({\\n    key,\\n    value: processedValue,\\n    oldValue,\\n    type: updateType\\n  });\\n  \\n  // Persist if enabled\\n  if (options.enablePersistence) {\\n    if (operationOptions.debounce) {\\n      timerManager.debounce(`persist-${key}`, () => {\\n        persistenceManager.save(Object.fromEntries(store));\\n      }, options.debounceDelay || 100);\\n    } else {\\n      persistenceManager.save(Object.fromEntries(store));\\n    }\\n  }\\n  \\n  return processedValue;\\n};\\n\\n// Create updateState operation\\nexport const createUpdateOperation = (\\n  store,\\n  historyManager,\\n  subscriptionManager,\\n  persistenceManager,\\n  timerManager,\\n  applyMiddlewares,\\n  options = {}\\n) => (key, updater, operationOptions = {}) => {\\n  const oldValue = store.get(key);\\n  \\n  if (typeof updater !== 'function') {\\n    throw new Error('Updater must be a function');\\n  }\\n  \\n  const newValue = updater(oldValue);\\n  const updateType = StateUpdateType.UPDATE;\\n  \\n  // Apply middlewares\\n  const context = { key, value: newValue, oldValue, type: updateType, options: operationOptions };\\n  const processedValue = applyMiddlewares(context);\\n  \\n  // Update store\\n  store.set(key, processedValue);\\n  \\n  // Add to history\\n  if (options.enableHistory) {\\n    historyManager.push({\\n      type: updateType,\\n      key,\\n      oldValue,\\n      newValue: processedValue,\\n      updater: updater.toString(),\\n      options: operationOptions\\n    });\\n  }\\n  \\n  // Notify subscribers\\n  subscriptionManager.notify(key, {\\n    key,\\n    value: processedValue,\\n    oldValue,\\n    type: updateType\\n  });\\n  \\n  // Global notification\\n  subscriptionManager.notifyAll({\\n    key,\\n    value: processedValue,\\n    oldValue,\\n    type: updateType\\n  });\\n  \\n  // Persist if enabled\\n  if (options.enablePersistence) {\\n    if (operationOptions.debounce) {\\n      timerManager.debounce(`persist-${key}`, () => {\\n        persistenceManager.save(Object.fromEntries(store));\\n      }, options.debounceDelay || 100);\\n    } else {\\n      persistenceManager.save(Object.fromEntries(store));\\n    }\\n  }\\n  \\n  return processedValue;\\n};\\n\\n// Create deleteState operation\\nexport const createDeleteOperation = (\\n  store,\\n  historyManager,\\n  subscriptionManager,\\n  persistenceManager,\\n  timerManager,\\n  options = {}\\n) => (key) => {\\n  const oldValue = store.get(key);\\n  const existed = store.has(key);\\n  \\n  if (!existed) return false;\\n  \\n  store.delete(key);\\n  \\n  // Add to history\\n  if (options.enableHistory) {\\n    historyManager.push({\\n      type: StateUpdateType.DELETE,\\n      key,\\n      oldValue,\\n      newValue: undefined\\n    });\\n  }\\n  \\n  // Notify subscribers\\n  subscriptionManager.notify(key, {\\n    key,\\n    value: undefined,\\n    oldValue,\\n    type: StateUpdateType.DELETE\\n  });\\n  \\n  // Global notification\\n  subscriptionManager.notifyAll({\\n    key,\\n    value: undefined,\\n    oldValue,\\n    type: StateUpdateType.DELETE\\n  });\\n  \\n  // Persist if enabled\\n  if (options.enablePersistence) {\\n    timerManager.debounce('persist-delete', () => {\\n      persistenceManager.save(Object.fromEntries(store));\\n    }, options.debounceDelay || 100);\\n  }\\n  \\n  return true;\\n};\\n\\n// Create batch operations\\nexport const createBatchOperations = (\\n  store,\\n  historyManager,\\n  subscriptionManager,\\n  persistenceManager,\\n  timerManager,\\n  applyMiddlewares,\\n  options = {}\\n) => ({\\n  batchSet: (updates) => {\\n    const changes = [];\\n    \\n    for (const [key, value] of Object.entries(updates)) {\\n      const oldValue = store.get(key);\\n      const context = { key, value, oldValue, type: StateUpdateType.BATCH };\\n      const processedValue = applyMiddlewares(context);\\n      \\n      store.set(key, processedValue);\\n      changes.push({ key, oldValue, newValue: processedValue });\\n    }\\n    \\n    // Add to history\\n    if (options.enableHistory) {\\n      historyManager.push({\\n        type: StateUpdateType.BATCH,\\n        changes,\\n        count: changes.length\\n      });\\n    }\\n    \\n    // Notify all affected subscribers\\n    for (const change of changes) {\\n      subscriptionManager.notify(change.key, {\\n        key: change.key,\\n        value: change.newValue,\\n        oldValue: change.oldValue,\\n        type: StateUpdateType.BATCH\\n      });\\n    }\\n    \\n    // Global notification\\n    subscriptionManager.notifyAll({\\n      type: StateUpdateType.BATCH,\\n      changes\\n    });\\n    \\n    // Persist if enabled\\n    if (options.enablePersistence) {\\n      persistenceManager.save(Object.fromEntries(store));\\n    }\\n    \\n    return changes;\\n  },\\n  \\n  batchUpdate: (updates) => {\\n    const changes = [];\\n    \\n    for (const [key, updater] of Object.entries(updates)) {\\n      if (typeof updater !== 'function') continue;\\n      \\n      const oldValue = store.get(key);\\n      const newValue = updater(oldValue);\\n      const context = { key, value: newValue, oldValue, type: StateUpdateType.BATCH };\\n      const processedValue = applyMiddlewares(context);\\n      \\n      store.set(key, processedValue);\\n      changes.push({ key, oldValue, newValue: processedValue });\\n    }\\n    \\n    // Add to history\\n    if (options.enableHistory) {\\n      historyManager.push({\\n        type: StateUpdateType.BATCH,\\n        changes,\\n        count: changes.length\\n      });\\n    }\\n    \\n    // Notify all affected subscribers\\n    for (const change of changes) {\\n      subscriptionManager.notify(change.key, {\\n        key: change.key,\\n        value: change.newValue,\\n        oldValue: change.oldValue,\\n        type: StateUpdateType.BATCH\\n      });\\n    }\\n    \\n    // Global notification\\n    subscriptionManager.notifyAll({\\n      type: StateUpdateType.BATCH,\\n      changes\\n    });\\n    \\n    // Persist if enabled\\n    if (options.enablePersistence) {\\n      persistenceManager.save(Object.fromEntries(store));\\n    }\\n    \\n    return changes;\\n  }\\n});\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/examples/tutorials/simple-neon-app.js\",\"messages\":[{\"ruleId\":\"prefer-destructuring\",\"severity\":1,\"message\":\"Use array destructuring.\",\"line\":72,\"column\":15,\"nodeType\":\"VariableDeclarator\",\"messageId\":\"preferDestructuring\",\"endLine\":72,\"endColumn\":41},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":140,\"column\":16,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":140,\"endColumn\":17},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":140,\"column\":46,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":140,\"endColumn\":47},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":141,\"column\":16,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":141,\"endColumn\":17},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":141,\"column\":46,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":141,\"endColumn\":47},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":142,\"column\":26,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":142,\"endColumn\":27},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":142,\"column\":42,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":142,\"endColumn\":43},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":159,\"column\":25,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":159,\"endColumn\":26},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":159,\"column\":41,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":159,\"endColumn\":42}],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":9,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"#!/usr/bin/env node\\n/**\\n * SIMPLE NEON EYE TRACKER APP\\n * This is the actual application you would run\\n */\\n\\nimport { createDistributionConfigManager, createDistributionSessionManager } from '../../src/core/distribution/index.js';\\n\\n// ==============================================================================\\n// THIS IS YOUR ACTUAL APPLICATION\\n// You would save this as \\\"neon-app.js\\\" and run it with: node neon-app.js\\n// ==============================================================================\\n\\nclass NeonApp {\\n  constructor() {\\n    this.sessionManager = createDistributionSessionManager();\\n    this.configManager = createDistributionConfigManager();\\n    this.session = null;\\n  }\\n\\n  /**\\n   * Start the application\\n   */\\n  async start() {\\n    console.log('Starting Neon Eye Tracker Application\\\\n');\\n    \\n    // =========================================================================\\n    // WHERE CONFIGS LIVE - OPTION 1: External JSON file\\n    // =========================================================================\\n    \\n    // Check if config file exists\\n    const configFile = './neon-config.json';\\n    let config;\\n    \\n    const configExists = await Bun.file(configFile).exists();\\n    \\n    if (configExists) {\\n      // Load from file using Bun.file()\\n      console.log(`📋 Loading config from ${configFile}`);\\n      config = await Bun.file(configFile).json();\\n    } else {\\n      // Use default config\\n      console.log('📋 Using default configuration');\\n      config = this.getDefaultConfig();\\n      \\n      // Save it for next time using Bun.write()\\n      await Bun.write(configFile, JSON.stringify(config, null, 2));\\n      console.log(`💾 Saved config to ${configFile} for future use\\\\n`);\\n    }\\n    \\n    // =========================================================================\\n    // WHERE CONFIGS LIVE - OPTION 2: Override with environment variables\\n    // =========================================================================\\n    \\n    if (process.env.MQTT_BROKER) {\\n      console.log(`🔄 Overriding MQTT broker from environment: ${process.env.MQTT_BROKER}`);\\n      config.distributors.mqtt.broker = process.env.MQTT_BROKER;\\n    }\\n    \\n    if (process.env.PARTICIPANT_ID) {\\n      console.log(`🔄 Setting participant ID from environment: ${process.env.PARTICIPANT_ID}`);\\n      config.distributors.mqtt.clientId = `neon-${process.env.PARTICIPANT_ID}`;\\n    }\\n    \\n    // =========================================================================\\n    // WHERE CONFIGS LIVE - OPTION 3: Command line arguments\\n    // =========================================================================\\n    \\n    const args = process.argv.slice(2);\\n    for (const arg of args) {\\n      if (arg.startsWith('--mqtt-broker=')) {\\n        const broker = arg.split('=')[1];\\n        console.log(`🔄 Overriding MQTT broker from CLI: ${broker}`);\\n        config.distributors.mqtt.broker = broker;\\n      }\\n      if (arg.startsWith('--websocket-port=')) {\\n        const port = parseInt(arg.split('=')[1]);\\n        console.log(`🔄 Setting WebSocket port from CLI: ${port}`);\\n        config.distributors.websocket.port = port;\\n      }\\n    }\\n    \\n    // Create the session with final config\\n    console.log('\\\\n📡 Final Configuration:');\\n    console.log(`   MQTT Broker: ${config.distributors.mqtt.broker}`);\\n    console.log(`   Client ID: ${config.distributors.mqtt.clientId}`);\\n    console.log(`   WebSocket Port: ${config.distributors.websocket?.port || 'disabled'}`);\\n    console.log(`   HTTP Endpoint: ${config.distributors.http?.baseUrl || 'disabled'}`);\\n    console.log('');\\n    \\n    const sessionConfig = this.configManager.createSessionConfig(config);\\n    this.session = await this.sessionManager.createSession('neon-session', sessionConfig);\\n    \\n    console.log('✅ Application ready to receive Neon data\\\\n');\\n    \\n    // Start processing Neon data\\n    this.startNeonProcessing();\\n  }\\n\\n  /**\\n   * Default configuration (NOT hardcoded - this is just the fallback)\\n   */\\n  getDefaultConfig() {\\n    return {\\n      distributors: {\\n        mqtt: {\\n          broker: 'mqtt://localhost:1883',\\n          clientId: 'neon-default',\\n          topics: {\\n            gaze: 'eyetracking/gaze',\\n            events: 'eyetracking/events'\\n          }\\n        },\\n        websocket: {\\n          port: 8080,\\n          compression: true\\n        }\\n      },\\n      eventRouting: {\\n        'gaze': ['mqtt', 'websocket'],\\n        'fixation': ['mqtt'],\\n        'blink': ['mqtt']\\n      }\\n    };\\n  }\\n\\n  /**\\n   * This simulates receiving and processing Neon data\\n   */\\n  startNeonProcessing() {\\n    console.log('👁️ Processing Neon eye tracker data...\\\\n');\\n    \\n    // In a real app, this would be your Neon SDK connection\\n    // For demo, we'll simulate data\\n    let sampleCount = 0;\\n    \\n    setInterval(async () => {\\n      // Simulated Neon data\\n      const gazeData = {\\n        x: 0.5 + Math.sin(Date.now() / 1000) * 0.3,\\n        y: 0.5 + Math.cos(Date.now() / 1000) * 0.3,\\n        confidence: 0.85 + Math.random() * 0.15,\\n        timestamp: Date.now()\\n      };\\n      \\n      // Send to configured distributors\\n      await this.sessionManager.routeEvent('neon-session', 'gaze', gazeData);\\n      \\n      sampleCount++;\\n      if (sampleCount % 20 === 0) {\\n        console.log(`📊 Processed ${sampleCount} gaze samples`);\\n      }\\n      \\n      // Occasionally send events\\n      if (Math.random() < 0.05) {\\n        await this.sessionManager.routeEvent('neon-session', 'fixation', {\\n          x: gazeData.x,\\n          y: gazeData.y,\\n          duration: 200 + Math.random() * 300,\\n          timestamp: Date.now()\\n        });\\n        console.log('🎯 Fixation detected');\\n      }\\n      \\n    }, 50); // 20Hz\\n  }\\n\\n  /**\\n   * Shutdown gracefully\\n   */\\n  async shutdown() {\\n    console.log('\\\\n🛑 Shutting down...');\\n    await this.sessionManager.cleanup();\\n    process.exit(0);\\n  }\\n}\\n\\n// ==============================================================================\\n// RUN THE APPLICATION\\n// ==============================================================================\\n\\nconst app = new NeonApp();\\n\\n// Start the app\\napp.start().catch(error => {\\n  console.error('❌ Failed to start:', error);\\n  process.exit(1);\\n});\\n\\n// Handle shutdown\\nprocess.on('SIGINT', () => {\\n  app.shutdown();\\n});\\n\\n// ==============================================================================\\n// HOW TO RUN THIS APPLICATION:\\n// ==============================================================================\\n\\nconsole.log(`\\n================================================================================\\nNEON EYE TRACKER APPLICATION\\n\\nThis is YOUR application that bridges Neon data to distribution systems.\\n\\nHOW TO RUN:\\n-----------\\n1. Basic:\\n   $ node simple-neon-app.js\\n\\n2. With custom MQTT broker:\\n   $ node simple-neon-app.js --mqtt-broker=mqtt://my-broker.local:1883\\n\\n3. With environment variables:\\n   $ MQTT_BROKER=mqtt://lab.local:1883 PARTICIPANT_ID=P001 node simple-neon-app.js\\n\\n4. Edit neon-config.json to change settings permanently\\n\\nWHERE CONFIGS LIVE:\\n-------------------\\n1. ./neon-config.json (created automatically on first run)\\n2. Environment variables (override file config)\\n3. Command line arguments (override everything)\\n\\nThe config is NOT hardcoded - it's loaded at runtime from these sources!\\n================================================================================\\n`);\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/browser-speech-client.js\",\"messages\":[{\"ruleId\":\"max-lines-per-function\",\"severity\":1,\"message\":\"Arrow function has too many lines (302). Maximum allowed is 150.\",\"line\":11,\"column\":42,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"exceed\",\"endLine\":428,\"endColumn\":2},{\"ruleId\":\"func-style\",\"severity\":1,\"message\":\"Expected a function expression.\",\"line\":46,\"column\":3,\"nodeType\":\"FunctionDeclaration\",\"messageId\":\"expression\",\"endLine\":48,\"endColumn\":4},{\"ruleId\":\"prefer-destructuring\",\"severity\":1,\"message\":\"Use array destructuring.\",\"line\":88,\"column\":15,\"nodeType\":\"VariableDeclarator\",\"messageId\":\"preferDestructuring\",\"endLine\":88,\"endColumn\":39}],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":3,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Browser Speech Client\\n * Handles Web Speech API for transcription and sends text to server for analysis\\n * Following functional programming patterns with factory functions\\n */\\n\\nimport { createDevValidator } from './shared/utils/url-validator.js';\\nimport { createLogger } from './shared/utils/logger.js';\\n\\n// Create browser speech client factory\\nexport const createBrowserSpeechClient = (config = {}) => {\\n  const logger = createLogger({ level: config.logLevel });\\n  \\n  const state = {\\n    recognition: null,\\n    isListening: false,\\n    serverUrl: config.serverUrl || (process.env.SPEECH_SERVER_URL || 'http://localhost:3000/api/analyze'),\\n    sessionId: config.sessionId || generateSessionId(),\\n    \\n    // Configuration\\n    config: {\\n      language: config.language || 'en-US',\\n      continuous: config.continuous !== false,\\n      interimResults: config.interimResults !== false,\\n      maxAlternatives: config.maxAlternatives || 1,\\n      sendInterimResults: config.sendInterimResults || false,\\n      batchSize: config.batchSize || 5, // Batch text chunks before sending\\n      batchTimeout: config.batchTimeout || 2000, // Send batch after 2 seconds\\n      ...config\\n    },\\n    \\n    // Text batching\\n    textBatch: [],\\n    batchTimer: null,\\n    \\n    // Callbacks\\n    callbacks: {\\n      onTranscript: [],\\n      onAnalysis: [],\\n      onError: [],\\n      onStatusChange: []\\n    }\\n  };\\n\\n  // Generate session ID\\n  function generateSessionId() {\\n    return `session_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;\\n  }\\n\\n  // Initialize Web Speech API\\n  const initialize = () => {\\n    // Validate server URL for security\\n    const urlValidator = createDevValidator();\\n    const validation = urlValidator.validate(state.serverUrl);\\n    \\n    if (!validation.valid) {\\n      throw new Error(`Invalid server URL: ${validation.error}`);\\n    }\\n    \\n    // Check for Web Speech API support\\n    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\\n    \\n    if (!SpeechRecognition) {\\n      throw new Error('Web Speech API not supported in this browser');\\n    }\\n\\n    // Create recognition instance\\n    state.recognition = new SpeechRecognition();\\n    state.recognition.lang = state.config.language;\\n    state.recognition.continuous = state.config.continuous;\\n    state.recognition.interimResults = state.config.interimResults;\\n    state.recognition.maxAlternatives = state.config.maxAlternatives;\\n\\n    // Setup event handlers\\n    setupRecognitionHandlers();\\n    \\n    logger.info('✅ Browser speech client initialized');\\n    logger.debug(`✅ Server URL validated: ${validation.hostname}:${validation.port}`);\\n    return true;\\n  };\\n\\n  // Setup recognition event handlers\\n  const setupRecognitionHandlers = () => {\\n    // Handle results\\n    state.recognition.onresult = (event) => {\\n      for (let i = event.resultIndex; i < event.results.length; i++) {\\n        const result = event.results[i];\\n        const {transcript} = result[0];\\n        const confidence = result[0].confidence || 0.95;\\n        \\n        const transcriptData = {\\n          text: transcript,\\n          confidence,\\n          isFinal: result.isFinal,\\n          timestamp: Date.now(),\\n          sessionId: state.sessionId\\n        };\\n\\n        // Notify transcript callbacks\\n        notifyCallbacks('onTranscript', transcriptData);\\n\\n        // Add to batch if final\\n        if (result.isFinal || (state.config.sendInterimResults && !result.isFinal)) {\\n          addToBatch(transcriptData);\\n        }\\n      }\\n    };\\n\\n    // Handle errors\\n    state.recognition.onerror = (event) => {\\n      logger.error('Speech recognition error:', event.error);\\n      \\n      const errorData = {\\n        type: 'recognition_error',\\n        error: event.error,\\n        message: getErrorMessage(event.error),\\n        timestamp: Date.now()\\n      };\\n      \\n      notifyCallbacks('onError', errorData);\\n      \\n      // Auto-restart on certain errors\\n      if (['network', 'audio-capture'].includes(event.error) && state.isListening) {\\n        logger.warn('Attempting to restart recognition...');\\n        setTimeout(() => {\\n          if (state.isListening) {\\n            state.recognition.start();\\n          }\\n        }, 1000);\\n      }\\n    };\\n\\n    // Handle end\\n    state.recognition.onend = () => {\\n      logger.info('Speech recognition ended');\\n      \\n      // Send any remaining batch\\n      if (state.textBatch.length > 0) {\\n        sendBatch();\\n      }\\n      \\n      // Restart if still listening (for continuous mode)\\n      if (state.isListening && state.config.continuous) {\\n        state.recognition.start();\\n      } else {\\n        state.isListening = false;\\n        notifyCallbacks('onStatusChange', { isListening: false });\\n      }\\n    };\\n\\n    // Handle start\\n    state.recognition.onstart = () => {\\n      console.log('🎤 Speech recognition started');\\n      state.isListening = true;\\n      notifyCallbacks('onStatusChange', { isListening: true });\\n    };\\n  };\\n\\n  // Get error message\\n  const getErrorMessage = (error) => {\\n    const errorMessages = {\\n      'no-speech': 'No speech detected',\\n      'audio-capture': 'Microphone not available',\\n      'not-allowed': 'Microphone permission denied',\\n      'network': 'Network error',\\n      'aborted': 'Recognition aborted',\\n      'language-not-supported': 'Language not supported',\\n      'service-not-allowed': 'Service not allowed'\\n    };\\n    \\n    return errorMessages[error] || `Unknown error: ${error}`;\\n  };\\n\\n  // Add transcript to batch\\n  const addToBatch = (transcriptData) => {\\n    state.textBatch.push(transcriptData);\\n    \\n    // Clear existing timer\\n    if (state.batchTimer) {\\n      clearTimeout(state.batchTimer);\\n    }\\n    \\n    // Send batch if it reaches the size limit\\n    if (state.textBatch.length >= state.config.batchSize) {\\n      sendBatch();\\n    } else {\\n      // Set timer to send batch after timeout\\n      state.batchTimer = setTimeout(() => {\\n        if (state.textBatch.length > 0) {\\n          sendBatch();\\n        }\\n      }, state.config.batchTimeout);\\n    }\\n  };\\n\\n  // Send batch to server\\n  const sendBatch = async () => {\\n    if (state.textBatch.length === 0) return;\\n    \\n    const batch = [...state.textBatch];\\n    state.textBatch = [];\\n    \\n    // Clear timer\\n    if (state.batchTimer) {\\n      clearTimeout(state.batchTimer);\\n      state.batchTimer = null;\\n    }\\n    \\n    try {\\n      const response = await fetch(state.config.serverUrl, {\\n        method: 'POST',\\n        headers: {\\n          'Content-Type': 'application/json'\\n        },\\n        body: JSON.stringify({\\n          sessionId: state.sessionId,\\n          transcripts: batch,\\n          timestamp: Date.now()\\n        })\\n      });\\n\\n      if (!response.ok) {\\n        throw new Error(`Server error: ${response.status}`);\\n      }\\n\\n      const analysisResult = await response.json();\\n      \\n      // Notify analysis callbacks\\n      notifyCallbacks('onAnalysis', analysisResult);\\n      \\n    } catch (error) {\\n      logger.error('Failed to send batch to server:', error);\\n      \\n      notifyCallbacks('onError', {\\n        type: 'server_error',\\n        error: error.message,\\n        batch,\\n        timestamp: Date.now()\\n      });\\n      \\n      // Re-add batch for retry if needed\\n      if (state.config.retryOnError) {\\n        state.textBatch = [...batch, ...state.textBatch];\\n      }\\n    }\\n  };\\n\\n  // Start listening\\n  const startListening = async () => {\\n    if (!state.recognition) {\\n      throw new Error('Speech client not initialized');\\n    }\\n    \\n    if (state.isListening) {\\n      console.warn('Already listening');\\n      return;\\n    }\\n    \\n    try {\\n      // Request microphone permission if needed\\n      if (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {\\n        await navigator.mediaDevices.getUserMedia({ audio: true });\\n      }\\n      \\n      state.recognition.start();\\n      \\n    } catch (error) {\\n      console.error('Failed to start listening:', error);\\n      throw error;\\n    }\\n  };\\n\\n  // Stop listening\\n  const stopListening = () => {\\n    if (!state.recognition || !state.isListening) {\\n      return;\\n    }\\n    \\n    state.isListening = false;\\n    state.recognition.stop();\\n    \\n    // Send any remaining batch\\n    if (state.textBatch.length > 0) {\\n      sendBatch();\\n    }\\n  };\\n\\n  // Send text directly (for manual input)\\n  const sendText = async (text, options = {}) => {\\n    const transcriptData = {\\n      text,\\n      confidence: 1.0,\\n      isFinal: true,\\n      timestamp: Date.now(),\\n      sessionId: state.sessionId,\\n      isManual: true,\\n      ...options\\n    };\\n    \\n    // Notify transcript callbacks\\n    notifyCallbacks('onTranscript', transcriptData);\\n    \\n    // Send immediately\\n    try {\\n      const response = await fetch(state.config.serverUrl, {\\n        method: 'POST',\\n        headers: {\\n          'Content-Type': 'application/json'\\n        },\\n        body: JSON.stringify({\\n          sessionId: state.sessionId,\\n          transcripts: [transcriptData],\\n          timestamp: Date.now()\\n        })\\n      });\\n\\n      if (!response.ok) {\\n        throw new Error(`Server error: ${response.status}`);\\n      }\\n\\n      const analysisResult = await response.json();\\n      \\n      // Notify analysis callbacks\\n      notifyCallbacks('onAnalysis', analysisResult);\\n      \\n      return analysisResult;\\n      \\n    } catch (error) {\\n      console.error('Failed to send text to server:', error);\\n      \\n      notifyCallbacks('onError', {\\n        type: 'server_error',\\n        error: error.message,\\n        text,\\n        timestamp: Date.now()\\n      });\\n      \\n      throw error;\\n    }\\n  };\\n\\n  // Update configuration\\n  const updateConfig = (newConfig) => {\\n    Object.assign(state.config, newConfig);\\n    \\n    if (state.recognition) {\\n      state.recognition.lang = state.config.language;\\n      state.recognition.continuous = state.config.continuous;\\n      state.recognition.interimResults = state.config.interimResults;\\n      state.recognition.maxAlternatives = state.config.maxAlternatives;\\n    }\\n  };\\n\\n  // Event subscription methods\\n  const onTranscript = (callback) => subscribeCallback('onTranscript', callback);\\n  const onAnalysis = (callback) => subscribeCallback('onAnalysis', callback);\\n  const onError = (callback) => subscribeCallback('onError', callback);\\n  const onStatusChange = (callback) => subscribeCallback('onStatusChange', callback);\\n\\n  // Helper functions\\n  const subscribeCallback = (eventType, callback) => {\\n    state.callbacks[eventType].push(callback);\\n    return () => {\\n      const index = state.callbacks[eventType].indexOf(callback);\\n      if (index !== -1) state.callbacks[eventType].splice(index, 1);\\n    };\\n  };\\n\\n  const notifyCallbacks = (eventType, data) => {\\n    state.callbacks[eventType].forEach(callback => {\\n      try {\\n        callback(data);\\n      } catch (error) {\\n        console.warn(`Callback error for ${eventType}:`, error);\\n      }\\n    });\\n  };\\n\\n  // Cleanup\\n  const cleanup = () => {\\n    stopListening();\\n    \\n    if (state.batchTimer) {\\n      clearTimeout(state.batchTimer);\\n      state.batchTimer = null;\\n    }\\n    \\n    state.textBatch = [];\\n    state.callbacks = {\\n      onTranscript: [],\\n      onAnalysis: [],\\n      onError: [],\\n      onStatusChange: []\\n    };\\n    \\n    console.log('🧹 Browser speech client cleaned up');\\n  };\\n\\n  return {\\n    // Core functionality\\n    initialize,\\n    startListening,\\n    stopListening,\\n    sendText,\\n    cleanup,\\n    \\n    // Configuration\\n    updateConfig,\\n    getConfig: () => ({ ...state.config }),\\n    \\n    // Session management\\n    getSessionId: () => state.sessionId,\\n    newSession: () => {\\n      state.sessionId = generateSessionId();\\n      return state.sessionId;\\n    },\\n    \\n    // Status\\n    isListening: () => state.isListening,\\n    isInitialized: () => state.recognition !== null,\\n    \\n    // Event handlers\\n    onTranscript,\\n    onAnalysis,\\n    onError,\\n    onStatusChange\\n  };\\n};\\n\\n// Export default configuration\\nexport const DEFAULT_CLIENT_CONFIG = {\\n  language: 'en-US',\\n  continuous: true,\\n  interimResults: true,\\n  sendInterimResults: false,\\n  batchSize: 5,\\n  batchTimeout: 2000,\\n  serverUrl: process.env.SPEECH_SERVER_URL || 'http://localhost:3000/api/analyze',\\n  retryOnError: false\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/core/configuration/config-validator.js\",\"messages\":[],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/core/configuration/validation-helpers.js\",\"messages\":[],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/core/configuration/validation-utilities.js\",\"messages\":[],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/core/engine/face-analysis-engine.js\",\"messages\":[{\"ruleId\":\"max-lines-per-function\",\"severity\":1,\"message\":\"Arrow function has too many lines (363). Maximum allowed is 150.\",\"line\":17,\"column\":41,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"exceed\",\"endLine\":487,\"endColumn\":2}],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":1,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Modular Face Analysis Engine - Main Entry Point\\n * Composable, plugin-based face analysis system with unified configuration\\n * Updated to support all integrated pipelines including eye tracking\\n */\\n\\nimport { createWebGLEngine } from './webgl-engine.js';\\nimport { createCameraManager } from '../../shared/utils/camera.js';\\nimport { ErrorCategory, ErrorSeverity, createErrorHandler } from '../../shared/utils/error-handler.js';\\nimport { createAnalysisPipeline } from '../pipeline/analysis-pipeline.js';\\nimport { createConfigurationManager } from '../configuration/configuration.js';\\nimport { createOrchestrator } from '../orchestration/orchestrator.js';\\n\\n// Import pipeline factories\\nimport { createEyeTrackingPipelineFactory } from '../../features/eye-tracking/devices/neon/pipeline.js';\\n\\nexport const createFaceAnalysisEngine = (canvas, userConfig = {}) => {\\n  // Initialize unified configuration system\\n  const configManager = createConfigurationManager(userConfig);\\n  const config = configManager.getConfig();\\n  \\n  const state = {\\n    canvas,\\n    webglEngine: null,\\n    camera: null,\\n    pipeline: null,\\n    orchestrator: null,\\n    isInitialized: false,\\n    isProcessing: false,\\n    config,\\n    configManager,\\n    errorHandler: null,\\n    stats: {\\n      fps: 0,\\n      frameTime: 0,\\n      pipelineTime: 0,\\n      totalFrames: 0,\\n      lastFpsUpdate: 0,\\n      pipelineStats: new Map()\\n    },\\n    pipelines: new Map()\\n  };\\n\\n  // Initialize error handler\\n  const initializeErrorHandler = () => {\\n    state.errorHandler = createErrorHandler({\\n      logLevel: ErrorSeverity.WARNING,\\n      enableConsole: true,\\n      enableCollection: true,\\n      enableRecovery: true,\\n      onError: (error) => {\\n        if (error.severity === ErrorSeverity.FATAL) {\\n          console.error('FATAL ERROR - Engine may be in unstable state:', error);\\n        }\\n      }\\n    });\\n  };\\n\\n  const initializePipelines = async () => {\\n    if (!state.orchestrator) {\\n      throw new Error('Orchestrator not initialized');\\n    }\\n\\n    const enabledPipelines = state.configManager.getEnabledPipelines();\\n    \\n    for (const pipelineConfig of enabledPipelines) {\\n      try {\\n        const config = state.configManager.getPipelineConfig(pipelineConfig.name);\\n        const pipeline = await state.orchestrator.createPipeline(pipelineConfig.name, config);\\n        \\n        if (pipeline) {\\n          state.pipelines.set(pipelineConfig.name, pipeline);\\n          console.log(`✅ ${pipelineConfig.name} pipeline initialized`);\\n        }\\n      } catch (error) {\\n        console.warn(`⚠️ Failed to initialize ${pipelineConfig.name} pipeline:`, error.message);\\n        \\n        // Continue with other pipelines - graceful degradation\\n        state.errorHandler?.handleError(\\n          `Pipeline initialization failed: ${pipelineConfig.name}`,\\n          ErrorCategory.INITIALIZATION,\\n          ErrorSeverity.WARNING,\\n          { pipeline: pipelineConfig.name, error: error.message }\\n        );\\n      }\\n    }\\n    \\n    console.log(`📦 ${state.pipelines.size} pipelines initialized successfully`);\\n  };\\n\\n  const createPipeline = () => {\\n    // Get enabled pipelines from unified configuration\\n    const enabledPipelines = state.configManager.getEnabledPipelines();\\n    \\n    // Initialize orchestrator with unified config\\n    state.orchestrator = createOrchestrator({\\n      performance: state.config.performance,\\n      system: state.config.system\\n    });\\n    \\n    // Register pipeline factories based on enabled pipelines\\n    registerPipelineFactories(enabledPipelines);\\n    \\n    console.log(`🔗 Pipeline orchestrator created with ${enabledPipelines.length} enabled pipelines`);\\n  };\\n  \\n  const registerPipelineFactories = (enabledPipelines) => {\\n    // Register eye tracking pipeline if enabled\\n    const eyeTrackingConfig = enabledPipelines.find(p => p.name === 'eyeTracking');\\n    if (eyeTrackingConfig) {\\n      const factory = createEyeTrackingPipelineFactory();\\n      state.orchestrator.registerPipelineFactory(factory.name, factory);\\n      console.log('📦 Eye tracking pipeline factory registered');\\n    }\\n    \\n    // Register face detection pipeline (always available)\\n    state.orchestrator.registerPipelineFactory('detection', {\\n      name: 'detection',\\n      description: 'Face detection pipeline',\\n      create: (config) => createAnalysisPipeline(config),\\n      requiresHardware: false,\\n      supportsRealtime: true\\n    });\\n    \\n    console.log('📦 Core detection pipeline factory registered');\\n  };\\n\\n  const initialize = async (options = {}) => {\\n    try {\\n      initializeErrorHandler();\\n      \\n      state.errorHandler.handleError(\\n        'Initializing Modular Face Analysis Engine...',\\n        ErrorCategory.INITIALIZATION,\\n        ErrorSeverity.INFO\\n      );\\n\\n      // Merge options with config\\n      state.config = { ...state.config, ...options };\\n\\n      // Initialize WebGL engine\\n      console.log('🔧 Creating WebGL engine...');\\n      state.webglEngine = createWebGLEngine(state.canvas);\\n      \\n      if (!state.webglEngine) {\\n        throw new Error('WebGL engine initialization failed');\\n      }\\n\\n      state.errorHandler.handleError(\\n        `WebGL${state.webglEngine.isWebGL2 ? '2' : '1'} engine initialized successfully`,\\n        ErrorCategory.WEBGL,\\n        ErrorSeverity.INFO\\n      );\\n\\n      // Create orchestrator and register pipelines\\n      console.log('🔗 Creating pipeline orchestrator...');\\n      createPipeline();\\n\\n      // Initialize all enabled pipelines\\n      await initializePipelines();\\n      \\n      // Start orchestrator if we have pipelines\\n      if (state.pipelines.size > 0) {\\n        await state.orchestrator.start();\\n        console.log('✅ Pipeline orchestrator started');\\n      }\\n\\n      // Initialize camera if requested\\n      if (options.camera === true) {\\n        await initializeCamera(options.cameraConstraints);\\n      }\\n\\n      state.isInitialized = true;\\n\\n      state.errorHandler.handleError(\\n        'Modular Face Analysis Engine initialized successfully',\\n        ErrorCategory.INITIALIZATION,\\n        ErrorSeverity.INFO\\n      );\\n\\n      return {\\n        webglVersion: state.webglEngine.isWebGL2 ? 2 : 1,\\n        orchestrator: state.orchestrator ? state.orchestrator.getStatus() : null,\\n        pipelines: Array.from(state.pipelines.keys()),\\n        pipelineStats: getPipelineStats(),\\n        features: getAvailableFeatures(),\\n        errorStats: state.errorHandler.getStatistics(),\\n        configuration: {\\n          validated: state.configManager.isValidated(),\\n          enabledPipelines: state.configManager.getEnabledPipelines().map(p => p.name)\\n        }\\n      };\\n\\n    } catch (error) {\\n      state.errorHandler?.handleError(\\n        `Initialization failed: ${error.message}`,\\n        ErrorCategory.INITIALIZATION,\\n        ErrorSeverity.FATAL,\\n        { originalError: error.stack }\\n      );\\n      throw error;\\n    }\\n  };\\n\\n  const initializeCamera = async (constraints) => {\\n    state.camera = createCameraManager();\\n    await state.camera.initialize(constraints);\\n    console.log('📹 Camera initialized');\\n  };\\n\\n  const getAvailableFeatures = () => {\\n    const features = {};\\n    \\n    // Get features from all active pipelines\\n    for (const [pipelineName, pipeline] of state.pipelines) {\\n      try {\\n        if (pipeline.getCapabilities) {\\n          const capabilities = pipeline.getCapabilities();\\n          for (const capability of capabilities) {\\n            features[capability] = true;\\n          }\\n        }\\n        \\n        // Mark pipeline as available\\n        features[pipelineName] = true;\\n      } catch (error) {\\n        console.warn(`Failed to get capabilities from ${pipelineName}:`, error.message);\\n      }\\n    }\\n    \\n    // Add core WebGL features\\n    if (state.webglEngine) {\\n      features.webgl = true;\\n      features.webgl2 = state.webglEngine.isWebGL2;\\n    }\\n    \\n    return features;\\n  };\\n  \\n  const getPipelineStats = () => {\\n    const stats = {};\\n    \\n    for (const [pipelineName, pipeline] of state.pipelines) {\\n      try {\\n        if (pipeline.getStatus) {\\n          stats[pipelineName] = pipeline.getStatus();\\n        }\\n      } catch (error) {\\n        stats[pipelineName] = { error: error.message };\\n      }\\n    }\\n    \\n    return stats;\\n  };\\n\\n  const startProcessing = (options = {}) => {\\n    if (!state.isInitialized) {\\n      throw new Error('Engine not initialized');\\n    }\\n\\n    if (state.isProcessing) {\\n      return;\\n    }\\n\\n    state.isProcessing = true;\\n    console.log('▶️ Starting processing loop...');\\n\\n    const frameLoop = async () => {\\n      if (!state.isProcessing) return;\\n\\n      const frameStart = performance.now();\\n\\n      try {\\n        // Get current frame\\n        let frameData;\\n        if (state.camera) {\\n          frameData = state.camera.getFrame();\\n        } else if (options.getFrame) {\\n          frameData = options.getFrame();\\n        } else {\\n          throw new Error('No frame source available');\\n        }\\n\\n        if (!frameData) {\\n          requestAnimationFrame(frameLoop);\\n          return;\\n        }\\n\\n        // Process through orchestrator and all active pipelines\\n        const pipelineStart = performance.now();\\n        const results = {};\\n        \\n        for (const [pipelineName, pipeline] of state.pipelines) {\\n          try {\\n            if (pipeline.process) {\\n              const pipelineResult = await pipeline.process(frameData, {\\n                timestamp: performance.now(),\\n                frameNumber: state.stats.totalFrames\\n              });\\n              results[pipelineName] = pipelineResult;\\n            }\\n          } catch (pipelineError) {\\n            state.errorHandler?.handleError(\\n              `Pipeline ${pipelineName} processing failed: ${pipelineError.message}`,\\n              ErrorCategory.PROCESSING,\\n              ErrorSeverity.WARNING,\\n              { pipeline: pipelineName, frameNumber: state.stats.totalFrames }\\n            );\\n            // Continue with other pipelines\\n          }\\n        }\\n        \\n        const pipelineTime = performance.now() - pipelineStart;\\n\\n        // Update statistics\\n        const frameTime = performance.now() - frameStart;\\n        updateStats(frameTime, pipelineTime);\\n\\n        // Call result callback\\n        if (options.onResults) {\\n          options.onResults({\\n            results,\\n            stats: getStats(),\\n            timestamp: performance.now(),\\n            pipelineStats: getPipelineStats()\\n          });\\n        }\\n\\n      } catch (error) {\\n        const standardError = state.errorHandler.handleError(\\n          `Frame processing failed: ${error.message}`,\\n          ErrorCategory.PROCESSING,\\n          ErrorSeverity.ERROR,\\n          {\\n            frameNumber: state.stats.totalFrames,\\n            hasCamera: !!state.camera,\\n            originalError: error.stack\\n          }\\n        );\\n\\n        if (options.onError) {\\n          options.onError(standardError);\\n        }\\n      }\\n\\n      // Schedule next frame\\n      requestAnimationFrame(frameLoop);\\n    };\\n\\n    frameLoop();\\n  };\\n\\n  const stopProcessing = () => {\\n    state.isProcessing = false;\\n    console.log('⏹️ Processing stopped');\\n  };\\n\\n  const updateStats = (frameTime, pipelineTime) => {\\n    state.stats.totalFrames++;\\n    state.stats.frameTime = frameTime;\\n    state.stats.pipelineTime = pipelineTime;\\n\\n    // Calculate FPS\\n    const now = performance.now();\\n    if (now - state.stats.lastFpsUpdate > 1000) {\\n      state.stats.fps = Math.round(1000 / frameTime);\\n      state.stats.lastFpsUpdate = now;\\n    }\\n  };\\n\\n  const getStats = () => ({\\n    ...state.stats,\\n    pipelineStats: getPipelineStats(),\\n    orchestratorStats: state.orchestrator ? state.orchestrator.getStats() : null,\\n    activePipelines: Array.from(state.pipelines.keys())\\n  });\\n\\n  const switchAlgorithm = async (pipelineName, algorithm, config = {}) => {\\n    if (!state.orchestrator) {\\n      throw new Error('Orchestrator not initialized');\\n    }\\n\\n    try {\\n      // Update configuration\\n      state.configManager.set(`pipelines.${pipelineName}.primary`, algorithm);\\n      if (config && Object.keys(config).length > 0) {\\n        state.configManager.set(`pipelines.${pipelineName}.${algorithm}`, config);\\n      }\\n      \\n      // Recreate pipeline with new configuration\\n      const pipelineConfig = state.configManager.getPipelineConfig(pipelineName);\\n      const newPipeline = await state.orchestrator.createPipeline(pipelineName, pipelineConfig);\\n      \\n      if (newPipeline) {\\n        // Stop and cleanup old pipeline\\n        const oldPipeline = state.pipelines.get(pipelineName);\\n        if (oldPipeline && oldPipeline.cleanup) {\\n          await oldPipeline.cleanup();\\n        }\\n        \\n        // Replace with new pipeline\\n        state.pipelines.set(pipelineName, newPipeline);\\n        console.log(`🔄 Switched ${pipelineName} algorithm to ${algorithm}`);\\n      }\\n    } catch (error) {\\n      state.errorHandler?.handleError(\\n        `Algorithm switch failed: ${pipelineName} to ${algorithm}`,\\n        ErrorCategory.INITIALIZATION,\\n        ErrorSeverity.ERROR,\\n        { pipeline: pipelineName, algorithm, error: error.message }\\n      );\\n      throw error;\\n    }\\n  };\\n\\n  const cleanup = async () => {\\n    console.log('🧹 Cleaning up Face Analysis Engine...');\\n    \\n    stopProcessing();\\n    \\n    // Cleanup all pipelines\\n    for (const [pipelineName, pipeline] of state.pipelines) {\\n      try {\\n        if (pipeline.cleanup) {\\n          await pipeline.cleanup();\\n        }\\n        console.log(`✅ ${pipelineName} pipeline cleaned up`);\\n      } catch (error) {\\n        console.warn(`⚠️ Failed to cleanup ${pipelineName} pipeline:`, error.message);\\n      }\\n    }\\n    state.pipelines.clear();\\n    \\n    // Cleanup orchestrator\\n    if (state.orchestrator) {\\n      try {\\n        await state.orchestrator.shutdown();\\n      } catch (error) {\\n        console.warn('⚠️ Failed to shutdown orchestrator:', error.message);\\n      }\\n      state.orchestrator = null;\\n    }\\n    \\n    // Cleanup camera\\n    if (state.camera) {\\n      state.camera.cleanup();\\n      state.camera = null;\\n    }\\n    \\n    // Cleanup WebGL engine\\n    if (state.webglEngine) {\\n      state.webglEngine.cleanup();\\n      state.webglEngine = null;\\n    }\\n    \\n    state.isInitialized = false;\\n    console.log('✅ Face Analysis Engine cleanup complete');\\n  };\\n\\n  // Public API\\n  return {\\n    initialize,\\n    startProcessing,\\n    stopProcessing,\\n    switchAlgorithm,\\n    getStats,\\n    getAvailableFeatures,\\n    cleanup,\\n    \\n    // Utilities\\n    getCanvas: () => state.canvas,\\n    getWebGLEngine: () => state.webglEngine,\\n    getOrchestrator: () => state.orchestrator,\\n    getPipeline: (name) => state.pipelines.get(name),\\n    getAllPipelines: () => new Map(state.pipelines),\\n    getCamera: () => state.camera,\\n    getConfigManager: () => state.configManager,\\n    \\n    // Camera controls\\n    getCameraInfo: () => state.camera ? state.camera.getStreamInfo() : null,\\n    switchCamera: async (facingMode = 'user') => {\\n      if (state.camera) {\\n        await state.camera.switchCamera(facingMode);\\n      }\\n    }\\n  };\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/core/engine/image-operations.js\",\"messages\":[{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":86,\"column\":47,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":86,\"endColumn\":48},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":86,\"column\":51,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":86,\"endColumn\":52},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":86,\"column\":51,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":86,\"endColumn\":52},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":86,\"column\":59,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":86,\"endColumn\":60},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":86,\"column\":63,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":86,\"endColumn\":64},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":86,\"column\":71,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":86,\"endColumn\":72},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":127,\"column\":39,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":127,\"endColumn\":40},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":127,\"column\":50,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":127,\"endColumn\":51},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":128,\"column\":29,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":128,\"endColumn\":30},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":128,\"column\":41,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":128,\"endColumn\":42},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":153,\"column\":81,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":153,\"endColumn\":82},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":153,\"column\":93,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":153,\"endColumn\":94},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":159,\"column\":42,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":159,\"endColumn\":43},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":159,\"column\":48,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":159,\"endColumn\":49},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":159,\"column\":70,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":159,\"endColumn\":71},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":159,\"column\":82,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":159,\"endColumn\":83},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":162,\"column\":68,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":162,\"endColumn\":69},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":162,\"column\":98,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":162,\"endColumn\":99},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":195,\"column\":29,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":195,\"endColumn\":30},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":195,\"column\":33,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":195,\"endColumn\":34},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'kernelArea' is assigned a value but never used. Allowed unused vars must match /^_/u.\",\"line\":196,\"column\":9,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":196,\"endColumn\":19,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"kernelArea\"},\"fix\":{\"range\":[6207,6250],\"text\":\"\"},\"desc\":\"Remove unused variable 'kernelArea'.\"}]},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":200,\"column\":28,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":200,\"endColumn\":29},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":200,\"column\":36,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":200,\"endColumn\":37},{\"ruleId\":\"max-depth\",\"severity\":1,\"message\":\"Blocks are nested too deeply (6). Maximum allowed is 5.\",\"line\":211,\"column\":13,\"nodeType\":\"IfStatement\",\"messageId\":\"tooDeeply\",\"endLine\":215,\"endColumn\":14},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":212,\"column\":31,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":212,\"endColumn\":32},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":212,\"column\":39,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":212,\"endColumn\":40},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":212,\"column\":45,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":212,\"endColumn\":46},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":212,\"column\":56,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":212,\"endColumn\":57}],\"suppressedMessages\":[],\"errorCount\":1,\"fatalErrorCount\":0,\"warningCount\":27,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Core image processing operations\\n */\\n\\nexport const IMAGE_FORMATS = {\\n  RGB: { channels: 3, bytesPerPixel: 3 },\\n  RGBA: { channels: 4, bytesPerPixel: 4 },\\n  GRAYSCALE: { channels: 1, bytesPerPixel: 1 },\\n  BGR: { channels: 3, bytesPerPixel: 3 }\\n};\\n\\nexport const INTERPOLATION_METHODS = {\\n  NEAREST: 'nearest',\\n  BILINEAR: 'bilinear',\\n  BICUBIC: 'bicubic'\\n};\\n\\nexport const createImageOperations = (resourcePool) => {\\n  \\n  const resizeImage = (imageData, targetWidth, targetHeight, method = INTERPOLATION_METHODS.BILINEAR) => {\\n    const { data, width, height } = imageData;\\n    const channels = data.length / (width * height);\\n    \\n    // Get canvas from resource pool\\n    const canvas = resourcePool.acquire('Canvas', targetWidth, targetHeight);\\n    const ctx = canvas.getContext('2d');\\n    \\n    try {\\n      // Create temporary canvas for source image\\n      const sourceCanvas = resourcePool.acquire('Canvas', width, height);\\n      const sourceCtx = sourceCanvas.getContext('2d');\\n      \\n      // Put image data on source canvas\\n      const sourceImageData = sourceCtx.createImageData(width, height);\\n      sourceImageData.data.set(data);\\n      sourceCtx.putImageData(sourceImageData, 0, 0);\\n      \\n      // Configure interpolation\\n      if (method === INTERPOLATION_METHODS.NEAREST) {\\n        ctx.imageSmoothingEnabled = false;\\n      } else {\\n        ctx.imageSmoothingEnabled = true;\\n        ctx.imageSmoothingQuality = method === INTERPOLATION_METHODS.BICUBIC ? 'high' : 'medium';\\n      }\\n      \\n      // Resize\\n      ctx.drawImage(sourceCanvas, 0, 0, width, height, 0, 0, targetWidth, targetHeight);\\n      \\n      // Get resized image data\\n      const resizedImageData = ctx.getImageData(0, 0, targetWidth, targetHeight);\\n      \\n      // Return to pool\\n      resourcePool.release('Canvas', sourceCanvas);\\n      resourcePool.release('Canvas', canvas);\\n      \\n      return {\\n        data: resizedImageData.data,\\n        width: targetWidth,\\n        height: targetHeight,\\n        channels\\n      };\\n      \\n    } catch (error) {\\n      // Ensure cleanup on error\\n      resourcePool.release('Canvas', canvas);\\n      throw error;\\n    }\\n  };\\n\\n  const convertColorSpace = (imageData, fromFormat, toFormat) => {\\n    const { data, width, height } = imageData;\\n    const fromChannels = IMAGE_FORMATS[fromFormat]?.channels || 3;\\n    const toChannels = IMAGE_FORMATS[toFormat]?.channels || 3;\\n    \\n    const outputData = new Uint8Array(width * height * toChannels);\\n    \\n    for (let i = 0; i < width * height; i++) {\\n      const srcIdx = i * fromChannels;\\n      const dstIdx = i * toChannels;\\n      \\n      if (fromFormat === 'RGB' && toFormat === 'GRAYSCALE') {\\n        // RGB to Grayscale\\n        const r = data[srcIdx];\\n        const g = data[srcIdx + 1];\\n        const b = data[srcIdx + 2];\\n        outputData[dstIdx] = Math.round(0.299 * r + 0.587 * g + 0.114 * b);\\n      } else if (fromFormat === 'RGBA' && toFormat === 'RGB') {\\n        // RGBA to RGB\\n        outputData[dstIdx] = data[srcIdx];\\n        outputData[dstIdx + 1] = data[srcIdx + 1];\\n        outputData[dstIdx + 2] = data[srcIdx + 2];\\n      } else if (fromFormat === 'RGB' && toFormat === 'BGR') {\\n        // RGB to BGR\\n        outputData[dstIdx] = data[srcIdx + 2];\\n        outputData[dstIdx + 1] = data[srcIdx + 1];\\n        outputData[dstIdx + 2] = data[srcIdx];\\n      } else {\\n        // Copy as-is for unsupported conversions\\n        for (let c = 0; c < Math.min(fromChannels, toChannels); c++) {\\n          outputData[dstIdx + c] = data[srcIdx + c];\\n        }\\n      }\\n    }\\n    \\n    return {\\n      data: outputData,\\n      width,\\n      height,\\n      channels: toChannels\\n    };\\n  };\\n\\n  const cropImage = (imageData, x, y, width, height) => {\\n    const { data, width: srcWidth, height: srcHeight } = imageData;\\n    const channels = data.length / (srcWidth * srcHeight);\\n    \\n    // Validate crop region\\n    const cropX = Math.max(0, Math.min(x, srcWidth));\\n    const cropY = Math.max(0, Math.min(y, srcHeight));\\n    const cropWidth = Math.min(width, srcWidth - cropX);\\n    const cropHeight = Math.min(height, srcHeight - cropY);\\n    \\n    const croppedData = new Uint8Array(cropWidth * cropHeight * channels);\\n    \\n    for (let row = 0; row < cropHeight; row++) {\\n      for (let col = 0; col < cropWidth; col++) {\\n        const srcIdx = ((cropY + row) * srcWidth + (cropX + col)) * channels;\\n        const dstIdx = (row * cropWidth + col) * channels;\\n        \\n        for (let c = 0; c < channels; c++) {\\n          croppedData[dstIdx + c] = data[srcIdx + c];\\n        }\\n      }\\n    }\\n    \\n    return {\\n      data: croppedData,\\n      width: cropWidth,\\n      height: cropHeight,\\n      channels\\n    };\\n  };\\n\\n  const applyFilter = (imageData, filterType, intensity = 1.0) => {\\n    const { data, width, height } = imageData;\\n    const channels = data.length / (width * height);\\n    const filteredData = new Uint8Array(data);\\n    \\n    switch (filterType) {\\n      case 'brightness':\\n        for (let i = 0; i < filteredData.length; i += channels) {\\n          for (let c = 0; c < Math.min(3, channels); c++) {\\n            filteredData[i + c] = Math.min(255, Math.max(0, filteredData[i + c] + intensity * 50));\\n          }\\n        }\\n        break;\\n        \\n      case 'contrast':\\n        const factor = (259 * (intensity * 100 + 255)) / (255 * (259 - intensity * 100));\\n        for (let i = 0; i < filteredData.length; i += channels) {\\n          for (let c = 0; c < Math.min(3, channels); c++) {\\n            filteredData[i + c] = Math.min(255, Math.max(0, factor * (filteredData[i + c] - 128) + 128));\\n          }\\n        }\\n        break;\\n        \\n      case 'blur':\\n        // Simple box blur\\n        applyBoxBlur(filteredData, width, height, channels, Math.max(1, intensity * 3));\\n        break;\\n        \\n      default:\\n        console.warn(`Unknown filter type: ${filterType}`);\\n    }\\n    \\n    return {\\n      data: filteredData,\\n      width,\\n      height,\\n      channels\\n    };\\n  };\\n\\n  return {\\n    resizeImage,\\n    convertColorSpace,\\n    cropImage,\\n    applyFilter\\n  };\\n};\\n\\n// Helper function for box blur\\nconst applyBoxBlur = (data, width, height, channels, radius) => {\\n  const original = new Uint8Array(data);\\n  const kernelSize = radius * 2 + 1;\\n  const kernelArea = kernelSize * kernelSize;\\n  \\n  for (let y = 0; y < height; y++) {\\n    for (let x = 0; x < width; x++) {\\n      const centerIdx = (y * width + x) * channels;\\n      \\n      for (let c = 0; c < Math.min(3, channels); c++) {\\n        let sum = 0;\\n        let count = 0;\\n        \\n        for (let ky = -radius; ky <= radius; ky++) {\\n          for (let kx = -radius; kx <= radius; kx++) {\\n            const ny = y + ky;\\n            const nx = x + kx;\\n            \\n            if (ny >= 0 && ny < height && nx >= 0 && nx < width) {\\n              const idx = (ny * width + nx) * channels + c;\\n              sum += original[idx];\\n              count++;\\n            }\\n          }\\n        }\\n        \\n        data[centerIdx + c] = Math.round(sum / count);\\n      }\\n    }\\n  }\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/core/engine/image-processing-cache.js\",\"messages\":[],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/core/engine/image-processing/cache/processing-cache.js\",\"messages\":[{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'ErrorCategory' is defined but never used. Allowed unused vars must match /^_/u.\",\"line\":6,\"column\":10,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":6,\"endColumn\":23,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"ErrorCategory\"},\"fix\":{\"range\":[114,128],\"text\":\"\"},\"desc\":\"Remove unused variable 'ErrorCategory'.\"}]},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'ErrorSeverity' is defined but never used. Allowed unused vars must match /^_/u.\",\"line\":6,\"column\":25,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":6,\"endColumn\":38,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"ErrorSeverity\"},\"fix\":{\"range\":[127,142],\"text\":\"\"},\"desc\":\"Remove unused variable 'ErrorSeverity'.\"}]},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'handleError' is defined but never used. Allowed unused vars must match /^_/u.\",\"line\":6,\"column\":40,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":6,\"endColumn\":51,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"handleError\"},\"fix\":{\"range\":[142,155],\"text\":\"\"},\"desc\":\"Remove unused variable 'handleError'.\"}]},{\"ruleId\":\"max-lines-per-function\",\"severity\":1,\"message\":\"Arrow function has too many lines (230). Maximum allowed is 150.\",\"line\":11,\"column\":38,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"exceed\",\"endLine\":322,\"endColumn\":2},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":202,\"column\":35,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":202,\"endColumn\":36},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":202,\"column\":62,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":202,\"endColumn\":63},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'hits' is assigned a value but never used. Allowed unused vars must match /^_/u.\",\"line\":249,\"column\":13,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":249,\"endColumn\":17,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"hits\"},\"fix\":{\"range\":[6917,6922],\"text\":\"\"},\"desc\":\"Remove unused variable 'hits'.\"}]},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'misses' is assigned a value but never used. Allowed unused vars must match /^_/u.\",\"line\":249,\"column\":19,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":249,\"endColumn\":25,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"misses\"},\"fix\":{\"range\":[6921,6929],\"text\":\"\"},\"desc\":\"Remove unused variable 'misses'.\"}]},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'evictions' is assigned a value but never used. Allowed unused vars must match /^_/u.\",\"line\":249,\"column\":27,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":249,\"endColumn\":36,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"evictions\"},\"fix\":{\"range\":[6929,6940],\"text\":\"\"},\"desc\":\"Remove unused variable 'evictions'.\"}]},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'totalRequests' is assigned a value but never used. Allowed unused vars must match /^_/u.\",\"line\":249,\"column\":38,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":249,\"endColumn\":51,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"totalRequests\"},\"fix\":{\"range\":[6940,6955],\"text\":\"\"},\"desc\":\"Remove unused variable 'totalRequests'.\"}]},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'avgHitTime' is assigned a value but never used. Allowed unused vars must match /^_/u.\",\"line\":249,\"column\":53,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":249,\"endColumn\":63,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"avgHitTime\"},\"fix\":{\"range\":[6955,6967],\"text\":\"\"},\"desc\":\"Remove unused variable 'avgHitTime'.\"}]},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'memoryPressureEvictions' is assigned a value but never used. Allowed unused vars must match /^_/u.\",\"line\":249,\"column\":65,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":249,\"endColumn\":88,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"memoryPressureEvictions\"},\"fix\":{\"range\":[6967,6992],\"text\":\"\"},\"desc\":\"Remove unused variable 'memoryPressureEvictions'.\"}]},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'startTime' is defined but never used. Allowed unused args must match /^_/u.\",\"line\":307,\"column\":33,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":307,\"endColumn\":42,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"startTime\"},\"fix\":{\"range\":[8619,8629],\"text\":\"\"},\"desc\":\"Remove unused variable 'startTime'.\"}]},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'endTime' is defined but never used. Allowed unused args must match /^_/u.\",\"line\":307,\"column\":44,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":307,\"endColumn\":51,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"endTime\"},\"fix\":{\"range\":[8628,8637],\"text\":\"\"},\"desc\":\"Remove unused variable 'endTime'.\"}]}],\"suppressedMessages\":[],\"errorCount\":11,\"fatalErrorCount\":0,\"warningCount\":3,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Image Processing Cache\\n * LRU cache for processed image results with smart eviction policies\\n */\\n\\nimport { ErrorCategory, ErrorSeverity, handleError } from '../../../../shared/utils/error-handler.js';\\n\\n/**\\n * Creates processing cache with LRU eviction\\n */\\nexport const createProcessingCache = (config = {}) => {\\n  const cacheConfig = {\\n    maxSize: config.cacheSize || 50,\\n    maxMemoryMB: config.maxMemoryMB || 100,\\n    ttlMs: config.ttlMs || 300000, // 5 minutes default TTL\\n    enableMetrics: config.enableMetrics !== false,\\n    enableCompression: config.enableCompression || false,\\n    ...config\\n  };\\n\\n  const state = {\\n    cache: new Map(),\\n    accessOrder: [], // For LRU tracking\\n    memoryUsage: 0,\\n    metrics: {\\n      hits: 0,\\n      misses: 0,\\n      evictions: 0,\\n      totalRequests: 0,\\n      avgHitTime: 0,\\n      memoryPressureEvictions: 0\\n    }\\n  };\\n\\n  // Generate cache key from operation and parameters\\n  const generateCacheKey = (operation, params) => {\\n    const paramString = JSON.stringify(params, Object.keys(params).sort());\\n    return `${operation}:${paramString}`;\\n  };\\n\\n  // Estimate memory usage of ImageData\\n  const estimateImageDataSize = (imageData) => {\\n    if (!imageData || !imageData.data) return 0;\\n    // ImageData size = width * height * 4 bytes (RGBA) + overhead\\n    return imageData.data.length + 64; // 64 bytes estimated overhead\\n  };\\n\\n  // Update access order for LRU\\n  const updateAccessOrder = (key) => {\\n    const index = state.accessOrder.indexOf(key);\\n    if (index > -1) {\\n      state.accessOrder.splice(index, 1);\\n    }\\n    state.accessOrder.push(key);\\n  };\\n\\n  // Evict least recently used item\\n  const evictLRU = () => {\\n    if (state.accessOrder.length === 0) return false;\\n    \\n    const keyToEvict = state.accessOrder.shift();\\n    const entry = state.cache.get(keyToEvict);\\n    \\n    if (entry) {\\n      state.memoryUsage -= entry.size;\\n      state.cache.delete(keyToEvict);\\n      state.metrics.evictions++;\\n      return true;\\n    }\\n    \\n    return false;\\n  };\\n\\n  // Evict expired entries\\n  const evictExpired = () => {\\n    const now = Date.now();\\n    let evictedCount = 0;\\n    \\n    for (const [key, entry] of state.cache.entries()) {\\n      if (now - entry.timestamp > cacheConfig.ttlMs) {\\n        state.cache.delete(key);\\n        state.memoryUsage -= entry.size;\\n        \\n        const accessIndex = state.accessOrder.indexOf(key);\\n        if (accessIndex > -1) {\\n          state.accessOrder.splice(accessIndex, 1);\\n        }\\n        \\n        evictedCount++;\\n      }\\n    }\\n    \\n    if (evictedCount > 0) {\\n      state.metrics.evictions += evictedCount;\\n    }\\n    \\n    return evictedCount;\\n  };\\n\\n  // Enforce cache size and memory limits\\n  const enforceMemoryLimits = () => {\\n    const maxMemoryBytes = cacheConfig.maxMemoryMB * 1024 * 1024;\\n    \\n    // Evict expired entries first\\n    evictExpired();\\n    \\n    // Evict LRU entries if over memory limit\\n    while (state.memoryUsage > maxMemoryBytes && state.cache.size > 0) {\\n      if (!evictLRU()) break;\\n      state.metrics.memoryPressureEvictions++;\\n    }\\n    \\n    // Evict LRU entries if over count limit\\n    while (state.cache.size > cacheConfig.maxSize) {\\n      if (!evictLRU()) break;\\n    }\\n  };\\n\\n  // Compress ImageData (simple implementation)\\n  const compressImageData = (imageData) => {\\n    if (!cacheConfig.enableCompression) return imageData;\\n    \\n    // Simple compression: store only unique colors and their positions\\n    // This is a basic implementation - real compression would use better algorithms\\n    const { data, width, height } = imageData;\\n    const colorMap = new Map();\\n    const positions = [];\\n    \\n    for (let i = 0; i < data.length; i += 4) {\\n      const color = (data[i] << 24) | (data[i + 1] << 16) | (data[i + 2] << 8) | data[i + 3];\\n      \\n      if (!colorMap.has(color)) {\\n        colorMap.set(color, colorMap.size);\\n      }\\n      \\n      positions.push(colorMap.get(color));\\n    }\\n    \\n    return {\\n      compressed: true,\\n      width,\\n      height,\\n      colorMap: Array.from(colorMap.keys()),\\n      positions: new Uint16Array(positions)\\n    };\\n  };\\n\\n  // Decompress ImageData\\n  const decompressImageData = (compressed) => {\\n    if (!compressed.compressed) return compressed;\\n    \\n    const { width, height, colorMap, positions } = compressed;\\n    const data = new Uint8ClampedArray(width * height * 4);\\n    \\n    for (let i = 0; i < positions.length; i++) {\\n      const color = colorMap[positions[i]];\\n      const pixelIndex = i * 4;\\n      \\n      data[pixelIndex] = (color >> 24) & 0xFF;     // R\\n      data[pixelIndex + 1] = (color >> 16) & 0xFF; // G\\n      data[pixelIndex + 2] = (color >> 8) & 0xFF;  // B\\n      data[pixelIndex + 3] = color & 0xFF;         // A\\n    }\\n    \\n    return new ImageData(data, width, height);\\n  };\\n\\n  const getCached = (operation, params) => {\\n    const startTime = performance.now();\\n    const key = generateCacheKey(operation, params);\\n    \\n    state.metrics.totalRequests++;\\n    \\n    const entry = state.cache.get(key);\\n    \\n    if (!entry) {\\n      state.metrics.misses++;\\n      return null;\\n    }\\n    \\n    // Check if expired\\n    if (Date.now() - entry.timestamp > cacheConfig.ttlMs) {\\n      state.cache.delete(key);\\n      state.memoryUsage -= entry.size;\\n      \\n      const accessIndex = state.accessOrder.indexOf(key);\\n      if (accessIndex > -1) {\\n        state.accessOrder.splice(accessIndex, 1);\\n      }\\n      \\n      state.metrics.misses++;\\n      return null;\\n    }\\n    \\n    // Update access order and metrics\\n    updateAccessOrder(key);\\n    state.metrics.hits++;\\n    \\n    if (cacheConfig.enableMetrics) {\\n      const hitTime = performance.now() - startTime;\\n      state.metrics.avgHitTime = \\n        (state.metrics.avgHitTime * (state.metrics.hits - 1) + hitTime) / state.metrics.hits;\\n    }\\n    \\n    // Decompress if needed\\n    return decompressImageData(entry.data);\\n  };\\n\\n  const setCached = (operation, params, imageData) => {\\n    try {\\n      const key = generateCacheKey(operation, params);\\n      \\n      // Compress data if enabled\\n      const dataToStore = compressImageData(imageData);\\n      const size = estimateImageDataSize(imageData);\\n      \\n      const entry = {\\n        data: dataToStore,\\n        timestamp: Date.now(),\\n        size,\\n        accessCount: 1\\n      };\\n      \\n      // Remove existing entry if present\\n      if (state.cache.has(key)) {\\n        const oldEntry = state.cache.get(key);\\n        state.memoryUsage -= oldEntry.size;\\n      }\\n      \\n      // Add new entry\\n      state.cache.set(key, entry);\\n      state.memoryUsage += size;\\n      updateAccessOrder(key);\\n      \\n      // Enforce limits\\n      enforceMemoryLimits();\\n      \\n    } catch (error) {\\n      console.warn('Cache set operation failed:', error.message);\\n    }\\n  };\\n\\n  const clear = () => {\\n    state.cache.clear();\\n    state.accessOrder = [];\\n    state.memoryUsage = 0;\\n    \\n    // Reset metrics except configuration-dependent ones\\n    const { hits, misses, evictions, totalRequests, avgHitTime, memoryPressureEvictions } = state.metrics;\\n    state.metrics = {\\n      hits: 0,\\n      misses: 0,\\n      evictions: 0,\\n      totalRequests: 0,\\n      avgHitTime: 0,\\n      memoryPressureEvictions: 0\\n    };\\n  };\\n\\n  const getMetrics = () => {\\n    const hitRate = state.metrics.totalRequests > 0 \\n      ? state.metrics.hits / state.metrics.totalRequests \\n      : 0;\\n    \\n    return {\\n      ...state.metrics,\\n      hitRate,\\n      currentSize: state.cache.size,\\n      maxSize: cacheConfig.maxSize,\\n      memoryUsageMB: state.memoryUsage / (1024 * 1024),\\n      maxMemoryMB: cacheConfig.maxMemoryMB,\\n      memoryUtilization: state.memoryUsage / (cacheConfig.maxMemoryMB * 1024 * 1024)\\n    };\\n  };\\n\\n  const getStats = () => ({\\n    ...getMetrics(),\\n    oldestEntryAge: state.accessOrder.length > 0 \\n      ? Date.now() - (state.cache.get(state.accessOrder[0])?.timestamp || Date.now())\\n      : 0,\\n    newestEntryAge: state.accessOrder.length > 0 \\n      ? Date.now() - (state.cache.get(state.accessOrder[state.accessOrder.length - 1])?.timestamp || Date.now())\\n      : 0,\\n    compressionEnabled: cacheConfig.enableCompression\\n  });\\n\\n  // Periodic maintenance\\n  const performMaintenance = () => {\\n    evictExpired();\\n    enforceMemoryLimits();\\n  };\\n\\n  // Set up periodic maintenance if TTL is enabled\\n  let maintenanceInterval = null;\\n  if (cacheConfig.ttlMs > 0) {\\n    maintenanceInterval = setInterval(performMaintenance, Math.min(cacheConfig.ttlMs / 2, 60000));\\n  }\\n\\n  const cleanup = async () => {\\n    if (maintenanceInterval) {\\n      clearInterval(maintenanceInterval);\\n      maintenanceInterval = null;\\n    }\\n    clear();\\n  };\\n\\n  const recordProcessingTime = (startTime, endTime) => {\\n    // This method is called by the main processor for metrics consistency\\n    // No-op in cache for interface consistency\\n  };\\n\\n  return {\\n    getCached,\\n    setCached,\\n    clear,\\n    getMetrics,\\n    getStats,\\n    performMaintenance,\\n    recordProcessingTime,\\n    cleanup\\n  };\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/core/engine/image-processing/image-processor.js\",\"messages\":[{\"ruleId\":\"max-lines-per-function\",\"severity\":1,\"message\":\"Arrow function has too many lines (213). Maximum allowed is 150.\",\"line\":22,\"column\":37,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"exceed\",\"endLine\":288,\"endColumn\":2}],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":1,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Main Image Processor Factory\\n * Provides optimized image processing with pluggable operations and caching\\n * Eliminates duplicate image processing code and improves performance\\n */\\n\\nimport { getGlobalResourcePool } from '../../performance/resource-pool.js';\\nimport { ErrorCategory, ErrorSeverity, handleError } from '../../../shared/utils/error-handler.js';\\nimport { createResizeOperations } from './operations/resize-operations.js';\\nimport { createColorOperations } from './operations/color-operations.js';\\nimport { createFilterOperations } from './operations/filter-operations.js';\\nimport { createCropOperations } from './operations/crop-operations.js';\\nimport { createProcessingCache } from './cache/processing-cache.js';\\nimport { createBatchProcessor } from './optimization/batch-processor.js';\\nimport { createMemoryOptimizer } from './optimization/memory-optimizer.js';\\n\\n/**\\n * Creates an optimized image processor with modular operations\\n * @param {Object} config - Processor configuration\\n * @returns {Object} - Image processor instance\\n */\\nexport const createImageProcessor = (config = {}) => {\\n  const resourcePool = config.resourcePool || getGlobalResourcePool();\\n  const processorConfig = {\\n    defaultInterpolation: config.defaultInterpolation || 'bilinear',\\n    enableCaching: config.enableCaching !== false,\\n    cacheSize: config.cacheSize || 50,\\n    enableMetrics: config.enableMetrics !== false,\\n    enableBatching: config.enableBatching !== false,\\n    batchSize: config.batchSize || 10,\\n    enableMemoryOptimization: config.enableMemoryOptimization !== false,\\n    ...config\\n  };\\n  \\n  // Initialize modular components\\n  const cache = processorConfig.enableCaching ? createProcessingCache(processorConfig) : null;\\n  const batchProcessor = processorConfig.enableBatching ? createBatchProcessor(processorConfig) : null;\\n  const memoryOptimizer = processorConfig.enableMemoryOptimization ? createMemoryOptimizer(processorConfig) : null;\\n  \\n  // Create operation modules with shared resource pool\\n  const resizeOps = createResizeOperations(resourcePool, processorConfig);\\n  const colorOps = createColorOperations(resourcePool, processorConfig);\\n  const filterOps = createFilterOperations(resourcePool, processorConfig);\\n  const cropOps = createCropOperations(resourcePool, processorConfig);\\n  \\n  // Processing state and metrics\\n  const state = {\\n    metrics: {\\n      processedFrames: 0,\\n      totalProcessingTime: 0,\\n      averageProcessingTime: 0,\\n      cacheHits: 0,\\n      cacheMisses: 0,\\n      batchedOperations: 0,\\n      memoryOptimizations: 0\\n    }\\n  };\\n  \\n  // Enhanced wrapper for processing with caching, batching, and metrics\\n  const processWithEnhancements = async (operation, params, processFn) => {\\n    const startTime = performance.now();\\n    \\n    try {\\n      // Try cache first if enabled\\n      if (cache) {\\n        const cached = cache.getCached(operation, params);\\n        if (cached) {\\n          state.metrics.cacheHits++;\\n          updateMetrics(startTime);\\n          return cached;\\n        }\\n        state.metrics.cacheMisses++;\\n      }\\n      \\n      // Check if operation can be batched\\n      if (batchProcessor && batchProcessor.canBatch(operation, params)) {\\n        const result = await batchProcessor.addToBatch(operation, params, processFn);\\n        if (result) {\\n          state.metrics.batchedOperations++;\\n          updateMetrics(startTime);\\n          if (cache) cache.setCached(operation, params, result);\\n          return result;\\n        }\\n      }\\n      \\n      // Process individually\\n      const result = await processFn();\\n      \\n      // Cache result if enabled\\n      if (cache) {\\n        cache.setCached(operation, params, result);\\n      }\\n      \\n      // Memory optimization if enabled\\n      if (memoryOptimizer && memoryOptimizer.shouldOptimize()) {\\n        memoryOptimizer.optimizeMemory();\\n        state.metrics.memoryOptimizations++;\\n      }\\n      \\n      updateMetrics(startTime);\\n      return result;\\n      \\n    } catch (error) {\\n      updateMetrics(startTime);\\n      throw handleError(\\n        `Image processing failed for ${operation}: ${error.message}`,\\n        ErrorCategory.IMAGE_PROCESSING,\\n        ErrorSeverity.ERROR\\n      );\\n    }\\n  };\\n  \\n  const updateMetrics = (startTime) => {\\n    const processingTime = performance.now() - startTime;\\n    state.metrics.processedFrames++;\\n    state.metrics.totalProcessingTime += processingTime;\\n    state.metrics.averageProcessingTime = state.metrics.totalProcessingTime / state.metrics.processedFrames;\\n  };\\n  \\n  // Main processing operations\\n  const resize = async (imageData, targetWidth, targetHeight, method) => {\\n    return processWithEnhancements(\\n      'resize', \\n      { width: targetWidth, height: targetHeight, method: method || processorConfig.defaultInterpolation },\\n      () => resizeOps.resize(imageData, targetWidth, targetHeight, method)\\n    );\\n  };\\n  \\n  const convert = async (imageData, fromFormat, toFormat) => {\\n    return processWithEnhancements(\\n      'convert',\\n      { fromFormat, toFormat },\\n      () => colorOps.convertColorSpace(imageData, fromFormat, toFormat)\\n    );\\n  };\\n  \\n  const crop = async (imageData, x, y, width, height) => {\\n    return processWithEnhancements(\\n      'crop',\\n      { x, y, width, height },\\n      () => cropOps.crop(imageData, x, y, width, height)\\n    );\\n  };\\n  \\n  const applyFilter = async (imageData, filterType, params = {}) => {\\n    return processWithEnhancements(\\n      'filter',\\n      { filterType, ...params },\\n      () => filterOps.applyFilter(imageData, filterType, params)\\n    );\\n  };\\n  \\n  const normalize = async (imageData) => {\\n    return processWithEnhancements(\\n      'normalize',\\n      {},\\n      () => colorOps.normalize(imageData)\\n    );\\n  };\\n  \\n  const adjustBrightness = async (imageData, factor) => {\\n    return processWithEnhancements(\\n      'brightness',\\n      { factor },\\n      () => colorOps.adjustBrightness(imageData, factor)\\n    );\\n  };\\n  \\n  const adjustContrast = async (imageData, factor) => {\\n    return processWithEnhancements(\\n      'contrast',\\n      { factor },\\n      () => colorOps.adjustContrast(imageData, factor)\\n    );\\n  };\\n  \\n  // Batch processing interface\\n  const processBatch = async (operations) => {\\n    if (!batchProcessor) {\\n      // Process individually if batching disabled\\n      const results = [];\\n      for (const op of operations) {\\n        const result = await processOperation(op);\\n        results.push(result);\\n      }\\n      return results;\\n    }\\n    \\n    return await batchProcessor.processBatch(operations);\\n  };\\n  \\n  // Single operation processor for batch interface\\n  const processOperation = async (operation) => {\\n    const { type, imageData, params } = operation;\\n    \\n    switch (type) {\\n      case 'resize':\\n        return await resize(imageData, params.width, params.height, params.method);\\n      case 'convert':\\n        return await convert(imageData, params.fromFormat, params.toFormat);\\n      case 'crop':\\n        return await crop(imageData, params.x, params.y, params.width, params.height);\\n      case 'filter':\\n        return await applyFilter(imageData, params.filterType, params.filterParams);\\n      case 'normalize':\\n        return await normalize(imageData);\\n      case 'brightness':\\n        return await adjustBrightness(imageData, params.factor);\\n      case 'contrast':\\n        return await adjustContrast(imageData, params.factor);\\n      default:\\n        throw new Error(`Unknown operation type: ${type}`);\\n    }\\n  };\\n  \\n  // Metrics and diagnostics\\n  const getMetrics = () => {\\n    const metrics = { ...state.metrics };\\n    \\n    if (cache) {\\n      const cacheMetrics = cache.getMetrics();\\n      Object.assign(metrics, cacheMetrics);\\n    }\\n    \\n    if (batchProcessor) {\\n      const batchMetrics = batchProcessor.getMetrics();\\n      Object.assign(metrics, batchMetrics);\\n    }\\n    \\n    if (memoryOptimizer) {\\n      const memoryMetrics = memoryOptimizer.getMetrics();\\n      Object.assign(metrics, memoryMetrics);\\n    }\\n    \\n    return metrics;\\n  };\\n  \\n  const getStats = () => ({\\n    ...getMetrics(),\\n    cacheEnabled: !!cache,\\n    batchingEnabled: !!batchProcessor,\\n    memoryOptimizationEnabled: !!memoryOptimizer,\\n    config: processorConfig\\n  });\\n  \\n  // Resource cleanup\\n  const cleanup = async () => {\\n    if (cache?.cleanup) await cache.cleanup();\\n    if (batchProcessor?.cleanup) await batchProcessor.cleanup();\\n    if (memoryOptimizer?.cleanup) await memoryOptimizer.cleanup();\\n    if (resizeOps?.cleanup) await resizeOps.cleanup();\\n    if (colorOps?.cleanup) await colorOps.cleanup();\\n    if (filterOps?.cleanup) await filterOps.cleanup();\\n    if (cropOps?.cleanup) await cropOps.cleanup();\\n  };\\n  \\n  return {\\n    // Core operations\\n    resize,\\n    convert,\\n    crop,\\n    applyFilter,\\n    normalize,\\n    adjustBrightness,\\n    adjustContrast,\\n    \\n    // Batch processing\\n    processBatch,\\n    processOperation,\\n    \\n    // Utilities\\n    getMetrics,\\n    getStats,\\n    cleanup,\\n    \\n    // Component access for advanced usage\\n    operations: {\\n      resize: resizeOps,\\n      color: colorOps,\\n      filter: filterOps,\\n      crop: cropOps\\n    },\\n    \\n    cache,\\n    batchProcessor,\\n    memoryOptimizer\\n  };\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/core/engine/image-processing/operations/color-operations.js\",\"messages\":[{\"ruleId\":\"max-lines-per-function\",\"severity\":1,\"message\":\"Arrow function has too many lines (247). Maximum allowed is 150.\",\"line\":21,\"column\":38,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"exceed\",\"endLine\":349,\"endColumn\":2},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'opConfig' is assigned a value but never used. Allowed unused vars must match /^_/u.\",\"line\":22,\"column\":9,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":22,\"endColumn\":17,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"opConfig\"},\"fix\":{\"range\":[453,652],\"text\":\"\"},\"desc\":\"Remove unused variable 'opConfig'.\"}]},{\"ruleId\":\"no-param-reassign\",\"severity\":1,\"message\":\"Assignment to function parameter 'r'.\",\"line\":52,\"column\":7,\"nodeType\":\"Identifier\",\"messageId\":\"assignmentToFunctionParam\",\"endLine\":52,\"endColumn\":8},{\"ruleId\":\"no-param-reassign\",\"severity\":1,\"message\":\"Assignment to function parameter 'g'.\",\"line\":52,\"column\":17,\"nodeType\":\"Identifier\",\"messageId\":\"assignmentToFunctionParam\",\"endLine\":52,\"endColumn\":18},{\"ruleId\":\"no-param-reassign\",\"severity\":1,\"message\":\"Assignment to function parameter 'b'.\",\"line\":52,\"column\":27,\"nodeType\":\"Identifier\",\"messageId\":\"assignmentToFunctionParam\",\"endLine\":52,\"endColumn\":28},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '/' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":64,\"column\":32,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":64,\"endColumn\":33},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '/' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":64,\"column\":39,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":64,\"endColumn\":40},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '/' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":65,\"column\":32,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":65,\"endColumn\":33},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '/' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":65,\"column\":39,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":65,\"endColumn\":40},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '/' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":66,\"column\":32,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":66,\"endColumn\":33},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '/' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":66,\"column\":39,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":66,\"endColumn\":40},{\"ruleId\":\"no-param-reassign\",\"severity\":1,\"message\":\"Assignment to function parameter 'h'.\",\"line\":75,\"column\":7,\"nodeType\":\"Identifier\",\"messageId\":\"assignmentToFunctionParam\",\"endLine\":75,\"endColumn\":8},{\"ruleId\":\"no-param-reassign\",\"severity\":1,\"message\":\"Assignment to function parameter 's'.\",\"line\":75,\"column\":17,\"nodeType\":\"Identifier\",\"messageId\":\"assignmentToFunctionParam\",\"endLine\":75,\"endColumn\":18},{\"ruleId\":\"no-param-reassign\",\"severity\":1,\"message\":\"Assignment to function parameter 'v'.\",\"line\":75,\"column\":27,\"nodeType\":\"Identifier\",\"messageId\":\"assignmentToFunctionParam\",\"endLine\":75,\"endColumn\":28},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":119,\"column\":21,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":119,\"endColumn\":22},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":119,\"column\":34,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":119,\"endColumn\":35},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":119,\"column\":34,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":119,\"endColumn\":35},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":120,\"column\":25,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":120,\"endColumn\":26},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":120,\"column\":38,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":120,\"endColumn\":39},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":121,\"column\":25,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":121,\"endColumn\":26},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":260,\"column\":56,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":260,\"endColumn\":57},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":260,\"column\":74,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":260,\"endColumn\":75},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":261,\"column\":60,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":261,\"endColumn\":61},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":261,\"column\":82,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":261,\"endColumn\":83},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":262,\"column\":60,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":262,\"endColumn\":61},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":262,\"column\":82,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":262,\"endColumn\":83},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":295,\"column\":24,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":295,\"endColumn\":25},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":295,\"column\":37,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":295,\"endColumn\":38},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":295,\"column\":37,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":295,\"endColumn\":38},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":295,\"column\":41,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":295,\"endColumn\":42},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":295,\"column\":54,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":295,\"endColumn\":55},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":295,\"column\":58,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":295,\"endColumn\":59},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":298,\"column\":46,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":298,\"endColumn\":47},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":298,\"column\":55,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":298,\"endColumn\":56},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":299,\"column\":50,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":299,\"endColumn\":51},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":299,\"column\":59,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":299,\"endColumn\":60},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":300,\"column\":50,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":300,\"endColumn\":51},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":300,\"column\":59,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":300,\"endColumn\":60},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":320,\"column\":40,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":320,\"endColumn\":41},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":320,\"column\":57,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":320,\"endColumn\":58}],\"suppressedMessages\":[],\"errorCount\":1,\"fatalErrorCount\":0,\"warningCount\":39,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Color Space Operations\\n * Optimized color space conversions and adjustments\\n */\\n\\nimport { ErrorCategory, ErrorSeverity, handleError } from '../../../../shared/utils/error-handler.js';\\n\\nexport const COLOR_FORMATS = {\\n  RGB: 'rgb',\\n  RGBA: 'rgba',\\n  GRAYSCALE: 'grayscale',\\n  HSV: 'hsv',\\n  HSL: 'hsl',\\n  LAB: 'lab',\\n  YUV: 'yuv'\\n};\\n\\n/**\\n * Creates color operations module\\n */\\nexport const createColorOperations = (resourcePool, config = {}) => {\\n  const opConfig = {\\n    defaultFormat: config.defaultFormat || COLOR_FORMATS.RGBA,\\n    enableGammaCorrection: config.enableGammaCorrection !== false,\\n    gamma: config.gamma || 2.2,\\n    ...config\\n  };\\n\\n  const state = {\\n    metrics: {\\n      totalConversions: 0,\\n      totalAdjustments: 0,\\n      conversionTypes: {},\\n      avgProcessingTime: 0\\n    }\\n  };\\n\\n  // Color space conversion matrices and functions\\n  const colorMath = {\\n    // RGB to Grayscale conversion weights (ITU-R BT.709)\\n    grayscaleWeights: [0.2126, 0.7152, 0.0722],\\n    \\n    // Gamma correction\\n    applyGamma: (value, gamma) => Math.pow(value / 255, 1 / gamma) * 255,\\n    removeGamma: (value, gamma) => Math.pow(value / 255, gamma) * 255,\\n    \\n    // Clamp value to 0-255 range\\n    clamp: (value) => Math.max(0, Math.min(255, Math.round(value))),\\n    \\n    // RGB to HSV conversion\\n    rgbToHsv: (r, g, b) => {\\n      r /= 255; g /= 255; b /= 255;\\n      \\n      const max = Math.max(r, g, b);\\n      const min = Math.min(r, g, b);\\n      const diff = max - min;\\n      \\n      let h = 0;\\n      const s = max === 0 ? 0 : diff / max;\\n      const v = max;\\n      \\n      if (diff !== 0) {\\n        switch (max) {\\n          case r: h = ((g - b) / diff + (g < b ? 6 : 0)) / 6; break;\\n          case g: h = ((b - r) / diff + 2) / 6; break;\\n          case b: h = ((r - g) / diff + 4) / 6; break;\\n        }\\n      }\\n      \\n      return [h * 360, s * 100, v * 100];\\n    },\\n    \\n    // HSV to RGB conversion\\n    hsvToRgb: (h, s, v) => {\\n      h /= 360; s /= 100; v /= 100;\\n      \\n      const c = v * s;\\n      const x = c * (1 - Math.abs(((h * 6) % 2) - 1));\\n      const m = v - c;\\n      \\n      let r = 0, g = 0, b = 0;\\n      \\n      if (h < 1/6) { r = c; g = x; b = 0; }\\n      else if (h < 2/6) { r = x; g = c; b = 0; }\\n      else if (h < 3/6) { r = 0; g = c; b = x; }\\n      else if (h < 4/6) { r = 0; g = x; b = c; }\\n      else if (h < 5/6) { r = x; g = 0; b = c; }\\n      else { r = c; g = 0; b = x; }\\n      \\n      return [\\n        colorMath.clamp((r + m) * 255),\\n        colorMath.clamp((g + m) * 255),\\n        colorMath.clamp((b + m) * 255)\\n      ];\\n    }\\n  };\\n\\n  const convertColorSpace = async (imageData, fromFormat, toFormat) => {\\n    const startTime = performance.now();\\n    \\n    try {\\n      const { data, width, height } = imageData;\\n      \\n      if (fromFormat === toFormat) {\\n        return imageData;\\n      }\\n      \\n      let resultData;\\n      const conversionKey = `${fromFormat}->${toFormat}`;\\n      \\n      // RGB/RGBA to Grayscale\\n      if ((fromFormat === COLOR_FORMATS.RGB || fromFormat === COLOR_FORMATS.RGBA) && \\n          toFormat === COLOR_FORMATS.GRAYSCALE) {\\n        resultData = new Uint8ClampedArray(width * height * 4);\\n        const weights = colorMath.grayscaleWeights;\\n        \\n        for (let i = 0; i < data.length; i += 4) {\\n          const gray = colorMath.clamp(\\n            data[i] * weights[0] +     // R\\n            data[i + 1] * weights[1] + // G\\n            data[i + 2] * weights[2]   // B\\n          );\\n          \\n          resultData[i] = gray;     // R\\n          resultData[i + 1] = gray; // G\\n          resultData[i + 2] = gray; // B\\n          resultData[i + 3] = data[i + 3]; // A\\n        }\\n      }\\n      \\n      // RGB to RGBA (add alpha channel)\\n      else if (fromFormat === COLOR_FORMATS.RGB && toFormat === COLOR_FORMATS.RGBA) {\\n        resultData = new Uint8ClampedArray(width * height * 4);\\n        \\n        for (let i = 0; i < data.length; i += 3) {\\n          const outputIndex = (i / 3) * 4;\\n          resultData[outputIndex] = data[i];         // R\\n          resultData[outputIndex + 1] = data[i + 1]; // G\\n          resultData[outputIndex + 2] = data[i + 2]; // B\\n          resultData[outputIndex + 3] = 255;         // A (opaque)\\n        }\\n      }\\n      \\n      // RGBA to RGB (remove alpha channel)\\n      else if (fromFormat === COLOR_FORMATS.RGBA && toFormat === COLOR_FORMATS.RGB) {\\n        resultData = new Uint8ClampedArray(width * height * 3);\\n        \\n        for (let i = 0; i < data.length; i += 4) {\\n          const outputIndex = (i / 4) * 3;\\n          resultData[outputIndex] = data[i];         // R\\n          resultData[outputIndex + 1] = data[i + 1]; // G\\n          resultData[outputIndex + 2] = data[i + 2]; // B\\n        }\\n      }\\n      \\n      else {\\n        throw new Error(`Unsupported color space conversion: ${fromFormat} to ${toFormat}`);\\n      }\\n      \\n      // Update metrics\\n      const processingTime = performance.now() - startTime;\\n      state.metrics.totalConversions++;\\n      state.metrics.conversionTypes[conversionKey] = (state.metrics.conversionTypes[conversionKey] || 0) + 1;\\n      updateMetrics(processingTime);\\n      \\n      return new ImageData(resultData, width, height);\\n      \\n    } catch (error) {\\n      throw handleError(\\n        `Color space conversion failed: ${error.message}`,\\n        ErrorCategory.IMAGE_PROCESSING,\\n        ErrorSeverity.ERROR\\n      );\\n    }\\n  };\\n\\n  const normalize = async (imageData) => {\\n    const startTime = performance.now();\\n    \\n    try {\\n      const { data, width, height } = imageData;\\n      const resultData = new Uint8ClampedArray(data.length);\\n      \\n      // Find min and max values for each channel\\n      let minR = 255, maxR = 0, minG = 255, maxG = 0, minB = 255, maxB = 0;\\n      \\n      for (let i = 0; i < data.length; i += 4) {\\n        minR = Math.min(minR, data[i]);\\n        maxR = Math.max(maxR, data[i]);\\n        minG = Math.min(minG, data[i + 1]);\\n        maxG = Math.max(maxG, data[i + 1]);\\n        minB = Math.min(minB, data[i + 2]);\\n        maxB = Math.max(maxB, data[i + 2]);\\n      }\\n      \\n      // Calculate normalization factors\\n      const rangeR = maxR - minR || 1;\\n      const rangeG = maxG - minG || 1;\\n      const rangeB = maxB - minB || 1;\\n      \\n      // Apply normalization\\n      for (let i = 0; i < data.length; i += 4) {\\n        resultData[i] = colorMath.clamp(((data[i] - minR) / rangeR) * 255);         // R\\n        resultData[i + 1] = colorMath.clamp(((data[i + 1] - minG) / rangeG) * 255); // G\\n        resultData[i + 2] = colorMath.clamp(((data[i + 2] - minB) / rangeB) * 255); // B\\n        resultData[i + 3] = data[i + 3];                                             // A\\n      }\\n      \\n      updateMetrics(performance.now() - startTime);\\n      return new ImageData(resultData, width, height);\\n      \\n    } catch (error) {\\n      throw handleError(\\n        `Normalization failed: ${error.message}`,\\n        ErrorCategory.IMAGE_PROCESSING,\\n        ErrorSeverity.ERROR\\n      );\\n    }\\n  };\\n\\n  const adjustBrightness = async (imageData, factor) => {\\n    const startTime = performance.now();\\n    \\n    try {\\n      const { data, width, height } = imageData;\\n      const resultData = new Uint8ClampedArray(data.length);\\n      \\n      // Apply brightness adjustment\\n      for (let i = 0; i < data.length; i += 4) {\\n        resultData[i] = colorMath.clamp(data[i] * factor);         // R\\n        resultData[i + 1] = colorMath.clamp(data[i + 1] * factor); // G\\n        resultData[i + 2] = colorMath.clamp(data[i + 2] * factor); // B\\n        resultData[i + 3] = data[i + 3];                           // A\\n      }\\n      \\n      state.metrics.totalAdjustments++;\\n      updateMetrics(performance.now() - startTime);\\n      return new ImageData(resultData, width, height);\\n      \\n    } catch (error) {\\n      throw handleError(\\n        `Brightness adjustment failed: ${error.message}`,\\n        ErrorCategory.IMAGE_PROCESSING,\\n        ErrorSeverity.ERROR\\n      );\\n    }\\n  };\\n\\n  const adjustContrast = async (imageData, factor) => {\\n    const startTime = performance.now();\\n    \\n    try {\\n      const { data, width, height } = imageData;\\n      const resultData = new Uint8ClampedArray(data.length);\\n      \\n      const contrastFactor = (259 * (factor + 255)) / (255 * (259 - factor));\\n      \\n      // Apply contrast adjustment\\n      for (let i = 0; i < data.length; i += 4) {\\n        resultData[i] = colorMath.clamp(contrastFactor * (data[i] - 128) + 128);         // R\\n        resultData[i + 1] = colorMath.clamp(contrastFactor * (data[i + 1] - 128) + 128); // G\\n        resultData[i + 2] = colorMath.clamp(contrastFactor * (data[i + 2] - 128) + 128); // B\\n        resultData[i + 3] = data[i + 3];                                                 // A\\n      }\\n      \\n      state.metrics.totalAdjustments++;\\n      updateMetrics(performance.now() - startTime);\\n      return new ImageData(resultData, width, height);\\n      \\n    } catch (error) {\\n      throw handleError(\\n        `Contrast adjustment failed: ${error.message}`,\\n        ErrorCategory.IMAGE_PROCESSING,\\n        ErrorSeverity.ERROR\\n      );\\n    }\\n  };\\n\\n  const adjustSaturation = async (imageData, factor) => {\\n    const startTime = performance.now();\\n    \\n    try {\\n      const { data, width, height } = imageData;\\n      const resultData = new Uint8ClampedArray(data.length);\\n      \\n      const weights = colorMath.grayscaleWeights;\\n      \\n      // Apply saturation adjustment\\n      for (let i = 0; i < data.length; i += 4) {\\n        const r = data[i];\\n        const g = data[i + 1];\\n        const b = data[i + 2];\\n        \\n        // Calculate grayscale value\\n        const gray = r * weights[0] + g * weights[1] + b * weights[2];\\n        \\n        // Interpolate between grayscale and original color\\n        resultData[i] = colorMath.clamp(gray + factor * (r - gray));     // R\\n        resultData[i + 1] = colorMath.clamp(gray + factor * (g - gray)); // G\\n        resultData[i + 2] = colorMath.clamp(gray + factor * (b - gray)); // B\\n        resultData[i + 3] = data[i + 3];                                 // A\\n      }\\n      \\n      state.metrics.totalAdjustments++;\\n      updateMetrics(performance.now() - startTime);\\n      return new ImageData(resultData, width, height);\\n      \\n    } catch (error) {\\n      throw handleError(\\n        `Saturation adjustment failed: ${error.message}`,\\n        ErrorCategory.IMAGE_PROCESSING,\\n        ErrorSeverity.ERROR\\n      );\\n    }\\n  };\\n\\n  const updateMetrics = (processingTime) => {\\n    const totalOps = state.metrics.totalConversions + state.metrics.totalAdjustments;\\n    state.metrics.avgProcessingTime = \\n      (state.metrics.avgProcessingTime * (totalOps - 1) + processingTime) / totalOps;\\n  };\\n\\n  const getMetrics = () => ({ ...state.metrics });\\n\\n  const cleanup = async () => {\\n    state.metrics = {\\n      totalConversions: 0,\\n      totalAdjustments: 0,\\n      conversionTypes: {},\\n      avgProcessingTime: 0\\n    };\\n  };\\n\\n  return {\\n    convertColorSpace,\\n    normalize,\\n    adjustBrightness,\\n    adjustContrast,\\n    adjustSaturation,\\n    getMetrics,\\n    cleanup,\\n    \\n    // Constants\\n    COLOR_FORMATS,\\n    \\n    // Utility functions\\n    colorMath\\n  };\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/core/engine/image-processing/operations/crop-operations.js\",\"messages\":[{\"ruleId\":\"max-lines-per-function\",\"severity\":1,\"message\":\"Arrow function has too many lines (255). Maximum allowed is 150.\",\"line\":19,\"column\":37,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"exceed\",\"endLine\":369,\"endColumn\":2},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":120,\"column\":40,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":120,\"endColumn\":41},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":120,\"column\":53,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":120,\"endColumn\":54},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":121,\"column\":33,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":121,\"endColumn\":34},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":121,\"column\":46,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":121,\"endColumn\":47},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":136,\"column\":42,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":136,\"endColumn\":43},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":136,\"column\":75,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":136,\"endColumn\":76},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'data' is assigned a value but never used. Allowed unused vars must match /^_/u.\",\"line\":152,\"column\":13,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":152,\"endColumn\":17,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"data\"},\"fix\":{\"range\":[5168,5173],\"text\":\"\"},\"desc\":\"Remove unused variable 'data'.\"}]},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":189,\"column\":25,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":189,\"endColumn\":26},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":189,\"column\":38,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":189,\"endColumn\":39},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":200,\"column\":32,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":200,\"endColumn\":33},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":200,\"column\":45,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":200,\"endColumn\":46},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":201,\"column\":48,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":201,\"endColumn\":49},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":201,\"column\":61,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":201,\"endColumn\":62},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'data' is assigned a value but never used. Allowed unused vars must match /^_/u.\",\"line\":230,\"column\":13,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":230,\"endColumn\":17,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"data\"},\"fix\":{\"range\":[8198,8203],\"text\":\"\"},\"desc\":\"Remove unused variable 'data'.\"}]},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":263,\"column\":33,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":263,\"endColumn\":34},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":263,\"column\":46,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":263,\"endColumn\":47},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":264,\"column\":30,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":264,\"endColumn\":31},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":264,\"column\":43,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":264,\"endColumn\":44},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":272,\"column\":41,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":272,\"endColumn\":42},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":272,\"column\":54,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":272,\"endColumn\":55},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":273,\"column\":45,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":273,\"endColumn\":46},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":273,\"column\":58,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":273,\"endColumn\":59},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":284,\"column\":29,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":284,\"endColumn\":30},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":284,\"column\":42,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":284,\"endColumn\":43},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":285,\"column\":31,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":285,\"endColumn\":32},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":285,\"column\":44,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":285,\"endColumn\":45},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":293,\"column\":30,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":293,\"endColumn\":31},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":293,\"column\":43,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":293,\"endColumn\":44},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":294,\"column\":31,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":294,\"endColumn\":32},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":294,\"column\":44,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":294,\"endColumn\":45},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":314,\"column\":24,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":314,\"endColumn\":25},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":314,\"column\":32,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":314,\"endColumn\":33}],\"suppressedMessages\":[],\"errorCount\":2,\"fatalErrorCount\":0,\"warningCount\":31,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Image Crop Operations\\n * Optimized cropping with smart region detection and validation\\n */\\n\\nimport { ErrorCategory, ErrorSeverity, handleError } from '../../../../shared/utils/error-handler.js';\\n\\nexport const CROP_MODES = {\\n  EXACT: 'exact',           // Exact coordinates\\n  CENTER: 'center',         // Center crop to dimensions\\n  SMART: 'smart',           // Content-aware cropping\\n  FACE_FOCUS: 'face_focus', // Focus on detected faces\\n  EDGE_AWARE: 'edge_aware'  // Crop avoiding edges\\n};\\n\\n/**\\n * Creates crop operations module\\n */\\nexport const createCropOperations = (resourcePool, config = {}) => {\\n  const opConfig = {\\n    defaultMode: config.defaultMode || CROP_MODES.EXACT,\\n    enableSmartCrop: config.enableSmartCrop !== false,\\n    edgeThreshold: config.edgeThreshold || 50,\\n    minCropRatio: config.minCropRatio || 0.1,\\n    ...config\\n  };\\n\\n  const state = {\\n    metrics: {\\n      totalCrops: 0,\\n      cropModeUsage: {},\\n      avgProcessingTime: 0,\\n      smartCropHits: 0\\n    }\\n  };\\n\\n  // Initialize crop mode usage tracking\\n  Object.values(CROP_MODES).forEach(mode => {\\n    state.metrics.cropModeUsage[mode] = 0;\\n  });\\n\\n  const validateCropParams = (imageWidth, imageHeight, x, y, width, height) => {\\n    if (x < 0 || y < 0) {\\n      throw new Error('Crop coordinates cannot be negative');\\n    }\\n    \\n    if (width <= 0 || height <= 0) {\\n      throw new Error('Crop dimensions must be positive');\\n    }\\n    \\n    if (x + width > imageWidth || y + height > imageHeight) {\\n      throw new Error('Crop area extends beyond image boundaries');\\n    }\\n    \\n    const cropRatio = (width * height) / (imageWidth * imageHeight);\\n    if (cropRatio < opConfig.minCropRatio) {\\n      throw new Error(`Crop area too small (${(cropRatio * 100).toFixed(1)}% of image)`);\\n    }\\n  };\\n\\n  const crop = async (imageData, x, y, width, height, mode = opConfig.defaultMode) => {\\n    const startTime = performance.now();\\n    \\n    try {\\n      const { data: sourceData, width: imageWidth, height: imageHeight } = imageData;\\n      \\n      let finalX = x, finalY = y, finalWidth = width, finalHeight = height;\\n      \\n      // Apply crop mode transformations\\n      switch (mode) {\\n        case CROP_MODES.EXACT:\\n          // Use provided coordinates as-is\\n          break;\\n          \\n        case CROP_MODES.CENTER:\\n          // Center the crop area\\n          finalX = Math.floor((imageWidth - width) / 2);\\n          finalY = Math.floor((imageHeight - height) / 2);\\n          break;\\n          \\n        case CROP_MODES.SMART:\\n          if (opConfig.enableSmartCrop) {\\n            const smartRegion = findSmartCropRegion(imageData, width, height);\\n            finalX = smartRegion.x;\\n            finalY = smartRegion.y;\\n            finalWidth = smartRegion.width;\\n            finalHeight = smartRegion.height;\\n            state.metrics.smartCropHits++;\\n          }\\n          break;\\n          \\n        case CROP_MODES.FACE_FOCUS:\\n          // This would integrate with face detection\\n          // For now, fallback to center crop\\n          finalX = Math.floor((imageWidth - width) / 2);\\n          finalY = Math.floor((imageHeight - height) / 2);\\n          break;\\n          \\n        case CROP_MODES.EDGE_AWARE:\\n          const edgeAwareRegion = findEdgeAwareCropRegion(imageData, width, height);\\n          finalX = edgeAwareRegion.x;\\n          finalY = edgeAwareRegion.y;\\n          break;\\n          \\n        default:\\n          throw new Error(`Unknown crop mode: ${mode}`);\\n      }\\n      \\n      // Validate final crop parameters\\n      validateCropParams(imageWidth, imageHeight, finalX, finalY, finalWidth, finalHeight);\\n      \\n      // Perform the crop\\n      const croppedData = new Uint8ClampedArray(finalWidth * finalHeight * 4);\\n      \\n      for (let cy = 0; cy < finalHeight; cy++) {\\n        for (let cx = 0; cx < finalWidth; cx++) {\\n          const sourceX = finalX + cx;\\n          const sourceY = finalY + cy;\\n          \\n          const sourceIndex = (sourceY * imageWidth + sourceX) * 4;\\n          const destIndex = (cy * finalWidth + cx) * 4;\\n          \\n          // Copy RGBA values\\n          croppedData[destIndex] = sourceData[sourceIndex];         // R\\n          croppedData[destIndex + 1] = sourceData[sourceIndex + 1]; // G\\n          croppedData[destIndex + 2] = sourceData[sourceIndex + 2]; // B\\n          croppedData[destIndex + 3] = sourceData[sourceIndex + 3]; // A\\n        }\\n      }\\n      \\n      // Update metrics\\n      const processingTime = performance.now() - startTime;\\n      state.metrics.totalCrops++;\\n      state.metrics.cropModeUsage[mode] = (state.metrics.cropModeUsage[mode] || 0) + 1;\\n      state.metrics.avgProcessingTime = \\n        (state.metrics.avgProcessingTime * (state.metrics.totalCrops - 1) + processingTime) / \\n        state.metrics.totalCrops;\\n      \\n      return new ImageData(croppedData, finalWidth, finalHeight);\\n      \\n    } catch (error) {\\n      throw handleError(\\n        `Crop operation failed: ${error.message}`,\\n        ErrorCategory.IMAGE_PROCESSING,\\n        ErrorSeverity.ERROR\\n      );\\n    }\\n  };\\n\\n  // Smart crop: find the most interesting region\\n  const findSmartCropRegion = (imageData, targetWidth, targetHeight) => {\\n    const { data, width, height } = imageData;\\n    \\n    // Calculate interest scores for different regions\\n    const stepX = Math.max(1, Math.floor(width / 20));\\n    const stepY = Math.max(1, Math.floor(height / 20));\\n    \\n    let bestScore = -1;\\n    let bestRegion = { x: 0, y: 0, width: targetWidth, height: targetHeight };\\n    \\n    for (let y = 0; y <= height - targetHeight; y += stepY) {\\n      for (let x = 0; x <= width - targetWidth; x += stepX) {\\n        const score = calculateInterestScore(imageData, x, y, targetWidth, targetHeight);\\n        \\n        if (score > bestScore) {\\n          bestScore = score;\\n          bestRegion = { x, y, width: targetWidth, height: targetHeight };\\n        }\\n      }\\n    }\\n    \\n    return bestRegion;\\n  };\\n\\n  // Calculate interest score for a region\\n  const calculateInterestScore = (imageData, x, y, width, height) => {\\n    const { data, width: imageWidth } = imageData;\\n    \\n    let varianceSum = 0;\\n    let edgeCount = 0;\\n    let brightnessPenalty = 0;\\n    \\n    // Sample points in the region\\n    const sampleStep = Math.max(1, Math.floor(Math.min(width, height) / 10));\\n    const samples = [];\\n    \\n    for (let sy = y; sy < y + height; sy += sampleStep) {\\n      for (let sx = x; sx < x + width; sx += sampleStep) {\\n        const idx = (sy * imageWidth + sx) * 4;\\n        const brightness = (data[idx] + data[idx + 1] + data[idx + 2]) / 3;\\n        samples.push(brightness);\\n        \\n        // Penalty for very bright or very dark regions\\n        if (brightness < 20 || brightness > 235) {\\n          brightnessPenalty += 10;\\n        }\\n        \\n        // Simple edge detection\\n        if (sx < x + width - sampleStep && sy < y + height - sampleStep) {\\n          const rightIdx = (sy * imageWidth + (sx + sampleStep)) * 4;\\n          const bottomIdx = ((sy + sampleStep) * imageWidth + sx) * 4;\\n          \\n          const rightBrightness = (data[rightIdx] + data[rightIdx + 1] + data[rightIdx + 2]) / 3;\\n          const bottomBrightness = (data[bottomIdx] + data[bottomIdx + 1] + data[bottomIdx + 2]) / 3;\\n          \\n          if (Math.abs(brightness - rightBrightness) > opConfig.edgeThreshold ||\\n              Math.abs(brightness - bottomBrightness) > opConfig.edgeThreshold) {\\n            edgeCount++;\\n          }\\n        }\\n      }\\n    }\\n    \\n    // Calculate variance (measure of detail)\\n    if (samples.length > 1) {\\n      const mean = samples.reduce((sum, s) => sum + s, 0) / samples.length;\\n      varianceSum = samples.reduce((sum, s) => sum + Math.pow(s - mean, 2), 0) / samples.length;\\n    }\\n    \\n    // Combine metrics into interest score\\n    const varianceScore = Math.min(varianceSum / 100, 100); // Cap variance contribution\\n    const edgeScore = Math.min(edgeCount * 5, 100); // Edge density\\n    const penaltyScore = Math.min(brightnessPenalty, 50); // Brightness penalty\\n    \\n    return varianceScore + edgeScore - penaltyScore;\\n  };\\n\\n  // Edge-aware crop: avoid cropping through strong edges\\n  const findEdgeAwareCropRegion = (imageData, targetWidth, targetHeight) => {\\n    const { data, width, height } = imageData;\\n    \\n    // Find regions with minimal edge crossings at boundaries\\n    let bestScore = Infinity;\\n    let bestRegion = { x: 0, y: 0 };\\n    \\n    const stepSize = Math.max(1, Math.floor(Math.min(width, height) / 50));\\n    \\n    for (let y = 0; y <= height - targetHeight; y += stepSize) {\\n      for (let x = 0; x <= width - targetWidth; x += stepSize) {\\n        const edgeScore = calculateBoundaryEdgeScore(imageData, x, y, targetWidth, targetHeight);\\n        \\n        if (edgeScore < bestScore) {\\n          bestScore = edgeScore;\\n          bestRegion = { x, y };\\n        }\\n      }\\n    }\\n    \\n    return bestRegion;\\n  };\\n\\n  // Calculate edge crossings at crop boundaries\\n  const calculateBoundaryEdgeScore = (imageData, x, y, width, height) => {\\n    const { data, width: imageWidth } = imageData;\\n    \\n    let edgeScore = 0;\\n    const sampleStep = Math.max(1, Math.floor(Math.min(width, height) / 20));\\n    \\n    // Check top and bottom boundaries\\n    for (let sx = x; sx < x + width; sx += sampleStep) {\\n      // Top boundary\\n      if (y > 0) {\\n        const topIdx = ((y - 1) * imageWidth + sx) * 4;\\n        const insideIdx = (y * imageWidth + sx) * 4;\\n        const topBrightness = (data[topIdx] + data[topIdx + 1] + data[topIdx + 2]) / 3;\\n        const insideBrightness = (data[insideIdx] + data[insideIdx + 1] + data[insideIdx + 2]) / 3;\\n        edgeScore += Math.abs(topBrightness - insideBrightness);\\n      }\\n      \\n      // Bottom boundary\\n      if (y + height < imageWidth) {\\n        const bottomIdx = ((y + height) * imageWidth + sx) * 4;\\n        const insideIdx = ((y + height - 1) * imageWidth + sx) * 4;\\n        const bottomBrightness = (data[bottomIdx] + data[bottomIdx + 1] + data[bottomIdx + 2]) / 3;\\n        const insideBrightness = (data[insideIdx] + data[insideIdx + 1] + data[insideIdx + 2]) / 3;\\n        edgeScore += Math.abs(bottomBrightness - insideBrightness);\\n      }\\n    }\\n    \\n    // Check left and right boundaries\\n    for (let sy = y; sy < y + height; sy += sampleStep) {\\n      // Left boundary\\n      if (x > 0) {\\n        const leftIdx = (sy * imageWidth + (x - 1)) * 4;\\n        const insideIdx = (sy * imageWidth + x) * 4;\\n        const leftBrightness = (data[leftIdx] + data[leftIdx + 1] + data[leftIdx + 2]) / 3;\\n        const insideBrightness = (data[insideIdx] + data[insideIdx + 1] + data[insideIdx + 2]) / 3;\\n        edgeScore += Math.abs(leftBrightness - insideBrightness);\\n      }\\n      \\n      // Right boundary\\n      if (x + width < imageWidth) {\\n        const rightIdx = (sy * imageWidth + (x + width)) * 4;\\n        const insideIdx = (sy * imageWidth + (x + width - 1)) * 4;\\n        const rightBrightness = (data[rightIdx] + data[rightIdx + 1] + data[rightIdx + 2]) / 3;\\n        const insideBrightness = (data[insideIdx] + data[insideIdx + 1] + data[insideIdx + 2]) / 3;\\n        edgeScore += Math.abs(rightBrightness - insideBrightness);\\n      }\\n    }\\n    \\n    return edgeScore;\\n  };\\n\\n  // Utility function to auto-detect crop bounds\\n  const detectCropBounds = (imageData, threshold = 10) => {\\n    const { data, width, height } = imageData;\\n    \\n    let minX = width, maxX = 0, minY = height, maxY = 0;\\n    let hasContent = false;\\n    \\n    // Scan for non-background content\\n    for (let y = 0; y < height; y++) {\\n      for (let x = 0; x < width; x++) {\\n        const idx = (y * width + x) * 4;\\n        const brightness = (data[idx] + data[idx + 1] + data[idx + 2]) / 3;\\n        \\n        // Consider pixel as content if it's not near white or black\\n        if (brightness > threshold && brightness < 255 - threshold) {\\n          hasContent = true;\\n          minX = Math.min(minX, x);\\n          maxX = Math.max(maxX, x);\\n          minY = Math.min(minY, y);\\n          maxY = Math.max(maxY, y);\\n        }\\n      }\\n    }\\n    \\n    return hasContent ? {\\n      x: minX,\\n      y: minY,\\n      width: maxX - minX + 1,\\n      height: maxY - minY + 1\\n    } : {\\n      x: 0,\\n      y: 0,\\n      width,\\n      height\\n    };\\n  };\\n\\n  const getMetrics = () => ({ ...state.metrics });\\n\\n  const cleanup = async () => {\\n    state.metrics = {\\n      totalCrops: 0,\\n      cropModeUsage: {},\\n      avgProcessingTime: 0,\\n      smartCropHits: 0\\n    };\\n    \\n    Object.values(CROP_MODES).forEach(mode => {\\n      state.metrics.cropModeUsage[mode] = 0;\\n    });\\n  };\\n\\n  return {\\n    crop,\\n    detectCropBounds,\\n    getMetrics,\\n    cleanup,\\n    \\n    // Constants\\n    CROP_MODES,\\n    \\n    // Utility functions\\n    calculateInterestScore,\\n    findSmartCropRegion\\n  };\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/core/engine/image-processing/operations/filter-operations.js\",\"messages\":[{\"ruleId\":\"max-lines-per-function\",\"severity\":1,\"message\":\"Arrow function has too many lines (310). Maximum allowed is 150.\",\"line\":21,\"column\":39,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"exceed\",\"endLine\":430,\"endColumn\":2},{\"ruleId\":\"no-param-reassign\",\"severity\":1,\"message\":\"Assignment to function parameter 'size'.\",\"line\":85,\"column\":25,\"nodeType\":\"Identifier\",\"messageId\":\"assignmentToFunctionParam\",\"endLine\":85,\"endColumn\":29},{\"ruleId\":\"no-param-reassign\",\"severity\":1,\"message\":\"Assignment to function parameter 'sigma'.\",\"line\":86,\"column\":17,\"nodeType\":\"Identifier\",\"messageId\":\"assignmentToFunctionParam\",\"endLine\":86,\"endColumn\":22},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":97,\"column\":37,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":97,\"endColumn\":38},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":97,\"column\":42,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":97,\"endColumn\":43},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":97,\"column\":42,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":97,\"endColumn\":43},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":97,\"column\":47,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":97,\"endColumn\":48},{\"ruleId\":\"no-param-reassign\",\"severity\":1,\"message\":\"Assignment to function parameter 'size'.\",\"line\":115,\"column\":25,\"nodeType\":\"Identifier\",\"messageId\":\"assignmentToFunctionParam\",\"endLine\":115,\"endColumn\":29},{\"ruleId\":\"no-param-reassign\",\"severity\":1,\"message\":\"Assignment to function parameter 'sigma'.\",\"line\":116,\"column\":17,\"nodeType\":\"Identifier\",\"messageId\":\"assignmentToFunctionParam\",\"endLine\":116,\"endColumn\":22},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":151,\"column\":40,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":151,\"endColumn\":41},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":151,\"column\":48,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":151,\"endColumn\":49},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":160,\"column\":32,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":160,\"endColumn\":33},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":160,\"column\":40,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":160,\"endColumn\":41},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":185,\"column\":33,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":185,\"endColumn\":34},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":185,\"column\":41,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":185,\"endColumn\":42},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":193,\"column\":32,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":193,\"endColumn\":33},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":193,\"column\":40,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":193,\"endColumn\":41},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":210,\"column\":38,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":210,\"endColumn\":39},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":210,\"column\":46,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":210,\"endColumn\":47},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":218,\"column\":32,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":218,\"endColumn\":33},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":218,\"column\":40,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":218,\"endColumn\":41},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":290,\"column\":42,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":290,\"endColumn\":43},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":290,\"column\":77,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":290,\"endColumn\":78},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":313,\"column\":38,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":313,\"endColumn\":39},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":313,\"column\":43,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":313,\"endColumn\":44},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":313,\"column\":43,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":313,\"endColumn\":44},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":313,\"column\":48,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":313,\"endColumn\":49},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":340,\"column\":29,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":340,\"endColumn\":30},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":340,\"column\":37,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":340,\"endColumn\":38},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":354,\"column\":32,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":354,\"endColumn\":33},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":354,\"column\":40,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":354,\"endColumn\":41},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":373,\"column\":54,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":373,\"endColumn\":55},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":373,\"column\":58,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":373,\"endColumn\":59},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":388,\"column\":38,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":388,\"endColumn\":39},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":388,\"column\":47,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":388,\"endColumn\":48}],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":35,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Image Filter Operations\\n * Optimized image filters and convolution operations\\n */\\n\\nimport { ErrorCategory, ErrorSeverity, handleError } from '../../../../shared/utils/error-handler.js';\\n\\nexport const FILTER_TYPES = {\\n  BLUR: 'blur',\\n  GAUSSIAN_BLUR: 'gaussian_blur',\\n  SHARPEN: 'sharpen',\\n  EDGE_DETECT: 'edge_detect',\\n  EMBOSS: 'emboss',\\n  NOISE_REDUCTION: 'noise_reduction',\\n  UNSHARP_MASK: 'unsharp_mask'\\n};\\n\\n/**\\n * Creates filter operations module\\n */\\nexport const createFilterOperations = (resourcePool, config = {}) => {\\n  const opConfig = {\\n    defaultKernelSize: config.defaultKernelSize || 3,\\n    enableSeparableFilters: config.enableSeparableFilters !== false,\\n    maxKernelSize: config.maxKernelSize || 15,\\n    ...config\\n  };\\n\\n  const state = {\\n    metrics: {\\n      totalFilters: 0,\\n      filterUsage: {},\\n      avgProcessingTime: 0,\\n      separableOptimizations: 0\\n    }\\n  };\\n\\n  // Initialize filter usage tracking\\n  Object.values(FILTER_TYPES).forEach(filter => {\\n    state.metrics.filterUsage[filter] = 0;\\n  });\\n\\n  // Predefined convolution kernels\\n  const kernels = {\\n    blur3x3: [\\n      [1/9, 1/9, 1/9],\\n      [1/9, 1/9, 1/9],\\n      [1/9, 1/9, 1/9]\\n    ],\\n    \\n    sharpen3x3: [\\n      [ 0, -1,  0],\\n      [-1,  5, -1],\\n      [ 0, -1,  0]\\n    ],\\n    \\n    edgeDetect3x3: [\\n      [-1, -1, -1],\\n      [-1,  8, -1],\\n      [-1, -1, -1]\\n    ],\\n    \\n    emboss3x3: [\\n      [-2, -1,  0],\\n      [-1,  1,  1],\\n      [ 0,  1,  2]\\n    ],\\n    \\n    // Sobel operators for edge detection\\n    sobelX: [\\n      [-1,  0,  1],\\n      [-2,  0,  2],\\n      [-1,  0,  1]\\n    ],\\n    \\n    sobelY: [\\n      [-1, -2, -1],\\n      [ 0,  0,  0],\\n      [ 1,  2,  1]\\n    ]\\n  };\\n\\n  // Generate Gaussian kernel\\n  const generateGaussianKernel = (size, sigma = null) => {\\n    if (size % 2 === 0) size++; // Ensure odd size\\n    if (!sigma) sigma = size / 6; // Default sigma\\n    \\n    const kernel = [];\\n    const center = Math.floor(size / 2);\\n    let sum = 0;\\n    \\n    for (let y = 0; y < size; y++) {\\n      kernel[y] = [];\\n      for (let x = 0; x < size; x++) {\\n        const dx = x - center;\\n        const dy = y - center;\\n        const value = Math.exp(-(dx * dx + dy * dy) / (2 * sigma * sigma));\\n        kernel[y][x] = value;\\n        sum += value;\\n      }\\n    }\\n    \\n    // Normalize kernel\\n    for (let y = 0; y < size; y++) {\\n      for (let x = 0; x < size; x++) {\\n        kernel[y][x] /= sum;\\n      }\\n    }\\n    \\n    return kernel;\\n  };\\n\\n  // Generate 1D Gaussian kernel for separable filtering\\n  const generate1DGaussianKernel = (size, sigma = null) => {\\n    if (size % 2 === 0) size++; // Ensure odd size\\n    if (!sigma) sigma = size / 6;\\n    \\n    const kernel = [];\\n    const center = Math.floor(size / 2);\\n    let sum = 0;\\n    \\n    for (let i = 0; i < size; i++) {\\n      const dx = i - center;\\n      const value = Math.exp(-(dx * dx) / (2 * sigma * sigma));\\n      kernel[i] = value;\\n      sum += value;\\n    }\\n    \\n    // Normalize kernel\\n    return kernel.map(v => v / sum);\\n  };\\n\\n  // Apply convolution with kernel\\n  const applyConvolution = (imageData, kernel) => {\\n    const { data, width, height } = imageData;\\n    const resultData = new Uint8ClampedArray(data.length);\\n    \\n    const kernelSize = kernel.length;\\n    const kernelRadius = Math.floor(kernelSize / 2);\\n    \\n    for (let y = 0; y < height; y++) {\\n      for (let x = 0; x < width; x++) {\\n        let r = 0, g = 0, b = 0;\\n        \\n        // Apply kernel\\n        for (let ky = 0; ky < kernelSize; ky++) {\\n          for (let kx = 0; kx < kernelSize; kx++) {\\n            const pixelX = Math.min(width - 1, Math.max(0, x + kx - kernelRadius));\\n            const pixelY = Math.min(height - 1, Math.max(0, y + ky - kernelRadius));\\n            \\n            const pixelIndex = (pixelY * width + pixelX) * 4;\\n            const kernelValue = kernel[ky][kx];\\n            \\n            r += data[pixelIndex] * kernelValue;\\n            g += data[pixelIndex + 1] * kernelValue;\\n            b += data[pixelIndex + 2] * kernelValue;\\n          }\\n        }\\n        \\n        const resultIndex = (y * width + x) * 4;\\n        resultData[resultIndex] = Math.max(0, Math.min(255, Math.round(r)));\\n        resultData[resultIndex + 1] = Math.max(0, Math.min(255, Math.round(g)));\\n        resultData[resultIndex + 2] = Math.max(0, Math.min(255, Math.round(b)));\\n        resultData[resultIndex + 3] = data[resultIndex + 3]; // Preserve alpha\\n      }\\n    }\\n    \\n    return new ImageData(resultData, width, height);\\n  };\\n\\n  // Apply separable convolution (more efficient for Gaussian blur)\\n  const applySeparableConvolution = (imageData, kernel1D) => {\\n    const { data, width, height } = imageData;\\n    \\n    // First pass: horizontal\\n    const tempData = new Uint8ClampedArray(data.length);\\n    const kernelRadius = Math.floor(kernel1D.length / 2);\\n    \\n    for (let y = 0; y < height; y++) {\\n      for (let x = 0; x < width; x++) {\\n        let r = 0, g = 0, b = 0;\\n        \\n        for (let k = 0; k < kernel1D.length; k++) {\\n          const pixelX = Math.min(width - 1, Math.max(0, x + k - kernelRadius));\\n          const pixelIndex = (y * width + pixelX) * 4;\\n          const kernelValue = kernel1D[k];\\n          \\n          r += data[pixelIndex] * kernelValue;\\n          g += data[pixelIndex + 1] * kernelValue;\\n          b += data[pixelIndex + 2] * kernelValue;\\n        }\\n        \\n        const resultIndex = (y * width + x) * 4;\\n        tempData[resultIndex] = Math.max(0, Math.min(255, Math.round(r)));\\n        tempData[resultIndex + 1] = Math.max(0, Math.min(255, Math.round(g)));\\n        tempData[resultIndex + 2] = Math.max(0, Math.min(255, Math.round(b)));\\n        tempData[resultIndex + 3] = data[resultIndex + 3];\\n      }\\n    }\\n    \\n    // Second pass: vertical\\n    const resultData = new Uint8ClampedArray(data.length);\\n    \\n    for (let y = 0; y < height; y++) {\\n      for (let x = 0; x < width; x++) {\\n        let r = 0, g = 0, b = 0;\\n        \\n        for (let k = 0; k < kernel1D.length; k++) {\\n          const pixelY = Math.min(height - 1, Math.max(0, y + k - kernelRadius));\\n          const pixelIndex = (pixelY * width + x) * 4;\\n          const kernelValue = kernel1D[k];\\n          \\n          r += tempData[pixelIndex] * kernelValue;\\n          g += tempData[pixelIndex + 1] * kernelValue;\\n          b += tempData[pixelIndex + 2] * kernelValue;\\n        }\\n        \\n        const resultIndex = (y * width + x) * 4;\\n        resultData[resultIndex] = Math.max(0, Math.min(255, Math.round(r)));\\n        resultData[resultIndex + 1] = Math.max(0, Math.min(255, Math.round(g)));\\n        resultData[resultIndex + 2] = Math.max(0, Math.min(255, Math.round(b)));\\n        resultData[resultIndex + 3] = tempData[resultIndex + 3];\\n      }\\n    }\\n    \\n    state.metrics.separableOptimizations++;\\n    return new ImageData(resultData, width, height);\\n  };\\n\\n  const applyFilter = async (imageData, filterType, params = {}) => {\\n    const startTime = performance.now();\\n    \\n    try {\\n      let result;\\n      \\n      switch (filterType) {\\n        case FILTER_TYPES.BLUR:\\n          result = applyConvolution(imageData, kernels.blur3x3);\\n          break;\\n          \\n        case FILTER_TYPES.GAUSSIAN_BLUR:\\n          const blurSize = params.size || 5;\\n          const blurSigma = params.sigma || null;\\n          \\n          if (opConfig.enableSeparableFilters) {\\n            const kernel1D = generate1DGaussianKernel(blurSize, blurSigma);\\n            result = applySeparableConvolution(imageData, kernel1D);\\n          } else {\\n            const kernel2D = generateGaussianKernel(blurSize, blurSigma);\\n            result = applyConvolution(imageData, kernel2D);\\n          }\\n          break;\\n          \\n        case FILTER_TYPES.SHARPEN:\\n          result = applyConvolution(imageData, kernels.sharpen3x3);\\n          break;\\n          \\n        case FILTER_TYPES.EDGE_DETECT:\\n          if (params.method === 'sobel') {\\n            // Apply both Sobel operators and combine\\n            const sobelX = applyConvolution(imageData, kernels.sobelX);\\n            const sobelY = applyConvolution(imageData, kernels.sobelY);\\n            result = combineSobelResults(sobelX, sobelY);\\n          } else {\\n            result = applyConvolution(imageData, kernels.edgeDetect3x3);\\n          }\\n          break;\\n          \\n        case FILTER_TYPES.EMBOSS:\\n          result = applyConvolution(imageData, kernels.emboss3x3);\\n          break;\\n          \\n        case FILTER_TYPES.NOISE_REDUCTION:\\n          result = applyMedianFilter(imageData, params.size || 3);\\n          break;\\n          \\n        case FILTER_TYPES.UNSHARP_MASK:\\n          result = applyUnsharpMask(imageData, params);\\n          break;\\n          \\n        default:\\n          throw new Error(`Unknown filter type: ${filterType}`);\\n      }\\n      \\n      // Update metrics\\n      const processingTime = performance.now() - startTime;\\n      state.metrics.totalFilters++;\\n      state.metrics.filterUsage[filterType] = (state.metrics.filterUsage[filterType] || 0) + 1;\\n      state.metrics.avgProcessingTime = \\n        (state.metrics.avgProcessingTime * (state.metrics.totalFilters - 1) + processingTime) / \\n        state.metrics.totalFilters;\\n      \\n      return result;\\n      \\n    } catch (error) {\\n      throw handleError(\\n        `Filter operation failed: ${error.message}`,\\n        ErrorCategory.IMAGE_PROCESSING,\\n        ErrorSeverity.ERROR\\n      );\\n    }\\n  };\\n\\n  // Combine Sobel X and Y results\\n  const combineSobelResults = (sobelX, sobelY) => {\\n    const { data: dataX, width, height } = sobelX;\\n    const { data: dataY } = sobelY;\\n    const resultData = new Uint8ClampedArray(dataX.length);\\n    \\n    for (let i = 0; i < dataX.length; i += 4) {\\n      const gx = (dataX[i] + dataX[i + 1] + dataX[i + 2]) / 3;\\n      const gy = (dataY[i] + dataY[i + 1] + dataY[i + 2]) / 3;\\n      const magnitude = Math.sqrt(gx * gx + gy * gy);\\n      \\n      const value = Math.max(0, Math.min(255, magnitude));\\n      resultData[i] = value;\\n      resultData[i + 1] = value;\\n      resultData[i + 2] = value;\\n      resultData[i + 3] = dataX[i + 3];\\n    }\\n    \\n    return new ImageData(resultData, width, height);\\n  };\\n\\n  // Median filter for noise reduction\\n  const applyMedianFilter = (imageData, kernelSize) => {\\n    const { data, width, height } = imageData;\\n    const resultData = new Uint8ClampedArray(data.length);\\n    const radius = Math.floor(kernelSize / 2);\\n    \\n    for (let y = 0; y < height; y++) {\\n      for (let x = 0; x < width; x++) {\\n        const rValues = [], gValues = [], bValues = [];\\n        \\n        // Collect neighborhood values\\n        for (let dy = -radius; dy <= radius; dy++) {\\n          for (let dx = -radius; dx <= radius; dx++) {\\n            const nx = Math.min(width - 1, Math.max(0, x + dx));\\n            const ny = Math.min(height - 1, Math.max(0, y + dy));\\n            const idx = (ny * width + nx) * 4;\\n            \\n            rValues.push(data[idx]);\\n            gValues.push(data[idx + 1]);\\n            bValues.push(data[idx + 2]);\\n          }\\n        }\\n        \\n        // Find median values\\n        rValues.sort((a, b) => a - b);\\n        gValues.sort((a, b) => a - b);\\n        bValues.sort((a, b) => a - b);\\n        \\n        const medianIndex = Math.floor(rValues.length / 2);\\n        const resultIndex = (y * width + x) * 4;\\n        \\n        resultData[resultIndex] = rValues[medianIndex];\\n        resultData[resultIndex + 1] = gValues[medianIndex];\\n        resultData[resultIndex + 2] = bValues[medianIndex];\\n        resultData[resultIndex + 3] = data[resultIndex + 3];\\n      }\\n    }\\n    \\n    return new ImageData(resultData, width, height);\\n  };\\n\\n  // Unsharp mask filter\\n  const applyUnsharpMask = (imageData, params = {}) => {\\n    const amount = params.amount || 1.5;\\n    const radius = params.radius || 1;\\n    const threshold = params.threshold || 0;\\n    \\n    // Create blurred version\\n    const kernel1D = generate1DGaussianKernel(radius * 4 + 1, radius);\\n    const blurred = applySeparableConvolution(imageData, kernel1D);\\n    \\n    const { data: originalData, width, height } = imageData;\\n    const { data: blurredData } = blurred;\\n    const resultData = new Uint8ClampedArray(originalData.length);\\n    \\n    for (let i = 0; i < originalData.length; i += 4) {\\n      for (let c = 0; c < 3; c++) { // RGB channels\\n        const original = originalData[i + c];\\n        const blur = blurredData[i + c];\\n        const diff = original - blur;\\n        \\n        // Apply threshold\\n        if (Math.abs(diff) >= threshold) {\\n          const sharpened = original + amount * diff;\\n          resultData[i + c] = Math.max(0, Math.min(255, Math.round(sharpened)));\\n        } else {\\n          resultData[i + c] = original;\\n        }\\n      }\\n      resultData[i + 3] = originalData[i + 3]; // Alpha\\n    }\\n    \\n    return new ImageData(resultData, width, height);\\n  };\\n\\n  const getMetrics = () => ({ ...state.metrics });\\n\\n  const cleanup = async () => {\\n    state.metrics = {\\n      totalFilters: 0,\\n      filterUsage: {},\\n      avgProcessingTime: 0,\\n      separableOptimizations: 0\\n    };\\n    \\n    Object.values(FILTER_TYPES).forEach(filter => {\\n      state.metrics.filterUsage[filter] = 0;\\n    });\\n  };\\n\\n  return {\\n    applyFilter,\\n    getMetrics,\\n    cleanup,\\n    \\n    // Constants\\n    FILTER_TYPES,\\n    \\n    // Utility functions\\n    generateGaussianKernel,\\n    generate1DGaussianKernel,\\n    \\n    // Direct kernel access\\n    kernels\\n  };\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/core/engine/image-processing/operations/resize-operations.js\",\"messages\":[{\"ruleId\":\"max-lines-per-function\",\"severity\":1,\"message\":\"Arrow function has too many lines (235). Maximum allowed is 150.\",\"line\":18,\"column\":39,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"exceed\",\"endLine\":331,\"endColumn\":2},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":89,\"column\":32,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":89,\"endColumn\":33},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":89,\"column\":40,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":89,\"endColumn\":41},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":90,\"column\":30,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":90,\"endColumn\":31},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":90,\"column\":44,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":90,\"endColumn\":45},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":123,\"column\":30,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":123,\"endColumn\":31},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":123,\"column\":44,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":123,\"endColumn\":45},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":127,\"column\":31,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":127,\"endColumn\":32},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":127,\"column\":39,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":127,\"endColumn\":40},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":127,\"column\":45,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":127,\"endColumn\":46},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":127,\"column\":49,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":127,\"endColumn\":50},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":128,\"column\":31,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":128,\"endColumn\":32},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":128,\"column\":39,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":128,\"endColumn\":40},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":128,\"column\":45,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":128,\"endColumn\":46},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":128,\"column\":49,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":128,\"endColumn\":50},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":129,\"column\":31,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":129,\"endColumn\":32},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":129,\"column\":39,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":129,\"endColumn\":40},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":129,\"column\":45,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":129,\"endColumn\":46},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":129,\"column\":49,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":129,\"endColumn\":50},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":130,\"column\":31,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":130,\"endColumn\":32},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":130,\"column\":39,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":130,\"endColumn\":40},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":130,\"column\":45,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":130,\"endColumn\":46},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":130,\"column\":49,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":130,\"endColumn\":50},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":132,\"column\":26,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":132,\"endColumn\":27},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":132,\"column\":42,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":132,\"endColumn\":43},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":132,\"column\":42,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":132,\"endColumn\":43},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":132,\"column\":47,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":132,\"endColumn\":48},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":133,\"column\":29,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":133,\"endColumn\":30},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":133,\"column\":45,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":133,\"endColumn\":46},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":133,\"column\":45,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":133,\"endColumn\":46},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":133,\"column\":50,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":133,\"endColumn\":51},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":134,\"column\":30,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":134,\"endColumn\":31},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":134,\"column\":46,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":134,\"endColumn\":47},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":134,\"column\":46,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":134,\"endColumn\":47},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":134,\"column\":55,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":134,\"endColumn\":56},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '-'. Use parentheses to clarify the intended order of operations.\",\"line\":158,\"column\":24,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":158,\"endColumn\":25},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '-'. Use parentheses to clarify the intended order of operations.\",\"line\":158,\"column\":44,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":158,\"endColumn\":45},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":158,\"column\":44,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":158,\"endColumn\":45},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":158,\"column\":54,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":158,\"endColumn\":55},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '-'. Use parentheses to clarify the intended order of operations.\",\"line\":160,\"column\":18,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":160,\"endColumn\":19},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '-'. Use parentheses to clarify the intended order of operations.\",\"line\":160,\"column\":38,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":160,\"endColumn\":39},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":160,\"column\":38,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":160,\"endColumn\":39},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":160,\"column\":46,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":160,\"endColumn\":47},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":160,\"column\":66,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":160,\"endColumn\":67},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":160,\"column\":74,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":160,\"endColumn\":75},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":160,\"column\":81,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":160,\"endColumn\":82},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":160,\"column\":85,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":160,\"endColumn\":86},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":173,\"column\":30,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":173,\"endColumn\":31},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":173,\"column\":44,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":173,\"endColumn\":45},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":187,\"column\":44,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":187,\"endColumn\":45},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":187,\"column\":52,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":187,\"endColumn\":53},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":187,\"column\":63,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":187,\"endColumn\":64},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":187,\"column\":67,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":187,\"endColumn\":68},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":250,\"column\":42,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":250,\"endColumn\":43},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":250,\"column\":77,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":250,\"endColumn\":78}],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":55,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Image Resize Operations\\n * Optimized resize algorithms with multiple interpolation methods\\n */\\n\\nimport { ErrorCategory, ErrorSeverity, handleError } from '../../../../shared/utils/error-handler.js';\\n\\nexport const INTERPOLATION_METHODS = {\\n  NEAREST: 'nearest',\\n  BILINEAR: 'bilinear',\\n  BICUBIC: 'bicubic',\\n  LANCZOS: 'lanczos'\\n};\\n\\n/**\\n * Creates resize operations module\\n */\\nexport const createResizeOperations = (resourcePool, config = {}) => {\\n  const opConfig = {\\n    defaultMethod: config.defaultInterpolation || INTERPOLATION_METHODS.BILINEAR,\\n    enableGPUAcceleration: config.enableGPUAcceleration || false,\\n    preserveAspectRatio: config.preserveAspectRatio || false,\\n    ...config\\n  };\\n\\n  const state = {\\n    metrics: {\\n      totalResizes: 0,\\n      avgProcessingTime: 0,\\n      methodUsage: {}\\n    }\\n  };\\n\\n  // Initialize method usage tracking\\n  Object.values(INTERPOLATION_METHODS).forEach(method => {\\n    state.metrics.methodUsage[method] = 0;\\n  });\\n\\n  const validateDimensions = (width, height, targetWidth, targetHeight) => {\\n    if (!width || !height || !targetWidth || !targetHeight) {\\n      throw new Error('Invalid dimensions provided');\\n    }\\n    \\n    if (width <= 0 || height <= 0 || targetWidth <= 0 || targetHeight <= 0) {\\n      throw new Error('Dimensions must be positive numbers');\\n    }\\n    \\n    if (targetWidth > 8192 || targetHeight > 8192) {\\n      throw new Error('Target dimensions exceed maximum supported size (8192x8192)');\\n    }\\n  };\\n\\n  const calculateAspectRatio = (width, height, targetWidth, targetHeight) => {\\n    if (!opConfig.preserveAspectRatio) {\\n      return { width: targetWidth, height: targetHeight };\\n    }\\n\\n    const aspectRatio = width / height;\\n    const targetAspectRatio = targetWidth / targetHeight;\\n\\n    if (aspectRatio > targetAspectRatio) {\\n      // Image is wider than target\\n      return {\\n        width: targetWidth,\\n        height: Math.round(targetWidth / aspectRatio)\\n      };\\n    } else {\\n      // Image is taller than target\\n      return {\\n        width: Math.round(targetHeight * aspectRatio),\\n        height: targetHeight\\n      };\\n    }\\n  };\\n\\n  // Nearest neighbor interpolation (fastest)\\n  const resizeNearest = (imageData, targetWidth, targetHeight) => {\\n    const { data, width, height } = imageData;\\n    const targetData = new Uint8ClampedArray(targetWidth * targetHeight * 4);\\n\\n    const xRatio = width / targetWidth;\\n    const yRatio = height / targetHeight;\\n\\n    for (let y = 0; y < targetHeight; y++) {\\n      for (let x = 0; x < targetWidth; x++) {\\n        const srcX = Math.floor(x * xRatio);\\n        const srcY = Math.floor(y * yRatio);\\n        \\n        const srcIndex = (srcY * width + srcX) * 4;\\n        const destIndex = (y * targetWidth + x) * 4;\\n        \\n        targetData[destIndex] = data[srcIndex];         // R\\n        targetData[destIndex + 1] = data[srcIndex + 1]; // G\\n        targetData[destIndex + 2] = data[srcIndex + 2]; // B\\n        targetData[destIndex + 3] = data[srcIndex + 3]; // A\\n      }\\n    }\\n\\n    return new ImageData(targetData, targetWidth, targetHeight);\\n  };\\n\\n  // Bilinear interpolation (good quality/speed balance)\\n  const resizeBilinear = (imageData, targetWidth, targetHeight) => {\\n    const { data, width, height } = imageData;\\n    const targetData = new Uint8ClampedArray(targetWidth * targetHeight * 4);\\n\\n    const xRatio = (width - 1) / targetWidth;\\n    const yRatio = (height - 1) / targetHeight;\\n\\n    for (let y = 0; y < targetHeight; y++) {\\n      for (let x = 0; x < targetWidth; x++) {\\n        const srcX = x * xRatio;\\n        const srcY = y * yRatio;\\n        \\n        const x1 = Math.floor(srcX);\\n        const y1 = Math.floor(srcY);\\n        const x2 = Math.min(x1 + 1, width - 1);\\n        const y2 = Math.min(y1 + 1, height - 1);\\n        \\n        const xWeight = srcX - x1;\\n        const yWeight = srcY - y1;\\n        \\n        const destIndex = (y * targetWidth + x) * 4;\\n        \\n        // Bilinear interpolation for each channel\\n        for (let c = 0; c < 4; c++) {\\n          const tl = data[(y1 * width + x1) * 4 + c]; // Top-left\\n          const tr = data[(y1 * width + x2) * 4 + c]; // Top-right\\n          const bl = data[(y2 * width + x1) * 4 + c]; // Bottom-left\\n          const br = data[(y2 * width + x2) * 4 + c]; // Bottom-right\\n          \\n          const top = tl * (1 - xWeight) + tr * xWeight;\\n          const bottom = bl * (1 - xWeight) + br * xWeight;\\n          const result = top * (1 - yWeight) + bottom * yWeight;\\n          \\n          targetData[destIndex + c] = Math.round(result);\\n        }\\n      }\\n    }\\n\\n    return new ImageData(targetData, targetWidth, targetHeight);\\n  };\\n\\n  // Bicubic interpolation (highest quality, slower)\\n  const resizeBicubic = (imageData, targetWidth, targetHeight) => {\\n    const { data, width, height } = imageData;\\n    const targetData = new Uint8ClampedArray(targetWidth * targetHeight * 4);\\n\\n    const xRatio = width / targetWidth;\\n    const yRatio = height / targetHeight;\\n\\n    // Bicubic kernel function\\n    const bicubicKernel = (t) => {\\n      const a = -0.5;\\n      const absT = Math.abs(t);\\n      \\n      if (absT <= 1) {\\n        return (a + 2) * Math.pow(absT, 3) - (a + 3) * Math.pow(absT, 2) + 1;\\n      } else if (absT <= 2) {\\n        return a * Math.pow(absT, 3) - 5 * a * Math.pow(absT, 2) + 8 * a * absT - 4 * a;\\n      }\\n      return 0;\\n    };\\n\\n    for (let y = 0; y < targetHeight; y++) {\\n      for (let x = 0; x < targetWidth; x++) {\\n        const srcX = x * xRatio;\\n        const srcY = y * yRatio;\\n        \\n        const x1 = Math.floor(srcX);\\n        const y1 = Math.floor(srcY);\\n        \\n        const destIndex = (y * targetWidth + x) * 4;\\n        \\n        // Bicubic interpolation for each channel\\n        for (let c = 0; c < 4; c++) {\\n          let result = 0;\\n          let weightSum = 0;\\n          \\n          // Sample 4x4 neighborhood\\n          for (let dy = -1; dy <= 2; dy++) {\\n            for (let dx = -1; dx <= 2; dx++) {\\n              const sampleX = Math.max(0, Math.min(width - 1, x1 + dx));\\n              const sampleY = Math.max(0, Math.min(height - 1, y1 + dy));\\n              \\n              const weight = bicubicKernel(srcX - sampleX) * bicubicKernel(srcY - sampleY);\\n              const sample = data[(sampleY * width + sampleX) * 4 + c];\\n              \\n              result += weight * sample;\\n              weightSum += weight;\\n            }\\n          }\\n          \\n          targetData[destIndex + c] = Math.max(0, Math.min(255, Math.round(result / Math.max(weightSum, 1e-8))));\\n        }\\n      }\\n    }\\n\\n    return new ImageData(targetData, targetWidth, targetHeight);\\n  };\\n\\n  // Main resize function with method selection\\n  const resize = async (imageData, targetWidth, targetHeight, method = opConfig.defaultMethod) => {\\n    const startTime = performance.now();\\n    \\n    try {\\n      validateDimensions(imageData.width, imageData.height, targetWidth, targetHeight);\\n      \\n      // Adjust dimensions if preserving aspect ratio\\n      const adjustedDimensions = calculateAspectRatio(\\n        imageData.width, \\n        imageData.height, \\n        targetWidth, \\n        targetHeight\\n      );\\n      \\n      const finalWidth = adjustedDimensions.width;\\n      const finalHeight = adjustedDimensions.height;\\n      \\n      // Skip processing if dimensions are the same\\n      if (imageData.width === finalWidth && imageData.height === finalHeight) {\\n        return imageData;\\n      }\\n\\n      let result;\\n      \\n      // Select resize algorithm\\n      switch (method) {\\n        case INTERPOLATION_METHODS.NEAREST:\\n          result = resizeNearest(imageData, finalWidth, finalHeight);\\n          break;\\n        case INTERPOLATION_METHODS.BILINEAR:\\n          result = resizeBilinear(imageData, finalWidth, finalHeight);\\n          break;\\n        case INTERPOLATION_METHODS.BICUBIC:\\n          result = resizeBicubic(imageData, finalWidth, finalHeight);\\n          break;\\n        case INTERPOLATION_METHODS.LANCZOS:\\n          // Fallback to bicubic for now (Lanczos requires more complex implementation)\\n          result = resizeBicubic(imageData, finalWidth, finalHeight);\\n          break;\\n        default:\\n          throw new Error(`Unknown interpolation method: ${method}`);\\n      }\\n      \\n      // Update metrics\\n      const processingTime = performance.now() - startTime;\\n      state.metrics.totalResizes++;\\n      state.metrics.avgProcessingTime = \\n        (state.metrics.avgProcessingTime * (state.metrics.totalResizes - 1) + processingTime) / \\n        state.metrics.totalResizes;\\n      state.metrics.methodUsage[method] = (state.metrics.methodUsage[method] || 0) + 1;\\n      \\n      return result;\\n      \\n    } catch (error) {\\n      throw handleError(\\n        `Resize operation failed: ${error.message}`,\\n        ErrorCategory.IMAGE_PROCESSING,\\n        ErrorSeverity.ERROR\\n      );\\n    }\\n  };\\n\\n  // Utility functions\\n  const getOptimalMethod = (sourceSize, targetSize, qualityPreference = 'balanced') => {\\n    const scaleFactor = Math.min(targetSize.width / sourceSize.width, targetSize.height / sourceSize.height);\\n    \\n    // Choose method based on scale factor and quality preference\\n    if (qualityPreference === 'speed') {\\n      return INTERPOLATION_METHODS.NEAREST;\\n    } else if (qualityPreference === 'quality') {\\n      return scaleFactor < 0.5 ? INTERPOLATION_METHODS.BICUBIC : INTERPOLATION_METHODS.BILINEAR;\\n    } else { // balanced\\n      return scaleFactor > 2 || scaleFactor < 0.5 ? INTERPOLATION_METHODS.BILINEAR : INTERPOLATION_METHODS.BILINEAR;\\n    }\\n  };\\n\\n  const calculateOptimalDimensions = (sourceWidth, sourceHeight, maxWidth, maxHeight, preserveAspect = true) => {\\n    if (!preserveAspect) {\\n      return { width: maxWidth, height: maxHeight };\\n    }\\n\\n    const aspectRatio = sourceWidth / sourceHeight;\\n    \\n    if (sourceWidth > sourceHeight) {\\n      return {\\n        width: Math.min(maxWidth, sourceWidth),\\n        height: Math.min(maxHeight, Math.round(Math.min(maxWidth, sourceWidth) / aspectRatio))\\n      };\\n    } else {\\n      return {\\n        width: Math.min(maxWidth, Math.round(Math.min(maxHeight, sourceHeight) * aspectRatio)),\\n        height: Math.min(maxHeight, sourceHeight)\\n      };\\n    }\\n  };\\n\\n  const getMetrics = () => ({ ...state.metrics });\\n\\n  const cleanup = async () => {\\n    // Reset metrics\\n    state.metrics = {\\n      totalResizes: 0,\\n      avgProcessingTime: 0,\\n      methodUsage: {}\\n    };\\n    \\n    Object.values(INTERPOLATION_METHODS).forEach(method => {\\n      state.metrics.methodUsage[method] = 0;\\n    });\\n  };\\n\\n  return {\\n    resize,\\n    getOptimalMethod,\\n    calculateOptimalDimensions,\\n    getMetrics,\\n    cleanup,\\n    \\n    // Constants\\n    INTERPOLATION_METHODS,\\n    \\n    // Individual algorithm access (for advanced usage)\\n    algorithms: {\\n      nearest: resizeNearest,\\n      bilinear: resizeBilinear,\\n      bicubic: resizeBicubic\\n    }\\n  };\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/core/engine/image-processor.js\",\"messages\":[{\"ruleId\":\"max-lines-per-function\",\"severity\":1,\"message\":\"Arrow function has too many lines (393). Maximum allowed is 150.\",\"line\":17,\"column\":37,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"exceed\",\"endLine\":592,\"endColumn\":2},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'resize' is assigned a value but never used. Allowed unused vars must match /^_/u.\",\"line\":64,\"column\":9,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":64,\"endColumn\":15,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"resize\"},\"fix\":{\"range\":[2139,2450],\"text\":\"\"},\"desc\":\"Remove unused variable 'resize'.\"}]},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'convert' is assigned a value but never used. Allowed unused vars must match /^_/u.\",\"line\":72,\"column\":9,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":72,\"endColumn\":16,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"convert\"},\"fix\":{\"range\":[2456,2680],\"text\":\"\"},\"desc\":\"Remove unused variable 'convert'.\"}]},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'crop' is assigned a value but never used. Allowed unused vars must match /^_/u.\",\"line\":80,\"column\":9,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":80,\"endColumn\":13,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"crop\"},\"fix\":{\"range\":[2686,2893],\"text\":\"\"},\"desc\":\"Remove unused variable 'crop'.\"}]},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'filter' is assigned a value but never used. Allowed unused vars must match /^_/u.\",\"line\":88,\"column\":9,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":88,\"endColumn\":15,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"filter\"},\"fix\":{\"range\":[2899,3118],\"text\":\"\"},\"desc\":\"Remove unused variable 'filter'.\"}]},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":393,\"column\":21,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":393,\"endColumn\":22},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":393,\"column\":45,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":393,\"endColumn\":46},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":393,\"column\":45,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":393,\"endColumn\":46},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":394,\"column\":21,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":394,\"endColumn\":22},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":394,\"column\":49,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":394,\"endColumn\":50},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":395,\"column\":21,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":395,\"endColumn\":22},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":528,\"column\":75,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":528,\"endColumn\":76},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":528,\"column\":79,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":528,\"endColumn\":80},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":529,\"column\":78,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":529,\"endColumn\":79},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":529,\"column\":82,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":529,\"endColumn\":83}],\"suppressedMessages\":[],\"errorCount\":4,\"fatalErrorCount\":0,\"warningCount\":11,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Shared Image Processing Utilities\\n * Provides optimized image processing functions used across all pipelines\\n * Eliminates duplicate image processing code and improves performance\\n */\\n\\nimport { getGlobalResourcePool } from '../performance/resource-pool.js';\\nimport { ErrorCategory, ErrorSeverity, handleError } from '../../shared/utils/error-handler.js';\\nimport { IMAGE_FORMATS, INTERPOLATION_METHODS, createImageOperations } from './image-operations.js';\\nimport { createProcessingCache } from './image-processing-cache.js';\\n\\n/**\\n * Creates an optimized image processor with shared utilities\\n * @param {Object} config - Processor configuration\\n * @returns {Object} - Image processor instance\\n */\\nexport const createImageProcessor = (config = {}) => {\\n  const resourcePool = config.resourcePool || getGlobalResourcePool();\\n  const processorConfig = {\\n    defaultInterpolation: config.defaultInterpolation || INTERPOLATION_METHODS.BILINEAR,\\n    enableCaching: config.enableCaching !== false,\\n    cacheSize: config.cacheSize || 50,\\n    enableMetrics: config.enableMetrics !== false,\\n    ...config\\n  };\\n  \\n  const cache = createProcessingCache(processorConfig);\\n  const operations = createImageOperations(resourcePool);\\n  \\n  // Processing state and metrics\\n  const state = {\\n    metrics: {\\n      processedFrames: 0,\\n      totalProcessingTime: 0,\\n      averageProcessingTime: 0,\\n      cacheHits: 0,\\n      cacheMisses: 0\\n    }\\n  };\\n  \\n  // Wrapper functions that integrate caching and metrics\\n  const processWithCache = async (operation, params, processFn) => {\\n    const startTime = performance.now();\\n    \\n    // Try cache first\\n    const cached = cache.getCached(operation, params);\\n    if (cached) {\\n      cache.recordProcessingTime(startTime, performance.now());\\n      return cached;\\n    }\\n    \\n    // Process and cache result\\n    try {\\n      const result = await processFn();\\n      cache.setCached(operation, params, result);\\n      cache.recordProcessingTime(startTime, performance.now());\\n      return result;\\n    } catch (error) {\\n      cache.recordProcessingTime(startTime, performance.now());\\n      throw error;\\n    }\\n  };\\n  \\n  const resize = async (imageData, targetWidth, targetHeight, method) => {\\n    return processWithCache(\\n      'resize', \\n      { width: targetWidth, height: targetHeight, method },\\n      () => operations.resizeImage(imageData, targetWidth, targetHeight, method || processorConfig.defaultInterpolation)\\n    );\\n  };\\n  \\n  const convert = async (imageData, fromFormat, toFormat) => {\\n    return processWithCache(\\n      'convert',\\n      { fromFormat, toFormat },\\n      () => operations.convertColorSpace(imageData, fromFormat, toFormat)\\n    );\\n  };\\n  \\n  const crop = async (imageData, x, y, width, height) => {\\n    return processWithCache(\\n      'crop',\\n      { x, y, width, height },\\n      () => operations.cropImage(imageData, x, y, width, height)\\n    );\\n  };\\n  \\n  const filter = async (imageData, filterType, intensity) => {\\n    return processWithCache(\\n      'filter',\\n      { filterType, intensity },\\n      () => operations.applyFilter(imageData, filterType, intensity)\\n    );\\n  };\\n  \\n  /**\\n   * Preprocesses image data for pipeline consumption\\n   * @param {ImageData|HTMLCanvasElement|HTMLImageElement|HTMLVideoElement} input - Input image\\n   * @param {Object} options - Processing options\\n   * @returns {ImageData} - Processed image data\\n   */\\n  const preprocessImage = (input, options = {}) => {\\n    const startTime = performance.now();\\n    \\n    try {\\n      const opts = {\\n        targetSize: options.targetSize || [224, 224],\\n        format: options.format || 'RGBA',\\n        normalize: options.normalize !== false,\\n        interpolation: options.interpolation || processorConfig.defaultInterpolation,\\n        centerCrop: options.centerCrop !== false,\\n        ...options\\n      };\\n      \\n      // Generate cache key if caching enabled\\n      let cacheKey = null;\\n      if (processorConfig.enableCaching && input.src) {\\n        cacheKey = `preprocess_${input.src}_${JSON.stringify(opts)}`;\\n        const cached = state.cache.get(cacheKey);\\n        if (cached) {\\n          state.metrics.cacheHits++;\\n          updateMetrics(startTime);\\n          return cached;\\n        }\\n      }\\n      \\n      // Extract image data from various input types\\n      let imageData = extractImageData(input);\\n      \\n      // Resize image if needed\\n      if (opts.targetSize && \\n          (imageData.width !== opts.targetSize[0] || imageData.height !== opts.targetSize[1])) {\\n        imageData = resizeImage(imageData, opts.targetSize[0], opts.targetSize[1], opts.interpolation);\\n      }\\n      \\n      // Center crop if enabled and aspect ratios don't match\\n      if (opts.centerCrop) {\\n        imageData = centerCropImage(imageData, opts.targetSize[0], opts.targetSize[1]);\\n      }\\n      \\n      // Convert format if needed\\n      if (opts.format !== 'RGBA') {\\n        imageData = convertImageFormat(imageData, opts.format);\\n      }\\n      \\n      // Normalize pixel values if requested\\n      if (opts.normalize) {\\n        imageData = normalizeImage(imageData);\\n      }\\n      \\n      // Cache result if enabled\\n      if (cacheKey && processorConfig.enableCaching) {\\n        if (state.cache.size >= processorConfig.cacheSize) {\\n          // Remove oldest entry\\n          const firstKey = state.cache.keys().next().value;\\n          state.cache.delete(firstKey);\\n        }\\n        state.cache.set(cacheKey, imageData);\\n        state.metrics.cacheMisses++;\\n      }\\n      \\n      updateMetrics(startTime);\\n      return imageData;\\n      \\n    } catch (error) {\\n      handleError(\\n        `Image preprocessing failed: ${error.message}`,\\n        ErrorCategory.PROCESSING,\\n        ErrorSeverity.ERROR,\\n        { options }\\n      );\\n      throw error;\\n    }\\n  };\\n  \\n  /**\\n   * Extracts face region from image data\\n   * @param {ImageData} imageData - Source image data\\n   * @param {Object} boundingBox - Face bounding box {x, y, width, height}\\n   * @param {Object} options - Extraction options\\n   * @returns {ImageData} - Extracted face region\\n   */\\n  const extractFaceRegion = (imageData, boundingBox, options = {}) => {\\n    try {\\n      const opts = {\\n        padding: options.padding || 0.1, // 10% padding around face\\n        minSize: options.minSize || [64, 64],\\n        maxSize: options.maxSize || [512, 512],\\n        maintainAspectRatio: options.maintainAspectRatio !== false,\\n        ...options\\n      };\\n      \\n      // Normalize bounding box coordinates\\n      const bbox = normalizeBoundingBox(boundingBox, imageData.width, imageData.height);\\n      \\n      // Apply padding\\n      const paddedBbox = addPaddingToBbox(bbox, opts.padding, imageData.width, imageData.height);\\n      \\n      // Extract region using canvas\\n      const canvas = resourcePool.getCanvas(paddedBbox.width, paddedBbox.height);\\n      const ctx = canvas.getContext('2d');\\n      \\n      // Create temporary canvas with original image\\n      const sourceCanvas = resourcePool.getCanvas(imageData.width, imageData.height);\\n      const sourceCtx = sourceCanvas.getContext('2d');\\n      sourceCtx.putImageData(imageData, 0, 0);\\n      \\n      // Draw face region\\n      ctx.drawImage(\\n        sourceCanvas,\\n        paddedBbox.x, paddedBbox.y, paddedBbox.width, paddedBbox.height,\\n        0, 0, paddedBbox.width, paddedBbox.height\\n      );\\n      \\n      const faceData = ctx.getImageData(0, 0, paddedBbox.width, paddedBbox.height);\\n      \\n      // Clean up resources\\n      resourcePool.returnCanvas(canvas);\\n      resourcePool.returnCanvas(sourceCanvas);\\n      \\n      // Resize to target size if specified\\n      if (opts.targetSize) {\\n        return resizeImage(faceData, opts.targetSize[0], opts.targetSize[1]);\\n      }\\n      \\n      return faceData;\\n      \\n    } catch (error) {\\n      handleError(\\n        `Face region extraction failed: ${error.message}`,\\n        ErrorCategory.PROCESSING,\\n        ErrorSeverity.ERROR,\\n        { boundingBox, options }\\n      );\\n      throw error;\\n    }\\n  };\\n  \\n  /**\\n   * Resizes image data to target dimensions\\n   * @param {ImageData} imageData - Source image data\\n   * @param {number} targetWidth - Target width\\n   * @param {number} targetHeight - Target height\\n   * @param {string} interpolation - Interpolation method\\n   * @returns {ImageData} - Resized image data\\n   */\\n  const resizeImage = (imageData, targetWidth, targetHeight, interpolation = INTERPOLATION_METHODS.BILINEAR) => {\\n    try {\\n      const canvas = resourcePool.getCanvas(targetWidth, targetHeight);\\n      const ctx = canvas.getContext('2d');\\n      \\n      // Set interpolation quality\\n      switch (interpolation) {\\n        case INTERPOLATION_METHODS.NEAREST:\\n          ctx.imageSmoothingEnabled = false;\\n          break;\\n        case INTERPOLATION_METHODS.BILINEAR:\\n          ctx.imageSmoothingEnabled = true;\\n          ctx.imageSmoothingQuality = 'medium';\\n          break;\\n        case INTERPOLATION_METHODS.BICUBIC:\\n          ctx.imageSmoothingEnabled = true;\\n          ctx.imageSmoothingQuality = 'high';\\n          break;\\n      }\\n      \\n      // Create source canvas\\n      const sourceCanvas = resourcePool.getCanvas(imageData.width, imageData.height);\\n      const sourceCtx = sourceCanvas.getContext('2d');\\n      sourceCtx.putImageData(imageData, 0, 0);\\n      \\n      // Draw resized image\\n      ctx.drawImage(sourceCanvas, 0, 0, imageData.width, imageData.height, 0, 0, targetWidth, targetHeight);\\n      \\n      const resizedData = ctx.getImageData(0, 0, targetWidth, targetHeight);\\n      \\n      // Clean up resources\\n      resourcePool.returnCanvas(canvas);\\n      resourcePool.returnCanvas(sourceCanvas);\\n      \\n      return resizedData;\\n      \\n    } catch (error) {\\n      handleError(\\n        `Image resizing failed: ${error.message}`,\\n        ErrorCategory.PROCESSING,\\n        ErrorSeverity.ERROR,\\n        { sourceSize: [imageData.width, imageData.height], targetSize: [targetWidth, targetHeight] }\\n      );\\n      throw error;\\n    }\\n  };\\n  \\n  /**\\n   * Center crops image to target dimensions\\n   * @param {ImageData} imageData - Source image data\\n   * @param {number} targetWidth - Target width\\n   * @param {number} targetHeight - Target height\\n   * @returns {ImageData} - Cropped image data\\n   */\\n  const centerCropImage = (imageData, targetWidth, targetHeight) => {\\n    try {\\n      const sourceWidth = imageData.width;\\n      const sourceHeight = imageData.height;\\n      \\n      // Calculate crop area\\n      const cropWidth = Math.min(sourceWidth, targetWidth);\\n      const cropHeight = Math.min(sourceHeight, targetHeight);\\n      const cropX = Math.floor((sourceWidth - cropWidth) / 2);\\n      const cropY = Math.floor((sourceHeight - cropHeight) / 2);\\n      \\n      const canvas = resourcePool.getCanvas(cropWidth, cropHeight);\\n      const ctx = canvas.getContext('2d');\\n      \\n      // Create source canvas\\n      const sourceCanvas = resourcePool.getCanvas(sourceWidth, sourceHeight);\\n      const sourceCtx = sourceCanvas.getContext('2d');\\n      sourceCtx.putImageData(imageData, 0, 0);\\n      \\n      // Draw cropped region\\n      ctx.drawImage(\\n        sourceCanvas,\\n        cropX, cropY, cropWidth, cropHeight,\\n        0, 0, cropWidth, cropHeight\\n      );\\n      \\n      const croppedData = ctx.getImageData(0, 0, cropWidth, cropHeight);\\n      \\n      // Clean up resources\\n      resourcePool.returnCanvas(canvas);\\n      resourcePool.returnCanvas(sourceCanvas);\\n      \\n      return croppedData;\\n      \\n    } catch (error) {\\n      handleError(\\n        `Image center cropping failed: ${error.message}`,\\n        ErrorCategory.PROCESSING,\\n        ErrorSeverity.ERROR,\\n        { sourceSize: [imageData.width, imageData.height], targetSize: [targetWidth, targetHeight] }\\n      );\\n      throw error;\\n    }\\n  };\\n  \\n  /**\\n   * Converts image format (RGBA -> RGB, etc.)\\n   * @param {ImageData} imageData - Source image data\\n   * @param {string} targetFormat - Target format\\n   * @returns {ImageData|Uint8Array} - Converted image data\\n   */\\n  const convertImageFormat = (imageData, targetFormat) => {\\n    try {\\n      const targetFormatInfo = IMAGE_FORMATS[targetFormat];\\n      \\n      if (!targetFormatInfo) {\\n        throw new Error(`Unsupported target format: ${targetFormat}`);\\n      }\\n      \\n      const sourceData = imageData.data;\\n      const pixelCount = imageData.width * imageData.height;\\n      const targetBuffer = resourcePool.getImageBuffer(\\n        imageData.width, \\n        imageData.height, \\n        targetFormatInfo.channels\\n      );\\n      \\n      switch (targetFormat) {\\n        case 'RGB':\\n          for (let i = 0; i < pixelCount; i++) {\\n            const sourceIdx = i * 4;\\n            const targetIdx = i * 3;\\n            targetBuffer[targetIdx] = sourceData[sourceIdx];     // R\\n            targetBuffer[targetIdx + 1] = sourceData[sourceIdx + 1]; // G\\n            targetBuffer[targetIdx + 2] = sourceData[sourceIdx + 2]; // B\\n          }\\n          break;\\n          \\n        case 'BGR':\\n          for (let i = 0; i < pixelCount; i++) {\\n            const sourceIdx = i * 4;\\n            const targetIdx = i * 3;\\n            targetBuffer[targetIdx] = sourceData[sourceIdx + 2]; // B\\n            targetBuffer[targetIdx + 1] = sourceData[sourceIdx + 1]; // G\\n            targetBuffer[targetIdx + 2] = sourceData[sourceIdx];     // R\\n          }\\n          break;\\n          \\n        case 'GRAYSCALE':\\n          for (let i = 0; i < pixelCount; i++) {\\n            const sourceIdx = i * 4;\\n            const gray = Math.round(\\n              0.299 * sourceData[sourceIdx] +     // R\\n              0.587 * sourceData[sourceIdx + 1] + // G\\n              0.114 * sourceData[sourceIdx + 2]   // B\\n            );\\n            targetBuffer[i] = gray;\\n          }\\n          break;\\n          \\n        case 'RGBA':\\n        default:\\n          return imageData;\\n      }\\n      \\n      return {\\n        data: targetBuffer,\\n        width: imageData.width,\\n        height: imageData.height,\\n        format: targetFormat\\n      };\\n      \\n    } catch (error) {\\n      handleError(\\n        `Image format conversion failed: ${error.message}`,\\n        ErrorCategory.PROCESSING,\\n        ErrorSeverity.ERROR,\\n        { targetFormat }\\n      );\\n      throw error;\\n    }\\n  };\\n  \\n  /**\\n   * Normalizes image pixel values to 0-1 range\\n   * @param {ImageData|Object} imageData - Image data\\n   * @returns {Object} - Normalized image data\\n   */\\n  const normalizeImage = (imageData) => {\\n    try {\\n      const {data} = imageData;\\n      const normalizedData = new Float32Array(data.length);\\n      \\n      for (let i = 0; i < data.length; i++) {\\n        normalizedData[i] = data[i] / 255.0;\\n      }\\n      \\n      return {\\n        ...imageData,\\n        data: normalizedData,\\n        normalized: true\\n      };\\n      \\n    } catch (error) {\\n      handleError(\\n        `Image normalization failed: ${error.message}`,\\n        ErrorCategory.PROCESSING,\\n        ErrorSeverity.ERROR\\n      );\\n      throw error;\\n    }\\n  };\\n  \\n  /**\\n   * Extracts ImageData from various input types\\n   * @param {ImageData|HTMLCanvasElement|HTMLImageElement|HTMLVideoElement} input - Input source\\n   * @returns {ImageData} - Extracted image data\\n   */\\n  const extractImageData = (input) => {\\n    try {\\n      if (input instanceof ImageData) {\\n        return input;\\n      }\\n      \\n      let canvas, ctx;\\n      \\n      if (input instanceof HTMLCanvasElement) {\\n        canvas = input;\\n        ctx = canvas.getContext('2d');\\n      } else {\\n        // Create canvas for other input types\\n        canvas = resourcePool.getCanvas(input.width || input.videoWidth, input.height || input.videoHeight);\\n        ctx = canvas.getContext('2d');\\n        ctx.drawImage(input, 0, 0);\\n      }\\n      \\n      const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);\\n      \\n      // Return canvas to pool if we created it\\n      if (!(input instanceof HTMLCanvasElement)) {\\n        resourcePool.returnCanvas(canvas);\\n      }\\n      \\n      return imageData;\\n      \\n    } catch (error) {\\n      handleError(\\n        `Failed to extract image data: ${error.message}`,\\n        ErrorCategory.PROCESSING,\\n        ErrorSeverity.ERROR,\\n        { inputType: input.constructor.name }\\n      );\\n      throw error;\\n    }\\n  };\\n  \\n  /**\\n   * Normalizes bounding box coordinates\\n   * @param {Object} bbox - Bounding box\\n   * @param {number} imageWidth - Image width\\n   * @param {number} imageHeight - Image height\\n   * @returns {Object} - Normalized bounding box\\n   */\\n  const normalizeBoundingBox = (bbox, imageWidth, imageHeight) => {\\n    return {\\n      x: Math.max(0, Math.floor(bbox.x * imageWidth)),\\n      y: Math.max(0, Math.floor(bbox.y * imageHeight)),\\n      width: Math.min(imageWidth, Math.ceil(bbox.width * imageWidth)),\\n      height: Math.min(imageHeight, Math.ceil(bbox.height * imageHeight))\\n    };\\n  };\\n  \\n  /**\\n   * Adds padding to bounding box\\n   * @param {Object} bbox - Bounding box\\n   * @param {number} padding - Padding factor (0-1)\\n   * @param {number} imageWidth - Image width\\n   * @param {number} imageHeight - Image height\\n   * @returns {Object} - Padded bounding box\\n   */\\n  const addPaddingToBbox = (bbox, padding, imageWidth, imageHeight) => {\\n    const padX = Math.floor(bbox.width * padding);\\n    const padY = Math.floor(bbox.height * padding);\\n    \\n    return {\\n      x: Math.max(0, bbox.x - padX),\\n      y: Math.max(0, bbox.y - padY),\\n      width: Math.min(imageWidth - Math.max(0, bbox.x - padX), bbox.width + 2 * padX),\\n      height: Math.min(imageHeight - Math.max(0, bbox.y - padY), bbox.height + 2 * padY)\\n    };\\n  };\\n  \\n  /**\\n   * Updates processing metrics\\n   * @param {number} startTime - Processing start time\\n   */\\n  const updateMetrics = (startTime) => {\\n    if (!processorConfig.enableMetrics) return;\\n    \\n    const processingTime = performance.now() - startTime;\\n    state.metrics.processedFrames++;\\n    state.metrics.totalProcessingTime += processingTime;\\n    state.metrics.averageProcessingTime = state.metrics.totalProcessingTime / state.metrics.processedFrames;\\n  };\\n  \\n  /**\\n   * Gets processing metrics\\n   * @returns {Object} - Metrics data\\n   */\\n  const getMetrics = () => {\\n    if (!processorConfig.enableMetrics) {\\n      return { enabled: false };\\n    }\\n    \\n    return {\\n      ...state.metrics,\\n      cacheEfficiency: state.metrics.cacheHits / (state.metrics.cacheHits + state.metrics.cacheMisses),\\n      cacheSize: state.cache.size,\\n      enabled: true\\n    };\\n  };\\n  \\n  /**\\n   * Clears processing cache and resets metrics\\n   */\\n  const cleanup = () => {\\n    cache.clear();\\n  };\\n  \\n  return {\\n    // Core processing functions\\n    preprocessImage,\\n    extractFaceRegion,\\n    resizeImage,\\n    centerCropImage,\\n    convertImageFormat,\\n    normalizeImage,\\n    extractImageData,\\n    \\n    // Utility functions\\n    normalizeBoundingBox,\\n    addPaddingToBbox,\\n    \\n    // Management functions\\n    getMetrics,\\n    cleanup,\\n    \\n    // Constants\\n    IMAGE_FORMATS,\\n    INTERPOLATION_METHODS\\n  };\\n};\\n\\n// Export format constants for external use\\nexport { IMAGE_FORMATS, INTERPOLATION_METHODS };\\n\\n// Export default processor factory for convenience\\n\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/core/engine/processors/color-processor.js\",\"messages\":[{\"ruleId\":\"max-lines-per-function\",\"severity\":1,\"message\":\"Arrow function has too many lines (217). Maximum allowed is 150.\",\"line\":9,\"column\":37,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"exceed\",\"endLine\":295,\"endColumn\":2},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":85,\"column\":19,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":85,\"endColumn\":20},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":85,\"column\":43,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":85,\"endColumn\":44},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":85,\"column\":43,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":85,\"endColumn\":44},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":86,\"column\":19,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":86,\"endColumn\":20},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":86,\"column\":47,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":86,\"endColumn\":48},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":87,\"column\":19,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":87,\"endColumn\":20},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":258,\"column\":34,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":258,\"endColumn\":35},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":258,\"column\":50,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":258,\"endColumn\":51}],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":9,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Image Color Processing Module\\n * Handles color space conversions and format transformations\\n */\\n\\nimport { IMAGE_FORMATS } from '../image-operations.js';\\nimport { ErrorCategory, ErrorSeverity, handleError } from '../../../shared/utils/error-handler.js';\\n\\nexport const createColorProcessor = (resourcePool) => {\\n  /**\\n   * Convert color space between different formats\\n   */\\n  const convertColorSpace = (imageData, fromFormat, toFormat) => {\\n    try {\\n      if (fromFormat === toFormat) {\\n        return imageData;\\n      }\\n      \\n      const fromFormatInfo = IMAGE_FORMATS[fromFormat];\\n      const toFormatInfo = IMAGE_FORMATS[toFormat];\\n      \\n      if (!fromFormatInfo || !toFormatInfo) {\\n        throw new Error(`Unsupported format conversion: ${fromFormat} -> ${toFormat}`);\\n      }\\n      \\n      const sourceData = imageData.data;\\n      const pixelCount = imageData.width * imageData.height;\\n      const targetBuffer = resourcePool.getImageBuffer(\\n        imageData.width, \\n        imageData.height, \\n        toFormatInfo.channels\\n      );\\n      \\n      // Handle specific conversions\\n      if (fromFormat === 'RGBA') {\\n        return convertFromRGBA(sourceData, pixelCount, targetBuffer, toFormat);\\n      } else if (toFormat === 'RGBA') {\\n        return convertToRGBA(sourceData, pixelCount, targetBuffer, fromFormat, imageData.width, imageData.height);\\n      } else {\\n        // Convert through RGBA as intermediate format\\n        const rgbaData = convertToRGBA(sourceData, pixelCount, new Uint8ClampedArray(pixelCount * 4), fromFormat, imageData.width, imageData.height);\\n        return convertFromRGBA(rgbaData.data, pixelCount, targetBuffer, toFormat);\\n      }\\n      \\n    } catch (error) {\\n      handleError(\\n        `Color space conversion failed: ${error.message}`,\\n        ErrorCategory.PROCESSING,\\n        ErrorSeverity.ERROR,\\n        { fromFormat, toFormat }\\n      );\\n      throw error;\\n    }\\n  };\\n\\n  /**\\n   * Convert from RGBA to other formats\\n   */\\n  const convertFromRGBA = (sourceData, pixelCount, targetBuffer, toFormat) => {\\n    switch (toFormat) {\\n      case 'RGB':\\n        for (let i = 0; i < pixelCount; i++) {\\n          const sourceIdx = i * 4;\\n          const targetIdx = i * 3;\\n          targetBuffer[targetIdx] = sourceData[sourceIdx];         // R\\n          targetBuffer[targetIdx + 1] = sourceData[sourceIdx + 1]; // G\\n          targetBuffer[targetIdx + 2] = sourceData[sourceIdx + 2]; // B\\n        }\\n        break;\\n        \\n      case 'BGR':\\n        for (let i = 0; i < pixelCount; i++) {\\n          const sourceIdx = i * 4;\\n          const targetIdx = i * 3;\\n          targetBuffer[targetIdx] = sourceData[sourceIdx + 2];     // B\\n          targetBuffer[targetIdx + 1] = sourceData[sourceIdx + 1]; // G\\n          targetBuffer[targetIdx + 2] = sourceData[sourceIdx];     // R\\n        }\\n        break;\\n        \\n      case 'GRAYSCALE':\\n        for (let i = 0; i < pixelCount; i++) {\\n          const sourceIdx = i * 4;\\n          const gray = Math.round(\\n            0.299 * sourceData[sourceIdx] +     // R\\n            0.587 * sourceData[sourceIdx + 1] + // G\\n            0.114 * sourceData[sourceIdx + 2]   // B\\n          );\\n          targetBuffer[i] = gray;\\n        }\\n        break;\\n        \\n      default:\\n        throw new Error(`Unsupported target format: ${toFormat}`);\\n    }\\n    \\n    return {\\n      data: targetBuffer,\\n      width: Math.sqrt(pixelCount * IMAGE_FORMATS[toFormat].channels / IMAGE_FORMATS[toFormat].channels),\\n      height: Math.sqrt(pixelCount * IMAGE_FORMATS[toFormat].channels / IMAGE_FORMATS[toFormat].channels),\\n      format: toFormat\\n    };\\n  };\\n\\n  /**\\n   * Convert from other formats to RGBA\\n   */\\n  const convertToRGBA = (sourceData, pixelCount, targetBuffer, fromFormat, width, height) => {\\n    switch (fromFormat) {\\n      case 'RGB':\\n        for (let i = 0; i < pixelCount; i++) {\\n          const sourceIdx = i * 3;\\n          const targetIdx = i * 4;\\n          targetBuffer[targetIdx] = sourceData[sourceIdx];         // R\\n          targetBuffer[targetIdx + 1] = sourceData[sourceIdx + 1]; // G\\n          targetBuffer[targetIdx + 2] = sourceData[sourceIdx + 2]; // B\\n          targetBuffer[targetIdx + 3] = 255;                       // A\\n        }\\n        break;\\n        \\n      case 'BGR':\\n        for (let i = 0; i < pixelCount; i++) {\\n          const sourceIdx = i * 3;\\n          const targetIdx = i * 4;\\n          targetBuffer[targetIdx] = sourceData[sourceIdx + 2];     // R\\n          targetBuffer[targetIdx + 1] = sourceData[sourceIdx + 1]; // G\\n          targetBuffer[targetIdx + 2] = sourceData[sourceIdx];     // B\\n          targetBuffer[targetIdx + 3] = 255;                       // A\\n        }\\n        break;\\n        \\n      case 'GRAYSCALE':\\n        for (let i = 0; i < pixelCount; i++) {\\n          const targetIdx = i * 4;\\n          const grayValue = sourceData[i];\\n          targetBuffer[targetIdx] = grayValue;     // R\\n          targetBuffer[targetIdx + 1] = grayValue; // G\\n          targetBuffer[targetIdx + 2] = grayValue; // B\\n          targetBuffer[targetIdx + 3] = 255;       // A\\n        }\\n        break;\\n        \\n      default:\\n        throw new Error(`Unsupported source format: ${fromFormat}`);\\n    }\\n    \\n    return new ImageData(targetBuffer, width, height);\\n  };\\n\\n  /**\\n   * Normalize image pixel values to 0-1 range\\n   */\\n  const normalizeImage = (imageData) => {\\n    try {\\n      const { data } = imageData;\\n      const normalizedData = new Float32Array(data.length);\\n      \\n      for (let i = 0; i < data.length; i++) {\\n        normalizedData[i] = data[i] / 255.0;\\n      }\\n      \\n      return {\\n        ...imageData,\\n        data: normalizedData,\\n        normalized: true\\n      };\\n      \\n    } catch (error) {\\n      handleError(\\n        `Image normalization failed: ${error.message}`,\\n        ErrorCategory.PROCESSING,\\n        ErrorSeverity.ERROR\\n      );\\n      throw error;\\n    }\\n  };\\n\\n  /**\\n   * Denormalize image pixel values from 0-1 to 0-255 range\\n   */\\n  const denormalizeImage = (imageData) => {\\n    try {\\n      const { data } = imageData;\\n      const denormalizedData = new Uint8ClampedArray(data.length);\\n      \\n      for (let i = 0; i < data.length; i++) {\\n        denormalizedData[i] = Math.round(Math.max(0, Math.min(255, data[i] * 255)));\\n      }\\n      \\n      return {\\n        ...imageData,\\n        data: denormalizedData,\\n        normalized: false\\n      };\\n      \\n    } catch (error) {\\n      handleError(\\n        `Image denormalization failed: ${error.message}`,\\n        ErrorCategory.PROCESSING,\\n        ErrorSeverity.ERROR\\n      );\\n      throw error;\\n    }\\n  };\\n\\n  /**\\n   * Apply gamma correction\\n   */\\n  const gammaCorrection = (imageData, gamma = 2.2) => {\\n    try {\\n      const { data } = imageData;\\n      const correctedData = new Uint8ClampedArray(data.length);\\n      const invGamma = 1.0 / gamma;\\n      \\n      // Pre-compute lookup table for efficiency\\n      const gammaTable = new Uint8Array(256);\\n      for (let i = 0; i < 256; i++) {\\n        gammaTable[i] = Math.round(255 * Math.pow(i / 255, invGamma));\\n      }\\n      \\n      for (let i = 0; i < data.length; i += 4) {\\n        correctedData[i] = gammaTable[data[i]];         // R\\n        correctedData[i + 1] = gammaTable[data[i + 1]]; // G\\n        correctedData[i + 2] = gammaTable[data[i + 2]]; // B\\n        correctedData[i + 3] = data[i + 3];             // A (unchanged)\\n      }\\n      \\n      return new ImageData(correctedData, imageData.width, imageData.height);\\n      \\n    } catch (error) {\\n      handleError(\\n        `Gamma correction failed: ${error.message}`,\\n        ErrorCategory.PROCESSING,\\n        ErrorSeverity.ERROR,\\n        { gamma }\\n      );\\n      throw error;\\n    }\\n  };\\n\\n  /**\\n   * Adjust brightness and contrast\\n   */\\n  const adjustBrightnessContrast = (imageData, brightness = 0, contrast = 0) => {\\n    try {\\n      const { data } = imageData;\\n      const adjustedData = new Uint8ClampedArray(data.length);\\n      \\n      // Convert contrast from -100,100 range to multiplier\\n      const contrastFactor = (259 * (contrast + 255)) / (255 * (259 - contrast));\\n      \\n      for (let i = 0; i < data.length; i += 4) {\\n        // Apply brightness and contrast to RGB channels\\n        for (let j = 0; j < 3; j++) {\\n          let pixel = data[i + j];\\n          \\n          // Apply contrast\\n          pixel = contrastFactor * (pixel - 128) + 128;\\n          \\n          // Apply brightness\\n          pixel += brightness;\\n          \\n          // Clamp to valid range\\n          adjustedData[i + j] = Math.max(0, Math.min(255, pixel));\\n        }\\n        \\n        // Keep alpha unchanged\\n        adjustedData[i + 3] = data[i + 3];\\n      }\\n      \\n      return new ImageData(adjustedData, imageData.width, imageData.height);\\n      \\n    } catch (error) {\\n      handleError(\\n        `Brightness/contrast adjustment failed: ${error.message}`,\\n        ErrorCategory.PROCESSING,\\n        ErrorSeverity.ERROR,\\n        { brightness, contrast }\\n      );\\n      throw error;\\n    }\\n  };\\n\\n  return {\\n    convertColorSpace,\\n    normalizeImage,\\n    denormalizeImage,\\n    gammaCorrection,\\n    adjustBrightnessContrast,\\n    \\n    // Export individual conversion functions\\n    convertFromRGBA,\\n    convertToRGBA\\n  };\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/core/engine/processors/crop-processor.js\",\"messages\":[{\"ruleId\":\"max-lines-per-function\",\"severity\":1,\"message\":\"Arrow function has too many lines (227). Maximum allowed is 150.\",\"line\":8,\"column\":36,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"exceed\",\"endLine\":313,\"endColumn\":2}],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":1,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Image Crop Processing Module\\n * Handles image cropping and extraction operations\\n */\\n\\nimport { ErrorCategory, ErrorSeverity, handleError } from '../../../shared/utils/error-handler.js';\\n\\nexport const createCropProcessor = (resourcePool) => {\\n  /**\\n   * Basic crop operation\\n   */\\n  const cropImage = (imageData, x, y, width, height) => {\\n    try {\\n      if (!imageData || !imageData.data) {\\n        throw new Error('Invalid image data provided');\\n      }\\n      \\n      const sourceWidth = imageData.width;\\n      const sourceHeight = imageData.height;\\n      \\n      // Validate crop bounds\\n      if (x < 0 || y < 0 || x + width > sourceWidth || y + height > sourceHeight) {\\n        throw new Error('Crop bounds exceed image dimensions');\\n      }\\n      \\n      if (width <= 0 || height <= 0) {\\n        throw new Error('Crop dimensions must be positive');\\n      }\\n      \\n      const canvas = resourcePool.getCanvas(width, height);\\n      const ctx = canvas.getContext('2d');\\n      \\n      // Create source canvas\\n      const sourceCanvas = resourcePool.getCanvas(sourceWidth, sourceHeight);\\n      const sourceCtx = sourceCanvas.getContext('2d');\\n      sourceCtx.putImageData(imageData, 0, 0);\\n      \\n      // Draw cropped region\\n      ctx.drawImage(\\n        sourceCanvas,\\n        x, y, width, height,\\n        0, 0, width, height\\n      );\\n      \\n      const croppedData = ctx.getImageData(0, 0, width, height);\\n      \\n      // Clean up resources\\n      resourcePool.returnCanvas(canvas);\\n      resourcePool.returnCanvas(sourceCanvas);\\n      \\n      return croppedData;\\n      \\n    } catch (error) {\\n      handleError(\\n        `Image crop failed: ${error.message}`,\\n        ErrorCategory.PROCESSING,\\n        ErrorSeverity.ERROR,\\n        { \\n          sourceSize: [imageData?.width, imageData?.height], \\n          cropBounds: [x, y, width, height] \\n        }\\n      );\\n      throw error;\\n    }\\n  };\\n\\n  /**\\n   * Center crop to specific dimensions\\n   */\\n  const centerCropImage = (imageData, targetWidth, targetHeight) => {\\n    try {\\n      const sourceWidth = imageData.width;\\n      const sourceHeight = imageData.height;\\n      \\n      // Calculate crop area\\n      const cropWidth = Math.min(sourceWidth, targetWidth);\\n      const cropHeight = Math.min(sourceHeight, targetHeight);\\n      const cropX = Math.floor((sourceWidth - cropWidth) / 2);\\n      const cropY = Math.floor((sourceHeight - cropHeight) / 2);\\n      \\n      return cropImage(imageData, cropX, cropY, cropWidth, cropHeight);\\n      \\n    } catch (error) {\\n      handleError(\\n        `Image center cropping failed: ${error.message}`,\\n        ErrorCategory.PROCESSING,\\n        ErrorSeverity.ERROR,\\n        { \\n          sourceSize: [imageData?.width, imageData?.height], \\n          targetSize: [targetWidth, targetHeight] \\n        }\\n      );\\n      throw error;\\n    }\\n  };\\n\\n  /**\\n   * Smart crop to maintain aspect ratio\\n   */\\n  const aspectRatioCrop = (imageData, targetAspectRatio) => {\\n    try {\\n      const sourceWidth = imageData.width;\\n      const sourceHeight = imageData.height;\\n      const sourceAspectRatio = sourceWidth / sourceHeight;\\n      \\n      let cropWidth, cropHeight, cropX, cropY;\\n      \\n      if (sourceAspectRatio > targetAspectRatio) {\\n        // Source is wider - crop width\\n        cropHeight = sourceHeight;\\n        cropWidth = Math.round(sourceHeight * targetAspectRatio);\\n        cropX = Math.round((sourceWidth - cropWidth) / 2);\\n        cropY = 0;\\n      } else {\\n        // Source is taller - crop height\\n        cropWidth = sourceWidth;\\n        cropHeight = Math.round(sourceWidth / targetAspectRatio);\\n        cropX = 0;\\n        cropY = Math.round((sourceHeight - cropHeight) / 2);\\n      }\\n      \\n      return cropImage(imageData, cropX, cropY, cropWidth, cropHeight);\\n      \\n    } catch (error) {\\n      handleError(\\n        `Aspect ratio crop failed: ${error.message}`,\\n        ErrorCategory.PROCESSING,\\n        ErrorSeverity.ERROR,\\n        { targetAspectRatio }\\n      );\\n      throw error;\\n    }\\n  };\\n\\n  /**\\n   * Crop with padding if needed\\n   */\\n  const cropWithPadding = (imageData, x, y, width, height, paddingColor = [0, 0, 0, 255]) => {\\n    try {\\n      const sourceWidth = imageData.width;\\n      const sourceHeight = imageData.height;\\n      \\n      // Calculate intersection with source image\\n      const sourceX = Math.max(0, x);\\n      const sourceY = Math.max(0, y);\\n      const sourceEndX = Math.min(sourceWidth, x + width);\\n      const sourceEndY = Math.min(sourceHeight, y + height);\\n      \\n      const intersectWidth = Math.max(0, sourceEndX - sourceX);\\n      const intersectHeight = Math.max(0, sourceEndY - sourceY);\\n      \\n      // Create output canvas\\n      const canvas = resourcePool.getCanvas(width, height);\\n      const ctx = canvas.getContext('2d');\\n      \\n      // Fill with padding color\\n      ctx.fillStyle = `rgba(${paddingColor[0]}, ${paddingColor[1]}, ${paddingColor[2]}, ${paddingColor[3]/255})`;\\n      ctx.fillRect(0, 0, width, height);\\n      \\n      if (intersectWidth > 0 && intersectHeight > 0) {\\n        // Create source canvas\\n        const sourceCanvas = resourcePool.getCanvas(sourceWidth, sourceHeight);\\n        const sourceCtx = sourceCanvas.getContext('2d');\\n        sourceCtx.putImageData(imageData, 0, 0);\\n        \\n        // Draw intersecting region\\n        const destX = sourceX - x;\\n        const destY = sourceY - y;\\n        \\n        ctx.drawImage(\\n          sourceCanvas,\\n          sourceX, sourceY, intersectWidth, intersectHeight,\\n          destX, destY, intersectWidth, intersectHeight\\n        );\\n        \\n        resourcePool.returnCanvas(sourceCanvas);\\n      }\\n      \\n      const result = ctx.getImageData(0, 0, width, height);\\n      resourcePool.returnCanvas(canvas);\\n      \\n      return result;\\n      \\n    } catch (error) {\\n      handleError(\\n        `Padded crop failed: ${error.message}`,\\n        ErrorCategory.PROCESSING,\\n        ErrorSeverity.ERROR,\\n        { cropBounds: [x, y, width, height] }\\n      );\\n      throw error;\\n    }\\n  };\\n\\n  /**\\n   * Multi-region crop (extract multiple regions at once)\\n   */\\n  const multiCrop = (imageData, regions) => {\\n    try {\\n      if (!Array.isArray(regions) || regions.length === 0) {\\n        throw new Error('Regions must be a non-empty array');\\n      }\\n      \\n      return regions.map((region, index) => {\\n        const { x, y, width, height, id } = region;\\n        \\n        try {\\n          const cropped = cropImage(imageData, x, y, width, height);\\n          return {\\n            id: id || `region_${index}`,\\n            imageData: cropped,\\n            bounds: { x, y, width, height },\\n            success: true\\n          };\\n        } catch (error) {\\n          return {\\n            id: id || `region_${index}`,\\n            imageData: null,\\n            bounds: { x, y, width, height },\\n            success: false,\\n            error: error.message\\n          };\\n        }\\n      });\\n      \\n    } catch (error) {\\n      handleError(\\n        `Multi-crop failed: ${error.message}`,\\n        ErrorCategory.PROCESSING,\\n        ErrorSeverity.ERROR,\\n        { regionCount: regions?.length }\\n      );\\n      throw error;\\n    }\\n  };\\n\\n  /**\\n   * Extract region of interest (ROI) with metadata\\n   */\\n  const extractROI = (imageData, roi) => {\\n    try {\\n      const { x, y, width, height, label, confidence } = roi;\\n      const cropped = cropImage(imageData, x, y, width, height);\\n      \\n      return {\\n        imageData: cropped,\\n        metadata: {\\n          originalBounds: { x, y, width, height },\\n          label: label || 'unknown',\\n          confidence: confidence || 1.0,\\n          extractedAt: Date.now(),\\n          originalSize: {\\n            width: imageData.width,\\n            height: imageData.height\\n          }\\n        }\\n      };\\n      \\n    } catch (error) {\\n      handleError(\\n        `ROI extraction failed: ${error.message}`,\\n        ErrorCategory.PROCESSING,\\n        ErrorSeverity.ERROR,\\n        { roi }\\n      );\\n      throw error;\\n    }\\n  };\\n\\n  /**\\n   * Normalize bounding box coordinates\\n   */\\n  const normalizeBoundingBox = (bbox, imageWidth, imageHeight) => {\\n    try {\\n      let { x, y, width, height } = bbox;\\n      \\n      // Handle relative coordinates (0-1 range)\\n      if (x <= 1 && y <= 1 && width <= 1 && height <= 1) {\\n        x = Math.round(x * imageWidth);\\n        y = Math.round(y * imageHeight);\\n        width = Math.round(width * imageWidth);\\n        height = Math.round(height * imageHeight);\\n      }\\n      \\n      // Clamp to image bounds\\n      x = Math.max(0, Math.min(imageWidth - 1, x));\\n      y = Math.max(0, Math.min(imageHeight - 1, y));\\n      width = Math.max(1, Math.min(imageWidth - x, width));\\n      height = Math.max(1, Math.min(imageHeight - y, height));\\n      \\n      return { x, y, width, height };\\n      \\n    } catch (error) {\\n      handleError(\\n        `Bounding box normalization failed: ${error.message}`,\\n        ErrorCategory.PROCESSING,\\n        ErrorSeverity.ERROR,\\n        { bbox, imageSize: [imageWidth, imageHeight] }\\n      );\\n      throw error;\\n    }\\n  };\\n\\n  return {\\n    cropImage,\\n    centerCropImage,\\n    aspectRatioCrop,\\n    cropWithPadding,\\n    multiCrop,\\n    extractROI,\\n    normalizeBoundingBox\\n  };\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/core/engine/processors/filter-processor.js\",\"messages\":[{\"ruleId\":\"max-lines-per-function\",\"severity\":1,\"message\":\"Arrow function has too many lines (241). Maximum allowed is 150.\",\"line\":8,\"column\":38,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"exceed\",\"endLine\":336,\"endColumn\":2},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'resourcePool' is defined but never used. Allowed unused args must match /^_/u.\",\"line\":8,\"column\":39,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":8,\"endColumn\":51,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"resourcePool\"},\"fix\":{\"range\":[255,267],\"text\":\"\"},\"desc\":\"Remove unused variable 'resourcePool'.\"}]},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":50,\"column\":33,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":50,\"endColumn\":34},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":50,\"column\":41,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":50,\"endColumn\":42},{\"ruleId\":\"max-depth\",\"severity\":1,\"message\":\"Blocks are nested too deeply (6). Maximum allowed is 5.\",\"line\":57,\"column\":15,\"nodeType\":\"ForStatement\",\"messageId\":\"tooDeeply\",\"endLine\":67,\"endColumn\":16},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":64,\"column\":47,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":64,\"endColumn\":48},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":64,\"column\":55,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":64,\"endColumn\":56},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":64,\"column\":67,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":64,\"endColumn\":68},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":64,\"column\":71,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":64,\"endColumn\":72},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":70,\"column\":78,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":70,\"endColumn\":79},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":70,\"column\":87,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":70,\"endColumn\":88},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":97,\"column\":54,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":97,\"endColumn\":55},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":97,\"column\":58,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":97,\"endColumn\":59},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'windowSize' is assigned a value but never used. Allowed unused vars must match /^_/u.\",\"line\":176,\"column\":13,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":176,\"endColumn\":23,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"windowSize\"},\"fix\":{\"range\":[4743,4777],\"text\":\"\"},\"desc\":\"Remove unused variable 'windowSize'.\"}]},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":176,\"column\":33,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":176,\"endColumn\":34},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":176,\"column\":37,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":176,\"endColumn\":38},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":180,\"column\":33,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":180,\"endColumn\":34},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":180,\"column\":41,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":180,\"endColumn\":42},{\"ruleId\":\"max-depth\",\"severity\":1,\"message\":\"Blocks are nested too deeply (6). Maximum allowed is 5.\",\"line\":187,\"column\":15,\"nodeType\":\"ForStatement\",\"messageId\":\"tooDeeply\",\"endLine\":192,\"endColumn\":16},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":190,\"column\":41,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":190,\"endColumn\":42},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":190,\"column\":49,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":190,\"endColumn\":50},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":190,\"column\":55,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":190,\"endColumn\":56},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":190,\"column\":59,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":190,\"endColumn\":60},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":238,\"column\":40,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":238,\"endColumn\":41},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":238,\"column\":53,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":238,\"endColumn\":54},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":273,\"column\":33,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":273,\"endColumn\":34},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":273,\"column\":41,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":273,\"endColumn\":42},{\"ruleId\":\"max-depth\",\"severity\":1,\"message\":\"Blocks are nested too deeply (6). Maximum allowed is 5.\",\"line\":281,\"column\":15,\"nodeType\":\"ForStatement\",\"messageId\":\"tooDeeply\",\"endLine\":298,\"endColumn\":16},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":284,\"column\":43,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":284,\"endColumn\":44},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":284,\"column\":51,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":284,\"endColumn\":52},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":284,\"column\":57,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":284,\"endColumn\":58},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":284,\"column\":61,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":284,\"endColumn\":62},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":288,\"column\":54,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":288,\"endColumn\":55},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":288,\"column\":59,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":288,\"endColumn\":60},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":288,\"column\":59,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":288,\"endColumn\":60},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":288,\"column\":64,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":288,\"endColumn\":65}],\"suppressedMessages\":[],\"errorCount\":2,\"fatalErrorCount\":0,\"warningCount\":34,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Image Filter Processing Module\\n * Handles image filtering operations like blur, sharpen, edge detection\\n */\\n\\nimport { ErrorCategory, ErrorSeverity, handleError } from '../../../shared/utils/error-handler.js';\\n\\nexport const createFilterProcessor = (resourcePool) => {\\n  // Common convolution kernels\\n  const KERNELS = {\\n    BLUR: [\\n      [1/9, 1/9, 1/9],\\n      [1/9, 1/9, 1/9],\\n      [1/9, 1/9, 1/9]\\n    ],\\n    GAUSSIAN_BLUR: [\\n      [1/16, 2/16, 1/16],\\n      [2/16, 4/16, 2/16],\\n      [1/16, 2/16, 1/16]\\n    ],\\n    SHARPEN: [\\n      [ 0, -1,  0],\\n      [-1,  5, -1],\\n      [ 0, -1,  0]\\n    ],\\n    EDGE_DETECTION: [\\n      [-1, -1, -1],\\n      [-1,  8, -1],\\n      [-1, -1, -1]\\n    ],\\n    EMBOSS: [\\n      [-2, -1,  0],\\n      [-1,  1,  1],\\n      [ 0,  1,  2]\\n    ]\\n  };\\n\\n  /**\\n   * Apply convolution filter to image\\n   */\\n  const applyConvolution = (imageData, kernel, factor = 1, bias = 0) => {\\n    try {\\n      const { data, width, height } = imageData;\\n      const outputData = new Uint8ClampedArray(data.length);\\n      const kernelSize = kernel.length;\\n      const half = Math.floor(kernelSize / 2);\\n      \\n      for (let y = 0; y < height; y++) {\\n        for (let x = 0; x < width; x++) {\\n          const pixelIndex = (y * width + x) * 4;\\n          \\n          // Apply kernel to RGB channels\\n          for (let channel = 0; channel < 3; channel++) {\\n            let sum = 0;\\n            \\n            for (let ky = 0; ky < kernelSize; ky++) {\\n              for (let kx = 0; kx < kernelSize; kx++) {\\n                const py = y + ky - half;\\n                const px = x + kx - half;\\n                \\n                // Handle edge cases by clamping\\n                const clampedY = Math.max(0, Math.min(height - 1, py));\\n                const clampedX = Math.max(0, Math.min(width - 1, px));\\n                const sourceIndex = (clampedY * width + clampedX) * 4 + channel;\\n                \\n                sum += data[sourceIndex] * kernel[ky][kx];\\n              }\\n            }\\n            \\n            outputData[pixelIndex + channel] = Math.max(0, Math.min(255, sum * factor + bias));\\n          }\\n          \\n          // Copy alpha channel unchanged\\n          outputData[pixelIndex + 3] = data[pixelIndex + 3];\\n        }\\n      }\\n      \\n      return new ImageData(outputData, width, height);\\n      \\n    } catch (error) {\\n      handleError(\\n        `Convolution filter failed: ${error.message}`,\\n        ErrorCategory.PROCESSING,\\n        ErrorSeverity.ERROR,\\n        { kernelSize: kernel.length }\\n      );\\n      throw error;\\n    }\\n  };\\n\\n  /**\\n   * Apply Gaussian blur with variable radius\\n   */\\n  const gaussianBlur = (imageData, radius = 1) => {\\n    try {\\n      // Generate Gaussian kernel\\n      const size = Math.max(3, Math.ceil(radius * 2) * 2 + 1);\\n      const kernel = generateGaussianKernel(size, radius);\\n      \\n      return applyConvolution(imageData, kernel);\\n      \\n    } catch (error) {\\n      handleError(\\n        `Gaussian blur failed: ${error.message}`,\\n        ErrorCategory.PROCESSING,\\n        ErrorSeverity.ERROR,\\n        { radius }\\n      );\\n      throw error;\\n    }\\n  };\\n\\n  /**\\n   * Generate Gaussian kernel for blur operations\\n   */\\n  const generateGaussianKernel = (size, sigma) => {\\n    const kernel = [];\\n    const center = Math.floor(size / 2);\\n    let sum = 0;\\n    \\n    for (let y = 0; y < size; y++) {\\n      kernel[y] = [];\\n      for (let x = 0; x < size; x++) {\\n        const distanceSquared = Math.pow(x - center, 2) + Math.pow(y - center, 2);\\n        const value = Math.exp(-distanceSquared / (2 * sigma * sigma));\\n        kernel[y][x] = value;\\n        sum += value;\\n      }\\n    }\\n    \\n    // Normalize kernel\\n    for (let y = 0; y < size; y++) {\\n      for (let x = 0; x < size; x++) {\\n        kernel[y][x] /= sum;\\n      }\\n    }\\n    \\n    return kernel;\\n  };\\n\\n  /**\\n   * Apply predefined filter by name\\n   */\\n  const applyFilter = (imageData, filterType, intensity = 1.0) => {\\n    try {\\n      const kernel = KERNELS[filterType.toUpperCase()];\\n      if (!kernel) {\\n        throw new Error(`Unknown filter type: ${filterType}`);\\n      }\\n      \\n      // Scale kernel intensity\\n      const scaledKernel = kernel.map(row => \\n        row.map(value => value * intensity)\\n      );\\n      \\n      return applyConvolution(imageData, scaledKernel);\\n      \\n    } catch (error) {\\n      handleError(\\n        `Filter application failed: ${error.message}`,\\n        ErrorCategory.PROCESSING,\\n        ErrorSeverity.ERROR,\\n        { filterType, intensity }\\n      );\\n      throw error;\\n    }\\n  };\\n\\n  /**\\n   * Apply median filter for noise reduction\\n   */\\n  const medianFilter = (imageData, radius = 1) => {\\n    try {\\n      const { data, width, height } = imageData;\\n      const outputData = new Uint8ClampedArray(data.length);\\n      const windowSize = radius * 2 + 1;\\n      \\n      for (let y = 0; y < height; y++) {\\n        for (let x = 0; x < width; x++) {\\n          const pixelIndex = (y * width + x) * 4;\\n          \\n          // Apply median filter to RGB channels\\n          for (let channel = 0; channel < 3; channel++) {\\n            const values = [];\\n            \\n            for (let dy = -radius; dy <= radius; dy++) {\\n              for (let dx = -radius; dx <= radius; dx++) {\\n                const py = Math.max(0, Math.min(height - 1, y + dy));\\n                const px = Math.max(0, Math.min(width - 1, x + dx));\\n                const sourceIndex = (py * width + px) * 4 + channel;\\n                values.push(data[sourceIndex]);\\n              }\\n            }\\n            \\n            values.sort((a, b) => a - b);\\n            const medianIndex = Math.floor(values.length / 2);\\n            outputData[pixelIndex + channel] = values[medianIndex];\\n          }\\n          \\n          // Copy alpha channel unchanged\\n          outputData[pixelIndex + 3] = data[pixelIndex + 3];\\n        }\\n      }\\n      \\n      return new ImageData(outputData, width, height);\\n      \\n    } catch (error) {\\n      handleError(\\n        `Median filter failed: ${error.message}`,\\n        ErrorCategory.PROCESSING,\\n        ErrorSeverity.ERROR,\\n        { radius }\\n      );\\n      throw error;\\n    }\\n  };\\n\\n  /**\\n   * Apply unsharp mask for image sharpening\\n   */\\n  const unsharpMask = (imageData, amount = 1.0, radius = 1.0, threshold = 0) => {\\n    try {\\n      // Create blurred version\\n      const blurred = gaussianBlur(imageData, radius);\\n      \\n      const { data, width, height } = imageData;\\n      const blurredData = blurred.data;\\n      const outputData = new Uint8ClampedArray(data.length);\\n      \\n      for (let i = 0; i < data.length; i += 4) {\\n        for (let channel = 0; channel < 3; channel++) {\\n          const original = data[i + channel];\\n          const blur = blurredData[i + channel];\\n          const difference = original - blur;\\n          \\n          // Apply threshold\\n          if (Math.abs(difference) >= threshold) {\\n            const sharpened = original + difference * amount;\\n            outputData[i + channel] = Math.max(0, Math.min(255, sharpened));\\n          } else {\\n            outputData[i + channel] = original;\\n          }\\n        }\\n        \\n        // Copy alpha channel\\n        outputData[i + 3] = data[i + 3];\\n      }\\n      \\n      return new ImageData(outputData, width, height);\\n      \\n    } catch (error) {\\n      handleError(\\n        `Unsharp mask failed: ${error.message}`,\\n        ErrorCategory.PROCESSING,\\n        ErrorSeverity.ERROR,\\n        { amount, radius, threshold }\\n      );\\n      throw error;\\n    }\\n  };\\n\\n  /**\\n   * Apply bilateral filter for edge-preserving smoothing\\n   */\\n  const bilateralFilter = (imageData, spatialSigma = 5, colorSigma = 50) => {\\n    try {\\n      const { data, width, height } = imageData;\\n      const outputData = new Uint8ClampedArray(data.length);\\n      const radius = Math.ceil(spatialSigma * 3);\\n      \\n      for (let y = 0; y < height; y++) {\\n        for (let x = 0; x < width; x++) {\\n          const pixelIndex = (y * width + x) * 4;\\n          \\n          for (let channel = 0; channel < 3; channel++) {\\n            const centerValue = data[pixelIndex + channel];\\n            let weightedSum = 0;\\n            let normalization = 0;\\n            \\n            for (let dy = -radius; dy <= radius; dy++) {\\n              for (let dx = -radius; dx <= radius; dx++) {\\n                const py = Math.max(0, Math.min(height - 1, y + dy));\\n                const px = Math.max(0, Math.min(width - 1, x + dx));\\n                const neighborIndex = (py * width + px) * 4 + channel;\\n                const neighborValue = data[neighborIndex];\\n                \\n                // Spatial weight\\n                const spatialDistance = Math.sqrt(dx * dx + dy * dy);\\n                const spatialWeight = Math.exp(-(spatialDistance * spatialDistance) / (2 * spatialSigma * spatialSigma));\\n                \\n                // Color weight\\n                const colorDistance = Math.abs(centerValue - neighborValue);\\n                const colorWeight = Math.exp(-(colorDistance * colorDistance) / (2 * colorSigma * colorSigma));\\n                \\n                const totalWeight = spatialWeight * colorWeight;\\n                weightedSum += neighborValue * totalWeight;\\n                normalization += totalWeight;\\n              }\\n            }\\n            \\n            outputData[pixelIndex + channel] = Math.round(weightedSum / normalization);\\n          }\\n          \\n          // Copy alpha channel\\n          outputData[pixelIndex + 3] = data[pixelIndex + 3];\\n        }\\n      }\\n      \\n      return new ImageData(outputData, width, height);\\n      \\n    } catch (error) {\\n      handleError(\\n        `Bilateral filter failed: ${error.message}`,\\n        ErrorCategory.PROCESSING,\\n        ErrorSeverity.ERROR,\\n        { spatialSigma, colorSigma }\\n      );\\n      throw error;\\n    }\\n  };\\n\\n  return {\\n    applyFilter,\\n    applyConvolution,\\n    gaussianBlur,\\n    medianFilter,\\n    unsharpMask,\\n    bilateralFilter,\\n    \\n    // Export available filter types\\n    getAvailableFilters: () => Object.keys(KERNELS),\\n    \\n    // Export kernels for advanced use\\n    getKernel: (filterType) => KERNELS[filterType.toUpperCase()]\\n  };\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/core/engine/processors/resize-processor.js\",\"messages\":[{\"ruleId\":\"max-lines-per-function\",\"severity\":1,\"message\":\"Arrow function has too many lines (164). Maximum allowed is 150.\",\"line\":9,\"column\":38,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"exceed\",\"endLine\":250,\"endColumn\":2},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":39,\"column\":32,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":39,\"endColumn\":33},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":39,\"column\":46,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":39,\"endColumn\":47},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":42,\"column\":42,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":42,\"endColumn\":43},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":42,\"column\":56,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":42,\"endColumn\":57},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":42,\"column\":62,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":42,\"endColumn\":63},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":42,\"column\":66,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":42,\"endColumn\":67},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":43,\"column\":43,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":43,\"endColumn\":44},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":43,\"column\":57,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":43,\"endColumn\":58},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":43,\"column\":63,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":43,\"endColumn\":64},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":43,\"column\":67,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":43,\"endColumn\":68},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":44,\"column\":45,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":44,\"endColumn\":46},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":44,\"column\":59,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":44,\"endColumn\":60},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":44,\"column\":65,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":44,\"endColumn\":66},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":44,\"column\":69,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":44,\"endColumn\":70},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":45,\"column\":46,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":45,\"endColumn\":47},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":45,\"column\":60,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":45,\"endColumn\":61},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":45,\"column\":66,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":45,\"endColumn\":67},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":45,\"column\":70,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":45,\"endColumn\":71},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":47,\"column\":31,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":47,\"endColumn\":32},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":47,\"column\":42,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":47,\"endColumn\":43},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":47,\"column\":42,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":47,\"endColumn\":43},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":47,\"column\":53,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":47,\"endColumn\":54},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":48,\"column\":37,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":48,\"endColumn\":38},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":48,\"column\":48,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":48,\"endColumn\":49},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":48,\"column\":48,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":48,\"endColumn\":49},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":48,\"column\":62,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":48,\"endColumn\":63},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":49,\"column\":29,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":49,\"endColumn\":30},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":49,\"column\":40,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":49,\"endColumn\":41},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":49,\"column\":40,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":49,\"endColumn\":41},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":49,\"column\":49,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":49,\"endColumn\":50},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":81,\"column\":38,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":81,\"endColumn\":39},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":81,\"column\":52,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":81,\"endColumn\":53},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":82,\"column\":32,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":82,\"endColumn\":33},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":82,\"column\":46,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":82,\"endColumn\":47}],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":35,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Image Resize Processor\\n * Handles image resizing operations with multiple interpolation methods\\n */\\n\\nimport { INTERPOLATION_METHODS } from '../image-operations.js';\\nimport { ErrorCategory, ErrorSeverity, handleError } from '../../../shared/utils/error-handler.js';\\n\\nexport const createResizeProcessor = (resourcePool) => {\\n  /**\\n   * Resize image using bilinear interpolation\\n   */\\n  const bilinearResize = (imageData, targetWidth, targetHeight) => {\\n    const sourceWidth = imageData.width;\\n    const sourceHeight = imageData.height;\\n    const sourceData = imageData.data;\\n    \\n    const canvas = resourcePool.getCanvas(targetWidth, targetHeight);\\n    const ctx = canvas.getContext('2d');\\n    const targetImageData = ctx.createImageData(targetWidth, targetHeight);\\n    const targetData = targetImageData.data;\\n    \\n    const xRatio = sourceWidth / targetWidth;\\n    const yRatio = sourceHeight / targetHeight;\\n    \\n    for (let y = 0; y < targetHeight; y++) {\\n      for (let x = 0; x < targetWidth; x++) {\\n        const sourceX = x * xRatio;\\n        const sourceY = y * yRatio;\\n        \\n        const x1 = Math.floor(sourceX);\\n        const y1 = Math.floor(sourceY);\\n        const x2 = Math.min(x1 + 1, sourceWidth - 1);\\n        const y2 = Math.min(y1 + 1, sourceHeight - 1);\\n        \\n        const dx = sourceX - x1;\\n        const dy = sourceY - y1;\\n        \\n        const targetIndex = (y * targetWidth + x) * 4;\\n        \\n        for (let channel = 0; channel < 4; channel++) {\\n          const topLeft = sourceData[(y1 * sourceWidth + x1) * 4 + channel];\\n          const topRight = sourceData[(y1 * sourceWidth + x2) * 4 + channel];\\n          const bottomLeft = sourceData[(y2 * sourceWidth + x1) * 4 + channel];\\n          const bottomRight = sourceData[(y2 * sourceWidth + x2) * 4 + channel];\\n          \\n          const top = topLeft * (1 - dx) + topRight * dx;\\n          const bottom = bottomLeft * (1 - dx) + bottomRight * dx;\\n          const final = top * (1 - dy) + bottom * dy;\\n          \\n          targetData[targetIndex + channel] = Math.round(final);\\n        }\\n      }\\n    }\\n    \\n    resourcePool.returnCanvas(canvas);\\n    return targetImageData;\\n  };\\n\\n  /**\\n   * Resize image using nearest neighbor interpolation\\n   */\\n  const nearestNeighborResize = (imageData, targetWidth, targetHeight) => {\\n    const sourceWidth = imageData.width;\\n    const sourceHeight = imageData.height;\\n    const sourceData = imageData.data;\\n    \\n    const canvas = resourcePool.getCanvas(targetWidth, targetHeight);\\n    const ctx = canvas.getContext('2d');\\n    const targetImageData = ctx.createImageData(targetWidth, targetHeight);\\n    const targetData = targetImageData.data;\\n    \\n    const xRatio = sourceWidth / targetWidth;\\n    const yRatio = sourceHeight / targetHeight;\\n    \\n    for (let y = 0; y < targetHeight; y++) {\\n      for (let x = 0; x < targetWidth; x++) {\\n        const sourceX = Math.round(x * xRatio);\\n        const sourceY = Math.round(y * yRatio);\\n        \\n        const sourceIndex = (sourceY * sourceWidth + sourceX) * 4;\\n        const targetIndex = (y * targetWidth + x) * 4;\\n        \\n        targetData[targetIndex] = sourceData[sourceIndex];         // R\\n        targetData[targetIndex + 1] = sourceData[sourceIndex + 1]; // G\\n        targetData[targetIndex + 2] = sourceData[sourceIndex + 2]; // B\\n        targetData[targetIndex + 3] = sourceData[sourceIndex + 3]; // A\\n      }\\n    }\\n    \\n    resourcePool.returnCanvas(canvas);\\n    return targetImageData;\\n  };\\n\\n  /**\\n   * Resize image using canvas built-in interpolation (fastest)\\n   */\\n  const canvasResize = (imageData, targetWidth, targetHeight) => {\\n    // Create source canvas\\n    const sourceCanvas = resourcePool.getCanvas(imageData.width, imageData.height);\\n    const sourceCtx = sourceCanvas.getContext('2d');\\n    sourceCtx.putImageData(imageData, 0, 0);\\n    \\n    // Create target canvas\\n    const targetCanvas = resourcePool.getCanvas(targetWidth, targetHeight);\\n    const targetCtx = targetCanvas.getContext('2d');\\n    \\n    // Use canvas scaling\\n    targetCtx.drawImage(sourceCanvas, 0, 0, targetWidth, targetHeight);\\n    const result = targetCtx.getImageData(0, 0, targetWidth, targetHeight);\\n    \\n    // Clean up\\n    resourcePool.returnCanvas(sourceCanvas);\\n    resourcePool.returnCanvas(targetCanvas);\\n    \\n    return result;\\n  };\\n\\n  /**\\n   * Main resize function with method selection\\n   */\\n  const resizeImage = (imageData, targetWidth, targetHeight, method = INTERPOLATION_METHODS.BILINEAR) => {\\n    try {\\n      if (!imageData || !imageData.data) {\\n        throw new Error('Invalid image data provided');\\n      }\\n      \\n      if (targetWidth <= 0 || targetHeight <= 0) {\\n        throw new Error('Target dimensions must be positive');\\n      }\\n      \\n      // Skip resize if dimensions match\\n      if (imageData.width === targetWidth && imageData.height === targetHeight) {\\n        return imageData;\\n      }\\n      \\n      switch (method) {\\n        case INTERPOLATION_METHODS.NEAREST:\\n          return nearestNeighborResize(imageData, targetWidth, targetHeight);\\n        \\n        case INTERPOLATION_METHODS.BILINEAR:\\n          return bilinearResize(imageData, targetWidth, targetHeight);\\n        \\n        case INTERPOLATION_METHODS.CANVAS:\\n        default:\\n          return canvasResize(imageData, targetWidth, targetHeight);\\n      }\\n      \\n    } catch (error) {\\n      handleError(\\n        `Image resize failed: ${error.message}`,\\n        ErrorCategory.PROCESSING,\\n        ErrorSeverity.ERROR,\\n        { \\n          sourceSize: [imageData?.width, imageData?.height], \\n          targetSize: [targetWidth, targetHeight], \\n          method \\n        }\\n      );\\n      throw error;\\n    }\\n  };\\n\\n  /**\\n   * Resize with aspect ratio preservation\\n   */\\n  const resizeWithAspectRatio = (imageData, maxWidth, maxHeight, method) => {\\n    const sourceWidth = imageData.width;\\n    const sourceHeight = imageData.height;\\n    const sourceAspectRatio = sourceWidth / sourceHeight;\\n    const targetAspectRatio = maxWidth / maxHeight;\\n    \\n    let targetWidth, targetHeight;\\n    \\n    if (sourceAspectRatio > targetAspectRatio) {\\n      // Width is the limiting factor\\n      targetWidth = maxWidth;\\n      targetHeight = Math.round(maxWidth / sourceAspectRatio);\\n    } else {\\n      // Height is the limiting factor\\n      targetHeight = maxHeight;\\n      targetWidth = Math.round(maxHeight * sourceAspectRatio);\\n    }\\n    \\n    return resizeImage(imageData, targetWidth, targetHeight, method);\\n  };\\n\\n  /**\\n   * Center crop and resize\\n   */\\n  const centerCropAndResize = (imageData, targetWidth, targetHeight, method) => {\\n    const sourceWidth = imageData.width;\\n    const sourceHeight = imageData.height;\\n    \\n    // Calculate crop dimensions to match target aspect ratio\\n    const targetAspectRatio = targetWidth / targetHeight;\\n    const sourceAspectRatio = sourceWidth / sourceHeight;\\n    \\n    let cropWidth, cropHeight, cropX, cropY;\\n    \\n    if (sourceAspectRatio > targetAspectRatio) {\\n      // Source is wider - crop width\\n      cropHeight = sourceHeight;\\n      cropWidth = Math.round(sourceHeight * targetAspectRatio);\\n      cropX = Math.round((sourceWidth - cropWidth) / 2);\\n      cropY = 0;\\n    } else {\\n      // Source is taller - crop height\\n      cropWidth = sourceWidth;\\n      cropHeight = Math.round(sourceWidth / targetAspectRatio);\\n      cropX = 0;\\n      cropY = Math.round((sourceHeight - cropHeight) / 2);\\n    }\\n    \\n    // First crop, then resize\\n    const croppedData = cropImage(imageData, cropX, cropY, cropWidth, cropHeight);\\n    return resizeImage(croppedData, targetWidth, targetHeight, method);\\n  };\\n\\n  /**\\n   * Simple crop function for center crop and resize\\n   */\\n  const cropImage = (imageData, x, y, width, height) => {\\n    const canvas = resourcePool.getCanvas(width, height);\\n    const ctx = canvas.getContext('2d');\\n    \\n    const sourceCanvas = resourcePool.getCanvas(imageData.width, imageData.height);\\n    const sourceCtx = sourceCanvas.getContext('2d');\\n    sourceCtx.putImageData(imageData, 0, 0);\\n    \\n    ctx.drawImage(sourceCanvas, x, y, width, height, 0, 0, width, height);\\n    const result = ctx.getImageData(0, 0, width, height);\\n    \\n    resourcePool.returnCanvas(canvas);\\n    resourcePool.returnCanvas(sourceCanvas);\\n    \\n    return result;\\n  };\\n\\n  return {\\n    resizeImage,\\n    resizeWithAspectRatio,\\n    centerCropAndResize,\\n    \\n    // Export individual methods for advanced use\\n    bilinearResize,\\n    nearestNeighborResize,\\n    canvasResize\\n  };\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/core/engine/webgl-engine.js\",\"messages\":[{\"ruleId\":\"no-param-reassign\",\"severity\":1,\"message\":\"Assignment to function parameter 'format'.\",\"line\":222,\"column\":7,\"nodeType\":\"Identifier\",\"messageId\":\"assignmentToFunctionParam\",\"endLine\":222,\"endColumn\":13},{\"ruleId\":\"no-param-reassign\",\"severity\":1,\"message\":\"Assignment to function parameter 'type'.\",\"line\":225,\"column\":7,\"nodeType\":\"Identifier\",\"messageId\":\"assignmentToFunctionParam\",\"endLine\":225,\"endColumn\":11}],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":2,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Core WebGL2 Engine - Zero dependency WebGL management system\\n * Handles context initialization, shader compilation, and resource management\\n */\\n\\nexport const createWebGLEngine = (canvas) => {\\n  const state = {\\n    canvas,\\n    gl: null,\\n    programs: new Map(),\\n    buffers: null,\\n    textures: null,\\n    isInitialized: false,\\n    isWebGL2: false,\\n    ext_texture_float: null,\\n    ext_texture_half_float: null\\n  };\\n\\n  const init = () => {\\n    // Try WebGL2 first, fallback to WebGL1\\n    state.gl = state.canvas.getContext('webgl2', {\\n      alpha: false,\\n      antialias: false,\\n      depth: false,\\n      stencil: false,\\n      preserveDrawingBuffer: false,\\n      powerPreference: 'high-performance'\\n    });\\n\\n    if (!state.gl) {\\n      // Fallback to WebGL1\\n      state.gl = state.canvas.getContext('webgl', {\\n        alpha: false,\\n        antialias: false,\\n        depth: false,\\n        stencil: false,\\n        preserveDrawingBuffer: false,\\n        powerPreference: 'high-performance'\\n      });\\n      \\n      if (!state.gl) {\\n        throw new Error('WebGL not supported');\\n      }\\n      \\n      state.isWebGL2 = false;\\n    } else {\\n      state.isWebGL2 = true;\\n    }\\n\\n    // Get extensions\\n    state.ext_texture_float = state.gl.getExtension('OES_texture_float');\\n    state.ext_texture_half_float = state.gl.getExtension('OES_texture_half_float');\\n\\n    state.isInitialized = true;\\n    return state.gl;\\n  };\\n\\n  const compileShader = (type, source) => {\\n    const shader = state.gl.createShader(type);\\n    state.gl.shaderSource(shader, source);\\n    state.gl.compileShader(shader);\\n\\n    if (!state.gl.getShaderParameter(shader, state.gl.COMPILE_STATUS)) {\\n      const error = state.gl.getShaderInfoLog(shader);\\n      state.gl.deleteShader(shader);\\n      throw new Error(`Shader compilation failed: ${error}`);\\n    }\\n\\n    return shader;\\n  };\\n\\n  const createShaderProgram = (vertexShaderSource, fragmentShaderSource, name) => {\\n    const vertexShader = compileShader(state.gl.VERTEX_SHADER, vertexShaderSource);\\n    const fragmentShader = compileShader(state.gl.FRAGMENT_SHADER, fragmentShaderSource);\\n\\n    const program = state.gl.createProgram();\\n    state.gl.attachShader(program, vertexShader);\\n    state.gl.attachShader(program, fragmentShader);\\n    state.gl.linkProgram(program);\\n\\n    if (!state.gl.getProgramParameter(program, state.gl.LINK_STATUS)) {\\n      throw new Error(`Program linking failed: ${  state.gl.getProgramInfoLog(program)}`);\\n    }\\n\\n    const uniforms = getUniformLocations(program);\\n    const attributes = getAttributeLocations(program);\\n\\n    const programInfo = {\\n      program,\\n      uniforms,\\n      attributes\\n    };\\n\\n    if (name) {\\n      state.programs.set(name, programInfo);\\n    }\\n\\n    // Cleanup\\n    state.gl.deleteShader(vertexShader);\\n    state.gl.deleteShader(fragmentShader);\\n\\n    return programInfo;\\n  };\\n\\n  const getUniformLocations = (program) => {\\n    const {gl} = state;\\n    const uniforms = {};\\n    const uniformCount = gl.getProgramParameter(program, gl.ACTIVE_UNIFORMS);\\n    \\n    for (let i = 0; i < uniformCount; i++) {\\n      const uniformInfo = gl.getActiveUniform(program, i);\\n      const location = gl.getUniformLocation(program, uniformInfo.name);\\n      uniforms[uniformInfo.name] = location;\\n    }\\n    \\n    return uniforms;\\n  };\\n\\n  const getAttributeLocations = (program) => {\\n    const {gl} = state;\\n    const attributes = {};\\n    const attributeCount = gl.getProgramParameter(program, gl.ACTIVE_ATTRIBUTES);\\n    \\n    for (let i = 0; i < attributeCount; i++) {\\n      const attributeInfo = gl.getActiveAttrib(program, i);\\n      const location = gl.getAttribLocation(program, attributeInfo.name);\\n      attributes[attributeInfo.name] = location;\\n    }\\n    \\n    return attributes;\\n  };\\n\\n  const getProgram = (name) => {\\n    return state.programs.get(name);\\n  };\\n\\n  const useProgram = (name) => {\\n    const programInfo = state.programs.get(name);\\n    if (!programInfo) {\\n      throw new Error(`Shader program '${name}' not found`);\\n    }\\n    \\n    state.gl.useProgram(programInfo.program);\\n    return programInfo;\\n  };\\n\\n  // Initialize the engine\\n  init();\\n\\n  return {\\n    gl: state.gl,\\n    canvas: state.canvas,\\n    isWebGL2: state.isWebGL2,\\n    isInitialized: state.isInitialized,\\n    \\n    // Shader program management\\n    compileShader,\\n    createShaderProgram,\\n    getProgram,\\n    useProgram,\\n    \\n    // Resource managers\\n    buffers: createBufferManager(state.gl),\\n    textures: createTextureManager(state.gl),\\n    \\n    // Context information\\n    getContextInfo: () => ({\\n      version: state.isWebGL2 ? 2 : 1,\\n      vendor: state.gl.getParameter(state.gl.VENDOR),\\n      renderer: state.gl.getParameter(state.gl.RENDERER),\\n      maxTextureSize: state.gl.getParameter(state.gl.MAX_TEXTURE_SIZE),\\n      extensions: {\\n        textureFloat: !!state.ext_texture_float,\\n        textureHalfFloat: !!state.ext_texture_half_float\\n      }\\n    })\\n  };\\n};\\n\\n/**\\n * Buffer Manager - Efficient buffer creation and management\\n */\\nconst createBufferManager = (gl) => {\\n  const state = {\\n    gl,\\n    buffers: new Map()\\n  };\\n\\n  const getBuffer = (name) => {\\n    const bufferInfo = state.buffers.get(name);\\n    return bufferInfo ? bufferInfo.buffer : null;\\n  };\\n\\n  const cleanup = () => {\\n    for (const [, bufferInfo] of state.buffers) {\\n      gl.deleteBuffer(bufferInfo.buffer);\\n    }\\n    state.buffers.clear();\\n  };\\n\\n  return {\\n    getBuffer,\\n    cleanup\\n  };\\n};\\n\\n/**\\n * Texture Manager - Efficient texture creation and management\\n */\\nconst createTextureManager = (gl) => {\\n  const state = {\\n    gl,\\n    textures: new Map(),\\n    activeTextureUnit: 0\\n  };\\n\\n  const createTexture = (name, width, height, format = null, type = null, data = null) => {\\n    const glContext = state.gl;\\n    \\n    // Set defaults based on WebGL version\\n    if (!format) {\\n      format = glContext.RGBA;\\n    }\\n    if (!type) {\\n      type = glContext.UNSIGNED_BYTE;\\n    }\\n\\n    const texture = glContext.createTexture();\\n    glContext.bindTexture(glContext.TEXTURE_2D, texture);\\n    \\n    // Set texture parameters for computer vision (no filtering)\\n    glContext.texParameteri(glContext.TEXTURE_2D, glContext.TEXTURE_MIN_FILTER, glContext.NEAREST);\\n    glContext.texParameteri(glContext.TEXTURE_2D, glContext.TEXTURE_MAG_FILTER, glContext.NEAREST);\\n    glContext.texParameteri(glContext.TEXTURE_2D, glContext.TEXTURE_WRAP_S, glContext.CLAMP_TO_EDGE);\\n    glContext.texParameteri(glContext.TEXTURE_2D, glContext.TEXTURE_WRAP_T, glContext.CLAMP_TO_EDGE);\\n    \\n    // Upload texture data\\n    glContext.texImage2D(glContext.TEXTURE_2D, 0, format, width, height, 0, format, type, data);\\n    \\n    state.textures.set(name, {\\n      texture,\\n      width,\\n      height,\\n      format,\\n      type\\n    });\\n    \\n    return texture;\\n  };\\n\\n  const updateTexture = (name, data, width = null, height = null) => {\\n    const textureInfo = state.textures.get(name);\\n    if (!textureInfo) {\\n      throw new Error(`Texture '${name}' not found`);\\n    }\\n    \\n    const glContext = state.gl;\\n    glContext.bindTexture(glContext.TEXTURE_2D, textureInfo.texture);\\n    \\n    const w = width || textureInfo.width;\\n    const h = height || textureInfo.height;\\n    \\n    glContext.texSubImage2D(glContext.TEXTURE_2D, 0, 0, 0, w, h, textureInfo.format, textureInfo.type, data);\\n  };\\n\\n  const bindTexture = (name, unit = 0) => {\\n    const textureInfo = state.textures.get(name);\\n    if (!textureInfo) {\\n      throw new Error(`Texture '${name}' not found`);\\n    }\\n    \\n    const glContext = state.gl;\\n    glContext.activeTexture(glContext.TEXTURE0 + unit);\\n    glContext.bindTexture(glContext.TEXTURE_2D, textureInfo.texture);\\n    state.activeTextureUnit = unit;\\n    \\n    return unit;\\n  };\\n\\n  const getTexture = (name) => {\\n    return state.textures.get(name);\\n  };\\n\\n  const cleanup = () => {\\n    for (const [, textureInfo] of state.textures) {\\n      state.gl.deleteTexture(textureInfo.texture);\\n    }\\n    state.textures.clear();\\n  };\\n\\n  return {\\n    createTexture,\\n    updateTexture,\\n    bindTexture,\\n    getTexture,\\n    cleanup\\n  };\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/core/engine/webgl-lazy-loader.js\",\"messages\":[],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/core/integration/mediapipe-commons.js\",\"messages\":[],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/core/integration/module-interface.js\",\"messages\":[{\"ruleId\":\"no-undef\",\"severity\":2,\"message\":\"'data' is not defined.\",\"line\":36,\"column\":28,\"nodeType\":\"Identifier\",\"messageId\":\"undef\",\"endLine\":36,\"endColumn\":32},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":73,\"column\":45,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":73,\"endColumn\":46},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":73,\"column\":93,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":73,\"endColumn\":94}],\"suppressedMessages\":[],\"errorCount\":1,\"fatalErrorCount\":0,\"warningCount\":2,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Standard Interface for Face Analysis Modules\\n * All detection, analysis, and processing modules must implement this interface\\n */\\n\\n// Module metadata factory\\nexport const createModuleMetadata = (overrides = {}) => ({\\n  name: 'unknown',\\n  version: '1.0.0',\\n  type: 'unknown',\\n  capabilities: [],\\n  dependencies: [],\\n  performance: {\\n    cpu: 'unknown',\\n    gpu: 'unknown',\\n    memory: 'unknown',\\n    latency: 'unknown'\\n  },\\n  accuracy: {\\n    precision: 'unknown',\\n    recall: 'unknown',\\n    f1Score: 'unknown'\\n  },\\n  ...overrides\\n});\\n\\n// Base module factory function\\nexport const createAnalysisModule = (implementation) => {\\n  // Validate required implementation methods\\n  if (!implementation.initialize) {\\n    throw new Error('Module must implement initialize() function');\\n  }\\n  if (!implementation.process) {\\n    throw new Error('Module must implement process() function');\\n  }\\n  if (!implementation.meta,data) {\\n    throw new Error('Module must provide metadata object');\\n  }\\n\\n  const state = {\\n    config: {},\\n    isInitialized: false,\\n    metadata: implementation.metadata,\\n    performanceMetrics: {\\n      averageProcessingTime: 0,\\n      totalProcessed: 0,\\n      errorRate: 0,\\n      lastProcessingTime: 0,\\n      processingTimes: []\\n    }\\n  };\\n\\n  const validateInput = (input) => {\\n    return input !== null && input !== undefined;\\n  };\\n\\n  const updatePerformanceMetrics = (processingTime, hasError = false) => {\\n    state.performanceMetrics.totalProcessed++;\\n    state.performanceMetrics.lastProcessingTime = processingTime;\\n    \\n    // Keep rolling average of last 100 processing times\\n    state.performanceMetrics.processingTimes.push(processingTime);\\n    if (state.performanceMetrics.processingTimes.length > 100) {\\n      state.performanceMetrics.processingTimes.shift();\\n    }\\n    \\n    state.performanceMetrics.averageProcessingTime = \\n      state.performanceMetrics.processingTimes.reduce((a, b) => a + b, 0) / \\n      state.performanceMetrics.processingTimes.length;\\n\\n    if (hasError) {\\n      state.performanceMetrics.errorRate = \\n        (state.performanceMetrics.errorRate * (state.performanceMetrics.totalProcessed - 1) + 1) / \\n        state.performanceMetrics.totalProcessed;\\n    }\\n  };\\n\\n  const initialize = async (config = {}) => {\\n    state.config = { ...state.config, ...config };\\n    \\n    try {\\n      const result = await implementation.initialize(state.config);\\n      state.isInitialized = true;\\n      return result;\\n    } catch (error) {\\n      state.isInitialized = false;\\n      throw error;\\n    }\\n  };\\n\\n  const process = async (input, context = {}) => {\\n    if (!state.isInitialized) {\\n      throw new Error('Module not initialized. Call initialize() first.');\\n    }\\n    \\n    if (!validateInput(input)) {\\n      throw new Error('Invalid input provided to module');\\n    }\\n\\n    const startTime = performance.now();\\n    \\n    try {\\n      const result = await implementation.process(input, context, state);\\n      const processingTime = performance.now() - startTime;\\n      updatePerformanceMetrics(processingTime, false);\\n      return result;\\n    } catch (error) {\\n      const processingTime = performance.now() - startTime;\\n      updatePerformanceMetrics(processingTime, true);\\n      throw error;\\n    }\\n  };\\n\\n  const cleanup = () => {\\n    if (implementation.cleanup) {\\n      implementation.cleanup(state);\\n    }\\n    state.isInitialized = false;\\n  };\\n\\n  const getPerformanceMetrics = () => ({\\n    ...state.performanceMetrics,\\n    processingTimes: undefined // Don't expose internal array\\n  });\\n\\n  const getMetadata = () => ({ ...state.metadata });\\n  const getConfig = () => ({ ...state.config });\\n  const isReady = () => state.isInitialized;\\n\\n  return {\\n    initialize,\\n    process,\\n    cleanup,\\n    validateInput,\\n    getPerformanceMetrics,\\n    getMetadata,\\n    getConfig,\\n    isReady\\n  };\\n};\\n\\n// Module registry for dynamic loading\\nexport const createModuleRegistry = () => {\\n  const state = {\\n    modules: new Map(),\\n    loadedModules: new Map()\\n  };\\n\\n  const register = (category, name, moduleFactory) => {\\n    if (!state.modules.has(category)) {\\n      state.modules.set(category, new Map());\\n    }\\n    state.modules.get(category).set(name, moduleFactory);\\n  };\\n\\n  const getAvailable = (category = null) => {\\n    if (category) {\\n      const categoryModules = state.modules.get(category);\\n      return categoryModules ? Array.from(categoryModules.keys()) : [];\\n    }\\n    \\n    const all = {};\\n    for (const [cat, modules] of state.modules) {\\n      all[cat] = Array.from(modules.keys());\\n    }\\n    return all;\\n  };\\n\\n  const load = async (category, name, config = {}) => {\\n    const moduleKey = `${category}:${name}`;\\n    \\n    // Return cached module if already loaded\\n    if (state.loadedModules.has(moduleKey)) {\\n      return state.loadedModules.get(moduleKey);\\n    }\\n\\n    const categoryModules = state.modules.get(category);\\n    if (!categoryModules || !categoryModules.has(name)) {\\n      throw new Error(`Module ${category}:${name} not registered`);\\n    }\\n\\n    const moduleFactory = categoryModules.get(name);\\n    const module = await moduleFactory();\\n    const moduleInstance = createAnalysisModule(module);\\n    \\n    // Initialize the module\\n    await moduleInstance.initialize(config);\\n    \\n    // Cache the loaded module\\n    state.loadedModules.set(moduleKey, moduleInstance);\\n    \\n    return moduleInstance;\\n  };\\n\\n  const unload = (category, name) => {\\n    const moduleKey = `${category}:${name}`;\\n    const module = state.loadedModules.get(moduleKey);\\n    \\n    if (module) {\\n      module.cleanup();\\n      state.loadedModules.delete(moduleKey);\\n    }\\n  };\\n\\n  const clear = () => {\\n    // Cleanup all loaded modules\\n    for (const module of state.loadedModules.values()) {\\n      module.cleanup();\\n    }\\n    state.loadedModules.clear();\\n  };\\n\\n  return {\\n    register,\\n    getAvailable,\\n    load,\\n    unload,\\n    clear\\n  };\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/core/integration/transport.js\",\"messages\":[{\"ruleId\":\"max-lines-per-function\",\"severity\":1,\"message\":\"Arrow function has too many lines (255). Maximum allowed is 150.\",\"line\":11,\"column\":41,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"exceed\",\"endLine\":327,\"endColumn\":2},{\"ruleId\":\"consistent-return\",\"severity\":1,\"message\":\"Method 'fetch' expected no return value.\",\"line\":51,\"column\":9,\"nodeType\":\"ReturnStatement\",\"messageId\":\"unexpectedReturnValue\",\"endLine\":51,\"endColumn\":76}],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":2,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\nimport { createLogger } from '../shared/utils/logger.js';\\n\\nconst logger = createLogger({ level: 2 });\\n * Transport Infrastructure for Real-time Data Streaming\\n * Using Bun's native capabilities for WebSocket, HTTP/3, and other protocols\\n * Following functional programming patterns\\n */\\n\\n// WebSocket transport factory using Bun's WebSocket\\nexport const createWebSocketTransport = (config = {}) => {\\n  const state = {\\n    connections: new Map(),\\n    isServer: config.isServer || false,\\n    port: config.port || 8080,\\n    server: null,\\n    clientSocket: null,\\n    callbacks: {\\n      onConnect: [],\\n      onMessage: [],\\n      onDisconnect: [],\\n      onError: []\\n    },\\n    reconnect: {\\n      enabled: config.autoReconnect !== false,\\n      interval: config.reconnectInterval || 5000,\\n      maxAttempts: config.maxReconnectAttempts || 10,\\n      attempts: 0\\n    }\\n  };\\n\\n  // Server-side WebSocket implementation\\n  const startServer = () => {\\n    if (state.server) return state.server;\\n\\n    state.server = Bun.serve({\\n      port: state.port,\\n      fetch(req, server) {\\n        \\n        // Handle WebSocket upgrade\\n        if (server.upgrade(req, {\\n          data: { \\n            id: crypto.randomUUID(),\\n            connectedAt: Date.now()\\n          }\\n        })) {\\n          return; // Successfully upgraded\\n        }\\n        \\n        // Fallback for non-WebSocket requests\\n        return new Response(\\\"WebSocket transport server\\\", { status: 200 });\\n      },\\n      \\n      websocket: {\\n        open(ws) {\\n          const connectionId = ws.data.id;\\n          state.connections.set(connectionId, ws);\\n          \\n          // Notify connection callbacks\\n          state.callbacks.onConnect.forEach(cb => {\\n            try {\\n              cb({ id: connectionId, socket: ws });\\n            } catch (error) {\\n              console.warn('Connect callback error:', error);\\n            }\\n          });\\n        },\\n        \\n        message(ws, message) {\\n          let parsedMessage;\\n          try {\\n            parsedMessage = typeof message === 'string' ? JSON.parse(message) : message;\\n          } catch (error) {\\n            console.warn('Message parsing error:', error);\\n            return;\\n          }\\n          \\n          // Notify message callbacks\\n          state.callbacks.onMessage.forEach(cb => {\\n            try {\\n              cb(parsedMessage, ws);\\n            } catch (error) {\\n              console.warn('Message callback error:', error);\\n            }\\n          });\\n        },\\n        \\n        close(ws) {\\n          const connectionId = ws.data.id;\\n          state.connections.delete(connectionId);\\n          \\n          // Notify disconnect callbacks\\n          state.callbacks.onDisconnect.forEach(cb => {\\n            try {\\n              cb({ id: connectionId, socket: ws });\\n            } catch (error) {\\n              console.warn('Disconnect callback error:', error);\\n            }\\n          });\\n        },\\n        \\n        error(ws, error) {\\n          console.error('WebSocket error:', error);\\n          \\n          state.callbacks.onError.forEach(cb => {\\n            try {\\n              cb(error, ws);\\n            } catch (cbError) {\\n              console.warn('Error callback failed:', cbError);\\n            }\\n          });\\n        }\\n      }\\n    });\\n\\n    console.log(`WebSocket server listening on port ${state.port}`);\\n    return state.server;\\n  };\\n\\n  // Client-side WebSocket connection\\n  const connect = async (url) => {\\n    if (state.clientSocket) return state.clientSocket;\\n\\n    return new Promise((resolve, reject) => {\\n      try {\\n        state.clientSocket = new WebSocket(url);\\n        \\n        state.clientSocket.onopen = () => {\\n          state.reconnect.attempts = 0;\\n          \\n          state.callbacks.onConnect.forEach(cb => {\\n            try {\\n              cb({ socket: state.clientSocket });\\n            } catch (error) {\\n              console.warn('Connect callback error:', error);\\n            }\\n          });\\n          \\n          resolve(state.clientSocket);\\n        };\\n        \\n        state.clientSocket.onmessage = (event) => {\\n          let parsedMessage;\\n          try {\\n            parsedMessage = JSON.parse(event.data);\\n          } catch (error) {\\n            console.warn('Message parsing error:', error);\\n            return;\\n          }\\n          \\n          state.callbacks.onMessage.forEach(cb => {\\n            try {\\n              cb(parsedMessage, state.clientSocket);\\n            } catch (error) {\\n              console.warn('Message callback error:', error);\\n            }\\n          });\\n        };\\n        \\n        state.clientSocket.onclose = () => {\\n          state.clientSocket = null;\\n          \\n          state.callbacks.onDisconnect.forEach(cb => {\\n            try {\\n              cb({ socket: state.clientSocket });\\n            } catch (error) {\\n              console.warn('Disconnect callback error:', error);\\n            }\\n          });\\n          \\n          // Auto-reconnect if enabled\\n          if (state.reconnect.enabled && state.reconnect.attempts < state.reconnect.maxAttempts) {\\n            setTimeout(() => {\\n              state.reconnect.attempts++;\\n              console.log(`Reconnect attempt ${state.reconnect.attempts}/${state.reconnect.maxAttempts}`);\\n              connect(url);\\n            }, state.reconnect.interval);\\n          }\\n        };\\n        \\n        state.clientSocket.onerror = (error) => {\\n          state.callbacks.onError.forEach(cb => {\\n            try {\\n              cb(error, state.clientSocket);\\n            } catch (cbError) {\\n              console.warn('Error callback failed:', cbError);\\n            }\\n          });\\n          \\n          reject(error);\\n        };\\n        \\n      } catch (error) {\\n        reject(error);\\n      }\\n    });\\n  };\\n\\n  // Send data to all connections (server) or to server (client)\\n  const send = (data) => {\\n    const message = JSON.stringify(data);\\n    \\n    if (state.isServer) {\\n      // Broadcast to all connected clients\\n      let sent = 0;\\n      for (const [id, ws] of state.connections) {\\n        try {\\n          ws.send(message);\\n          sent++;\\n        } catch (error) {\\n          console.warn(`Failed to send to connection ${id}:`, error);\\n        }\\n      }\\n      return sent;\\n    } else {\\n      // Send to server\\n      if (state.clientSocket && state.clientSocket.readyState === WebSocket.OPEN) {\\n        state.clientSocket.send(message);\\n        return 1;\\n      }\\n      return 0;\\n    }\\n  };\\n\\n  // Send to specific connection (server only)\\n  const sendTo = (connectionId, data) => {\\n    if (!state.isServer) throw new Error('sendTo only available in server mode');\\n    \\n    const ws = state.connections.get(connectionId);\\n    if (ws) {\\n      try {\\n        ws.send(JSON.stringify(data));\\n        return true;\\n      } catch (error) {\\n        console.warn(`Failed to send to ${connectionId}:`, error);\\n        return false;\\n      }\\n    }\\n    return false;\\n  };\\n\\n  const stop = () => {\\n    // Close all connections\\n    for (const [id, ws] of state.connections) {\\n      try {\\n        ws.close();\\n      } catch (error) {\\n        console.warn(`Error closing connection ${id}:`, error);\\n      }\\n    }\\n    \\n    // Stop server if running\\n    if (state.server) {\\n      state.server.stop();\\n      state.server = null;\\n    }\\n    \\n    // Close client connection\\n    if (state.clientSocket) {\\n      state.clientSocket.close();\\n      state.clientSocket = null;\\n    }\\n    \\n    state.connections.clear();\\n  };\\n\\n  // Event handlers\\n  const onConnect = (callback) => {\\n    state.callbacks.onConnect.push(callback);\\n    return () => {\\n      const index = state.callbacks.onConnect.indexOf(callback);\\n      if (index !== -1) state.callbacks.onConnect.splice(index, 1);\\n    };\\n  };\\n\\n  const onMessage = (callback) => {\\n    state.callbacks.onMessage.push(callback);\\n    return () => {\\n      const index = state.callbacks.onMessage.indexOf(callback);\\n      if (index !== -1) state.callbacks.onMessage.splice(index, 1);\\n    };\\n  };\\n\\n  const onDisconnect = (callback) => {\\n    state.callbacks.onDisconnect.push(callback);\\n    return () => {\\n      const index = state.callbacks.onDisconnect.indexOf(callback);\\n      if (index !== -1) state.callbacks.onDisconnect.splice(index, 1);\\n    };\\n  };\\n\\n  const onError = (callback) => {\\n    state.callbacks.onError.push(callback);\\n    return () => {\\n      const index = state.callbacks.onError.indexOf(callback);\\n      if (index !== -1) state.callbacks.onError.splice(index, 1);\\n    };\\n  };\\n\\n  return {\\n    // Connection management\\n    startServer: state.isServer ? startServer : undefined,\\n    connect: !state.isServer ? connect : undefined,\\n    stop,\\n    \\n    // Data transmission\\n    send,\\n    sendTo: state.isServer ? sendTo : undefined,\\n    \\n    // Event handlers\\n    onConnect,\\n    onMessage,\\n    onDisconnect,\\n    onError,\\n    \\n    // Status\\n    getConnectionCount: () => state.connections.size,\\n    isConnected: () => state.isServer ? state.connections.size > 0 : \\n                       (state.clientSocket && state.clientSocket.readyState === WebSocket.OPEN),\\n    getStats: () => ({\\n      connectionCount: state.connections.size,\\n      isServer: state.isServer,\\n      port: state.port,\\n      reconnectAttempts: state.reconnect.attempts\\n    })\\n  };\\n};\\n\\n// HTTP transport factory using Bun's fetch\\nexport const createHttpTransport = (config = {}) => {\\n  const state = {\\n    baseUrl: config.baseUrl || (process.env.TRANSPORT_BASE_URL || 'http://localhost:8080'),\\n    headers: config.headers || {\\n      'Content-Type': 'application/json'\\n    },\\n    timeout: config.timeout || 10000\\n  };\\n\\n  const send = async (endpoint, data, options = {}) => {\\n    const url = `${state.baseUrl}${endpoint}`;\\n    const method = options.method || 'POST';\\n    \\n    try {\\n      const response = await fetch(url, {\\n        method,\\n        headers: {\\n          ...state.headers,\\n          ...options.headers\\n        },\\n        body: method !== 'GET' ? JSON.stringify(data) : undefined,\\n        signal: AbortSignal.timeout(state.timeout)\\n      });\\n\\n      if (!response.ok) {\\n        throw new Error(`HTTP ${response.status}: ${response.statusText}`);\\n      }\\n\\n      const result = await response.json();\\n      return {\\n        success: true,\\n        data: result,\\n        status: response.status,\\n        headers: Object.fromEntries(response.headers.entries())\\n      };\\n\\n    } catch (error) {\\n      return {\\n        success: false,\\n        error: error.message,\\n        data: null\\n      };\\n    }\\n  };\\n\\n  const get = (endpoint, options = {}) => send(endpoint, null, { ...options, method: 'GET' });\\n  const post = (endpoint, data, options = {}) => send(endpoint, data, { ...options, method: 'POST' });\\n  const put = (endpoint, data, options = {}) => send(endpoint, data, { ...options, method: 'PUT' });\\n  const del = (endpoint, options = {}) => send(endpoint, null, { ...options, method: 'DELETE' });\\n\\n  // Eye tracker specific API methods\\n  const getStatus = () => get('/api/status');\\n  const startRecording = (recordingId, config = {}) => post('/api/recordings', { \\n    recording_id: recordingId,\\n    ...config \\n  });\\n  const stopRecording = () => post('/api/recordings/stop');\\n  const getRecordings = () => get('/api/recordings');\\n  const startCalibration = () => post('/api/calibration/start');\\n  const stopCalibration = () => post('/api/calibration/stop');\\n  const getCalibration = () => get('/api/calibration');\\n\\n  return {\\n    send,\\n    get,\\n    post,\\n    put,\\n    delete: del,\\n    \\n    // Eye tracker specific methods\\n    getStatus,\\n    startRecording,\\n    stopRecording,\\n    getRecordings,\\n    startCalibration,\\n    stopCalibration,\\n    getCalibration,\\n    \\n    // Configuration\\n    getBaseUrl: () => state.baseUrl,\\n    setTimeout: (timeout) => { state.timeout = timeout; },\\n    setHeaders: (headers) => { state.headers = { ...state.headers, ...headers }; }\\n  };\\n};\\n\\n// UDP transport factory using Bun's dgram\\nexport const createUdpTransport = (config = {}) => {\\n  const state = {\\n    socket: null,\\n    port: config.port || 8080,\\n    host: config.host || (process.env.WEBSOCKET_HOST || 'localhost'),\\n    isServer: config.isServer || false,\\n    callbacks: {\\n      onMessage: [],\\n      onError: []\\n    }\\n  };\\n\\n  // Note: Bun doesn't have built-in UDP support yet\\n  // This is a placeholder for when it's available or using Node.js dgram\\n  const start = async () => {\\n    throw new Error('UDP transport not yet implemented - waiting for Bun UDP support');\\n  };\\n\\n  const send = async () => {\\n    throw new Error('UDP transport not yet implemented - waiting for Bun UDP support');\\n  };\\n\\n  const stop = () => {\\n    if (state.socket) {\\n      state.socket.close();\\n      state.socket = null;\\n    }\\n  };\\n\\n  return {\\n    start,\\n    send,\\n    stop,\\n    onMessage: (callback) => {\\n      state.callbacks.onMessage.push(callback);\\n      return () => {\\n        const index = state.callbacks.onMessage.indexOf(callback);\\n        if (index !== -1) state.callbacks.onMessage.splice(index, 1);\\n      };\\n    },\\n    onError: (callback) => {\\n      state.callbacks.onError.push(callback);\\n      return () => {\\n        const index = state.callbacks.onError.indexOf(callback);\\n        if (index !== -1) state.callbacks.onError.splice(index, 1);\\n      };\\n    }\\n  };\\n};\\n\\n// Transport factory registry\\nexport const createTransportFactory = () => {\\n  const transports = new Map();\\n  \\n  // Register default transports\\n  transports.set('websocket', createWebSocketTransport);\\n  transports.set('http', createHttpTransport);\\n  transports.set('udp', createUdpTransport);\\n\\n  const register = (protocol, factory) => {\\n    transports.set(protocol, factory);\\n  };\\n\\n  const create = (protocol, config = {}) => {\\n    const factory = transports.get(protocol);\\n    if (!factory) {\\n      throw new Error(`Unknown transport protocol: ${protocol}`);\\n    }\\n    return factory(config);\\n  };\\n\\n  const getAvailableProtocols = () => Array.from(transports.keys());\\n\\n  return {\\n    register,\\n    create,\\n    getAvailableProtocols\\n  };\\n};\\n\\n// Default transport factory instance\\nexport const transportFactory = createTransportFactory();\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/core/orchestration/aligners/buffer-aligner.js\",\"messages\":[{\"ruleId\":\"no-param-reassign\",\"severity\":1,\"message\":\"Assignment to function parameter 'streamDataArray'.\",\"line\":19,\"column\":7,\"nodeType\":\"Identifier\",\"messageId\":\"assignmentToFunctionParam\",\"endLine\":19,\"endColumn\":22},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '/'. Use parentheses to clarify the intended order of operations.\",\"line\":32,\"column\":37,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":32,\"endColumn\":38},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '/'. Use parentheses to clarify the intended order of operations.\",\"line\":32,\"column\":44,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":32,\"endColumn\":45},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '/'. Use parentheses to clarify the intended order of operations.\",\"line\":73,\"column\":25,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":73,\"endColumn\":26},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '/'. Use parentheses to clarify the intended order of operations.\",\"line\":73,\"column\":73,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":73,\"endColumn\":74}],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":5,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Buffer-Based Aligner\\n * Sliding window alignment for buffered stream synchronization\\n */\\n\\nimport { createSyncMetrics } from '../sync-metrics.js';\\n\\n// Buffer-based sliding window alignment\\nexport const createBufferBasedAligner = () => {\\n  const state = {\\n    windowSize: 1000, // 1 second window\\n    tolerance: 50, // 50ms tolerance\\n    referenceStream: null,\\n    alignmentHistory: []\\n  };\\n\\n  const align = (streamDataArray, referenceTimestamp) => {\\n    if (!Array.isArray(streamDataArray)) {\\n      streamDataArray = [streamDataArray];\\n    }\\n\\n    const results = [];\\n    \\n    for (const streamData of streamDataArray) {\\n      const timestamp = streamData.timestamp || Date.now();\\n      const diff = Math.abs(timestamp - referenceTimestamp);\\n      \\n      // Find closest match within tolerance\\n      if (diff <= state.tolerance) {\\n        const result = {\\n          alignedTimestamp: referenceTimestamp,\\n          confidence: Math.max(0, 1 - diff / state.tolerance),\\n          offset: timestamp - referenceTimestamp,\\n          data: streamData,\\n          streamId: streamData.streamId\\n        };\\n        \\n        results.push(result);\\n      }\\n    }\\n\\n    // Track alignment quality over time\\n    if (results.length > 0) {\\n      const avgConfidence = results.reduce((sum, r) => sum + r.confidence, 0) / results.length;\\n      state.alignmentHistory.push({\\n        timestamp: referenceTimestamp,\\n        alignedStreams: results.length,\\n        avgConfidence,\\n        maxOffset: Math.max(...results.map(r => Math.abs(r.offset)))\\n      });\\n      \\n      // Keep history manageable\\n      if (state.alignmentHistory.length > 100) {\\n        state.alignmentHistory.shift();\\n      }\\n    }\\n\\n    return results;\\n  };\\n\\n  const findBestAlignment = (streamBuffers, targetTimestamp) => {\\n    const aligned = new Map();\\n    \\n    for (const [streamId, buffer] of streamBuffers) {\\n      const closest = buffer.getClosest ? \\n        buffer.getClosest(targetTimestamp, state.tolerance) :\\n        findClosestInArray(buffer, targetTimestamp, state.tolerance);\\n        \\n      if (closest) {\\n        aligned.set(streamId, {\\n          data: closest,\\n          alignedTimestamp: targetTimestamp,\\n          confidence: 1 - Math.abs(closest.timestamp - targetTimestamp) / state.tolerance,\\n          offset: closest.timestamp - targetTimestamp,\\n          streamId\\n        });\\n      }\\n    }\\n    \\n    return aligned;\\n  };\\n\\n  const findClosestInArray = (dataArray, targetTimestamp, tolerance) => {\\n    let closest = null;\\n    let minDiff = Infinity;\\n    \\n    for (const data of dataArray) {\\n      const diff = Math.abs(data.timestamp - targetTimestamp);\\n      if (diff < minDiff && diff <= tolerance) {\\n        minDiff = diff;\\n        closest = data;\\n      }\\n    }\\n    \\n    return closest;\\n  };\\n\\n  const getQuality = (alignmentResults = null) => {\\n    if (alignmentResults && alignmentResults.size > 0) {\\n      // Calculate quality from current alignment results\\n      const confidences = Array.from(alignmentResults.values()).map(r => r.confidence);\\n      const avgConfidence = confidences.reduce((a, b) => a + b, 0) / confidences.length;\\n      const maxOffset = Math.max(...Array.from(alignmentResults.values()).map(r => Math.abs(r.offset)));\\n      \\n      return createSyncMetrics({\\n        quality: avgConfidence,\\n        latency: maxOffset,\\n        jitter: Math.max(0, maxOffset - state.tolerance),\\n        alignmentAccuracy: maxOffset\\n      });\\n    }\\n    \\n    // Calculate quality from historical performance\\n    if (state.alignmentHistory.length > 0) {\\n      const recent = state.alignmentHistory.slice(-10);\\n      const avgConfidence = recent.reduce((sum, h) => sum + h.avgConfidence, 0) / recent.length;\\n      const avgMaxOffset = recent.reduce((sum, h) => sum + h.maxOffset, 0) / recent.length;\\n      \\n      return createSyncMetrics({\\n        quality: avgConfidence,\\n        latency: avgMaxOffset,\\n        jitter: Math.max(0, avgMaxOffset - state.tolerance),\\n        alignmentAccuracy: avgMaxOffset\\n      });\\n    }\\n    \\n    return createSyncMetrics({ quality: 0 });\\n  };\\n\\n  const updateConfig = (newConfig) => {\\n    if (newConfig.windowSize !== undefined) {\\n      state.windowSize = newConfig.windowSize;\\n    }\\n    if (newConfig.tolerance !== undefined) {\\n      state.tolerance = newConfig.tolerance;\\n    }\\n  };\\n\\n  const reset = () => {\\n    state.referenceStream = null;\\n    state.alignmentHistory = [];\\n  };\\n\\n  const getStats = () => ({\\n    windowSize: state.windowSize,\\n    tolerance: state.tolerance,\\n    alignmentHistoryLength: state.alignmentHistory.length,\\n    recentPerformance: state.alignmentHistory.slice(-5)\\n  });\\n\\n  return { \\n    align, \\n    findBestAlignment,\\n    getQuality, \\n    updateConfig,\\n    reset,\\n    getStats,\\n    strategy: 'buffer_based'\\n  };\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/core/orchestration/aligners/event-aligner.js\",\"messages\":[{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":64,\"column\":52,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":64,\"endColumn\":53},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":64,\"column\":102,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":64,\"endColumn\":103},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '/'. Use parentheses to clarify the intended order of operations.\",\"line\":69,\"column\":35,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":69,\"endColumn\":36},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '/'. Use parentheses to clarify the intended order of operations.\",\"line\":69,\"column\":49,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":69,\"endColumn\":50},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '/'. Use parentheses to clarify the intended order of operations.\",\"line\":101,\"column\":37,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":101,\"endColumn\":38},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '/'. Use parentheses to clarify the intended order of operations.\",\"line\":101,\"column\":48,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":101,\"endColumn\":49},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '/'. Use parentheses to clarify the intended order of operations.\",\"line\":119,\"column\":43,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":119,\"endColumn\":44},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '/'. Use parentheses to clarify the intended order of operations.\",\"line\":119,\"column\":57,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":119,\"endColumn\":58},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '/'. Use parentheses to clarify the intended order of operations.\",\"line\":124,\"column\":39,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":124,\"endColumn\":40},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '/'. Use parentheses to clarify the intended order of operations.\",\"line\":124,\"column\":59,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":124,\"endColumn\":60}],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":10,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Event-Driven Aligner\\n * Trigger-based synchronization using external events\\n */\\n\\nimport { createSyncMetrics } from '../sync-metrics.js';\\n\\n// Event-driven synchronization (trigger-based)\\nexport const createEventDrivenAligner = () => {\\n  const state = {\\n    events: [],\\n    eventWindow: 100, // 100ms window around events\\n    lastEventTime: null,\\n    eventTypes: new Set(),\\n    alignmentStats: {\\n      totalAlignments: 0,\\n      successfulAlignments: 0,\\n      averageEventDistance: 0\\n    }\\n  };\\n\\n  const registerEvent = (eventType, timestamp = Date.now(), metadata = {}) => {\\n    const event = { \\n      type: eventType, \\n      timestamp, \\n      metadata,\\n      id: `${eventType}_${timestamp}_${Math.random().toString(36).substr(2, 9)}`\\n    };\\n    \\n    state.events.push(event);\\n    state.lastEventTime = timestamp;\\n    state.eventTypes.add(eventType);\\n    \\n    // Keep only recent events\\n    const cutoff = timestamp - 60000; // 1 minute\\n    state.events = state.events.filter(e => e.timestamp > cutoff);\\n    \\n    return event.id;\\n  };\\n\\n  const align = (streamData, eventType = null) => {\\n    const timestamp = streamData.timestamp || Date.now();\\n    \\n    // Find the nearest event\\n    let nearestEvent = null;\\n    let minDistance = Infinity;\\n    \\n    for (const event of state.events) {\\n      if (eventType && event.type !== eventType) continue;\\n      \\n      const distance = Math.abs(timestamp - event.timestamp);\\n      if (distance < minDistance && distance <= state.eventWindow) {\\n        minDistance = distance;\\n        nearestEvent = event;\\n      }\\n    }\\n\\n    // Update alignment statistics\\n    state.alignmentStats.totalAlignments++;\\n    \\n    if (nearestEvent) {\\n      state.alignmentStats.successfulAlignments++;\\n      state.alignmentStats.averageEventDistance = \\n        (state.alignmentStats.averageEventDistance * (state.alignmentStats.successfulAlignments - 1) + minDistance) / \\n        state.alignmentStats.successfulAlignments;\\n      \\n      return {\\n        alignedTimestamp: nearestEvent.timestamp,\\n        confidence: Math.max(0, 1 - minDistance / state.eventWindow),\\n        offset: timestamp - nearestEvent.timestamp,\\n        event: nearestEvent,\\n        streamId: streamData.streamId,\\n        eventDistance: minDistance\\n      };\\n    }\\n\\n    return {\\n      alignedTimestamp: timestamp,\\n      confidence: 0.1, // Low confidence without event alignment\\n      offset: 0,\\n      event: null,\\n      streamId: streamData.streamId,\\n      eventDistance: null\\n    };\\n  };\\n\\n  const alignToEvent = (streamDataArray, eventId) => {\\n    const event = state.events.find(e => e.id === eventId);\\n    if (!event) {\\n      throw new Error(`Event with ID ${eventId} not found`);\\n    }\\n\\n    const results = [];\\n    for (const streamData of streamDataArray) {\\n      const timestamp = streamData.timestamp || Date.now();\\n      const distance = Math.abs(timestamp - event.timestamp);\\n      \\n      if (distance <= state.eventWindow) {\\n        results.push({\\n          alignedTimestamp: event.timestamp,\\n          confidence: Math.max(0, 1 - distance / state.eventWindow),\\n          offset: timestamp - event.timestamp,\\n          event,\\n          streamId: streamData.streamId,\\n          eventDistance: distance,\\n          data: streamData\\n        });\\n      }\\n    }\\n    \\n    return results;\\n  };\\n\\n  const getQuality = () => {\\n    const successRate = state.alignmentStats.totalAlignments > 0 ? \\n      state.alignmentStats.successfulAlignments / state.alignmentStats.totalAlignments : 0;\\n    \\n    const avgDistance = state.alignmentStats.averageEventDistance;\\n    const distanceQuality = Math.max(0, 1 - avgDistance / state.eventWindow);\\n    \\n    return createSyncMetrics({\\n      quality: successRate * distanceQuality,\\n      latency: avgDistance,\\n      jitter: Math.max(0, avgDistance - state.eventWindow / 2),\\n      alignmentAccuracy: avgDistance\\n    });\\n  };\\n\\n  const getEventHistory = (eventType = null, limit = 50) => {\\n    let events = [...state.events];\\n    \\n    if (eventType) {\\n      events = events.filter(e => e.type === eventType);\\n    }\\n    \\n    return events\\n      .sort((a, b) => b.timestamp - a.timestamp)\\n      .slice(0, limit);\\n  };\\n\\n  const getEventTypes = () => Array.from(state.eventTypes);\\n\\n  const removeOldEvents = (maxAge = 60000) => {\\n    const cutoff = Date.now() - maxAge;\\n    const originalLength = state.events.length;\\n    state.events = state.events.filter(e => e.timestamp > cutoff);\\n    return originalLength - state.events.length;\\n  };\\n\\n  const updateConfig = (newConfig) => {\\n    if (newConfig.eventWindow !== undefined) {\\n      state.eventWindow = newConfig.eventWindow;\\n    }\\n  };\\n\\n  const reset = () => {\\n    state.events = [];\\n    state.lastEventTime = null;\\n    state.eventTypes.clear();\\n    state.alignmentStats = {\\n      totalAlignments: 0,\\n      successfulAlignments: 0,\\n      averageEventDistance: 0\\n    };\\n  };\\n\\n  const getStats = () => ({\\n    totalEvents: state.events.length,\\n    eventTypes: Array.from(state.eventTypes),\\n    lastEventTime: state.lastEventTime,\\n    eventWindow: state.eventWindow,\\n    alignmentStats: { ...state.alignmentStats }\\n  });\\n\\n  return { \\n    align, \\n    alignToEvent,\\n    registerEvent,\\n    getQuality,\\n    getEventHistory,\\n    getEventTypes,\\n    removeOldEvents,\\n    updateConfig,\\n    reset,\\n    getStats,\\n    strategy: 'event_driven'\\n  };\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/core/orchestration/aligners/hardware-aligner.js\",\"messages\":[{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '-'. Use parentheses to clarify the intended order of operations.\",\"line\":22,\"column\":25,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":22,\"endColumn\":26},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '-'. Use parentheses to clarify the intended order of operations.\",\"line\":22,\"column\":33,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":22,\"endColumn\":34},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":22,\"column\":33,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":22,\"endColumn\":34},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":22,\"column\":40,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":22,\"endColumn\":41},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '-'. Use parentheses to clarify the intended order of operations.\",\"line\":23,\"column\":33,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":23,\"endColumn\":34},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '-'. Use parentheses to clarify the intended order of operations.\",\"line\":23,\"column\":41,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":23,\"endColumn\":42},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":23,\"column\":41,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":23,\"endColumn\":42},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":23,\"column\":48,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":23,\"endColumn\":49}],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":8,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Hardware Timestamp Aligner\\n * Highest precision alignment using hardware timestamps with drift compensation\\n */\\n\\nimport { createSyncMetrics } from '../sync-metrics.js';\\n\\n// Helper function for linear slope calculation\\nconst calculateLinearSlope = (points) => {\\n  if (points.length < 2) return 0;\\n  \\n  const n = points.length;\\n  let sumX = 0, sumY = 0, sumXY = 0, sumXX = 0;\\n  \\n  for (const [x, y] of points) {\\n    sumX += x;\\n    sumY += y;\\n    sumXY += x * y;\\n    sumXX += x * x;\\n  }\\n  \\n  const denominator = n * sumXX - sumX * sumX;\\n  return denominator !== 0 ? (n * sumXY - sumX * sumY) / denominator : 0;\\n};\\n\\n// Hardware timestamp-based alignment (highest precision)\\nexport const createHardwareTimestampAligner = () => {\\n  const state = {\\n    referenceTime: null,\\n    clockOffsets: new Map(), // Track clock differences per stream\\n    driftCompensation: new Map()\\n  };\\n\\n  const align = (streamData) => {\\n    // Use hardware timestamps if available\\n    const hwTimestamp = streamData.hardwareTimestamp || streamData.timestamp;\\n    \\n    if (!state.referenceTime) {\\n      state.referenceTime = hwTimestamp;\\n    }\\n\\n    // Calculate offset from reference time\\n    const offset = hwTimestamp - state.referenceTime;\\n    \\n    // Track clock drift for this stream\\n    const {streamId} = streamData;\\n    if (!state.clockOffsets.has(streamId)) {\\n      state.clockOffsets.set(streamId, []);\\n    }\\n    \\n    const offsets = state.clockOffsets.get(streamId);\\n    offsets.push({ timestamp: Date.now(), offset });\\n    \\n    // Keep only recent offsets for drift calculation\\n    if (offsets.length > 100) {\\n      offsets.splice(0, offsets.length - 100);\\n    }\\n    \\n    // Calculate drift compensation\\n    let drift = 0;\\n    if (offsets.length > 10) {\\n      const recent = offsets.slice(-10);\\n      const slope = calculateLinearSlope(recent.map((o, i) => [i, o.offset]));\\n      drift = slope * offsets.length;\\n    }\\n    \\n    state.driftCompensation.set(streamId, drift);\\n    \\n    return {\\n      alignedTimestamp: hwTimestamp - drift,\\n      confidence: 0.95,\\n      offset: offset - drift,\\n      drift,\\n      streamId\\n    };\\n  };\\n\\n  const getQuality = () => createSyncMetrics({\\n    quality: 0.95,\\n    latency: 1, // ~1ms precision with hardware timestamps\\n    jitter: 0.5,\\n    alignmentAccuracy: 1\\n  });\\n\\n  const reset = () => {\\n    state.referenceTime = null;\\n    state.clockOffsets.clear();\\n    state.driftCompensation.clear();\\n  };\\n\\n  const getStreamDrift = (streamId) => {\\n    return state.driftCompensation.get(streamId) || 0;\\n  };\\n\\n  const getClockOffsets = () => {\\n    const offsets = {};\\n    for (const [streamId, offsetHistory] of state.clockOffsets) {\\n      offsets[streamId] = offsetHistory.slice(-10); // Recent history only\\n    }\\n    return offsets;\\n  };\\n\\n  return { \\n    align, \\n    getQuality, \\n    reset,\\n    getStreamDrift,\\n    getClockOffsets,\\n    strategy: 'hardware_timestamp'\\n  };\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/core/orchestration/aligners/software-aligner.js\",\"messages\":[{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":28,\"column\":59,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":28,\"endColumn\":60},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":29,\"column\":63,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":29,\"endColumn\":64},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":78,\"column\":34,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":78,\"endColumn\":35},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":78,\"column\":53,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":78,\"endColumn\":54},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":80,\"column\":17,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":80,\"endColumn\":18},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":80,\"column\":36,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":80,\"endColumn\":37},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":81,\"column\":28,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":81,\"endColumn\":29},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":81,\"column\":62,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":81,\"endColumn\":63}],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":8,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Software Timestamp Aligner\\n * NTP-style alignment with drift compensation for software timestamps\\n */\\n\\nimport { createSyncMetrics } from '../sync-metrics.js';\\n\\n// Software timestamp-based alignment with NTP-style drift compensation  \\nexport const createSoftwareTimestampAligner = () => {\\n  const state = {\\n    referenceTime: null,\\n    clockSync: {\\n      offset: 0,\\n      drift: 0,\\n      lastSync: Date.now()\\n    },\\n    syncHistory: []\\n  };\\n\\n  const align = (streamData) => {\\n    const timestamp = streamData.timestamp || Date.now();\\n    \\n    if (!state.referenceTime) {\\n      state.referenceTime = timestamp;\\n    }\\n\\n    // Apply clock synchronization\\n    const syncedTime = timestamp + state.clockSync.offset + \\n                      (Date.now() - state.clockSync.lastSync) * state.clockSync.drift;\\n    \\n    const offset = syncedTime - state.referenceTime;\\n    \\n    return {\\n      alignedTimestamp: syncedTime,\\n      confidence: 0.8,\\n      offset,\\n      drift: state.clockSync.drift,\\n      streamId: streamData.streamId\\n    };\\n  };\\n\\n  const updateClockSync = (serverTime, clientTime) => {\\n    const newOffset = serverTime - clientTime;\\n    const timeDiff = Date.now() - state.clockSync.lastSync;\\n    \\n    if (timeDiff > 0) {\\n      state.clockSync.drift = (newOffset - state.clockSync.offset) / timeDiff;\\n    }\\n    \\n    state.clockSync.offset = newOffset;\\n    state.clockSync.lastSync = Date.now();\\n    \\n    // Track sync history for quality metrics\\n    state.syncHistory.push({\\n      timestamp: Date.now(),\\n      offset: newOffset,\\n      drift: state.clockSync.drift\\n    });\\n    \\n    // Keep only recent history\\n    if (state.syncHistory.length > 100) {\\n      state.syncHistory.shift();\\n    }\\n  };\\n\\n  const getQuality = () => {\\n    // Calculate quality based on drift stability\\n    let driftVariability = 0;\\n    if (state.syncHistory.length > 10) {\\n      const recentDrifts = state.syncHistory.slice(-10).map(s => s.drift);\\n      const avgDrift = recentDrifts.reduce((a, b) => a + b, 0) / recentDrifts.length;\\n      driftVariability = Math.sqrt(\\n        recentDrifts.reduce((sum, d) => sum + Math.pow(d - avgDrift, 2), 0) / recentDrifts.length\\n      );\\n    }\\n    \\n    return createSyncMetrics({\\n      quality: Math.max(0.5, 0.8 - driftVariability * 10),\\n      latency: 10 + Math.abs(state.clockSync.offset),\\n      jitter: 2 + driftVariability * 5,\\n      alignmentAccuracy: 5 + Math.abs(state.clockSync.drift) * 100\\n    });\\n  };\\n\\n  const reset = () => {\\n    state.referenceTime = null;\\n    state.clockSync = {\\n      offset: 0,\\n      drift: 0,\\n      lastSync: Date.now()\\n    };\\n    state.syncHistory = [];\\n  };\\n\\n  const getSyncStatus = () => ({\\n    offset: state.clockSync.offset,\\n    drift: state.clockSync.drift,\\n    lastSync: state.clockSync.lastSync,\\n    historyLength: state.syncHistory.length\\n  });\\n\\n  return { \\n    align, \\n    getQuality, \\n    updateClockSync,\\n    reset,\\n    getSyncStatus,\\n    strategy: 'software_timestamp'\\n  };\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/core/orchestration/plugin-loader.js\",\"messages\":[],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/core/orchestration/registry-operations.js\",\"messages\":[],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/core/orchestration/registry.js\",\"messages\":[{\"ruleId\":\"max-lines-per-function\",\"severity\":1,\"message\":\"Arrow function has too many lines (232). Maximum allowed is 150.\",\"line\":65,\"column\":39,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"exceed\",\"endLine\":380,\"endColumn\":2},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'operations' is assigned a value but never used. Allowed unused vars must match /^_/u.\",\"line\":73,\"column\":9,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":73,\"endColumn\":19,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"operations\"},\"fix\":{\"range\":[1885,1936],\"text\":\"\"},\"desc\":\"Remove unused variable 'operations'.\"}]},{\"ruleId\":\"no-undef\",\"severity\":2,\"message\":\"'createRegistryOperations' is not defined.\",\"line\":73,\"column\":22,\"nodeType\":\"Identifier\",\"messageId\":\"undef\",\"endLine\":73,\"endColumn\":46},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'queries' is assigned a value but never used. Allowed unused vars must match /^_/u.\",\"line\":74,\"column\":9,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":74,\"endColumn\":16,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"queries\"},\"fix\":{\"range\":[1939,1984],\"text\":\"\"},\"desc\":\"Remove unused variable 'queries'.\"}]},{\"ruleId\":\"no-undef\",\"severity\":2,\"message\":\"'createRegistryQueries' is not defined.\",\"line\":74,\"column\":19,\"nodeType\":\"Identifier\",\"messageId\":\"undef\",\"endLine\":74,\"endColumn\":40},{\"ruleId\":\"no-undef\",\"severity\":2,\"message\":\"'pipelineFactories' is not defined.\",\"line\":100,\"column\":7,\"nodeType\":\"Identifier\",\"messageId\":\"undef\",\"endLine\":100,\"endColumn\":24},{\"ruleId\":\"no-undef\",\"severity\":2,\"message\":\"'categories' is not defined.\",\"line\":104,\"column\":12,\"nodeType\":\"Identifier\",\"messageId\":\"undef\",\"endLine\":104,\"endColumn\":22},{\"ruleId\":\"no-undef\",\"severity\":2,\"message\":\"'categories' is not defined.\",\"line\":105,\"column\":9,\"nodeType\":\"Identifier\",\"messageId\":\"undef\",\"endLine\":105,\"endColumn\":19},{\"ruleId\":\"no-undef\",\"severity\":2,\"message\":\"'categories' is not defined.\",\"line\":107,\"column\":7,\"nodeType\":\"Identifier\",\"messageId\":\"undef\",\"endLine\":107,\"endColumn\":17},{\"ruleId\":\"no-undef\",\"severity\":2,\"message\":\"'pipelineFactories' is not defined.\",\"line\":118,\"column\":19,\"nodeType\":\"Identifier\",\"messageId\":\"undef\",\"endLine\":118,\"endColumn\":36},{\"ruleId\":\"no-undef\",\"severity\":2,\"message\":\"'pipelines' is not defined.\",\"line\":127,\"column\":7,\"nodeType\":\"Identifier\",\"messageId\":\"undef\",\"endLine\":127,\"endColumn\":16},{\"ruleId\":\"no-undef\",\"severity\":2,\"message\":\"'pipelineFactories' is not defined.\",\"line\":182,\"column\":23,\"nodeType\":\"Identifier\",\"messageId\":\"undef\",\"endLine\":182,\"endColumn\":40},{\"ruleId\":\"no-undef\",\"severity\":2,\"message\":\"'pipelineFactories' is not defined.\",\"line\":186,\"column\":19,\"nodeType\":\"Identifier\",\"messageId\":\"undef\",\"endLine\":186,\"endColumn\":36},{\"ruleId\":\"no-undef\",\"severity\":2,\"message\":\"'pipelineFactories' is not defined.\",\"line\":192,\"column\":33,\"nodeType\":\"Identifier\",\"messageId\":\"undef\",\"endLine\":192,\"endColumn\":50},{\"ruleId\":\"no-undef\",\"severity\":2,\"message\":\"'categories' is not defined.\",\"line\":201,\"column\":23,\"nodeType\":\"Identifier\",\"messageId\":\"undef\",\"endLine\":201,\"endColumn\":33},{\"ruleId\":\"no-undef\",\"severity\":2,\"message\":\"'pipelineFactories' is not defined.\",\"line\":208,\"column\":33,\"nodeType\":\"Identifier\",\"messageId\":\"undef\",\"endLine\":208,\"endColumn\":50},{\"ruleId\":\"no-undef\",\"severity\":2,\"message\":\"'pipelineFactories' is not defined.\",\"line\":222,\"column\":33,\"nodeType\":\"Identifier\",\"messageId\":\"undef\",\"endLine\":222,\"endColumn\":50},{\"ruleId\":\"no-undef\",\"severity\":2,\"message\":\"'pipelineFactories' is not defined.\",\"line\":245,\"column\":19,\"nodeType\":\"Identifier\",\"messageId\":\"undef\",\"endLine\":245,\"endColumn\":36},{\"ruleId\":\"no-undef\",\"severity\":2,\"message\":\"'categories' is not defined.\",\"line\":250,\"column\":9,\"nodeType\":\"Identifier\",\"messageId\":\"undef\",\"endLine\":250,\"endColumn\":19},{\"ruleId\":\"no-undef\",\"severity\":2,\"message\":\"'categories' is not defined.\",\"line\":251,\"column\":7,\"nodeType\":\"Identifier\",\"messageId\":\"undef\",\"endLine\":251,\"endColumn\":17},{\"ruleId\":\"no-undef\",\"severity\":2,\"message\":\"'categories' is not defined.\",\"line\":252,\"column\":11,\"nodeType\":\"Identifier\",\"messageId\":\"undef\",\"endLine\":252,\"endColumn\":21},{\"ruleId\":\"no-undef\",\"severity\":2,\"message\":\"'categories' is not defined.\",\"line\":253,\"column\":9,\"nodeType\":\"Identifier\",\"messageId\":\"undef\",\"endLine\":253,\"endColumn\":19},{\"ruleId\":\"no-undef\",\"severity\":2,\"message\":\"'pipelineFactories' is not defined.\",\"line\":258,\"column\":5,\"nodeType\":\"Identifier\",\"messageId\":\"undef\",\"endLine\":258,\"endColumn\":22},{\"ruleId\":\"no-undef\",\"severity\":2,\"message\":\"'pipelines' is not defined.\",\"line\":261,\"column\":42,\"nodeType\":\"Identifier\",\"messageId\":\"undef\",\"endLine\":261,\"endColumn\":51},{\"ruleId\":\"no-undef\",\"severity\":2,\"message\":\"'pipelines' is not defined.\",\"line\":266,\"column\":9,\"nodeType\":\"Identifier\",\"messageId\":\"undef\",\"endLine\":266,\"endColumn\":18},{\"ruleId\":\"no-undef\",\"severity\":2,\"message\":\"'pipelines' is not defined.\",\"line\":276,\"column\":32,\"nodeType\":\"Identifier\",\"messageId\":\"undef\",\"endLine\":276,\"endColumn\":41},{\"ruleId\":\"no-undef\",\"severity\":2,\"message\":\"'pipelines' is not defined.\",\"line\":285,\"column\":5,\"nodeType\":\"Identifier\",\"messageId\":\"undef\",\"endLine\":285,\"endColumn\":14},{\"ruleId\":\"no-undef\",\"severity\":2,\"message\":\"'pipelineFactories' is not defined.\",\"line\":286,\"column\":5,\"nodeType\":\"Identifier\",\"messageId\":\"undef\",\"endLine\":286,\"endColumn\":22},{\"ruleId\":\"no-undef\",\"severity\":2,\"message\":\"'categories' is not defined.\",\"line\":287,\"column\":5,\"nodeType\":\"Identifier\",\"messageId\":\"undef\",\"endLine\":287,\"endColumn\":15},{\"ruleId\":\"no-undef\",\"severity\":2,\"message\":\"'pipelineFactories' is not defined.\",\"line\":301,\"column\":23,\"nodeType\":\"Identifier\",\"messageId\":\"undef\",\"endLine\":301,\"endColumn\":40},{\"ruleId\":\"no-undef\",\"severity\":2,\"message\":\"'pipelines' is not defined.\",\"line\":302,\"column\":24,\"nodeType\":\"Identifier\",\"messageId\":\"undef\",\"endLine\":302,\"endColumn\":33},{\"ruleId\":\"no-undef\",\"severity\":2,\"message\":\"'categories' is not defined.\",\"line\":303,\"column\":19,\"nodeType\":\"Identifier\",\"messageId\":\"undef\",\"endLine\":303,\"endColumn\":29},{\"ruleId\":\"no-undef\",\"severity\":2,\"message\":\"'categories' is not defined.\",\"line\":310,\"column\":43,\"nodeType\":\"Identifier\",\"messageId\":\"undef\",\"endLine\":310,\"endColumn\":53},{\"ruleId\":\"no-undef\",\"severity\":2,\"message\":\"'pipelineFactories' is not defined.\",\"line\":316,\"column\":29,\"nodeType\":\"Identifier\",\"messageId\":\"undef\",\"endLine\":316,\"endColumn\":46},{\"ruleId\":\"no-undef\",\"severity\":2,\"message\":\"'pipelineFactories' is not defined.\",\"line\":329,\"column\":21,\"nodeType\":\"Identifier\",\"messageId\":\"undef\",\"endLine\":329,\"endColumn\":38},{\"ruleId\":\"no-undef\",\"severity\":2,\"message\":\"'pipelines' is not defined.\",\"line\":330,\"column\":24,\"nodeType\":\"Identifier\",\"messageId\":\"undef\",\"endLine\":330,\"endColumn\":33},{\"ruleId\":\"no-undef\",\"severity\":2,\"message\":\"'pipelineFactories' is not defined.\",\"line\":337,\"column\":9,\"nodeType\":\"Identifier\",\"messageId\":\"undef\",\"endLine\":337,\"endColumn\":26},{\"ruleId\":\"no-undef\",\"severity\":2,\"message\":\"'pipelines' is not defined.\",\"line\":343,\"column\":37,\"nodeType\":\"Identifier\",\"messageId\":\"undef\",\"endLine\":343,\"endColumn\":46}],\"suppressedMessages\":[],\"errorCount\":37,\"fatalErrorCount\":0,\"warningCount\":1,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Pipeline Registry and Plugin System\\n * Manages dynamic pipeline registration, discovery, and plugin loading\\n */\\n\\nimport { validatePipelineConfig } from './pipeline.js';\\n\\n// Plugin loader for dynamic imports\\nexport const createPluginLoader = () => {\\n  const loadedPlugins = new Map();\\n  \\n  const loadPlugin = async (pluginPath, config = {}) => {\\n    try {\\n      // Dynamic import for ES modules\\n      const plugin = await import(pluginPath);\\n      \\n      if (typeof plugin.register !== 'function') {\\n        throw new Error(`Plugin ${pluginPath} must export a 'register' function`);\\n      }\\n      \\n      const registrationResult = await plugin.register(config);\\n      loadedPlugins.set(pluginPath, { plugin, config, result: registrationResult });\\n      \\n      return registrationResult;\\n      \\n    } catch (error) {\\n      throw new Error(`Failed to load plugin ${pluginPath}: ${error.message}`);\\n    }\\n  };\\n  \\n  const unloadPlugin = async (pluginPath) => {\\n    const entry = loadedPlugins.get(pluginPath);\\n    if (!entry) return false;\\n    \\n    try {\\n      if (entry.plugin.cleanup) {\\n        await entry.plugin.cleanup();\\n      }\\n      loadedPlugins.delete(pluginPath);\\n      return true;\\n    } catch (error) {\\n      console.warn(`Plugin cleanup failed for ${pluginPath}:`, error);\\n      loadedPlugins.delete(pluginPath); // Remove anyway\\n      return false;\\n    }\\n  };\\n  \\n  const getLoadedPlugins = () => {\\n    return Array.from(loadedPlugins.keys());\\n  };\\n  \\n  const getPluginInfo = (pluginPath) => {\\n    return loadedPlugins.get(pluginPath);\\n  };\\n  \\n  return {\\n    loadPlugin,\\n    unloadPlugin,\\n    getLoadedPlugins,\\n    getPluginInfo\\n  };\\n};\\n\\n// Main pipeline registry\\nexport const createPipelineRegistry = () => {\\n  const state = {\\n    pipelines: new Map(),\\n    pipelineFactories: new Map(),\\n    categories: new Map()\\n  };\\n  \\n  const pluginLoader = createPluginLoader();\\n  const operations = createRegistryOperations(state);\\n  const queries = createRegistryQueries(state);\\n  \\n  // Direct pipeline registration\\n  const register = (name, pipelineOrFactory, metadata = {}) => {\\n    try {\\n      // Validate if it's a pipeline config\\n      if (typeof pipelineOrFactory === 'object' && pipelineOrFactory.process) {\\n        validatePipelineConfig(pipelineOrFactory);\\n      }\\n      \\n      const entry = {\\n        name,\\n        factory: typeof pipelineOrFactory === 'function' ? pipelineOrFactory : () => pipelineOrFactory,\\n        metadata: {\\n          category: metadata.category || 'general',\\n          version: metadata.version || '1.0.0',\\n          description: metadata.description || '',\\n          author: metadata.author || 'unknown',\\n          capabilities: metadata.capabilities || [],\\n          dependencies: metadata.dependencies || [],\\n          tags: metadata.tags || [],\\n          registeredAt: Date.now(),\\n          ...metadata\\n        }\\n      };\\n      \\n      pipelineFactories.set(name, entry);\\n      \\n      // Add to category index\\n      const {category} = entry.metadata;\\n      if (!categories.has(category)) {\\n        categories.set(category, new Set());\\n      }\\n      categories.get(category).add(name);\\n      \\n      return true;\\n      \\n    } catch (error) {\\n      throw new Error(`Pipeline registration failed for '${name}': ${error.message}`);\\n    }\\n  };\\n  \\n  // Pipeline creation\\n  const create = async (name, config = {}) => {\\n    const entry = pipelineFactories.get(name);\\n    if (!entry) {\\n      throw new Error(`Pipeline '${name}' not found in registry`);\\n    }\\n    \\n    try {\\n      const pipeline = await entry.factory(config);\\n      \\n      // Store active instance\\n      pipelines.set(`${name}:${Date.now()}`, {\\n        instance: pipeline,\\n        name,\\n        config,\\n        createdAt: Date.now()\\n      });\\n      \\n      return pipeline;\\n      \\n    } catch (error) {\\n      throw new Error(`Failed to create pipeline '${name}': ${error.message}`);\\n    }\\n  };\\n  \\n  // Plugin-based registration\\n  const registerPlugin = async (pluginPath, pluginConfig = {}) => {\\n    try {\\n      const result = await pluginLoader.loadPlugin(pluginPath, pluginConfig);\\n      \\n      // Plugin should return pipeline registrations\\n      if (result && Array.isArray(result.pipelines)) {\\n        result.pipelines.forEach(pipelineInfo => {\\n          register(pipelineInfo.name, pipelineInfo.factory, {\\n            ...pipelineInfo.metadata,\\n            plugin: pluginPath\\n          });\\n        });\\n      }\\n      \\n      return result;\\n      \\n    } catch (error) {\\n      throw new Error(`Plugin registration failed: ${error.message}`);\\n    }\\n  };\\n  \\n  // Bulk registration from directory\\n  const registerFromDirectory = async (directoryPath) => {\\n    try {\\n      // This would use fs.readdir in a real implementation\\n      // For now, we'll provide the interface\\n      const registeredPlugins = [];\\n      \\n      // Placeholder for directory scanning\\n      console.log(`Would scan directory: ${directoryPath}`);\\n      \\n      return registeredPlugins;\\n      \\n    } catch (error) {\\n      throw new Error(`Directory registration failed: ${error.message}`);\\n    }\\n  };\\n  \\n  // Pipeline discovery and querying\\n  const list = () => {\\n    return Array.from(pipelineFactories.keys());\\n  };\\n  \\n  const getInfo = (name) => {\\n    const entry = pipelineFactories.get(name);\\n    return entry ? { ...entry.metadata, name } : null;\\n  };\\n  \\n  const findByCapability = (capability) => {\\n    const results = [];\\n    for (const [name, entry] of pipelineFactories) {\\n      if (entry.metadata.capabilities.includes(capability)) {\\n        results.push(name);\\n      }\\n    }\\n    return results;\\n  };\\n  \\n  const findByCategory = (category) => {\\n    return Array.from(categories.get(category) || []);\\n  };\\n  \\n  const findByTags = (tags) => {\\n    const targetTags = Array.isArray(tags) ? tags : [tags];\\n    const results = [];\\n    \\n    for (const [name, entry] of pipelineFactories) {\\n      const hasAnyTag = targetTags.some(tag => entry.metadata.tags.includes(tag));\\n      if (hasAnyTag) {\\n        results.push(name);\\n      }\\n    }\\n    \\n    return results;\\n  };\\n  \\n  const search = (query) => {\\n    const results = [];\\n    const searchTerm = query.toLowerCase();\\n    \\n    for (const [name, entry] of pipelineFactories) {\\n      const searchable = [\\n        name,\\n        entry.metadata.description,\\n        entry.metadata.category,\\n        ...entry.metadata.tags,\\n        ...entry.metadata.capabilities\\n      ].join(' ').toLowerCase();\\n      \\n      if (searchable.includes(searchTerm)) {\\n        results.push({\\n          name,\\n          relevance: searchable.split(searchTerm).length - 1, // Simple relevance scoring\\n          metadata: entry.metadata\\n        });\\n      }\\n    }\\n    \\n    return results.sort((a, b) => b.relevance - a.relevance);\\n  };\\n  \\n  // Registry management\\n  const unregister = (name) => {\\n    const entry = pipelineFactories.get(name);\\n    if (!entry) return false;\\n    \\n    // Remove from category index\\n    const {category} = entry.metadata;\\n    if (categories.has(category)) {\\n      categories.get(category).delete(name);\\n      if (categories.get(category).size === 0) {\\n        categories.delete(category);\\n      }\\n    }\\n    \\n    // Remove from main registry\\n    pipelineFactories.delete(name);\\n    \\n    // Clean up any active instances\\n    for (const [instanceId, instance] of pipelines) {\\n      if (instance.name === name) {\\n        if (instance.instance.cleanup) {\\n          instance.instance.cleanup().catch(console.warn);\\n        }\\n        pipelines.delete(instanceId);\\n      }\\n    }\\n    \\n    return true;\\n  };\\n  \\n  const clear = async () => {\\n    // Cleanup all active instances\\n    const cleanupPromises = [];\\n    for (const [, instance] of pipelines) {\\n      if (instance.instance.cleanup) {\\n        cleanupPromises.push(instance.instance.cleanup());\\n      }\\n    }\\n    \\n    await Promise.allSettled(cleanupPromises);\\n    \\n    // Clear registries\\n    pipelines.clear();\\n    pipelineFactories.clear();\\n    categories.clear();\\n    \\n    // Unload all plugins\\n    const loadedPlugins = pluginLoader.getLoadedPlugins();\\n    for (const pluginPath of loadedPlugins) {\\n      await pluginLoader.unloadPlugin(pluginPath);\\n    }\\n    \\n    return true;\\n  };\\n  \\n  // Statistics and health\\n  const getStats = () => {\\n    const stats = {\\n      totalPipelines: pipelineFactories.size,\\n      activePipelines: pipelines.size,\\n      categories: categories.size,\\n      loadedPlugins: pluginLoader.getLoadedPlugins().length,\\n      byCategory: {},\\n      byCapability: {}\\n    };\\n    \\n    // Category breakdown\\n    for (const [category, pipelineSet] of categories) {\\n      stats.byCategory[category] = pipelineSet.size;\\n    }\\n    \\n    // Capability breakdown\\n    const capabilityCount = new Map();\\n    for (const [, entry] of pipelineFactories) {\\n      entry.metadata.capabilities.forEach(cap => {\\n        capabilityCount.set(cap, (capabilityCount.get(cap) || 0) + 1);\\n      });\\n    }\\n    stats.byCapability = Object.fromEntries(capabilityCount);\\n    \\n    return stats;\\n  };\\n  \\n  const getHealth = () => {\\n    const health = {\\n      status: 'healthy',\\n      registrySize: pipelineFactories.size,\\n      activeInstances: pipelines.size,\\n      pluginStatus: 'ok',\\n      lastCheck: Date.now(),\\n      issues: []\\n    };\\n    \\n    // Check for common issues\\n    if (pipelineFactories.size === 0) {\\n      health.issues.push('No pipelines registered');\\n      health.status = 'degraded';\\n    }\\n    \\n    // Check active instances for memory leaks\\n    const oldInstances = Array.from(pipelines.values())\\n      .filter(instance => Date.now() - instance.createdAt > 300000); // 5 minutes\\n    \\n    if (oldInstances.length > 10) {\\n      health.issues.push(`${oldInstances.length} old pipeline instances detected`);\\n      health.status = 'warning';\\n    }\\n    \\n    return health;\\n  };\\n  \\n  return {\\n    // Registration\\n    register,\\n    registerPlugin,\\n    registerFromDirectory,\\n    unregister,\\n    clear,\\n    \\n    // Creation\\n    create,\\n    \\n    // Discovery\\n    list,\\n    getInfo,\\n    findByCapability,\\n    findByCategory,\\n    findByTags,\\n    search,\\n    \\n    // Management\\n    getStats,\\n    getHealth,\\n    \\n    // Plugin access\\n    pluginLoader\\n  };\\n};\\n\\n// Lazy pipeline loaders - High performance ML modules\\nexport const createLazyPipelineLoaders = () => {\\n  const loaders = {\\n    // MediaPipe pipelines - Heavy ML dependencies\\n    'mediapipe-face': null,\\n    'mediapipe-mesh': null,\\n    'emotion-analysis': null,\\n    'eye-tracking': null\\n  };\\n\\n  const getMediaPipeFacePipeline = async () => {\\n    if (!loaders['mediapipe-face']) {\\n      console.log('🔄 Lazy loading MediaPipe face detection pipeline...');\\n      const module = await import('../../features/face-detection/mediapipe-face-pipeline.js');\\n      loaders['mediapipe-face'] = module.createMediaPipeFacePipeline;\\n      console.log('✅ MediaPipe face detection pipeline loaded');\\n    }\\n    return loaders['mediapipe-face'];\\n  };\\n\\n  const getMediaPipeMeshPipeline = async () => {\\n    if (!loaders['mediapipe-mesh']) {\\n      console.log('🔄 Lazy loading MediaPipe mesh pipeline...');\\n      const module = await import('../../features/face-detection/mediapipe-pipeline.js');\\n      loaders['mediapipe-mesh'] = module.createMediaPipeMeshPipeline;\\n      console.log('✅ MediaPipe mesh pipeline loaded');\\n    }\\n    return loaders['mediapipe-mesh'];\\n  };\\n\\n  const getEmotionAnalysisPipeline = async () => {\\n    if (!loaders['emotion-analysis']) {\\n      console.log('🔄 Lazy loading emotion analysis pipeline...');\\n      const module = await import('../../features/emotion-analysis/emotion-analysis-pipeline.js');\\n      loaders['emotion-analysis'] = module.createEmotionAnalysisPipeline;\\n      console.log('✅ Emotion analysis pipeline loaded');\\n    }\\n    return loaders['emotion-analysis'];\\n  };\\n\\n  const getEyeTrackingPipeline = async () => {\\n    if (!loaders['eye-tracking']) {\\n      console.log('🔄 Lazy loading eye tracking pipeline...');\\n      const module = await import('../../features/eye-tracking/devices/webcam/pipeline.js');\\n      loaders['eye-tracking'] = module.createEyeTrackingPipeline;\\n      console.log('✅ Eye tracking pipeline loaded');\\n    }\\n    return loaders['eye-tracking'];\\n  };\\n\\n  return {\\n    getMediaPipeFacePipeline,\\n    getMediaPipeMeshPipeline,\\n    getEmotionAnalysisPipeline,\\n    getEyeTrackingPipeline\\n  };\\n};\\n\\n// Enhanced auto-registration with lazy loading\\nexport const autoRegisterBuiltins = async (registry) => {\\n  const lazyLoaders = createLazyPipelineLoaders();\\n  \\n  try {\\n    // Register lazy-loaded MediaPipe Face pipeline\\n    registry.register('mediapipe-face', async (config) => {\\n      const createPipeline = await lazyLoaders.getMediaPipeFacePipeline();\\n      return createPipeline(config);\\n    }, {\\n      category: 'detection',\\n      description: 'Fast face detection with MediaPipe (lazy loaded)',\\n      version: '2.0.0',\\n      capabilities: ['face_detection', 'pose_estimation_3dof', 'landmark_detection'],\\n      tags: ['fast', 'mobile', 'real-time', 'efficient', 'lazy'],\\n      author: 'Google/MediaPipe',\\n      dependencies: ['@mediapipe/face_detection'],\\n      lazy: true\\n    });\\n\\n    // Register lazy-loaded MediaPipe Mesh pipeline\\n    registry.register('mediapipe-mesh', async (config) => {\\n      const createPipeline = await lazyLoaders.getMediaPipeMeshPipeline();\\n      return createPipeline(config);\\n    }, {\\n      category: 'detection',\\n      description: 'High-precision face mesh with 468 landmarks (lazy loaded)',\\n      version: '2.0.0',\\n      capabilities: ['face_mesh', 'pose_estimation_6dof', 'iris_tracking'],\\n      tags: ['high-precision', 'mesh', 'landmarks', 'lazy'],\\n      author: 'Google/MediaPipe',\\n      dependencies: ['@mediapipe/face_mesh'],\\n      lazy: true\\n    });\\n\\n    // Register lazy-loaded Emotion Analysis pipeline\\n    registry.register('emotion-analysis', async (config) => {\\n      const createPipeline = await lazyLoaders.getEmotionAnalysisPipeline();\\n      return createPipeline(config);\\n    }, {\\n      category: 'analysis',\\n      description: 'CNN-based emotion recognition (lazy loaded)',\\n      version: '2.0.0',\\n      capabilities: ['emotion_detection', 'expression_analysis'],\\n      tags: ['cnn', 'emotion', 'analysis', 'lazy'],\\n      author: 'Synopticon',\\n      dependencies: ['tensorflow', 'onnx'],\\n      lazy: true\\n    });\\n\\n    // Register lazy-loaded Eye Tracking pipeline\\n    registry.register('eye-tracking', async (config) => {\\n      const createPipeline = await lazyLoaders.getEyeTrackingPipeline();\\n      return createPipeline(config);\\n    }, {\\n      category: 'tracking',\\n      description: 'Real-time eye tracking and gaze estimation (lazy loaded)',\\n      version: '2.0.0',\\n      capabilities: ['eye_tracking', 'gaze_estimation', 'pupil_detection'],\\n      tags: ['eye', 'gaze', 'tracking', 'lazy'],\\n      author: 'Synopticon',\\n      dependencies: ['mediapipe', 'opencv'],\\n      lazy: true\\n    });\\n    \\n    console.log('✅ Built-in pipelines registered with lazy loading');\\n    \\n  } catch (error) {\\n    console.warn('⚠️ Some built-in pipelines failed to register:', error.message);\\n  }\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/core/orchestration/sync-metrics.js\",\"messages\":[],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/core/orchestration/synchronization.js\",\"messages\":[{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":133,\"column\":59,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":133,\"endColumn\":60},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":134,\"column\":63,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":134,\"endColumn\":64},{\"ruleId\":\"no-param-reassign\",\"severity\":1,\"message\":\"Assignment to function parameter 'streamDataArray'.\",\"line\":183,\"column\":7,\"nodeType\":\"Identifier\",\"messageId\":\"assignmentToFunctionParam\",\"endLine\":183,\"endColumn\":22},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '/'. Use parentheses to clarify the intended order of operations.\",\"line\":196,\"column\":37,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":196,\"endColumn\":38},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '/'. Use parentheses to clarify the intended order of operations.\",\"line\":196,\"column\":44,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":196,\"endColumn\":45},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '/'. Use parentheses to clarify the intended order of operations.\",\"line\":215,\"column\":25,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":215,\"endColumn\":26},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '/'. Use parentheses to clarify the intended order of operations.\",\"line\":215,\"column\":73,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":215,\"endColumn\":74},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '/'. Use parentheses to clarify the intended order of operations.\",\"line\":286,\"column\":35,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":286,\"endColumn\":36},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '/'. Use parentheses to clarify the intended order of operations.\",\"line\":286,\"column\":49,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":286,\"endColumn\":50},{\"ruleId\":\"max-lines-per-function\",\"severity\":1,\"message\":\"Arrow function has too many lines (153). Maximum allowed is 150.\",\"line\":316,\"column\":44,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"exceed\",\"endLine\":516,\"endColumn\":2},{\"ruleId\":\"prefer-destructuring\",\"severity\":1,\"message\":\"Use array destructuring.\",\"line\":368,\"column\":17,\"nodeType\":\"VariableDeclarator\",\"messageId\":\"preferDestructuring\",\"endLine\":368,\"endColumn\":59},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":609,\"column\":52,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":609,\"endColumn\":53},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":609,\"column\":56,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":609,\"endColumn\":57},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":610,\"column\":49,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":610,\"endColumn\":50},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":610,\"column\":53,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":610,\"endColumn\":54},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '-'. Use parentheses to clarify the intended order of operations.\",\"line\":612,\"column\":13,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":612,\"endColumn\":14},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '-'. Use parentheses to clarify the intended order of operations.\",\"line\":612,\"column\":21,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":612,\"endColumn\":22},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":612,\"column\":21,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":612,\"endColumn\":22},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":612,\"column\":28,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":612,\"endColumn\":29},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '-'. Use parentheses to clarify the intended order of operations.\",\"line\":612,\"column\":41,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":612,\"endColumn\":42},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '-'. Use parentheses to clarify the intended order of operations.\",\"line\":612,\"column\":49,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":612,\"endColumn\":50},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":612,\"column\":49,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":612,\"endColumn\":50},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":612,\"column\":56,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":612,\"endColumn\":57}],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":23,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Stream Synchronization Engine\\n * Enables precise temporal alignment of multimodal data streams\\n * Following functional programming patterns with factory functions\\n */\\n\\nimport { createStreamBuffer } from '../state/streams.js';\\n\\n// Synchronization strategy types\\nexport const SynchronizationStrategy = {\\n  HARDWARE_TIMESTAMP: 'hardware_timestamp',\\n  SOFTWARE_TIMESTAMP: 'software_timestamp', \\n  BUFFER_BASED: 'buffer_based',\\n  EVENT_DRIVEN: 'event_driven'\\n};\\n\\n// Synchronization quality metrics factory\\nexport const createSyncMetrics = (config = {}) => ({\\n  quality: config.quality || 1.0,\\n  latency: config.latency || 0,\\n  jitter: config.jitter || 0,\\n  droppedSamples: config.droppedSamples || 0,\\n  alignmentAccuracy: config.alignmentAccuracy || 0,\\n  lastUpdate: config.lastUpdate || Date.now(),\\n  \\n  // Quality scoring based on multiple factors\\n  computeOverallQuality() {\\n    const jitterPenalty = Math.min(this.jitter / 100, 0.3); // Max 30% penalty for jitter\\n    const dropPenalty = Math.min(this.droppedSamples / 1000, 0.4); // Max 40% penalty for drops\\n    const latencyPenalty = Math.min(this.latency / 1000, 0.2); // Max 20% penalty for latency\\n    \\n    return Math.max(0, 1.0 - jitterPenalty - dropPenalty - latencyPenalty);\\n  }\\n});\\n\\n// Temporal alignment algorithm implementations\\nexport const createTemporalAligner = (strategy = SynchronizationStrategy.BUFFER_BASED) => {\\n  const aligners = {\\n    [SynchronizationStrategy.HARDWARE_TIMESTAMP]: createHardwareTimestampAligner,\\n    [SynchronizationStrategy.SOFTWARE_TIMESTAMP]: createSoftwareTimestampAligner,\\n    [SynchronizationStrategy.BUFFER_BASED]: createBufferBasedAligner,\\n    [SynchronizationStrategy.EVENT_DRIVEN]: createEventDrivenAligner\\n  };\\n\\n  const aligner = aligners[strategy];\\n  if (!aligner) {\\n    throw new Error(`Unknown synchronization strategy: ${strategy}`);\\n  }\\n\\n  return aligner();\\n};\\n\\n// Hardware timestamp-based alignment (highest precision)\\nconst createHardwareTimestampAligner = () => {\\n  const state = {\\n    referenceTime: null,\\n    clockOffsets: new Map(), // Track clock differences per stream\\n    driftCompensation: new Map()\\n  };\\n\\n  const align = (streamData) => {\\n    // Use hardware timestamps if available\\n    const hwTimestamp = streamData.hardwareTimestamp || streamData.timestamp;\\n    \\n    if (!state.referenceTime) {\\n      state.referenceTime = hwTimestamp;\\n    }\\n\\n    // Calculate offset from reference time\\n    const offset = hwTimestamp - state.referenceTime;\\n    \\n    // Track clock drift for this stream\\n    const {streamId} = streamData;\\n    if (!state.clockOffsets.has(streamId)) {\\n      state.clockOffsets.set(streamId, []);\\n    }\\n    \\n    const offsets = state.clockOffsets.get(streamId);\\n    offsets.push({ timestamp: Date.now(), offset });\\n    \\n    // Keep only recent offsets for drift calculation\\n    if (offsets.length > 100) {\\n      offsets.splice(0, offsets.length - 100);\\n    }\\n    \\n    // Calculate drift compensation\\n    let drift = 0;\\n    if (offsets.length > 10) {\\n      const recent = offsets.slice(-10);\\n      const slope = calculateLinearSlope(recent.map((o, i) => [i, o.offset]));\\n      drift = slope * offsets.length;\\n    }\\n    \\n    state.driftCompensation.set(streamId, drift);\\n    \\n    return {\\n      alignedTimestamp: hwTimestamp - drift,\\n      confidence: 0.95,\\n      offset: offset - drift,\\n      drift\\n    };\\n  };\\n\\n  const getQuality = () => createSyncMetrics({\\n    quality: 0.95,\\n    latency: 1, // ~1ms precision with hardware timestamps\\n    jitter: 0.5,\\n    alignmentAccuracy: 1\\n  });\\n\\n  return { align, getQuality, strategy: SynchronizationStrategy.HARDWARE_TIMESTAMP };\\n};\\n\\n// Software timestamp-based alignment with NTP-style drift compensation  \\nconst createSoftwareTimestampAligner = () => {\\n  const state = {\\n    referenceTime: null,\\n    clockSync: {\\n      offset: 0,\\n      drift: 0,\\n      lastSync: Date.now()\\n    }\\n  };\\n\\n  const align = (streamData) => {\\n    const timestamp = streamData.timestamp || Date.now();\\n    \\n    if (!state.referenceTime) {\\n      state.referenceTime = timestamp;\\n    }\\n\\n    // Apply clock synchronization\\n    const syncedTime = timestamp + state.clockSync.offset + \\n                      (Date.now() - state.clockSync.lastSync) * state.clockSync.drift;\\n    \\n    const offset = syncedTime - state.referenceTime;\\n    \\n    return {\\n      alignedTimestamp: syncedTime,\\n      confidence: 0.8,\\n      offset,\\n      drift: state.clockSync.drift\\n    };\\n  };\\n\\n  const updateClockSync = (serverTime, clientTime) => {\\n    const newOffset = serverTime - clientTime;\\n    const timeDiff = Date.now() - state.clockSync.lastSync;\\n    \\n    if (timeDiff > 0) {\\n      state.clockSync.drift = (newOffset - state.clockSync.offset) / timeDiff;\\n    }\\n    \\n    state.clockSync.offset = newOffset;\\n    state.clockSync.lastSync = Date.now();\\n  };\\n\\n  const getQuality = () => createSyncMetrics({\\n    quality: 0.8,\\n    latency: 10,\\n    jitter: 2,\\n    alignmentAccuracy: 5\\n  });\\n\\n  return { \\n    align, \\n    getQuality, \\n    updateClockSync,\\n    strategy: SynchronizationStrategy.SOFTWARE_TIMESTAMP \\n  };\\n};\\n\\n// Buffer-based sliding window alignment\\nconst createBufferBasedAligner = () => {\\n  const state = {\\n    windowSize: 1000, // 1 second window\\n    tolerance: 50, // 50ms tolerance\\n    referenceStream: null\\n  };\\n\\n  const align = (streamDataArray, referenceTimestamp) => {\\n    if (!Array.isArray(streamDataArray)) {\\n      streamDataArray = [streamDataArray];\\n    }\\n\\n    const results = [];\\n    \\n    for (const streamData of streamDataArray) {\\n      const timestamp = streamData.timestamp || Date.now();\\n      const diff = Math.abs(timestamp - referenceTimestamp);\\n      \\n      // Find closest match within tolerance\\n      if (diff <= state.tolerance) {\\n        results.push({\\n          alignedTimestamp: referenceTimestamp,\\n          confidence: Math.max(0, 1 - diff / state.tolerance),\\n          offset: timestamp - referenceTimestamp,\\n          data: streamData\\n        });\\n      }\\n    }\\n\\n    return results;\\n  };\\n\\n  const findBestAlignment = (streamBuffers, targetTimestamp) => {\\n    const aligned = new Map();\\n    \\n    for (const [streamId, buffer] of streamBuffers) {\\n      const closest = buffer.getClosest(targetTimestamp, state.tolerance);\\n      if (closest) {\\n        aligned.set(streamId, {\\n          data: closest,\\n          alignedTimestamp: targetTimestamp,\\n          confidence: 1 - Math.abs(closest.timestamp - targetTimestamp) / state.tolerance,\\n          offset: closest.timestamp - targetTimestamp\\n        });\\n      }\\n    }\\n    \\n    return aligned;\\n  };\\n\\n  const getQuality = (alignmentResults) => {\\n    if (!alignmentResults || alignmentResults.size === 0) {\\n      return createSyncMetrics({ quality: 0 });\\n    }\\n\\n    const confidences = Array.from(alignmentResults.values()).map(r => r.confidence);\\n    const avgConfidence = confidences.reduce((a, b) => a + b, 0) / confidences.length;\\n    const maxOffset = Math.max(...Array.from(alignmentResults.values()).map(r => Math.abs(r.offset)));\\n    \\n    return createSyncMetrics({\\n      quality: avgConfidence,\\n      latency: maxOffset,\\n      jitter: Math.max(0, maxOffset - state.tolerance),\\n      alignmentAccuracy: maxOffset\\n    });\\n  };\\n\\n  return { \\n    align, \\n    findBestAlignment,\\n    getQuality, \\n    strategy: SynchronizationStrategy.BUFFER_BASED \\n  };\\n};\\n\\n// Event-driven synchronization (trigger-based)\\nconst createEventDrivenAligner = () => {\\n  const state = {\\n    events: [],\\n    eventWindow: 100, // 100ms window around events\\n    lastEventTime: null\\n  };\\n\\n  const registerEvent = (eventType, timestamp = Date.now()) => {\\n    state.events.push({ type: eventType, timestamp });\\n    state.lastEventTime = timestamp;\\n    \\n    // Keep only recent events\\n    const cutoff = timestamp - 60000; // 1 minute\\n    state.events = state.events.filter(e => e.timestamp > cutoff);\\n  };\\n\\n  const align = (streamData, eventType = null) => {\\n    const timestamp = streamData.timestamp || Date.now();\\n    \\n    // Find the nearest event\\n    let nearestEvent = null;\\n    let minDistance = Infinity;\\n    \\n    for (const event of state.events) {\\n      if (eventType && event.type !== eventType) continue;\\n      \\n      const distance = Math.abs(timestamp - event.timestamp);\\n      if (distance < minDistance && distance <= state.eventWindow) {\\n        minDistance = distance;\\n        nearestEvent = event;\\n      }\\n    }\\n\\n    if (nearestEvent) {\\n      return {\\n        alignedTimestamp: nearestEvent.timestamp,\\n        confidence: Math.max(0, 1 - minDistance / state.eventWindow),\\n        offset: timestamp - nearestEvent.timestamp,\\n        event: nearestEvent\\n      };\\n    }\\n\\n    return {\\n      alignedTimestamp: timestamp,\\n      confidence: 0.1, // Low confidence without event alignment\\n      offset: 0,\\n      event: null\\n    };\\n  };\\n\\n  const getQuality = (hasRecentEvent = false) => createSyncMetrics({\\n    quality: hasRecentEvent ? 0.9 : 0.3,\\n    latency: hasRecentEvent ? 5 : 50,\\n    jitter: hasRecentEvent ? 1 : 20,\\n    alignmentAccuracy: hasRecentEvent ? 2 : 50\\n  });\\n\\n  return { \\n    align, \\n    registerEvent,\\n    getQuality, \\n    strategy: SynchronizationStrategy.EVENT_DRIVEN \\n  };\\n};\\n\\n// Main synchronization engine factory\\nexport const createSynchronizationEngine = (config = {}) => {\\n  const state = {\\n    strategy: config.strategy || SynchronizationStrategy.BUFFER_BASED,\\n    tolerance: config.tolerance || 50, // 50ms default tolerance\\n    aligner: null,\\n    streams: new Map(),\\n    syncMetrics: createSyncMetrics(),\\n    callbacks: {\\n      onSync: [],\\n      onQualityChange: [],\\n      onError: []\\n    },\\n    isRunning: false\\n  };\\n\\n  // Initialize the appropriate aligner\\n  state.aligner = createTemporalAligner(state.strategy);\\n\\n  const addStream = (streamId, stream) => {\\n    state.streams.set(streamId, {\\n      stream,\\n      buffer: createStreamBuffer({ \\n        maxSize: config.bufferSize || 1000,\\n        windowMs: config.windowMs || 5000 \\n      }),\\n      lastTimestamp: null,\\n      metrics: createSyncMetrics()\\n    });\\n  };\\n\\n  const removeStream = (streamId) => {\\n    state.streams.delete(streamId);\\n  };\\n\\n  const synchronizeStreams = async (targetTimestamp = Date.now()) => {\\n    if (state.streams.size === 0) return new Map();\\n\\n    try {\\n      const streamBuffers = new Map();\\n      for (const [streamId, streamInfo] of state.streams) {\\n        streamBuffers.set(streamId, streamInfo.buffer);\\n      }\\n\\n      let alignmentResults;\\n      \\n      if (state.aligner.findBestAlignment) {\\n        // Buffer-based alignment\\n        alignmentResults = state.aligner.findBestAlignment(streamBuffers, targetTimestamp);\\n      } else {\\n        // Direct alignment for other strategies\\n        alignmentResults = new Map();\\n        for (const [streamId, streamInfo] of state.streams) {\\n          const latest = streamInfo.buffer.getLatest(1)[0];\\n          if (latest) {\\n            const result = state.aligner.align(latest, state.tolerance);\\n            alignmentResults.set(streamId, result);\\n          }\\n        }\\n      }\\n\\n      // Update sync metrics\\n      state.syncMetrics = state.aligner.getQuality(alignmentResults);\\n      \\n      // Notify callbacks\\n      state.callbacks.onSync.forEach(cb => {\\n        try {\\n          cb(alignmentResults, state.syncMetrics);\\n        } catch (error) {\\n          console.warn('Sync callback error:', error);\\n        }\\n      });\\n\\n      return alignmentResults;\\n      \\n    } catch (error) {\\n      state.callbacks.onError.forEach(cb => {\\n        try {\\n          cb(error);\\n        } catch (cbError) {\\n          console.warn('Error callback failed:', cbError);\\n        }\\n      });\\n      throw error;\\n    }\\n  };\\n\\n  const processStreamData = async (streamId, data) => {\\n    const streamInfo = state.streams.get(streamId);\\n    if (!streamInfo) {\\n      throw new Error(`Stream ${streamId} not registered`);\\n    }\\n\\n    // Add data to stream buffer\\n    const bufferedData = streamInfo.buffer.add(data);\\n    streamInfo.lastTimestamp = data.timestamp || Date.now();\\n\\n    // Trigger synchronization if we have multiple streams\\n    if (state.streams.size > 1 && state.isRunning) {\\n      return await synchronizeStreams(bufferedData.timestamp);\\n    }\\n\\n    return new Map([[streamId, { data: bufferedData, confidence: 1.0 }]]);\\n  };\\n\\n  const start = () => {\\n    state.isRunning = true;\\n  };\\n\\n  const stop = () => {\\n    state.isRunning = false;\\n  };\\n\\n  // Event handlers\\n  const onSync = (callback) => {\\n    state.callbacks.onSync.push(callback);\\n    return () => {\\n      const index = state.callbacks.onSync.indexOf(callback);\\n      if (index !== -1) state.callbacks.onSync.splice(index, 1);\\n    };\\n  };\\n\\n  const onQualityChange = (callback) => {\\n    state.callbacks.onQualityChange.push(callback);\\n    return () => {\\n      const index = state.callbacks.onQualityChange.indexOf(callback);\\n      if (index !== -1) state.callbacks.onQualityChange.splice(index, 1);\\n    };\\n  };\\n\\n  const onError = (callback) => {\\n    state.callbacks.onError.push(callback);\\n    return () => {\\n      const index = state.callbacks.onError.indexOf(callback);\\n      if (index !== -1) state.callbacks.onError.splice(index, 1);\\n    };\\n  };\\n\\n  // Getters\\n  const getStrategy = () => state.strategy;\\n  const getMetrics = () => ({ ...state.syncMetrics });\\n  const getStreamCount = () => state.streams.size;\\n  const isRunning = () => state.isRunning;\\n\\n  // Backward compatibility alias for onSynchronizedData\\n  const onSynchronizedData = (callback) => {\\n    // Transform the onSync callback signature to match expected syncedStreams format\\n    return onSync((alignmentResults, syncMetrics) => {\\n      const syncedStreams = [];\\n      \\n      for (const [streamId, alignmentData] of alignmentResults.entries()) {\\n        const streamType = streamId.includes('-') ? streamId.split('-')[0] : streamId;\\n        \\n        syncedStreams.push({\\n          streamId,\\n          streamType,\\n          timestamp: alignmentData.data?.timestamp || alignmentData.alignedTimestamp || Date.now(),\\n          data: alignmentData.data,\\n          confidence: alignmentData.confidence || 1.0,\\n          syncMetrics\\n        });\\n      }\\n      \\n      callback(syncedStreams);\\n    });\\n  };\\n\\n  return {\\n    // Stream management\\n    addStream,\\n    removeStream,\\n    \\n    // Synchronization\\n    synchronizeStreams,\\n    processStreamData,\\n    \\n    // Control\\n    start,\\n    stop,\\n    \\n    // Event handlers\\n    onSync,\\n    onSynchronizedData, // Backward compatibility alias\\n    onQualityChange, \\n    onError,\\n    \\n    // Status\\n    getStrategy,\\n    getMetrics,\\n    getStreamCount,\\n    isRunning,\\n    \\n    // Statistics for debugging\\n    getStats: () => ({\\n      streamCount: state.streams.size,\\n      strategy: state.strategy,\\n      tolerance: state.tolerance,\\n      isRunning: state.isRunning,\\n      metrics: { ...state.syncMetrics }\\n    })\\n  };\\n};\\n\\n// Multi-stream coordinator factory\\nexport const createMultiStreamCoordinator = (config = {}) => {\\n  const state = {\\n    syncEngine: createSynchronizationEngine(config.syncConfig),\\n    streams: new Map(),\\n    processingInterval: config.processingInterval || 33, // ~30 FPS\\n    intervalId: null,\\n    isActive: false\\n  };\\n\\n  const addStream = async (stream) => {\\n    const streamId = stream.getId();\\n    state.streams.set(streamId, stream);\\n    state.syncEngine.addStream(streamId, stream);\\n\\n    // Listen to stream data\\n    stream.onData(async (data) => {\\n      if (state.isActive) {\\n        try {\\n          await state.syncEngine.processStreamData(streamId, data);\\n        } catch (error) {\\n          console.warn(`Sync processing error for stream ${streamId}:`, error);\\n        }\\n      }\\n    });\\n  };\\n\\n  const removeStream = (streamId) => {\\n    const stream = state.streams.get(streamId);\\n    if (stream) {\\n      stream.stop();\\n      state.streams.delete(streamId);\\n      state.syncEngine.removeStream(streamId);\\n    }\\n  };\\n\\n  const start = async () => {\\n    // Start all streams\\n    for (const stream of state.streams.values()) {\\n      await stream.start();\\n    }\\n\\n    // Start synchronization engine\\n    state.syncEngine.start();\\n    state.isActive = true;\\n\\n    // Start processing interval\\n    state.intervalId = setInterval(async () => {\\n      try {\\n        await state.syncEngine.synchronizeStreams();\\n      } catch (error) {\\n        console.warn('Sync interval error:', error);\\n      }\\n    }, state.processingInterval);\\n  };\\n\\n  const stop = () => {\\n    // Stop processing interval\\n    if (state.intervalId) {\\n      clearInterval(state.intervalId);\\n      state.intervalId = null;\\n    }\\n\\n    // Stop synchronization engine\\n    state.syncEngine.stop();\\n    state.isActive = false;\\n\\n    // Stop all streams\\n    for (const stream of state.streams.values()) {\\n      stream.stop();\\n    }\\n  };\\n\\n  return {\\n    addStream,\\n    removeStream,\\n    start,\\n    stop,\\n    getSyncEngine: () => state.syncEngine,\\n    getStreams: () => new Map(state.streams),\\n    isActive: () => state.isActive\\n  };\\n};\\n\\n// Utility functions\\nconst calculateLinearSlope = (points) => {\\n  const n = points.length;\\n  if (n < 2) return 0;\\n\\n  const sumX = points.reduce((sum, [x]) => sum + x, 0);\\n  const sumY = points.reduce((sum, [, y]) => sum + y, 0);\\n  const sumXY = points.reduce((sum, [x, y]) => sum + x * y, 0);\\n  const sumX2 = points.reduce((sum, [x]) => sum + x * x, 0);\\n\\n  return (n * sumXY - sumX * sumY) / (n * sumX2 - sumX * sumX);\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/core/orchestration/synchronization/aligners/buffer-aligner.js\",\"messages\":[{\"ruleId\":\"max-lines-per-function\",\"severity\":1,\"message\":\"Arrow function has too many lines (159). Maximum allowed is 150.\",\"line\":13,\"column\":41,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"exceed\",\"endLine\":220,\"endColumn\":2},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '/'. Use parentheses to clarify the intended order of operations.\",\"line\":57,\"column\":66,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":57,\"endColumn\":67},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '/'. Use parentheses to clarify the intended order of operations.\",\"line\":57,\"column\":88,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":57,\"endColumn\":89},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'streamId' is assigned a value but never used. Allowed unused vars must match /^_/u.\",\"line\":153,\"column\":17,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":153,\"endColumn\":25,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"streamId\"},\"fix\":{\"range\":[5192,5200],\"text\":\"\"},\"desc\":\"Remove unused variable 'streamId'.\"}]}],\"suppressedMessages\":[],\"errorCount\":1,\"fatalErrorCount\":0,\"warningCount\":3,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Buffer-Based Aligner\\n * Alignment using buffering strategies for variable latency streams\\n */\\n\\nimport { SynchronizationStrategy } from '../strategies/sync-strategies.js';\\nimport { createSyncMetrics } from '../metrics/sync-metrics.js';\\n\\n/**\\n * Buffer-based alignment for variable latency streams\\n * Uses adaptive buffering to synchronize streams with different characteristics\\n */\\nexport const createBufferBasedAligner = (config = {}) => {\\n  const alignerConfig = {\\n    bufferSize: config.bufferSize || 100,\\n    maxBufferLatency: config.maxBufferLatency || 200, // ms\\n    adaptiveBuffering: config.adaptiveBuffering !== false,\\n    latencyThreshold: config.latencyThreshold || 50,\\n    confidenceThreshold: config.confidenceThreshold || 0.75,\\n    ...config\\n  };\\n\\n  const state = {\\n    streamBuffers: new Map(),\\n    referenceStream: null,\\n    bufferMetrics: {\\n      totalBuffered: 0,\\n      droppedSamples: 0,\\n      avgLatency: 0,\\n      maxLatency: 0\\n    }\\n  };\\n\\n  // Create buffer for a stream\\n  const createStreamBuffer = (streamId) => ({\\n    id: streamId,\\n    samples: [],\\n    latencyHistory: [],\\n    avgLatency: 0,\\n    isReference: false,\\n    lastFlush: Date.now()\\n  });\\n\\n  // Adaptive buffer size calculation\\n  const calculateOptimalBufferSize = (streamId) => {\\n    const buffer = state.streamBuffers.get(streamId);\\n    if (!buffer || buffer.latencyHistory.length < 10) {\\n      return alignerConfig.bufferSize;\\n    }\\n\\n    // Calculate variance in latency\\n    const recentLatency = buffer.latencyHistory.slice(-20);\\n    const avgLatency = recentLatency.reduce((sum, l) => sum + l, 0) / recentLatency.length;\\n    const variance = recentLatency.reduce((sum, l) => sum + Math.pow(l - avgLatency, 2), 0) / recentLatency.length;\\n    \\n    // Adaptive buffer size based on latency variance\\n    const adaptiveSize = Math.ceil(alignerConfig.bufferSize * (1 + Math.sqrt(variance) / 100));\\n    return Math.min(adaptiveSize, alignerConfig.bufferSize * 2);\\n  };\\n\\n  const align = (streamData) => {\\n    const { streamId, timestamp } = streamData;\\n    const now = Date.now();\\n    \\n    // Initialize stream buffer if needed\\n    if (!state.streamBuffers.has(streamId)) {\\n      const buffer = createStreamBuffer(streamId);\\n      state.streamBuffers.set(streamId, buffer);\\n      \\n      // Set first stream as reference if no reference exists\\n      if (!state.referenceStream) {\\n        state.referenceStream = streamId;\\n        buffer.isReference = true;\\n      }\\n    }\\n\\n    const buffer = state.streamBuffers.get(streamId);\\n    const latency = now - timestamp;\\n\\n    // Update latency tracking\\n    buffer.latencyHistory.push(latency);\\n    if (buffer.latencyHistory.length > 50) {\\n      buffer.latencyHistory.splice(0, 10);\\n    }\\n    buffer.avgLatency = buffer.latencyHistory.reduce((sum, l) => sum + l, 0) / buffer.latencyHistory.length;\\n\\n    // Add sample to buffer\\n    buffer.samples.push({\\n      ...streamData,\\n      arrivalTime: now,\\n      latency\\n    });\\n\\n    // Update global metrics\\n    state.bufferMetrics.totalBuffered++;\\n    state.bufferMetrics.avgLatency = (state.bufferMetrics.avgLatency + latency) / 2;\\n    state.bufferMetrics.maxLatency = Math.max(state.bufferMetrics.maxLatency, latency);\\n\\n    // Determine optimal buffer size\\n    const optimalBufferSize = alignerConfig.adaptiveBuffering \\n      ? calculateOptimalBufferSize(streamId)\\n      : alignerConfig.bufferSize;\\n\\n    // Keep buffer within limits\\n    if (buffer.samples.length > optimalBufferSize) {\\n      const dropped = buffer.samples.splice(0, buffer.samples.length - optimalBufferSize);\\n      state.bufferMetrics.droppedSamples += dropped.length;\\n    }\\n\\n    // Find alignment point\\n    let alignedTimestamp = timestamp;\\n    let confidence = alignerConfig.confidenceThreshold;\\n\\n    if (buffer.samples.length > 2) {\\n      // Use median timestamp for alignment stability\\n      const recentTimestamps = buffer.samples.slice(-5).map(s => s.timestamp).sort((a, b) => a - b);\\n      const medianIndex = Math.floor(recentTimestamps.length / 2);\\n      alignedTimestamp = recentTimestamps[medianIndex];\\n\\n      // Adjust confidence based on buffer stability\\n      const timestampVariance = recentTimestamps.reduce((sum, ts) => {\\n        return sum + Math.pow(ts - alignedTimestamp, 2);\\n      }, 0) / recentTimestamps.length;\\n\\n      confidence = Math.max(0.3, alignerConfig.confidenceThreshold - (timestampVariance / 10000));\\n    }\\n\\n    // Calculate synchronization offset\\n    const referenceBuffer = state.streamBuffers.get(state.referenceStream);\\n    let syncOffset = 0;\\n\\n    if (referenceBuffer && referenceBuffer.samples.length > 0 && !buffer.isReference) {\\n      const referenceTime = referenceBuffer.samples[referenceBuffer.samples.length - 1]?.timestamp || 0;\\n      syncOffset = alignedTimestamp - referenceTime;\\n    }\\n\\n    return {\\n      alignedTimestamp,\\n      confidence,\\n      offset: syncOffset,\\n      bufferSize: buffer.samples.length,\\n      optimalBufferSize,\\n      latency: buffer.avgLatency,\\n      strategy: SynchronizationStrategy.BUFFER_BASED\\n    };\\n  };\\n\\n  // Flush old samples from buffers\\n  const flushBuffers = () => {\\n    const now = Date.now();\\n    const flushThreshold = alignerConfig.maxBufferLatency;\\n\\n    for (const [streamId, buffer] of state.streamBuffers) {\\n      const initialSize = buffer.samples.length;\\n      buffer.samples = buffer.samples.filter(sample => \\n        (now - sample.arrivalTime) < flushThreshold\\n      );\\n      \\n      const flushed = initialSize - buffer.samples.length;\\n      if (flushed > 0) {\\n        state.bufferMetrics.droppedSamples += flushed;\\n      }\\n      \\n      buffer.lastFlush = now;\\n    }\\n  };\\n\\n  // Periodic buffer maintenance\\n  const maintenanceInterval = setInterval(flushBuffers, alignerConfig.maxBufferLatency / 2);\\n\\n  const getQuality = () => {\\n    const totalBufferSize = Array.from(state.streamBuffers.values())\\n      .reduce((sum, buffer) => sum + buffer.samples.length, 0);\\n    \\n    const avgBufferSize = totalBufferSize / Math.max(1, state.streamBuffers.size);\\n    const bufferEfficiency = Math.min(1, avgBufferSize / alignerConfig.bufferSize);\\n\\n    return createSyncMetrics({\\n      quality: bufferEfficiency * 0.75, // Buffer-based is inherently less precise\\n      latency: state.bufferMetrics.avgLatency / 10, // Convert to relative scale\\n      jitter: Math.min(state.bufferMetrics.maxLatency / 100, 1),\\n      droppedSamples: state.bufferMetrics.droppedSamples,\\n      alignmentAccuracy: avgBufferSize,\\n      bufferUtilization: bufferEfficiency\\n    });\\n  };\\n\\n  const getStats = () => ({\\n    ...state.bufferMetrics,\\n    activeStreams: state.streamBuffers.size,\\n    referenceStream: state.referenceStream,\\n    totalBufferSize: Array.from(state.streamBuffers.values())\\n      .reduce((sum, buffer) => sum + buffer.samples.length, 0),\\n    avgBufferSize: Array.from(state.streamBuffers.values())\\n      .reduce((sum, buffer) => sum + buffer.samples.length, 0) / Math.max(1, state.streamBuffers.size)\\n  });\\n\\n  const cleanup = async () => {\\n    if (maintenanceInterval) {\\n      clearInterval(maintenanceInterval);\\n    }\\n    state.streamBuffers.clear();\\n    state.referenceStream = null;\\n    state.bufferMetrics = {\\n      totalBuffered: 0,\\n      droppedSamples: 0,\\n      avgLatency: 0,\\n      maxLatency: 0\\n    };\\n  };\\n\\n  return { \\n    align, \\n    getQuality, \\n    getStats,\\n    flushBuffers,\\n    cleanup,\\n    strategy: SynchronizationStrategy.BUFFER_BASED \\n  };\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/core/orchestration/synchronization/aligners/event-aligner.js\",\"messages\":[{\"ruleId\":\"max-lines-per-function\",\"severity\":1,\"message\":\"Arrow function has too many lines (238). Maximum allowed is 150.\",\"line\":13,\"column\":41,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"exceed\",\"endLine\":322,\"endColumn\":2},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":85,\"column\":50,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":85,\"endColumn\":51},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":85,\"column\":56,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":85,\"endColumn\":57},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":85,\"column\":56,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":85,\"endColumn\":57},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":85,\"column\":73,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":85,\"endColumn\":74},{\"ruleId\":\"max-statements\",\"severity\":1,\"message\":\"Arrow function has too many statements (43). Maximum allowed is 40.\",\"line\":164,\"column\":17,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"exceed\",\"endLine\":272,\"endColumn\":4},{\"ruleId\":\"prefer-destructuring\",\"severity\":1,\"message\":\"Use array destructuring.\",\"line\":211,\"column\":15,\"nodeType\":\"VariableDeclarator\",\"messageId\":\"preferDestructuring\",\"endLine\":218,\"endColumn\":16},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":261,\"column\":30,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":261,\"endColumn\":31},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":261,\"column\":36,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":261,\"endColumn\":37},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":261,\"column\":36,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":261,\"endColumn\":37},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":261,\"column\":56,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":261,\"endColumn\":57},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":284,\"column\":33,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":284,\"endColumn\":34},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":284,\"column\":39,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":284,\"endColumn\":40},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":284,\"column\":39,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":284,\"endColumn\":40},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":284,\"column\":53,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":284,\"endColumn\":54}],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":15,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Event-Driven Aligner\\n * Alignment using event correlation and pattern matching\\n */\\n\\nimport { SynchronizationStrategy } from '../strategies/sync-strategies.js';\\nimport { createSyncMetrics } from '../metrics/sync-metrics.js';\\n\\n/**\\n * Event correlation-based synchronization\\n * Uses pattern matching and event correlation to align streams\\n */\\nexport const createEventDrivenAligner = (config = {}) => {\\n  const alignerConfig = {\\n    correlationWindow: config.correlationWindow || 1000, // ms\\n    minCorrelationScore: config.minCorrelationScore || 0.6,\\n    maxEventAge: config.maxEventAge || 5000, // ms\\n    patternMatchThreshold: config.patternMatchThreshold || 0.7,\\n    confidenceThreshold: config.confidenceThreshold || 0.6,\\n    ...config\\n  };\\n\\n  const state = {\\n    eventStreams: new Map(),\\n    correlationMatrix: new Map(),\\n    patternLibrary: new Map(),\\n    alignmentHistory: [],\\n    metrics: {\\n      totalEvents: 0,\\n      correlationHits: 0,\\n      patternMatches: 0,\\n      avgCorrelationScore: 0\\n    }\\n  };\\n\\n  // Create event stream tracker\\n  const createEventStream = (streamId) => ({\\n    id: streamId,\\n    events: [],\\n    patterns: [],\\n    correlationScore: 0,\\n    lastEventTime: 0\\n  });\\n\\n  // Extract features from stream data for pattern matching\\n  const extractEventFeatures = (streamData) => {\\n    const features = {\\n      timestamp: streamData.timestamp,\\n      type: streamData.type || 'unknown',\\n      magnitude: streamData.magnitude || streamData.amplitude || 1,\\n      duration: streamData.duration || 0,\\n      frequency: streamData.frequency || 0\\n    };\\n\\n    // Add contextual features\\n    if (streamData.audio) {\\n      features.audioEnergy = streamData.audio.energy || 0;\\n      features.audioFreq = streamData.audio.dominantFreq || 0;\\n    }\\n\\n    if (streamData.video) {\\n      features.motionLevel = streamData.video.motion || 0;\\n      features.brightness = streamData.video.brightness || 0;\\n    }\\n\\n    return features;\\n  };\\n\\n  // Calculate correlation between two event sequences\\n  const calculateEventCorrelation = (events1, events2, timeWindow) => {\\n    if (events1.length === 0 || events2.length === 0) return 0;\\n\\n    const correlationScores = [];\\n\\n    for (const event1 of events1) {\\n      const correlatedEvents = events2.filter(event2 => \\n        Math.abs(event1.timestamp - event2.timestamp) <= timeWindow\\n      );\\n\\n      for (const event2 of correlatedEvents) {\\n        // Calculate feature similarity\\n        const featureSimilarity = calculateFeatureSimilarity(event1.features, event2.features);\\n        const timeSimilarity = 1 - (Math.abs(event1.timestamp - event2.timestamp) / timeWindow);\\n        \\n        correlationScores.push(featureSimilarity * 0.7 + timeSimilarity * 0.3);\\n      }\\n    }\\n\\n    return correlationScores.length > 0 \\n      ? correlationScores.reduce((sum, score) => sum + score, 0) / correlationScores.length\\n      : 0;\\n  };\\n\\n  // Calculate similarity between two feature vectors\\n  const calculateFeatureSimilarity = (features1, features2) => {\\n    const keys = new Set([...Object.keys(features1), ...Object.keys(features2)]);\\n    let similarity = 0;\\n    let validComparisons = 0;\\n\\n    for (const key of keys) {\\n      if (features1[key] !== undefined && features2[key] !== undefined) {\\n        // Normalize feature values for comparison\\n        const val1 = typeof features1[key] === 'number' ? features1[key] : 0;\\n        const val2 = typeof features2[key] === 'number' ? features2[key] : 0;\\n        \\n        const maxVal = Math.max(Math.abs(val1), Math.abs(val2), 1);\\n        const diff = Math.abs(val1 - val2) / maxVal;\\n        \\n        similarity += (1 - diff);\\n        validComparisons++;\\n      }\\n    }\\n\\n    return validComparisons > 0 ? similarity / validComparisons : 0;\\n  };\\n\\n  // Detect patterns in event sequences\\n  const detectEventPatterns = (events) => {\\n    const patterns = [];\\n    const minPatternLength = 3;\\n\\n    if (events.length < minPatternLength) return patterns;\\n\\n    // Look for repeating patterns\\n    for (let i = 0; i < events.length - minPatternLength; i++) {\\n      for (let len = minPatternLength; len <= Math.min(10, events.length - i); len++) {\\n        const pattern = events.slice(i, i + len);\\n        const patternFeatures = pattern.map(e => e.features);\\n        \\n        // Check if this pattern repeats later\\n        for (let j = i + len; j <= events.length - len; j++) {\\n          const candidate = events.slice(j, j + len);\\n          const candidateFeatures = candidate.map(e => e.features);\\n          \\n          const similarity = calculatePatternSimilarity(patternFeatures, candidateFeatures);\\n          \\n          if (similarity > alignerConfig.patternMatchThreshold) {\\n            patterns.push({\\n              startIndex: i,\\n              length: len,\\n              repeatIndex: j,\\n              similarity,\\n              pattern: patternFeatures\\n            });\\n          }\\n        }\\n      }\\n    }\\n\\n    return patterns;\\n  };\\n\\n  // Calculate similarity between two patterns\\n  const calculatePatternSimilarity = (pattern1, pattern2) => {\\n    if (pattern1.length !== pattern2.length) return 0;\\n\\n    const similarities = pattern1.map((features1, index) => \\n      calculateFeatureSimilarity(features1, pattern2[index])\\n    );\\n\\n    return similarities.reduce((sum, sim) => sum + sim, 0) / similarities.length;\\n  };\\n\\n  const align = (streamData) => {\\n    const { streamId, timestamp } = streamData;\\n    const now = Date.now();\\n\\n    // Initialize stream if needed\\n    if (!state.eventStreams.has(streamId)) {\\n      state.eventStreams.set(streamId, createEventStream(streamId));\\n    }\\n\\n    const stream = state.eventStreams.get(streamId);\\n    const features = extractEventFeatures(streamData);\\n\\n    // Add event to stream\\n    const event = {\\n      timestamp,\\n      arrivalTime: now,\\n      features,\\n      streamId\\n    };\\n\\n    stream.events.push(event);\\n    stream.lastEventTime = timestamp;\\n    state.metrics.totalEvents++;\\n\\n    // Cleanup old events\\n    const maxAge = alignerConfig.maxEventAge;\\n    stream.events = stream.events.filter(e => (now - e.arrivalTime) < maxAge);\\n\\n    // Find correlations with other streams\\n    let bestCorrelationScore = 0;\\n    let alignedTimestamp = timestamp;\\n    let correlationOffset = 0;\\n\\n    for (const [otherStreamId, otherStream] of state.eventStreams) {\\n      if (otherStreamId === streamId || otherStream.events.length === 0) continue;\\n\\n      const correlationScore = calculateEventCorrelation(\\n        [event],\\n        otherStream.events.slice(-10), // Recent events\\n        alignerConfig.correlationWindow\\n      );\\n\\n      if (correlationScore > bestCorrelationScore && correlationScore > alignerConfig.minCorrelationScore) {\\n        bestCorrelationScore = correlationScore;\\n        state.metrics.correlationHits++;\\n\\n        // Find best matching event for alignment\\n        const matchingEvent = otherStream.events\\n          .slice(-10)\\n          .filter(e => Math.abs(e.timestamp - timestamp) <= alignerConfig.correlationWindow)\\n          .sort((a, b) => {\\n            const simA = calculateFeatureSimilarity(features, a.features);\\n            const simB = calculateFeatureSimilarity(features, b.features);\\n            return simB - simA;\\n          })[0];\\n\\n        if (matchingEvent) {\\n          correlationOffset = timestamp - matchingEvent.timestamp;\\n          alignedTimestamp = matchingEvent.timestamp;\\n        }\\n      }\\n    }\\n\\n    // Update correlation matrix\\n    if (bestCorrelationScore > 0) {\\n      const matrixKey = `${streamId}:correlation`;\\n      if (!state.correlationMatrix.has(matrixKey)) {\\n        state.correlationMatrix.set(matrixKey, []);\\n      }\\n      state.correlationMatrix.get(matrixKey).push(bestCorrelationScore);\\n\\n      // Keep recent correlation scores\\n      const scores = state.correlationMatrix.get(matrixKey);\\n      if (scores.length > 20) {\\n        scores.splice(0, 10);\\n      }\\n\\n      state.metrics.avgCorrelationScore = scores.reduce((sum, s) => sum + s, 0) / scores.length;\\n    }\\n\\n    // Detect patterns in current stream\\n    if (stream.events.length >= 10) {\\n      const patterns = detectEventPatterns(stream.events.slice(-20));\\n      if (patterns.length > 0) {\\n        stream.patterns = patterns;\\n        state.metrics.patternMatches++;\\n      }\\n    }\\n\\n    // Calculate confidence based on correlation and pattern strength\\n    const correlationConfidence = Math.min(bestCorrelationScore, 1);\\n    const patternConfidence = stream.patterns.length > 0 \\n      ? Math.max(...stream.patterns.map(p => p.similarity))\\n      : 0;\\n\\n    const confidence = Math.max(\\n      alignerConfig.confidenceThreshold,\\n      (correlationConfidence * 0.7 + patternConfidence * 0.3)\\n    );\\n\\n    return {\\n      alignedTimestamp,\\n      confidence: Math.min(confidence, 1),\\n      offset: correlationOffset,\\n      correlationScore: bestCorrelationScore,\\n      patternScore: patternConfidence,\\n      strategy: SynchronizationStrategy.EVENT_DRIVEN\\n    };\\n  };\\n\\n  const getQuality = () => {\\n    const correlationRate = state.metrics.totalEvents > 0 \\n      ? state.metrics.correlationHits / state.metrics.totalEvents\\n      : 0;\\n    \\n    const patternRate = state.metrics.totalEvents > 0\\n      ? state.metrics.patternMatches / state.metrics.totalEvents\\n      : 0;\\n\\n    return createSyncMetrics({\\n      quality: (correlationRate * 0.6 + patternRate * 0.4) * alignerConfig.confidenceThreshold,\\n      latency: 20, // Event correlation adds latency\\n      jitter: 1 - state.metrics.avgCorrelationScore, // Lower correlation = higher jitter\\n      droppedSamples: 0,\\n      alignmentAccuracy: state.metrics.avgCorrelationScore * 100,\\n      correlationRate,\\n      patternRate\\n    });\\n  };\\n\\n  const getStats = () => ({\\n    ...state.metrics,\\n    activeStreams: state.eventStreams.size,\\n    totalCorrelations: state.correlationMatrix.size,\\n    avgEventsPerStream: state.metrics.totalEvents / Math.max(1, state.eventStreams.size),\\n    patternLibrarySize: state.patternLibrary.size\\n  });\\n\\n  const cleanup = async () => {\\n    state.eventStreams.clear();\\n    state.correlationMatrix.clear();\\n    state.patternLibrary.clear();\\n    state.alignmentHistory = [];\\n    state.metrics = {\\n      totalEvents: 0,\\n      correlationHits: 0,\\n      patternMatches: 0,\\n      avgCorrelationScore: 0\\n    };\\n  };\\n\\n  return { \\n    align, \\n    getQuality, \\n    getStats,\\n    cleanup,\\n    strategy: SynchronizationStrategy.EVENT_DRIVEN \\n  };\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/core/orchestration/synchronization/aligners/hardware-aligner.js\",\"messages\":[{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":39,\"column\":54,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":39,\"endColumn\":55},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":39,\"column\":58,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":39,\"endColumn\":59},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":40,\"column\":51,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":40,\"endColumn\":52},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":40,\"column\":55,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":40,\"endColumn\":56},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '-'. Use parentheses to clarify the intended order of operations.\",\"line\":42,\"column\":22,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":42,\"endColumn\":23},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '-'. Use parentheses to clarify the intended order of operations.\",\"line\":42,\"column\":30,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":42,\"endColumn\":31},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":42,\"column\":30,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":42,\"endColumn\":31},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":42,\"column\":37,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":42,\"endColumn\":38},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '-'. Use parentheses to clarify the intended order of operations.\",\"line\":42,\"column\":50,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":42,\"endColumn\":51},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '-'. Use parentheses to clarify the intended order of operations.\",\"line\":42,\"column\":58,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":42,\"endColumn\":59},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":42,\"column\":58,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":42,\"endColumn\":59},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":42,\"column\":65,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":42,\"endColumn\":66}],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":12,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Hardware Timestamp Aligner\\n * Highest precision alignment using hardware timing sources\\n */\\n\\nimport { SynchronizationStrategy } from '../strategies/sync-strategies.js';\\nimport { createSyncMetrics } from '../metrics/sync-metrics.js';\\n\\n/**\\n * Hardware timestamp-based alignment (highest precision)\\n * Uses hardware timestamps with drift compensation\\n */\\nexport const createHardwareTimestampAligner = (config = {}) => {\\n  const alignerConfig = {\\n    maxOffsetHistory: config.maxOffsetHistory || 100,\\n    driftCalculationWindow: config.driftCalculationWindow || 10,\\n    confidenceThreshold: config.confidenceThreshold || 0.95,\\n    ...config\\n  };\\n\\n  const state = {\\n    referenceTime: null,\\n    clockOffsets: new Map(), // Track clock differences per stream\\n    driftCompensation: new Map(),\\n    alignmentStats: {\\n      totalAlignments: 0,\\n      averageOffset: 0,\\n      maxDrift: 0\\n    }\\n  };\\n\\n  // Linear slope calculation for drift compensation\\n  const calculateLinearSlope = (points) => {\\n    const n = points.length;\\n    if (n < 2) return 0;\\n\\n    const sumX = points.reduce((sum, [x]) => sum + x, 0);\\n    const sumY = points.reduce((sum, [, y]) => sum + y, 0);\\n    const sumXY = points.reduce((sum, [x, y]) => sum + x * y, 0);\\n    const sumXX = points.reduce((sum, [x]) => sum + x * x, 0);\\n\\n    const slope = (n * sumXY - sumX * sumY) / (n * sumXX - sumX * sumX);\\n    return isFinite(slope) ? slope : 0;\\n  };\\n\\n  const align = (streamData) => {\\n    // Use hardware timestamps if available\\n    const hwTimestamp = streamData.hardwareTimestamp || streamData.timestamp;\\n    \\n    if (!state.referenceTime) {\\n      state.referenceTime = hwTimestamp;\\n    }\\n\\n    // Calculate offset from reference time\\n    const offset = hwTimestamp - state.referenceTime;\\n    \\n    // Track clock drift for this stream\\n    const { streamId } = streamData;\\n    if (!state.clockOffsets.has(streamId)) {\\n      state.clockOffsets.set(streamId, []);\\n    }\\n    \\n    const offsets = state.clockOffsets.get(streamId);\\n    offsets.push({ timestamp: Date.now(), offset });\\n    \\n    // Keep only recent offsets for drift calculation\\n    if (offsets.length > alignerConfig.maxOffsetHistory) {\\n      offsets.splice(0, offsets.length - alignerConfig.maxOffsetHistory);\\n    }\\n    \\n    // Calculate drift compensation\\n    let drift = 0;\\n    let confidence = alignerConfig.confidenceThreshold;\\n    \\n    if (offsets.length > alignerConfig.driftCalculationWindow) {\\n      const recent = offsets.slice(-alignerConfig.driftCalculationWindow);\\n      const slope = calculateLinearSlope(recent.map((o, i) => [i, o.offset]));\\n      drift = slope * offsets.length;\\n      \\n      // Adjust confidence based on drift stability\\n      const variance = recent.reduce((sum, o) => {\\n        const expectedOffset = o.offset - drift;\\n        return sum + Math.pow(offset - expectedOffset, 2);\\n      }, 0) / recent.length;\\n      \\n      confidence = Math.max(0.5, alignerConfig.confidenceThreshold - (variance / 1000));\\n    }\\n    \\n    state.driftCompensation.set(streamId, drift);\\n    \\n    // Update stats\\n    state.alignmentStats.totalAlignments++;\\n    state.alignmentStats.averageOffset = (state.alignmentStats.averageOffset + Math.abs(offset)) / 2;\\n    state.alignmentStats.maxDrift = Math.max(state.alignmentStats.maxDrift, Math.abs(drift));\\n\\n    return {\\n      alignedTimestamp: hwTimestamp - drift,\\n      confidence,\\n      offset: offset - drift,\\n      drift,\\n      strategy: SynchronizationStrategy.HARDWARE_TIMESTAMP\\n    };\\n  };\\n\\n  const getQuality = () => createSyncMetrics({\\n    quality: Math.min(0.95, 1.0 - (state.alignmentStats.maxDrift / 10000)), // Penalize excessive drift\\n    latency: 1, // ~1ms precision with hardware timestamps\\n    jitter: state.alignmentStats.averageOffset / 10, // Convert to relative jitter\\n    droppedSamples: 0, // Hardware timestamps don't typically drop\\n    alignmentAccuracy: state.alignmentStats.averageOffset,\\n    totalAlignments: state.alignmentStats.totalAlignments\\n  });\\n\\n  const getStats = () => ({\\n    ...state.alignmentStats,\\n    activeStreams: state.clockOffsets.size,\\n    avgDrift: Array.from(state.driftCompensation.values()).reduce((sum, d) => sum + Math.abs(d), 0) / Math.max(1, state.driftCompensation.size)\\n  });\\n\\n  const cleanup = async () => {\\n    state.clockOffsets.clear();\\n    state.driftCompensation.clear();\\n    state.referenceTime = null;\\n    state.alignmentStats = {\\n      totalAlignments: 0,\\n      averageOffset: 0,\\n      maxDrift: 0\\n    };\\n  };\\n\\n  return { \\n    align, \\n    getQuality, \\n    getStats,\\n    cleanup,\\n    strategy: SynchronizationStrategy.HARDWARE_TIMESTAMP \\n  };\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/core/orchestration/synchronization/aligners/software-aligner.js\",\"messages\":[{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '/'. Use parentheses to clarify the intended order of operations.\",\"line\":48,\"column\":21,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":48,\"endColumn\":22},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '/'. Use parentheses to clarify the intended order of operations.\",\"line\":48,\"column\":33,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":48,\"endColumn\":34},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":56,\"column\":53,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":56,\"endColumn\":54},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":56,\"column\":85,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":56,\"endColumn\":86},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":56,\"column\":85,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":56,\"endColumn\":86},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":57,\"column\":35,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":57,\"endColumn\":36},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":80,\"column\":41,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":80,\"endColumn\":42},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":80,\"column\":75,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":80,\"endColumn\":76},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":97,\"column\":54,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":97,\"endColumn\":55},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":97,\"column\":58,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":97,\"endColumn\":59},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":98,\"column\":51,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":98,\"endColumn\":52},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":98,\"column\":55,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":98,\"endColumn\":56},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '-'. Use parentheses to clarify the intended order of operations.\",\"line\":100,\"column\":15,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":100,\"endColumn\":16},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '-'. Use parentheses to clarify the intended order of operations.\",\"line\":100,\"column\":23,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":100,\"endColumn\":24},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":100,\"column\":23,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":100,\"endColumn\":24},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":100,\"column\":30,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":100,\"endColumn\":31},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '-'. Use parentheses to clarify the intended order of operations.\",\"line\":100,\"column\":43,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":100,\"endColumn\":44},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '-'. Use parentheses to clarify the intended order of operations.\",\"line\":100,\"column\":51,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":100,\"endColumn\":52},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":100,\"column\":51,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":100,\"endColumn\":52},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":100,\"column\":58,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":100,\"endColumn\":59}],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":20,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Software Timestamp Aligner\\n * Software-based alignment with NTP-style drift compensation\\n */\\n\\nimport { SynchronizationStrategy } from '../strategies/sync-strategies.js';\\nimport { createSyncMetrics } from '../metrics/sync-metrics.js';\\n\\n/**\\n * Software timestamp-based alignment with NTP-style drift compensation\\n * Uses software timestamps with network time synchronization\\n */\\nexport const createSoftwareTimestampAligner = (config = {}) => {\\n  const alignerConfig = {\\n    ntpSyncInterval: config.ntpSyncInterval || 30000, // 30 seconds\\n    maxClockSkew: config.maxClockSkew || 1000, // 1 second\\n    smoothingFactor: config.smoothingFactor || 0.8,\\n    confidenceThreshold: config.confidenceThreshold || 0.85,\\n    ...config\\n  };\\n\\n  const state = {\\n    referenceTime: null,\\n    clockSync: {\\n      offset: 0,\\n      drift: 0,\\n      lastSync: 0,\\n      syncHistory: []\\n    },\\n    streamOffsets: new Map(),\\n    qualityMetrics: {\\n      avgLatency: 5,\\n      jitter: 2,\\n      syncQuality: alignerConfig.confidenceThreshold\\n    }\\n  };\\n\\n  // NTP-style network time synchronization\\n  const performTimeSync = async () => {\\n    const t1 = Date.now(); // Client send time\\n    \\n    try {\\n      // In a real implementation, this would query NTP server\\n      // For now, simulate network round-trip\\n      await new Promise(resolve => setTimeout(resolve, Math.random() * 10));\\n      \\n      const t4 = Date.now(); // Client receive time\\n      const t2 = t1 + (t4 - t1) / 2; // Simulated server receive time\\n      const t3 = t2; // Simulated server send time\\n      \\n      // Calculate offset and round-trip delay\\n      const offset = ((t2 - t1) + (t3 - t4)) / 2;\\n      const delay = (t4 - t1) - (t3 - t2);\\n      \\n      // Apply smoothing to reduce jitter\\n      const smoothedOffset = state.clockSync.offset * alignerConfig.smoothingFactor + \\n                           offset * (1 - alignerConfig.smoothingFactor);\\n      \\n      // Update clock sync state\\n      state.clockSync.offset = smoothedOffset;\\n      state.clockSync.lastSync = Date.now();\\n      state.clockSync.syncHistory.push({ timestamp: t4, offset, delay });\\n      \\n      // Keep only recent sync history\\n      if (state.clockSync.syncHistory.length > 50) {\\n        state.clockSync.syncHistory.splice(0, 10);\\n      }\\n      \\n      // Calculate drift\\n      if (state.clockSync.syncHistory.length > 5) {\\n        const recent = state.clockSync.syncHistory.slice(-5);\\n        const driftSlope = calculateLinearTrend(recent.map((s, i) => [i, s.offset]));\\n        state.clockSync.drift = driftSlope;\\n      }\\n      \\n      // Update quality metrics\\n      state.qualityMetrics.avgLatency = delay / 2;\\n      state.qualityMetrics.jitter = Math.sqrt(\\n        state.clockSync.syncHistory.slice(-10).reduce((sum, s) => {\\n          return sum + Math.pow(s.delay - state.qualityMetrics.avgLatency * 2, 2);\\n        }, 0) / Math.min(10, state.clockSync.syncHistory.length)\\n      );\\n      \\n    } catch (error) {\\n      console.warn('Time sync failed:', error.message);\\n      state.qualityMetrics.syncQuality *= 0.9; // Degrade quality on sync failure\\n    }\\n  };\\n\\n  // Linear trend calculation\\n  const calculateLinearTrend = (points) => {\\n    const n = points.length;\\n    if (n < 2) return 0;\\n\\n    const sumX = points.reduce((sum, [x]) => sum + x, 0);\\n    const sumY = points.reduce((sum, [, y]) => sum + y, 0);\\n    const sumXY = points.reduce((sum, [x, y]) => sum + x * y, 0);\\n    const sumXX = points.reduce((sum, [x]) => sum + x * x, 0);\\n\\n    return (n * sumXY - sumX * sumY) / (n * sumXX - sumX * sumX) || 0;\\n  };\\n\\n  // Initialize periodic time sync\\n  const syncInterval = setInterval(performTimeSync, alignerConfig.ntpSyncInterval);\\n  performTimeSync(); // Initial sync\\n\\n  const align = (streamData) => {\\n    const now = Date.now();\\n    const timestamp = streamData.timestamp || now;\\n    \\n    if (!state.referenceTime) {\\n      state.referenceTime = timestamp;\\n    }\\n\\n    // Apply clock offset and drift compensation\\n    const timeSinceLastSync = now - state.clockSync.lastSync;\\n    const driftAdjustment = state.clockSync.drift * (timeSinceLastSync / 1000);\\n    const adjustedTimestamp = timestamp + state.clockSync.offset + driftAdjustment;\\n    \\n    // Track stream-specific offsets\\n    const { streamId } = streamData;\\n    if (streamId) {\\n      if (!state.streamOffsets.has(streamId)) {\\n        state.streamOffsets.set(streamId, []);\\n      }\\n      \\n      const offsets = state.streamOffsets.get(streamId);\\n      const streamOffset = adjustedTimestamp - state.referenceTime;\\n      offsets.push({ timestamp: now, offset: streamOffset });\\n      \\n      // Keep recent history\\n      if (offsets.length > 20) {\\n        offsets.splice(0, 10);\\n      }\\n    }\\n\\n    // Calculate confidence based on sync quality and age\\n    const syncAge = timeSinceLastSync / alignerConfig.ntpSyncInterval;\\n    const confidence = Math.max(0.5, \\n      alignerConfig.confidenceThreshold * Math.exp(-syncAge) * state.qualityMetrics.syncQuality\\n    );\\n\\n    return {\\n      alignedTimestamp: adjustedTimestamp,\\n      confidence,\\n      offset: adjustedTimestamp - timestamp,\\n      drift: driftAdjustment,\\n      strategy: SynchronizationStrategy.SOFTWARE_TIMESTAMP\\n    };\\n  };\\n\\n  const getQuality = () => createSyncMetrics({\\n    quality: state.qualityMetrics.syncQuality,\\n    latency: state.qualityMetrics.avgLatency,\\n    jitter: state.qualityMetrics.jitter,\\n    droppedSamples: 0,\\n    alignmentAccuracy: Math.abs(state.clockSync.offset),\\n    lastSync: state.clockSync.lastSync\\n  });\\n\\n  const getStats = () => ({\\n    clockOffset: state.clockSync.offset,\\n    clockDrift: state.clockSync.drift,\\n    lastSyncAge: Date.now() - state.clockSync.lastSync,\\n    syncHistorySize: state.clockSync.syncHistory.length,\\n    activeStreams: state.streamOffsets.size,\\n    avgLatency: state.qualityMetrics.avgLatency,\\n    jitter: state.qualityMetrics.jitter\\n  });\\n\\n  const cleanup = async () => {\\n    if (syncInterval) {\\n      clearInterval(syncInterval);\\n    }\\n    state.streamOffsets.clear();\\n    state.clockSync.syncHistory = [];\\n    state.referenceTime = null;\\n  };\\n\\n  return { \\n    align, \\n    getQuality, \\n    getStats,\\n    cleanup,\\n    strategy: SynchronizationStrategy.SOFTWARE_TIMESTAMP \\n  };\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/core/orchestration/synchronization/metrics/sync-metrics.js\",\"messages\":[{\"ruleId\":\"max-lines-per-function\",\"severity\":1,\"message\":\"Arrow function has too many lines (171). Maximum allowed is 150.\",\"line\":63,\"column\":40,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"exceed\",\"endLine\":278,\"endColumn\":2},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":86,\"column\":18,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":86,\"endColumn\":19},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":86,\"column\":47,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":86,\"endColumn\":48},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":205,\"column\":55,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":205,\"endColumn\":56},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":205,\"column\":59,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":205,\"endColumn\":60},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '-'. Use parentheses to clarify the intended order of operations.\",\"line\":206,\"column\":37,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":206,\"endColumn\":38},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '-'. Use parentheses to clarify the intended order of operations.\",\"line\":206,\"column\":41,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":206,\"endColumn\":42},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '-'. Use parentheses to clarify the intended order of operations.\",\"line\":208,\"column\":22,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":208,\"endColumn\":23},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '-'. Use parentheses to clarify the intended order of operations.\",\"line\":208,\"column\":30,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":208,\"endColumn\":31},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":208,\"column\":30,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":208,\"endColumn\":31},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":208,\"column\":37,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":208,\"endColumn\":38},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '-'. Use parentheses to clarify the intended order of operations.\",\"line\":208,\"column\":50,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":208,\"endColumn\":51},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '-'. Use parentheses to clarify the intended order of operations.\",\"line\":208,\"column\":58,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":208,\"endColumn\":59},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":208,\"column\":58,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":208,\"endColumn\":59},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":208,\"column\":65,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":208,\"endColumn\":66},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":244,\"column\":30,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":244,\"endColumn\":31},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":244,\"column\":34,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":244,\"endColumn\":35},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":245,\"column\":28,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":245,\"endColumn\":29},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":245,\"column\":38,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":245,\"endColumn\":39}],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":19,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Synchronization Metrics and Quality Management\\n * Provides comprehensive quality tracking and calculation for sync systems\\n */\\n\\n/**\\n * Synchronization quality metrics factory\\n */\\nexport const createSyncMetrics = (config = {}) => ({\\n  quality: config.quality || 1.0,\\n  latency: config.latency || 0,\\n  jitter: config.jitter || 0,\\n  droppedSamples: config.droppedSamples || 0,\\n  alignmentAccuracy: config.alignmentAccuracy || 0,\\n  lastUpdate: config.lastUpdate || Date.now(),\\n  \\n  // Additional metrics for enhanced tracking\\n  totalAlignments: config.totalAlignments || 0,\\n  bufferUtilization: config.bufferUtilization || 0,\\n  correlationRate: config.correlationRate || 0,\\n  patternRate: config.patternRate || 0,\\n  lastSync: config.lastSync || 0,\\n  \\n  // Quality scoring based on multiple factors\\n  computeOverallQuality() {\\n    const jitterPenalty = Math.min(this.jitter / 100, 0.3); // Max 30% penalty for jitter\\n    const dropPenalty = Math.min(this.droppedSamples / 1000, 0.4); // Max 40% penalty for drops\\n    const latencyPenalty = Math.min(this.latency / 1000, 0.2); // Max 20% penalty for latency\\n    \\n    return Math.max(0, this.quality - jitterPenalty - dropPenalty - latencyPenalty);\\n  },\\n\\n  // Get quality grade (A-F)\\n  getQualityGrade() {\\n    const overallQuality = this.computeOverallQuality();\\n    if (overallQuality >= 0.9) return 'A';\\n    if (overallQuality >= 0.8) return 'B';\\n    if (overallQuality >= 0.7) return 'C';\\n    if (overallQuality >= 0.6) return 'D';\\n    return 'F';\\n  },\\n\\n  // Get detailed quality report\\n  getQualityReport() {\\n    return {\\n      overall: this.computeOverallQuality(),\\n      grade: this.getQualityGrade(),\\n      components: {\\n        baseQuality: this.quality,\\n        latency: this.latency,\\n        jitter: this.jitter,\\n        reliability: 1 - (this.droppedSamples / Math.max(this.totalAlignments, 1)),\\n        accuracy: this.alignmentAccuracy\\n      },\\n      timestamp: this.lastUpdate\\n    };\\n  }\\n});\\n\\n/**\\n * Quality calculator for comprehensive sync monitoring\\n */\\nexport const createQualityCalculator = (config = {}) => {\\n  const calculatorConfig = {\\n    qualityWindow: config.qualityWindow || 100, // Number of samples to track\\n    degradationThreshold: config.degradationThreshold || 0.1,\\n    recoveryThreshold: config.recoveryThreshold || 0.05,\\n    alertThreshold: config.alertThreshold || 0.6,\\n    ...config\\n  };\\n\\n  const state = {\\n    qualityHistory: [],\\n    alerts: [],\\n    overallMetrics: createSyncMetrics(),\\n    strategyMetrics: new Map(),\\n    degradationEvents: []\\n  };\\n\\n  const updateQuality = (syncResults) => {\\n    const now = Date.now();\\n    \\n    // Calculate weighted average quality from all sync results\\n    const totalWeight = syncResults.reduce((sum, result) => sum + result.confidence, 0);\\n    const weightedQuality = syncResults.reduce((sum, result) => {\\n      return sum + (result.confidence || 0.5) * (result.quality || 0.5);\\n    }, 0) / Math.max(totalWeight, 1);\\n\\n    // Calculate aggregate metrics\\n    const avgLatency = syncResults.reduce((sum, r) => sum + (r.latency || 0), 0) / syncResults.length;\\n    const avgJitter = Math.sqrt(\\n      syncResults.reduce((sum, r) => sum + Math.pow((r.latency || 0) - avgLatency, 2), 0) / syncResults.length\\n    );\\n    const totalDropped = syncResults.reduce((sum, r) => sum + (r.droppedSamples || 0), 0);\\n\\n    const qualitySnapshot = createSyncMetrics({\\n      quality: weightedQuality,\\n      latency: avgLatency,\\n      jitter: avgJitter,\\n      droppedSamples: totalDropped,\\n      alignmentAccuracy: syncResults.reduce((sum, r) => sum + (r.alignmentAccuracy || 0), 0) / syncResults.length,\\n      totalAlignments: syncResults.length,\\n      lastUpdate: now\\n    });\\n\\n    // Add to history\\n    state.qualityHistory.push(qualitySnapshot);\\n    if (state.qualityHistory.length > calculatorConfig.qualityWindow) {\\n      state.qualityHistory.shift();\\n    }\\n\\n    // Update overall metrics\\n    state.overallMetrics = qualitySnapshot;\\n\\n    // Detect quality degradation\\n    if (state.qualityHistory.length >= 10) {\\n      const recentAvg = state.qualityHistory.slice(-5)\\n        .reduce((sum, q) => sum + q.computeOverallQuality(), 0) / 5;\\n      const olderAvg = state.qualityHistory.slice(-10, -5)\\n        .reduce((sum, q) => sum + q.computeOverallQuality(), 0) / 5;\\n      \\n      const degradation = olderAvg - recentAvg;\\n      \\n      if (degradation > calculatorConfig.degradationThreshold) {\\n        const event = {\\n          type: 'quality_degradation',\\n          severity: degradation > 0.2 ? 'high' : 'medium',\\n          degradation,\\n          timestamp: now,\\n          oldQuality: olderAvg,\\n          newQuality: recentAvg\\n        };\\n        \\n        state.degradationEvents.push(event);\\n        state.alerts.push({\\n          ...event,\\n          message: `Sync quality degraded by ${(degradation * 100).toFixed(1)}%`\\n        });\\n      }\\n    }\\n\\n    // Generate alerts for low quality\\n    const currentQuality = qualitySnapshot.computeOverallQuality();\\n    if (currentQuality < calculatorConfig.alertThreshold) {\\n      state.alerts.push({\\n        type: 'low_quality',\\n        severity: currentQuality < 0.4 ? 'critical' : 'warning',\\n        quality: currentQuality,\\n        timestamp: now,\\n        message: `Sync quality is ${qualitySnapshot.getQualityGrade()} (${(currentQuality * 100).toFixed(1)}%)`\\n      });\\n    }\\n\\n    // Limit alert history\\n    if (state.alerts.length > 50) {\\n      state.alerts.splice(0, 10);\\n    }\\n\\n    return qualitySnapshot;\\n  };\\n\\n  const calculateOverallQuality = (syncResults) => {\\n    if (!syncResults || syncResults.length === 0) {\\n      return state.overallMetrics;\\n    }\\n\\n    return updateQuality(syncResults);\\n  };\\n\\n  const getOverallMetrics = () => {\\n    if (state.qualityHistory.length === 0) {\\n      return state.overallMetrics;\\n    }\\n\\n    // Calculate rolling statistics\\n    const recentQualities = state.qualityHistory.slice(-20).map(q => q.computeOverallQuality());\\n    const avgQuality = recentQualities.reduce((sum, q) => sum + q, 0) / recentQualities.length;\\n    const minQuality = Math.min(...recentQualities);\\n    const maxQuality = Math.max(...recentQualities);\\n    \\n    return {\\n      ...state.overallMetrics,\\n      rolling: {\\n        average: avgQuality,\\n        minimum: minQuality,\\n        maximum: maxQuality,\\n        variance: recentQualities.reduce((sum, q) => sum + Math.pow(q - avgQuality, 2), 0) / recentQualities.length\\n      },\\n      historySize: state.qualityHistory.length\\n    };\\n  };\\n\\n  const getQualityTrend = () => {\\n    if (state.qualityHistory.length < 10) {\\n      return { trend: 'insufficient_data', slope: 0 };\\n    }\\n\\n    // Calculate linear trend over recent history\\n    const recent = state.qualityHistory.slice(-20);\\n    const qualities = recent.map(q => q.computeOverallQuality());\\n    \\n    const n = qualities.length;\\n    const sumX = (n * (n - 1)) / 2; // Sum of indices\\n    const sumY = qualities.reduce((sum, q) => sum + q, 0);\\n    const sumXY = qualities.reduce((sum, q, i) => sum + i * q, 0);\\n    const sumXX = (n * (n - 1) * (2 * n - 1)) / 6; // Sum of squared indices\\n\\n    const slope = (n * sumXY - sumX * sumY) / (n * sumXX - sumX * sumX) || 0;\\n\\n    let trend;\\n    if (Math.abs(slope) < 0.001) trend = 'stable';\\n    else if (slope > 0) trend = 'improving';\\n    else trend = 'degrading';\\n\\n    return { trend, slope, confidence: Math.min(1, n / 20) };\\n  };\\n\\n  const getAlerts = (severityFilter = null) => {\\n    const filtered = severityFilter \\n      ? state.alerts.filter(alert => alert.severity === severityFilter)\\n      : state.alerts;\\n\\n    return filtered.sort((a, b) => b.timestamp - a.timestamp);\\n  };\\n\\n  const clearAlerts = () => {\\n    state.alerts = [];\\n  };\\n\\n  const getQualityHistogram = (buckets = 10) => {\\n    if (state.qualityHistory.length === 0) {\\n      return { buckets: [], distribution: [] };\\n    }\\n\\n    const qualities = state.qualityHistory.map(q => q.computeOverallQuality());\\n    const min = Math.min(...qualities);\\n    const max = Math.max(...qualities);\\n    const bucketSize = (max - min) / buckets;\\n\\n    const histogram = new Array(buckets).fill(0);\\n    const bucketRanges = [];\\n\\n    for (let i = 0; i < buckets; i++) {\\n      const rangeStart = min + i * bucketSize;\\n      const rangeEnd = min + (i + 1) * bucketSize;\\n      bucketRanges.push({ start: rangeStart, end: rangeEnd });\\n    }\\n\\n    qualities.forEach(quality => {\\n      const bucketIndex = Math.min(Math.floor((quality - min) / bucketSize), buckets - 1);\\n      histogram[bucketIndex]++;\\n    });\\n\\n    return {\\n      buckets: bucketRanges,\\n      distribution: histogram,\\n      total: qualities.length\\n    };\\n  };\\n\\n  const cleanup = async () => {\\n    state.qualityHistory = [];\\n    state.alerts = [];\\n    state.degradationEvents = [];\\n    state.strategyMetrics.clear();\\n  };\\n\\n  return {\\n    calculateOverallQuality,\\n    updateQuality,\\n    getOverallMetrics,\\n    getQualityTrend,\\n    getAlerts,\\n    clearAlerts,\\n    getQualityHistogram,\\n    cleanup\\n  };\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/core/orchestration/synchronization/strategies/sync-strategies.js\",\"messages\":[{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'streamCharacteristics' is assigned a value but never used. Allowed unused vars must match /^_/u.\",\"line\":55,\"column\":5,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":55,\"endColumn\":26,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"streamCharacteristics\"},\"fix\":{\"range\":[1536,1568],\"text\":\"\"},\"desc\":\"Remove unused variable 'streamCharacteristics'.\"}]}],\"suppressedMessages\":[],\"errorCount\":1,\"fatalErrorCount\":0,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Synchronization Strategy Definitions\\n * Defines available synchronization strategies and their characteristics\\n */\\n\\n// Core synchronization strategy types\\nexport const SynchronizationStrategy = {\\n  HARDWARE_TIMESTAMP: 'hardware_timestamp',\\n  SOFTWARE_TIMESTAMP: 'software_timestamp', \\n  BUFFER_BASED: 'buffer_based',\\n  EVENT_DRIVEN: 'event_driven'\\n};\\n\\n// Strategy characteristics and performance profiles\\nexport const StrategyProfiles = {\\n  [SynchronizationStrategy.HARDWARE_TIMESTAMP]: {\\n    precision: 0.95,\\n    latency: 1, // ~1ms\\n    complexity: 'low',\\n    requirements: ['hardware_timestamps'],\\n    description: 'Highest precision using hardware timing sources'\\n  },\\n  \\n  [SynchronizationStrategy.SOFTWARE_TIMESTAMP]: {\\n    precision: 0.85,\\n    latency: 5, // ~5ms\\n    complexity: 'medium',\\n    requirements: ['ntp_sync'],\\n    description: 'Software-based timing with NTP drift compensation'\\n  },\\n  \\n  [SynchronizationStrategy.BUFFER_BASED]: {\\n    precision: 0.75,\\n    latency: 10, // ~10ms\\n    complexity: 'medium',\\n    requirements: ['buffering'],\\n    description: 'Buffer-based alignment for variable latency streams'\\n  },\\n  \\n  [SynchronizationStrategy.EVENT_DRIVEN]: {\\n    precision: 0.60,\\n    latency: 20, // ~20ms\\n    complexity: 'high',\\n    requirements: ['event_correlation'],\\n    description: 'Event correlation-based synchronization'\\n  }\\n};\\n\\n// Strategy selection helper\\nexport const selectOptimalStrategy = (requirements = {}) => {\\n  const {\\n    maxLatency = 50,\\n    minPrecision = 0.7,\\n    availableFeatures = [],\\n    streamCharacteristics = {}\\n  } = requirements;\\n\\n  // Sort strategies by precision (descending)\\n  const candidates = Object.entries(StrategyProfiles)\\n    .filter(([, profile]) => {\\n      // Check precision requirement\\n      if (profile.precision < minPrecision) return false;\\n      \\n      // Check latency requirement\\n      if (profile.latency > maxLatency) return false;\\n      \\n      // Check feature availability\\n      const hasRequiredFeatures = profile.requirements.every(\\n        req => availableFeatures.includes(req)\\n      );\\n      \\n      return hasRequiredFeatures;\\n    })\\n    .sort((a, b) => b[1].precision - a[1].precision);\\n\\n  if (candidates.length === 0) {\\n    // Fallback to most flexible strategy\\n    return SynchronizationStrategy.BUFFER_BASED;\\n  }\\n\\n  return candidates[0][0];\\n};\\n\\n// Strategy compatibility matrix\\nexport const StrategyCompatibility = {\\n  [SynchronizationStrategy.HARDWARE_TIMESTAMP]: {\\n    compatibleWith: [SynchronizationStrategy.SOFTWARE_TIMESTAMP],\\n    fallbackTo: SynchronizationStrategy.SOFTWARE_TIMESTAMP,\\n    upgrade: null\\n  },\\n  \\n  [SynchronizationStrategy.SOFTWARE_TIMESTAMP]: {\\n    compatibleWith: [SynchronizationStrategy.BUFFER_BASED],\\n    fallbackTo: SynchronizationStrategy.BUFFER_BASED,\\n    upgrade: SynchronizationStrategy.HARDWARE_TIMESTAMP\\n  },\\n  \\n  [SynchronizationStrategy.BUFFER_BASED]: {\\n    compatibleWith: [SynchronizationStrategy.EVENT_DRIVEN],\\n    fallbackTo: SynchronizationStrategy.EVENT_DRIVEN,\\n    upgrade: SynchronizationStrategy.SOFTWARE_TIMESTAMP\\n  },\\n  \\n  [SynchronizationStrategy.EVENT_DRIVEN]: {\\n    compatibleWith: [],\\n    fallbackTo: null,\\n    upgrade: SynchronizationStrategy.BUFFER_BASED\\n  }\\n};\\n\\n// Strategy configuration factory\\nexport const createStrategyConfig = (strategy, overrides = {}) => {\\n  const profile = StrategyProfiles[strategy];\\n  if (!profile) {\\n    throw new Error(`Unknown strategy: ${strategy}`);\\n  }\\n\\n  return {\\n    strategy,\\n    precision: overrides.precision || profile.precision,\\n    maxLatency: overrides.maxLatency || profile.latency,\\n    complexity: profile.complexity,\\n    requirements: profile.requirements,\\n    description: profile.description,\\n    ...overrides\\n  };\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/core/orchestration/synchronization/sync-engine.js\",\"messages\":[{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'createSyncMetrics' is defined but never used. Allowed unused vars must match /^_/u.\",\"line\":12,\"column\":35,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":12,\"endColumn\":52,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"createSyncMetrics\"},\"fix\":{\"range\":[612,631],\"text\":\"\"},\"desc\":\"Remove unused variable 'createSyncMetrics'.\"}]}],\"suppressedMessages\":[],\"errorCount\":1,\"fatalErrorCount\":0,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Stream Synchronization Engine - Main Factory\\n * Provides unified interface for multimodal data stream synchronization\\n * Following functional programming patterns with factory functions\\n */\\n\\nimport { SynchronizationStrategy } from './strategies/sync-strategies.js';\\nimport { createHardwareTimestampAligner } from './aligners/hardware-aligner.js';\\nimport { createSoftwareTimestampAligner } from './aligners/software-aligner.js';\\nimport { createBufferBasedAligner } from './aligners/buffer-aligner.js';\\nimport { createEventDrivenAligner } from './aligners/event-aligner.js';\\nimport { createQualityCalculator, createSyncMetrics } from './metrics/sync-metrics.js';\\n\\n/**\\n * Main synchronization engine factory\\n * Creates configured synchronization system with pluggable alignment strategies\\n */\\nexport const createSynchronizationEngine = (config = {}) => {\\n  const engineConfig = {\\n    defaultStrategy: config.defaultStrategy || SynchronizationStrategy.BUFFER_BASED,\\n    enableQualityMonitoring: config.enableQualityMonitoring !== false,\\n    maxLatency: config.maxLatency || 50,\\n    qualityThreshold: config.qualityThreshold || 0.8,\\n    ...config\\n  };\\n\\n  // Strategy registry with lazy initialization\\n  const aligners = {\\n    [SynchronizationStrategy.HARDWARE_TIMESTAMP]: null,\\n    [SynchronizationStrategy.SOFTWARE_TIMESTAMP]: null,\\n    [SynchronizationStrategy.BUFFER_BASED]: null,\\n    [SynchronizationStrategy.EVENT_DRIVEN]: null\\n  };\\n\\n  const qualityCalculator = engineConfig.enableQualityMonitoring \\n    ? createQualityCalculator(engineConfig)\\n    : null;\\n\\n  // Lazy aligner creation\\n  const getAligner = (strategy) => {\\n    if (!aligners[strategy]) {\\n      const alignerFactories = {\\n        [SynchronizationStrategy.HARDWARE_TIMESTAMP]: createHardwareTimestampAligner,\\n        [SynchronizationStrategy.SOFTWARE_TIMESTAMP]: createSoftwareTimestampAligner,\\n        [SynchronizationStrategy.BUFFER_BASED]: createBufferBasedAligner,\\n        [SynchronizationStrategy.EVENT_DRIVEN]: createEventDrivenAligner\\n      };\\n\\n      const factory = alignerFactories[strategy];\\n      if (!factory) {\\n        throw new Error(`Unknown synchronization strategy: ${strategy}`);\\n      }\\n\\n      aligners[strategy] = factory(engineConfig);\\n    }\\n\\n    return aligners[strategy];\\n  };\\n\\n  // Main synchronization interface\\n  const synchronize = async (streams, options = {}) => {\\n    const strategy = options.strategy || engineConfig.defaultStrategy;\\n    const aligner = getAligner(strategy);\\n    \\n    const alignedStreams = [];\\n    const syncResults = [];\\n\\n    for (const stream of streams) {\\n      const alignmentResult = await aligner.align(stream);\\n      alignedStreams.push({\\n        ...stream,\\n        alignedTimestamp: alignmentResult.alignedTimestamp,\\n        syncQuality: alignmentResult.confidence\\n      });\\n      syncResults.push(alignmentResult);\\n    }\\n\\n    // Calculate overall synchronization quality\\n    let overallQuality = null;\\n    if (qualityCalculator) {\\n      overallQuality = qualityCalculator.calculateOverallQuality(syncResults);\\n    }\\n\\n    return {\\n      alignedStreams,\\n      syncResults,\\n      overallQuality,\\n      strategy,\\n      timestamp: Date.now()\\n    };\\n  };\\n\\n  // Strategy switching for adaptive synchronization\\n  const switchStrategy = (newStrategy) => {\\n    if (!Object.values(SynchronizationStrategy).includes(newStrategy)) {\\n      throw new Error(`Invalid synchronization strategy: ${newStrategy}`);\\n    }\\n    engineConfig.defaultStrategy = newStrategy;\\n  };\\n\\n  // Quality monitoring and diagnostics\\n  const getQualityMetrics = () => {\\n    if (!qualityCalculator) {\\n      return null;\\n    }\\n\\n    const metrics = {};\\n    for (const [strategy, aligner] of Object.entries(aligners)) {\\n      if (aligner) {\\n        metrics[strategy] = aligner.getQuality();\\n      }\\n    }\\n\\n    return {\\n      strategies: metrics,\\n      overall: qualityCalculator.getOverallMetrics(),\\n      timestamp: Date.now()\\n    };\\n  };\\n\\n  // Performance diagnostics\\n  const getDiagnostics = () => {\\n    return {\\n      activeStrategies: Object.keys(aligners).filter(key => aligners[key] !== null),\\n      config: engineConfig,\\n      qualityEnabled: !!qualityCalculator,\\n      timestamp: Date.now()\\n    };\\n  };\\n\\n  // Cleanup resources\\n  const cleanup = async () => {\\n    for (const aligner of Object.values(aligners)) {\\n      if (aligner?.cleanup) {\\n        await aligner.cleanup();\\n      }\\n    }\\n    \\n    if (qualityCalculator?.cleanup) {\\n      await qualityCalculator.cleanup();\\n    }\\n  };\\n\\n  return {\\n    // Core synchronization\\n    synchronize,\\n    switchStrategy,\\n    \\n    // Quality monitoring\\n    getQualityMetrics,\\n    getDiagnostics,\\n    \\n    // Strategy access\\n    getAligner,\\n    \\n    // Configuration\\n    getConfig: () => ({ ...engineConfig }),\\n    \\n    // Lifecycle\\n    cleanup\\n  };\\n};\\n\\n// Temporal alignment algorithm factory (backwards compatibility)\\nexport const createTemporalAligner = (strategy = SynchronizationStrategy.BUFFER_BASED) => {\\n  const engine = createSynchronizationEngine({ defaultStrategy: strategy });\\n  return engine.getAligner(strategy);\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/core/performance/adaptive-batching.js\",\"messages\":[{\"ruleId\":\"max-lines-per-function\",\"severity\":1,\"message\":\"Arrow function has too many lines (322). Maximum allowed is 150.\",\"line\":8,\"column\":45,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"exceed\",\"endLine\":439,\"endColumn\":2},{\"ruleId\":\"no-nested-ternary\",\"severity\":1,\"message\":\"Do not nest ternary expressions.\",\"line\":111,\"column\":31,\"nodeType\":\"ConditionalExpression\",\"messageId\":\"noNestedTernary\",\"endLine\":111,\"endColumn\":82},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":139,\"column\":40,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":139,\"endColumn\":41},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":139,\"column\":47,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":139,\"endColumn\":48},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":217,\"column\":70,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":217,\"endColumn\":71},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":217,\"column\":109,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":217,\"endColumn\":110},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":253,\"column\":68,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":253,\"endColumn\":69},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":253,\"column\":107,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":253,\"endColumn\":108},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":330,\"column\":38,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":330,\"endColumn\":39},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":330,\"column\":59,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":330,\"endColumn\":60},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":331,\"column\":53,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":331,\"endColumn\":54},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":331,\"column\":74,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":331,\"endColumn\":75}],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":12,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Adaptive Batching Strategies for High-Frequency Streaming\\n * Intelligent batching and buffering optimization for 200Hz eye tracking\\n * Following functional programming patterns with factory functions\\n */\\n\\n// Adaptive batch scheduler factory\\nexport const createAdaptiveBatchScheduler = (config = {}) => {\\n  const state = {\\n    strategy: config.strategy || 'adaptive',\\n    targetLatency: config.targetLatency || 50, // ms\\n    maxBatchSize: config.maxBatchSize || 20,\\n    minBatchSize: config.minBatchSize || 1,\\n    baseInterval: config.baseInterval || 16, // ~60fps\\n    systemLoad: {\\n      cpu: 0,\\n      memory: 0,\\n      frameRate: 60,\\n      latency: 0\\n    },\\n    metrics: {\\n      processedBatches: 0,\\n      averageBatchSize: 0,\\n      averageLatency: 0,\\n      droppedFrames: 0,\\n      totalProcessingTime: 0\\n    },\\n    adaptiveParams: {\\n      loadThreshold: config.loadThreshold || 0.8,\\n      latencyThreshold: config.latencyThreshold || 100,\\n      adaptationRate: config.adaptationRate || 0.1\\n    },\\n    callbacks: {\\n      onBatch: [],\\n      onSystemLoad: [],\\n      onAdaptation: []\\n    }\\n  };\\n\\n  // System performance monitoring\\n  const createPerformanceMonitor = () => {\\n    let lastFrameTime = performance.now();\\n    let frameCount = 0;\\n    let totalFrameTime = 0;\\n\\n    const updatePerformance = () => {\\n      const now = performance.now();\\n      const deltaTime = now - lastFrameTime;\\n      lastFrameTime = now;\\n      \\n      frameCount++;\\n      totalFrameTime += deltaTime;\\n      \\n      // Update frame rate every second\\n      if (frameCount >= 60) {\\n        state.systemLoad.frameRate = 1000 / (totalFrameTime / frameCount);\\n        frameCount = 0;\\n        totalFrameTime = 0;\\n      }\\n\\n      // Estimate CPU load from frame timing\\n      const expectedFrameTime = 1000 / 60; // 16.67ms for 60fps\\n      state.systemLoad.cpu = Math.min(1.0, deltaTime / expectedFrameTime);\\n\\n      // Memory usage (simplified estimate)\\n      if (performance.memory) {\\n        const memInfo = performance.memory;\\n        state.systemLoad.memory = memInfo.usedJSHeapSize / memInfo.jsHeapSizeLimit;\\n      }\\n\\n      return state.systemLoad;\\n    };\\n\\n    return { updatePerformance };\\n  };\\n\\n  const performanceMonitor = createPerformanceMonitor();\\n\\n  // Batching strategy implementations\\n  const strategies = {\\n    // Fixed-size batching\\n    fixed: (items) => ({\\n      batchSize: Math.min(config.batchSize || 10, items.length),\\n      interval: config.interval || 16,\\n      reason: 'fixed_strategy'\\n    }),\\n\\n    // Time-based batching\\n    time_based: (items, timeSinceLastBatch) => ({\\n      batchSize: items.length,\\n      interval: Math.max(8, Math.min(32, timeSinceLastBatch)),\\n      reason: 'time_based'\\n    }),\\n\\n    // Load-based batching\\n    load_based: (items) => {\\n      const load = Math.max(state.systemLoad.cpu, state.systemLoad.memory);\\n      let batchSize;\\n      \\n      if (load > 0.9) {\\n        batchSize = Math.max(state.minBatchSize, Math.floor(items.length * 0.3));\\n      } else if (load > 0.7) {\\n        batchSize = Math.max(state.minBatchSize, Math.floor(items.length * 0.6));\\n      } else {\\n        batchSize = Math.min(state.maxBatchSize, items.length);\\n      }\\n\\n      return {\\n        batchSize,\\n        interval: load > 0.8 ? Math.max(state.baseInterval * 1.5, 24) : state.baseInterval,\\n        reason: `load_based_${load > 0.9 ? 'high' : load > 0.7 ? 'medium' : 'low'}`\\n      };\\n    },\\n\\n    // Adaptive strategy combining multiple factors\\n    adaptive: (items, timeSinceLastBatch, queueSize) => {\\n      const systemLoad = performanceMonitor.updatePerformance();\\n      const load = Math.max(systemLoad.cpu, systemLoad.memory);\\n      const latency = state.metrics.averageLatency;\\n      \\n      // Base batch size calculation\\n      let batchSize = state.minBatchSize;\\n      let interval = state.baseInterval;\\n      let reason = 'adaptive';\\n\\n      // Factor 1: System load\\n      if (load > state.adaptiveParams.loadThreshold) {\\n        // High load: reduce batch size, increase interval\\n        batchSize = Math.max(state.minBatchSize, Math.floor(items.length * 0.4));\\n        interval = Math.max(interval * 1.5, 24);\\n        reason += '_high_load';\\n      } else if (load < 0.4) {\\n        // Low load: increase batch size, maintain interval\\n        batchSize = Math.min(state.maxBatchSize, items.length);\\n        reason += '_low_load';\\n      } else {\\n        // Medium load: balanced approach\\n        batchSize = Math.min(state.maxBatchSize, Math.max(state.minBatchSize, \\n          Math.floor(items.length * (1 - load * 0.5))));\\n        reason += '_balanced';\\n      }\\n\\n      // Factor 2: Latency compensation\\n      if (latency > state.adaptiveParams.latencyThreshold) {\\n        // High latency: smaller batches, faster processing\\n        batchSize = Math.max(state.minBatchSize, Math.floor(batchSize * 0.7));\\n        interval = Math.max(8, Math.floor(interval * 0.8));\\n        reason += '_high_latency';\\n      }\\n\\n      // Factor 3: Queue size pressure\\n      if (queueSize > state.maxBatchSize * 2) {\\n        // Large queue: bigger batches to catch up\\n        batchSize = Math.min(state.maxBatchSize, Math.floor(queueSize * 0.3));\\n        interval = Math.max(8, Math.floor(interval * 0.9));\\n        reason += '_queue_pressure';\\n      }\\n\\n      // Factor 4: Frame rate considerations\\n      if (systemLoad.frameRate < 30) {\\n        // Low frame rate: reduce processing load\\n        batchSize = Math.max(state.minBatchSize, Math.floor(batchSize * 0.6));\\n        interval = Math.max(interval * 1.2, 20);\\n        reason += '_low_fps';\\n      }\\n\\n      return { batchSize, interval, reason, systemLoad };\\n    },\\n\\n    // Quality-aware batching for eye tracking\\n    quality_aware: (items) => {\\n      if (!items || items.length === 0) {\\n        return { batchSize: 0, interval: state.baseInterval, reason: 'no_data' };\\n      }\\n\\n      // Analyze data quality\\n      const avgConfidence = items.reduce((sum, item) => sum + (item.confidence || 0), 0) / items.length;\\n      const highQualityItems = items.filter(item => (item.confidence || 0) > 0.8).length;\\n      const qualityRatio = highQualityItems / items.length;\\n\\n      let batchSize;\\n      let interval = state.baseInterval;\\n      let reason = 'quality_aware';\\n\\n      if (qualityRatio > 0.8 && avgConfidence > 0.85) {\\n        // High quality data: process more efficiently\\n        batchSize = Math.min(state.maxBatchSize, items.length);\\n        interval = Math.max(12, state.baseInterval * 0.8);\\n        reason += '_high_quality';\\n      } else if (qualityRatio < 0.5 || avgConfidence < 0.6) {\\n        // Low quality data: smaller batches, more processing time\\n        batchSize = Math.max(state.minBatchSize, Math.floor(items.length * 0.6));\\n        interval = state.baseInterval * 1.3;\\n        reason += '_low_quality';\\n      } else {\\n        // Medium quality: standard processing\\n        batchSize = Math.min(state.maxBatchSize, Math.max(state.minBatchSize, items.length));\\n        reason += '_medium_quality';\\n      }\\n\\n      return { batchSize, interval, reason, qualityMetrics: { avgConfidence, qualityRatio } };\\n    }\\n  };\\n\\n  // Main batching decision engine\\n  const decideBatchStrategy = (items, context = {}) => {\\n    const strategy = strategies[state.strategy] || strategies.adaptive;\\n    const decision = strategy(items, context.timeSinceLastBatch, context.queueSize);\\n    \\n    // Apply safety constraints\\n    decision.batchSize = Math.max(state.minBatchSize, \\n      Math.min(state.maxBatchSize, decision.batchSize));\\n    decision.interval = Math.max(8, Math.min(100, decision.interval));\\n\\n    // Track metrics\\n    state.metrics.processedBatches++;\\n    state.metrics.averageBatchSize = (state.metrics.averageBatchSize * (state.metrics.processedBatches - 1) + \\n      decision.batchSize) / state.metrics.processedBatches;\\n\\n    // Notify adaptation callbacks\\n    state.callbacks.onAdaptation.forEach(cb => {\\n      try {\\n        cb({ decision, context, systemLoad: state.systemLoad, timestamp: Date.now() });\\n      } catch (error) {\\n        console.warn('Adaptation callback error:', error);\\n      }\\n    });\\n\\n    return decision;\\n  };\\n\\n  // Batch processing execution\\n  const processBatch = async (items, processor) => {\\n    if (!items || items.length === 0) return [];\\n\\n    const startTime = performance.now();\\n    const context = {\\n      timeSinceLastBatch: startTime - (state.lastBatchTime || startTime),\\n      queueSize: items.length\\n    };\\n\\n    const decision = decideBatchStrategy(items, context);\\n    const batchItems = items.slice(0, decision.batchSize);\\n\\n    try {\\n      const results = await processor(batchItems);\\n      \\n      // Update performance metrics\\n      const endTime = performance.now();\\n      const processingTime = endTime - startTime;\\n      \\n      state.metrics.totalProcessingTime += processingTime;\\n      state.metrics.averageLatency = (state.metrics.averageLatency * (state.metrics.processedBatches - 1) + \\n        processingTime) / state.metrics.processedBatches;\\n      \\n      state.lastBatchTime = endTime;\\n\\n      // Notify batch callbacks\\n      state.callbacks.onBatch.forEach(cb => {\\n        try {\\n          cb({\\n            batchSize: batchItems.length,\\n            processingTime,\\n            results,\\n            decision,\\n            timestamp: endTime\\n          });\\n        } catch (error) {\\n          console.warn('Batch callback error:', error);\\n        }\\n      });\\n\\n      return {\\n        results,\\n        processed: batchItems.length,\\n        remaining: items.slice(decision.batchSize),\\n        processingTime,\\n        decision\\n      };\\n\\n    } catch (error) {\\n      state.metrics.droppedFrames += batchItems.length;\\n      throw error;\\n    }\\n  };\\n\\n  // Continuous batch processing with adaptive scheduling\\n  const createBatchProcessor = (processor) => {\\n    const queue = [];\\n    let isProcessing = false;\\n    let scheduledTimeout = null;\\n\\n    const processQueue = async () => {\\n      if (isProcessing || queue.length === 0) return;\\n\\n      isProcessing = true;\\n      \\n      try {\\n        const result = await processBatch(queue.slice(), processor);\\n        \\n        // Remove processed items from queue\\n        queue.splice(0, result.processed);\\n        \\n        // Schedule next processing based on adaptive interval\\n        if (queue.length > 0) {\\n          scheduledTimeout = setTimeout(processQueue, result.decision.interval);\\n        }\\n      } catch (error) {\\n        console.error('Batch processing error:', error);\\n      } finally {\\n        isProcessing = false;\\n      }\\n    };\\n\\n    const addToQueue = (items) => {\\n      if (Array.isArray(items)) {\\n        queue.push(...items);\\n      } else {\\n        queue.push(items);\\n      }\\n\\n      // Trigger processing if not already scheduled\\n      if (!isProcessing && !scheduledTimeout) {\\n        scheduledTimeout = setTimeout(processQueue, state.baseInterval);\\n      }\\n\\n      // Emergency queue size management\\n      if (queue.length > state.maxBatchSize * 5) {\\n        console.warn('Queue overflow, dropping oldest items');\\n        queue.splice(0, queue.length - state.maxBatchSize * 3);\\n        state.metrics.droppedFrames += queue.length - state.maxBatchSize * 3;\\n      }\\n    };\\n\\n    const getQueueSize = () => queue.length;\\n    const clearQueue = () => queue.splice(0);\\n\\n    const stop = () => {\\n      if (scheduledTimeout) {\\n        clearTimeout(scheduledTimeout);\\n        scheduledTimeout = null;\\n      }\\n      isProcessing = false;\\n    };\\n\\n    return {\\n      addToQueue,\\n      getQueueSize,\\n      clearQueue,\\n      stop\\n    };\\n  };\\n\\n  // Strategy switching\\n  const switchStrategy = (newStrategy) => {\\n    if (strategies[newStrategy]) {\\n      const oldStrategy = state.strategy;\\n      state.strategy = newStrategy;\\n      \\n      console.log(`Batch strategy switched from ${oldStrategy} to ${newStrategy}`);\\n      return true;\\n    }\\n    return false;\\n  };\\n\\n  // Metrics and monitoring\\n  const getMetrics = () => ({\\n    ...state.metrics,\\n    systemLoad: { ...state.systemLoad },\\n    currentStrategy: state.strategy,\\n    adaptiveParams: { ...state.adaptiveParams }\\n  });\\n\\n  const resetMetrics = () => {\\n    state.metrics = {\\n      processedBatches: 0,\\n      averageBatchSize: 0,\\n      averageLatency: 0,\\n      droppedFrames: 0,\\n      totalProcessingTime: 0\\n    };\\n  };\\n\\n  // Event handlers\\n  const onBatch = (callback) => {\\n    state.callbacks.onBatch.push(callback);\\n    return () => {\\n      const index = state.callbacks.onBatch.indexOf(callback);\\n      if (index !== -1) state.callbacks.onBatch.splice(index, 1);\\n    };\\n  };\\n\\n  const onSystemLoad = (callback) => {\\n    state.callbacks.onSystemLoad.push(callback);\\n    return () => {\\n      const index = state.callbacks.onSystemLoad.indexOf(callback);\\n      if (index !== -1) state.callbacks.onSystemLoad.splice(index, 1);\\n    };\\n  };\\n\\n  const onAdaptation = (callback) => {\\n    state.callbacks.onAdaptation.push(callback);\\n    return () => {\\n      const index = state.callbacks.onAdaptation.indexOf(callback);\\n      if (index !== -1) state.callbacks.onAdaptation.splice(index, 1);\\n    };\\n  };\\n\\n  return {\\n    // Core processing\\n    processBatch,\\n    createBatchProcessor,\\n    decideBatchStrategy,\\n    \\n    // Strategy management\\n    switchStrategy,\\n    getAvailableStrategies: () => Object.keys(strategies),\\n    \\n    // Monitoring\\n    getMetrics,\\n    resetMetrics,\\n    getSystemLoad: () => ({ ...state.systemLoad }),\\n    \\n    // Configuration\\n    setTargetLatency: (latency) => { state.targetLatency = latency; },\\n    setBatchSizeRange: (min, max) => { \\n      state.minBatchSize = min; \\n      state.maxBatchSize = max; \\n    },\\n    updateAdaptiveParams: (params) => {\\n      Object.assign(state.adaptiveParams, params);\\n    },\\n    \\n    // Event handlers\\n    onBatch,\\n    onSystemLoad,\\n    onAdaptation\\n  };\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/core/performance/memory-optimization.js\",\"messages\":[{\"ruleId\":\"max-lines-per-function\",\"severity\":1,\"message\":\"Arrow function has too many lines (212). Maximum allowed is 150.\",\"line\":233,\"column\":38,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"exceed\",\"endLine\":515,\"endColumn\":2}],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":1,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Memory Optimization for High-Frequency Streaming\\n * Advanced memory management and optimization strategies\\n * Following functional programming patterns with factory functions\\n */\\n\\nimport { createEnhancedMemoryPool } from '../shared/utils/enhanced-memory-pool.js';\\n\\n// Use createEnhancedMemoryPool directly\\n\\n// Enhanced memory pool factory for efficient object reuse\\nexport const createOptimizedMemoryPool = (config = {}) => {\\n  const state = {\\n    pools: new Map(),\\n    stats: {\\n      allocations: 0,\\n      deallocations: 0,\\n      reuseHits: 0,\\n      memoryLeaks: 0,\\n      poolSizes: {},\\n      peakMemoryUsage: 0\\n    },\\n    config: {\\n      maxPoolSize: config.maxPoolSize || 1000,\\n      gcThreshold: config.gcThreshold || 0.8,\\n      monitoringInterval: config.monitoringInterval || 5000\\n    }\\n  };\\n\\n  // Create type-specific object pools\\n  const createPool = (typeName, factory, reset = null) => {\\n    const pool = {\\n      typeName,\\n      factory,\\n      reset,\\n      available: [],\\n      inUse: new Set(),\\n      created: 0,\\n      reused: 0\\n    };\\n\\n    state.pools.set(typeName, pool);\\n    return pool;\\n  };\\n\\n  // Get object from pool or create new one\\n  const acquire = (typeName, ...args) => {\\n    const pool = state.pools.get(typeName);\\n    if (!pool) {\\n      throw new Error(`Pool for type '${typeName}' not found`);\\n    }\\n\\n    let obj;\\n    \\n    if (pool.available.length > 0) {\\n      // Reuse existing object\\n      obj = pool.available.pop();\\n      pool.reused++;\\n      state.stats.reuseHits++;\\n      \\n      // Reset object if reset function provided\\n      if (pool.reset) {\\n        pool.reset(obj, ...args);\\n      }\\n    } else {\\n      // Create new object\\n      obj = pool.factory(...args);\\n      pool.created++;\\n      state.stats.allocations++;\\n    }\\n\\n    pool.inUse.add(obj);\\n    return obj;\\n  };\\n\\n  // Return object to pool\\n  const release = (typeName, obj) => {\\n    const pool = state.pools.get(typeName);\\n    if (!pool) {\\n      console.warn(`Pool for type '${typeName}' not found`);\\n      return false;\\n    }\\n\\n    if (!pool.inUse.has(obj)) {\\n      console.warn(`Object not tracked by pool '${typeName}'`);\\n      return false;\\n    }\\n\\n    pool.inUse.delete(obj);\\n    \\n    // Return to pool if under limit\\n    if (pool.available.length < state.config.maxPoolSize) {\\n      pool.available.push(obj);\\n    }\\n    \\n    state.stats.deallocations++;\\n    return true;\\n  };\\n\\n  // Clear all pools\\n  const clear = () => {\\n    for (const pool of state.pools.values()) {\\n      pool.available.length = 0;\\n      pool.inUse.clear();\\n    }\\n  };\\n\\n  // Get pool statistics\\n  const getStats = () => ({\\n    ...state.stats,\\n    poolSizes: Object.fromEntries(\\n      Array.from(state.pools.entries()).map(([name, pool]) => [\\n        name,\\n        {\\n          available: pool.available.length,\\n          inUse: pool.inUse.size,\\n          created: pool.created,\\n          reused: pool.reused,\\n          reuseRatio: pool.created > 0 ? pool.reused / pool.created : 0\\n        }\\n      ])\\n    )\\n  });\\n\\n  return {\\n    createPool,\\n    acquire,\\n    release,\\n    clear,\\n    getStats\\n  };\\n};\\n\\n// Memory-efficient circular buffer for high-frequency data\\nexport const createCircularBuffer = (config = {}) => {\\n  const state = {\\n    size: config.size || 1000,\\n    buffer: new Array(config.size || 1000),\\n    head: 0,\\n    tail: 0,\\n    count: 0,\\n    overflowCount: 0,\\n    memoryPool: config.memoryPool || null\\n  };\\n\\n  const isFull = () => state.count === state.size;\\n  const isEmpty = () => state.count === 0;\\n  const getSize = () => state.count;\\n  const getCapacity = () => state.size;\\n\\n  const push = (item) => {\\n    if (isFull()) {\\n      // Handle overflow - drop oldest item\\n      const droppedItem = state.buffer[state.tail];\\n      if (state.memoryPool && droppedItem && droppedItem.type) {\\n        state.memoryPool.release(droppedItem.type, droppedItem);\\n      }\\n      state.tail = (state.tail + 1) % state.size;\\n      state.overflowCount++;\\n    } else {\\n      state.count++;\\n    }\\n\\n    state.buffer[state.head] = item;\\n    state.head = (state.head + 1) % state.size;\\n  };\\n\\n  const pop = () => {\\n    if (isEmpty()) return null;\\n\\n    const item = state.buffer[state.tail];\\n    state.buffer[state.tail] = null; // Allow GC\\n    state.tail = (state.tail + 1) % state.size;\\n    state.count--;\\n    \\n    return item;\\n  };\\n\\n  const peek = () => {\\n    if (isEmpty()) return null;\\n    return state.buffer[state.tail];\\n  };\\n\\n  const clear = () => {\\n    if (state.memoryPool) {\\n      // Return all items to memory pool\\n      for (let i = 0; i < state.count; i++) {\\n        const index = (state.tail + i) % state.size;\\n        const item = state.buffer[index];\\n        if (item && item.type) {\\n          state.memoryPool.release(item.type, item);\\n        }\\n      }\\n    }\\n\\n    state.buffer.fill(null);\\n    state.head = 0;\\n    state.tail = 0;\\n    state.count = 0;\\n  };\\n\\n  const toArray = () => {\\n    const result = new Array(state.count);\\n    for (let i = 0; i < state.count; i++) {\\n      result[i] = state.buffer[(state.tail + i) % state.size];\\n    }\\n    return result;\\n  };\\n\\n  const getStats = () => ({\\n    size: state.size,\\n    count: state.count,\\n    overflowCount: state.overflowCount,\\n    utilization: state.count / state.size,\\n    memoryUsage: state.size * 8 // Rough estimate in bytes\\n  });\\n\\n  return {\\n    push,\\n    pop,\\n    peek,\\n    clear,\\n    toArray,\\n    isFull,\\n    isEmpty,\\n    getSize,\\n    getCapacity,\\n    getStats\\n  };\\n};\\n\\n// Memory optimization manager for streaming systems\\nexport const createMemoryOptimizer = (config = {}) => {\\n  const state = {\\n    memoryPool: createEnhancedMemoryPool(config.pool),\\n    buffers: new Map(),\\n    monitoringInterval: null,\\n    gcScheduled: false,\\n    stats: {\\n      totalAllocations: 0,\\n      totalDeallocations: 0,\\n      gcRuns: 0,\\n      memoryPressure: 0,\\n      optimizationApplied: 0\\n    },\\n    thresholds: {\\n      memoryPressure: config.memoryPressureThreshold || 0.8,\\n      gcInterval: config.gcInterval || 10000,\\n      bufferSizeLimit: config.bufferSizeLimit || 5000\\n    }\\n  };\\n\\n  // Initialize common object pools for eye tracking\\n  const initializePools = () => {\\n    // Gaze data objects\\n    state.memoryPool.registerFactory('gazeData', () => ({\\n      type: 'gazeData',\\n      timestamp: 0,\\n      x: 0,\\n      y: 0,\\n      confidence: 0,\\n      semantic: null,\\n      metadata: {}\\n    }));\\n\\n    // Video frame objects\\n    state.memoryPool.registerFactory('videoFrame', () => ({\\n      type: 'videoFrame',\\n      timestamp: 0,\\n      width: 0,\\n      height: 0,\\n      data: null,\\n      format: 'rgba'\\n    }));\\n\\n    // Stream buffer entries\\n    state.memoryPool.registerFactory('bufferEntry', () => ({\\n      type: 'bufferEntry',\\n      data: null,\\n      timestamp: 0,\\n      streamId: null,\\n      processed: false\\n    }));\\n  };\\n\\n  // Create optimized circular buffer\\n  const createOptimizedBuffer = (bufferId, size = 1000) => {\\n    const buffer = createCircularBuffer({\\n      size,\\n      memoryPool: state.memoryPool\\n    });\\n\\n    state.buffers.set(bufferId, buffer);\\n    return buffer;\\n  };\\n\\n  // Memory monitoring and optimization\\n  const monitorMemoryUsage = () => {\\n    if (typeof performance !== 'undefined' && performance.memory) {\\n      const {memory} = performance;\\n      const usedRatio = memory.usedJSHeapSize / memory.jsHeapSizeLimit;\\n      \\n      state.stats.memoryPressure = usedRatio;\\n\\n      // Trigger optimization if memory pressure is high\\n      if (usedRatio > state.thresholds.memoryPressure) {\\n        applyMemoryOptimization();\\n      }\\n\\n      return {\\n        used: memory.usedJSHeapSize,\\n        total: memory.totalJSHeapSize,\\n        limit: memory.jsHeapSizeLimit,\\n        pressure: usedRatio\\n      };\\n    }\\n\\n    return null;\\n  };\\n\\n  // Apply memory optimization strategies\\n  const applyMemoryOptimization = () => {\\n    console.log('Applying memory optimization due to high memory pressure');\\n    \\n    // Clear old buffer data\\n    for (const buffer of state.buffers.values()) {\\n      if (buffer.getSize() > state.thresholds.bufferSizeLimit * 0.8) {\\n        const toRemove = Math.floor(buffer.getSize() * 0.3);\\n        for (let i = 0; i < toRemove; i++) {\\n          buffer.pop();\\n        }\\n      }\\n    }\\n\\n    // Clear memory pools\\n    state.memoryPool.clear();\\n\\n    // Schedule garbage collection\\n    scheduleGC();\\n\\n    state.stats.optimizationApplied++;\\n  };\\n\\n  // Intelligent garbage collection scheduling\\n  const scheduleGC = () => {\\n    if (state.gcScheduled) return;\\n    \\n    state.gcScheduled = true;\\n    \\n    // Use idle callback if available for non-blocking GC\\n    const runGC = () => {\\n      if (typeof window !== 'undefined' && window.requestIdleCallback) {\\n        window.requestIdleCallback(() => {\\n          performGC();\\n          state.gcScheduled = false;\\n        });\\n      } else {\\n        setTimeout(() => {\\n          performGC();\\n          state.gcScheduled = false;\\n        }, 0);\\n      }\\n    };\\n\\n    runGC();\\n  };\\n\\n  // Perform garbage collection optimization\\n  const performGC = () => {\\n    // Force garbage collection if available (Chrome DevTools)\\n    if (typeof window !== 'undefined' && window.gc) {\\n      window.gc();\\n    }\\n\\n    // Clean up weak references and null pointers\\n    cleanupReferences();\\n\\n    state.stats.gcRuns++;\\n  };\\n\\n  // Clean up weak references and null pointers\\n  const cleanupReferences = () => {\\n    // Clean up empty buffers\\n    for (const [, buffer] of state.buffers.entries()) {\\n      if (buffer.isEmpty()) {\\n        buffer.clear();\\n      }\\n    }\\n\\n    // Force cleanup of unused memory pools\\n    const poolStats = state.memoryPool.getStats();\\n    Object.entries(poolStats.poolSizes).forEach(([typeName, stats]) => {\\n      if (stats.available > stats.inUse * 2 && stats.available > 100) {\\n        // Too many unused objects, clear some\\n        console.log(`Cleaning up excess objects in pool: ${typeName}`);\\n      }\\n    });\\n  };\\n\\n  // Start memory monitoring\\n  const startMonitoring = () => {\\n    if (state.monitoringInterval) return;\\n\\n    state.monitoringInterval = setInterval(() => {\\n      monitorMemoryUsage();\\n    }, state.thresholds.gcInterval);\\n  };\\n\\n  // Stop memory monitoring\\n  const stopMonitoring = () => {\\n    if (state.monitoringInterval) {\\n      clearInterval(state.monitoringInterval);\\n      state.monitoringInterval = null;\\n    }\\n  };\\n\\n  // Optimized object creation helpers\\n  const createGazeData = (timestamp, x, y, confidence) => {\\n    const obj = state.memoryPool.acquire('gazeData');\\n    obj.timestamp = timestamp || Date.now();\\n    obj.x = x || 0;\\n    obj.y = y || 0;\\n    obj.confidence = confidence || 0;\\n    obj.semantic = null;\\n    obj.metadata = {};\\n    return obj;\\n  };\\n\\n  const createVideoFrame = (timestamp, width, height, data) => {\\n    const obj = state.memoryPool.acquire('videoFrame');\\n    obj.timestamp = timestamp || Date.now();\\n    obj.width = width || 0;\\n    obj.height = height || 0;\\n    obj.data = data || null;\\n    obj.format = 'rgba';\\n    return obj;\\n  };\\n\\n  const createBufferEntry = (data, streamId) => {\\n    const obj = state.memoryPool.acquire('bufferEntry');\\n    obj.data = data;\\n    obj.timestamp = Date.now();\\n    obj.streamId = streamId || null;\\n    obj.processed = false;\\n    return obj;\\n  };\\n\\n  // Release objects back to pool\\n  const releaseObject = (obj) => {\\n    if (obj && obj.type) {\\n      return state.memoryPool.release(obj.type, obj);\\n    }\\n    console.warn('Attempting to release untracked object');\\n    return false;\\n  };\\n\\n  // Get comprehensive statistics\\n  const getStats = () => ({\\n    ...state.stats,\\n    memoryPool: state.memoryPool.getStats(),\\n    buffers: Object.fromEntries(\\n      Array.from(state.buffers.entries()).map(([id, buffer]) => [\\n        id,\\n        buffer.getStats()\\n      ])\\n    ),\\n    thresholds: { ...state.thresholds },\\n    currentMemoryUsage: monitorMemoryUsage()\\n  });\\n\\n  // Configuration updates\\n  const updateThresholds = (newThresholds) => {\\n    Object.assign(state.thresholds, newThresholds);\\n  };\\n\\n  // Initialize memory optimizer\\n  initializePools();\\n\\n  return {\\n    // Pool management\\n    createGazeData,\\n    createVideoFrame,\\n    createBufferEntry,\\n    releaseObject,\\n    \\n    // Buffer management\\n    createOptimizedBuffer,\\n    getBuffer: (id) => state.buffers.get(id),\\n    \\n    // Monitoring and optimization\\n    startMonitoring,\\n    stopMonitoring,\\n    monitorMemoryUsage,\\n    applyMemoryOptimization,\\n    scheduleGC,\\n    \\n    // Statistics and configuration\\n    getStats,\\n    updateThresholds,\\n    \\n    // Cleanup\\n    cleanup: () => {\\n      stopMonitoring();\\n      if (state.memoryPool && typeof state.memoryPool.clear === 'function') {\\n        state.memoryPool.clear();\\n      }\\n      for (const buffer of state.buffers.values()) {\\n        if (buffer && typeof buffer.clear === 'function') {\\n          buffer.clear();\\n        }\\n      }\\n      state.buffers.clear();\\n    }\\n  };\\n};\\n\\n// Integration with existing stream system\\nexport const createMemoryOptimizedStream = (config = {}) => {\\n  const memoryOptimizer = createMemoryOptimizer(config.memory);\\n  const buffer = memoryOptimizer.createOptimizedBuffer(\\n    config.streamId || 'default',\\n    config.bufferSize || 2000\\n  );\\n\\n  // Start memory monitoring\\n  memoryOptimizer.startMonitoring();\\n\\n  const addData = (rawData) => {\\n    // Use memory pool for data objects\\n    const optimizedData = memoryOptimizer.createBufferEntry(rawData, config.streamId);\\n    buffer.push(optimizedData);\\n    \\n    return optimizedData;\\n  };\\n\\n  const getData = () => {\\n    const entry = buffer.pop();\\n    if (entry) {\\n      const {data} = entry;\\n      // Release the buffer entry back to pool\\n      memoryOptimizer.releaseObject(entry);\\n      return data;\\n    }\\n    return null;\\n  };\\n\\n  const getStats = () => ({\\n    buffer: buffer.getStats(),\\n    memory: memoryOptimizer.getStats()\\n  });\\n\\n  const cleanup = () => {\\n    buffer.clear();\\n    memoryOptimizer.cleanup();\\n  };\\n\\n  return {\\n    addData,\\n    getData,\\n    getStats,\\n    cleanup,\\n    getBuffer: () => buffer,\\n    getMemoryOptimizer: () => memoryOptimizer\\n  };\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/core/performance/performance-metrics.js\",\"messages\":[{\"ruleId\":\"max-lines-per-function\",\"severity\":1,\"message\":\"Arrow function has too many lines (296). Maximum allowed is 150.\",\"line\":21,\"column\":50,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"exceed\",\"endLine\":416,\"endColumn\":2},{\"ruleId\":\"no-undef\",\"severity\":2,\"message\":\"'meta' is not defined.\",\"line\":183,\"column\":42,\"nodeType\":\"Identifier\",\"messageId\":\"undef\",\"endLine\":183,\"endColumn\":46},{\"ruleId\":\"no-undef\",\"severity\":2,\"message\":\"'data' is not defined.\",\"line\":183,\"column\":47,\"nodeType\":\"Identifier\",\"messageId\":\"undef\",\"endLine\":183,\"endColumn\":51},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":234,\"column\":23,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":234,\"endColumn\":24},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":234,\"column\":38,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":234,\"endColumn\":39}],\"suppressedMessages\":[],\"errorCount\":2,\"fatalErrorCount\":0,\"warningCount\":3,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Performance Metrics Collection System\\n * Comprehensive performance monitoring and metrics collection\\n */\\n\\nimport { createEnhancedMemoryPool } from '../shared/utils/enhanced-memory-pool.js';\\n\\n/**\\n * Create Performance Metrics Collector\\n * \\n * Factory function that creates a comprehensive performance metrics collection\\n * system for monitoring pipeline performance, memory usage, and system health.\\n * \\n * @param {Object} config - Metrics configuration\\n * @param {number} [config.bufferSize=1000] - Metrics buffer size\\n * @param {number} [config.samplingInterval=100] - Sampling interval in ms\\n * @param {boolean} [config.enableMemoryMonitoring=true] - Enable memory monitoring\\n * @param {boolean} [config.enablePerformanceAPI=true] - Use Performance API if available\\n * @returns {Object} Metrics collector with collection and reporting methods\\n */\\nexport const createPerformanceMetricsCollector = (config = {}) => {\\n  const state = {\\n    config: {\\n      bufferSize: config.bufferSize || 1000,\\n      samplingInterval: config.samplingInterval || 100,\\n      enableMemoryMonitoring: config.enableMemoryMonitoring !== false,\\n      enablePerformanceAPI: config.enablePerformanceAPI !== false,\\n      ...config\\n    },\\n    memoryPool: createEnhancedMemoryPool(),\\n    metricsBuffer: [],\\n    currentMetrics: {\\n      processingTime: [],\\n      frameRate: [],\\n      memoryUsage: [],\\n      cpuUsage: [],\\n      errors: [],\\n      warnings: []\\n    },\\n    aggregatedStats: {\\n      totalProcessed: 0,\\n      totalErrors: 0,\\n      averageProcessingTime: 0,\\n      averageFrameRate: 0,\\n      peakMemoryUsage: 0,\\n      uptime: Date.now()\\n    },\\n    isCollecting: false,\\n    samplingInterval: null\\n  };\\n\\n  // Metric entry factory\\n  const createMetricEntry = (type, value, timestamp = Date.now(), metadata = {}) => {\\n    return state.memoryPool.acquire('MetricEntry', {\\n      type,\\n      value,\\n      timestamp,\\n      metadata,\\n      id: `${type}_${timestamp}_${Math.random().toString(36).substr(2, 9)}`\\n    });\\n  };\\n\\n  // Initialize memory pool for metrics\\n  const initializeMetricsPool = () => {\\n    state.memoryPool.registerFactory('MetricEntry', () => ({\\n      type: null,\\n      value: null,\\n      timestamp: 0,\\n      metadata: {},\\n      id: null\\n    }));\\n  };\\n\\n  // Start metrics collection\\n  const startCollection = () => {\\n    if (state.isCollecting) return;\\n    \\n    state.isCollecting = true;\\n    state.aggregatedStats.uptime = Date.now();\\n    \\n    // Start sampling interval\\n    if (state.config.samplingInterval > 0) {\\n      state.samplingInterval = setInterval(() => {\\n        collectSystemMetrics();\\n      }, state.config.samplingInterval);\\n    }\\n    \\n    console.log('📊 Performance metrics collection started');\\n  };\\n\\n  // Stop metrics collection\\n  const stopCollection = () => {\\n    if (!state.isCollecting) return;\\n    \\n    state.isCollecting = false;\\n    \\n    if (state.samplingInterval) {\\n      clearInterval(state.samplingInterval);\\n      state.samplingInterval = null;\\n    }\\n    \\n    console.log('📊 Performance metrics collection stopped');\\n  };\\n\\n  // Collect system-level metrics\\n  const collectSystemMetrics = () => {\\n    try {\\n      // Memory metrics (if available)\\n      if (state.config.enableMemoryMonitoring && typeof performance !== 'undefined' && performance.memory) {\\n        const memoryInfo = performance.memory;\\n        recordMetric('memory_used', memoryInfo.usedJSHeapSize, Date.now(), {\\n          total: memoryInfo.totalJSHeapSize,\\n          limit: memoryInfo.jsHeapSizeLimit,\\n          pressure: memoryInfo.usedJSHeapSize / memoryInfo.jsHeapSizeLimit\\n        });\\n        \\n        // Update peak memory usage\\n        if (memoryInfo.usedJSHeapSize > state.aggregatedStats.peakMemoryUsage) {\\n          state.aggregatedStats.peakMemoryUsage = memoryInfo.usedJSHeapSize;\\n        }\\n      }\\n      \\n      // Performance entries (if available)\\n      if (state.config.enablePerformanceAPI && typeof performance !== 'undefined' && performance.getEntries) {\\n        const entries = performance.getEntries();\\n        const recentEntries = entries.filter(entry => \\n          Date.now() - entry.startTime < state.config.samplingInterval * 2\\n        );\\n        \\n        recentEntries.forEach(entry => {\\n          if (entry.entryType === 'measure') {\\n            recordMetric('performance_measure', entry.duration, entry.startTime, {\\n              name: entry.name,\\n              entryType: entry.entryType\\n            });\\n          }\\n        });\\n      }\\n      \\n      // Memory pool metrics\\n      const poolStats = state.memoryPool.getStats();\\n      recordMetric('memory_pool_efficiency', poolStats.efficiency, Date.now(), {\\n        totalAcquisitions: poolStats.totalAcquisitions,\\n        reuseHits: poolStats.reuseHits,\\n        activeObjects: poolStats.activeObjects\\n      });\\n      \\n    } catch (error) {\\n      recordError('system_metrics_collection', error, { \\n        sampling: true,\\n        timestamp: Date.now() \\n      });\\n    }\\n  };\\n\\n  // Record a performance metric\\n  const recordMetric = (type, value, timestamp = Date.now()) => {\\n    if (!state.isCollecting) return;\\n    \\n    try {\\n      const metric = createMetricEntry(type, value, timestamp);\\n      \\n      // Add to appropriate buffer\\n      if (state.currentMetrics[type]) {\\n        state.currentMetrics[type].push(metric);\\n        \\n        // Maintain buffer size\\n        if (state.currentMetrics[type].length > state.config.bufferSize) {\\n          const removed = state.currentMetrics[type].shift();\\n          state.memoryPool.release(removed);\\n        }\\n      } else {\\n        // Add to general metrics buffer\\n        state.metricsBuffer.push(metric);\\n        \\n        if (state.metricsBuffer.length > state.config.bufferSize) {\\n          const removed = state.metricsBuffer.shift();\\n          state.memoryPool.release(removed);\\n        }\\n      }\\n      \\n      // Update aggregated stats\\n      updateAggregatedStats(type, value, meta,data);\\n      \\n    } catch (error) {\\n      console.error('Error recording metric:', error);\\n    }\\n  };\\n\\n  // Record processing time metric\\n  const recordProcessingTime = (pipelineName, duration, metadata = {}) => {\\n    recordMetric('processing_time', duration, Date.now(), {\\n      pipeline: pipelineName,\\n      ...metadata\\n    });\\n    \\n    state.aggregatedStats.totalProcessed++;\\n  };\\n\\n  // Record frame rate metric\\n  const recordFrameRate = (fps, metadata = {}) => {\\n    recordMetric('frame_rate', fps, Date.now(), metadata);\\n  };\\n\\n  // Record error metric\\n  const recordError = (type, error, metadata = {}) => {\\n    recordMetric('error', 1, Date.now(), {\\n      errorType: type,\\n      message: error.message || error,\\n      stack: error.stack,\\n      ...metadata\\n    });\\n    \\n    state.aggregatedStats.totalErrors++;\\n  };\\n\\n  // Record warning metric\\n  const recordWarning = (type, message, metadata = {}) => {\\n    recordMetric('warning', 1, Date.now(), {\\n      warningType: type,\\n      message,\\n      ...metadata\\n    });\\n  };\\n\\n  // Update aggregated statistics\\n  const updateAggregatedStats = (type, value) => {\\n    switch (type) {\\n      case 'processing_time':\\n        // Update average processing time\\n        const currentCount = state.aggregatedStats.totalProcessed;\\n        const currentAvg = state.aggregatedStats.averageProcessingTime;\\n        state.aggregatedStats.averageProcessingTime = \\n          (currentAvg * currentCount + value) / (currentCount + 1);\\n        break;\\n        \\n      case 'frame_rate':\\n        // Update average frame rate\\n        const frameRateMetrics = state.currentMetrics.frameRate || [];\\n        if (frameRateMetrics.length > 0) {\\n          const total = frameRateMetrics.reduce((sum, m) => sum + m.value, 0);\\n          state.aggregatedStats.averageFrameRate = total / frameRateMetrics.length;\\n        }\\n        break;\\n    }\\n  };\\n\\n  // Get comprehensive metrics report\\n  const getMetricsReport = () => {\\n    const now = Date.now();\\n    const uptime = now - state.aggregatedStats.uptime;\\n    \\n    // Calculate percentiles for processing times\\n    const processingTimes = state.currentMetrics.processing_time?.map(m => m.value) || [];\\n    const sortedTimes = [...processingTimes].sort((a, b) => a - b);\\n    \\n    const calculatePercentile = (arr, percentile) => {\\n      if (arr.length === 0) return 0;\\n      const index = Math.ceil(arr.length * percentile / 100) - 1;\\n      return arr[Math.max(0, index)];\\n    };\\n\\n    return {\\n      timestamp: now,\\n      uptime,\\n      \\n      // Aggregated statistics\\n      aggregated: {\\n        ...state.aggregatedStats,\\n        uptime,\\n        errorRate: state.aggregatedStats.totalProcessed > 0 \\n          ? state.aggregatedStats.totalErrors / state.aggregatedStats.totalProcessed \\n          : 0\\n      },\\n      \\n      // Processing time analysis\\n      processingTime: {\\n        count: processingTimes.length,\\n        average: state.aggregatedStats.averageProcessingTime,\\n        median: calculatePercentile(sortedTimes, 50),\\n        p95: calculatePercentile(sortedTimes, 95),\\n        p99: calculatePercentile(sortedTimes, 99),\\n        min: sortedTimes.length > 0 ? sortedTimes[0] : 0,\\n        max: sortedTimes.length > 0 ? sortedTimes[sortedTimes.length - 1] : 0\\n      },\\n      \\n      // Frame rate analysis\\n      frameRate: {\\n        current: state.aggregatedStats.averageFrameRate,\\n        average: state.aggregatedStats.averageFrameRate\\n      },\\n      \\n      // Memory analysis\\n      memory: {\\n        peak: state.aggregatedStats.peakMemoryUsage,\\n        current: getCurrentMemoryUsage(),\\n        poolEfficiency: state.memoryPool.getStats().efficiency\\n      },\\n      \\n      // Error analysis\\n      errors: {\\n        total: state.aggregatedStats.totalErrors,\\n        rate: state.aggregatedStats.totalProcessed > 0 \\n          ? state.aggregatedStats.totalErrors / state.aggregatedStats.totalProcessed \\n          : 0,\\n        recent: state.currentMetrics.errors?.slice(-10) || []\\n      },\\n      \\n      // System health\\n      health: {\\n        isCollecting: state.isCollecting,\\n        bufferUtilization: state.metricsBuffer.length / state.config.bufferSize,\\n        samplingRate: 1000 / state.config.samplingInterval\\n      }\\n    };\\n  };\\n\\n  // Get current memory usage\\n  const getCurrentMemoryUsage = () => {\\n    if (typeof performance !== 'undefined' && performance.memory) {\\n      return performance.memory.usedJSHeapSize;\\n    }\\n    return 0;\\n  };\\n\\n  // Get metrics by type\\n  const getMetricsByType = (type, limit = 100) => {\\n    const metrics = state.currentMetrics[type] || [];\\n    return metrics.slice(-limit).map(m => ({\\n      value: m.value,\\n      timestamp: m.timestamp,\\n      metadata: m.metadata\\n    }));\\n  };\\n\\n  // Clear all metrics\\n  const clearMetrics = () => {\\n    // Release all metrics back to pool\\n    Object.values(state.currentMetrics).forEach(metrics => {\\n      metrics.forEach(metric => state.memoryPool.release(metric));\\n    });\\n    \\n    state.metricsBuffer.forEach(metric => state.memoryPool.release(metric));\\n    \\n    // Clear buffers\\n    Object.keys(state.currentMetrics).forEach(key => {\\n      state.currentMetrics[key] = [];\\n    });\\n    state.metricsBuffer = [];\\n    \\n    // Reset aggregated stats\\n    state.aggregatedStats = {\\n      totalProcessed: 0,\\n      totalErrors: 0,\\n      averageProcessingTime: 0,\\n      averageFrameRate: 0,\\n      peakMemoryUsage: 0,\\n      uptime: Date.now()\\n    };\\n    \\n    console.log('📊 Performance metrics cleared');\\n  };\\n\\n  // Export metrics to JSON\\n  const exportMetrics = () => {\\n    return {\\n      config: state.config,\\n      report: getMetricsReport(),\\n      rawMetrics: {\\n        processingTime: getMetricsByType('processing_time'),\\n        frameRate: getMetricsByType('frame_rate'),\\n        memory: getMetricsByType('memory_used'),\\n        errors: getMetricsByType('error')\\n      }\\n    };\\n  };\\n\\n  // Cleanup\\n  const cleanup = () => {\\n    stopCollection();\\n    clearMetrics();\\n    state.memoryPool.cleanup();\\n  };\\n\\n  // Initialize the metrics system\\n  initializeMetricsPool();\\n\\n  return {\\n    // Collection control\\n    startCollection,\\n    stopCollection,\\n    isCollecting: () => state.isCollecting,\\n    \\n    // Metric recording\\n    recordMetric,\\n    recordProcessingTime,\\n    recordFrameRate,\\n    recordError,\\n    recordWarning,\\n    \\n    // Reporting\\n    getMetricsReport,\\n    getMetricsByType,\\n    exportMetrics,\\n    \\n    // Utilities\\n    clearMetrics,\\n    cleanup,\\n    \\n    // Configuration\\n    updateConfig: (updates) => {\\n      Object.assign(state.config, updates);\\n    },\\n    getConfig: () => ({ ...state.config })\\n  };\\n};\\n\\n// Global metrics collector instance\\nlet globalMetricsCollector = null;\\n\\n/**\\n * Get or create global metrics collector\\n * @param {Object} config - Optional configuration for new instance\\n * @returns {Object} Global metrics collector instance\\n */\\nexport const getGlobalMetricsCollector = (config = {}) => {\\n  if (!globalMetricsCollector) {\\n    globalMetricsCollector = createPerformanceMetricsCollector(config);\\n  }\\n  return globalMetricsCollector;\\n};\\n\\n/**\\n * Measure execution time of an async function\\n * @param {string} name - Measurement name\\n * @param {Function} fn - Function to measure\\n * @param {Object} metadata - Additional metadata\\n * @returns {Promise} Result of the function with timing information\\n */\\nexport const measurePerformance = async (name, fn, metadata = {}) => {\\n  const collector = getGlobalMetricsCollector();\\n  const startTime = performance.now();\\n  \\n  try {\\n    const result = await fn();\\n    const endTime = performance.now();\\n    const duration = endTime - startTime;\\n    \\n    collector.recordProcessingTime(name, duration, {\\n      success: true,\\n      ...metadata\\n    });\\n    \\n    return { result, duration };\\n  } catch (error) {\\n    const endTime = performance.now();\\n    const duration = endTime - startTime;\\n    \\n    collector.recordError(name, error, {\\n      duration,\\n      ...metadata\\n    });\\n    \\n    throw error;\\n  }\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/core/performance/performance-monitor.js\",\"messages\":[{\"ruleId\":\"max-lines-per-function\",\"severity\":1,\"message\":\"Arrow function has too many lines (258). Maximum allowed is 150.\",\"line\":11,\"column\":41,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"exceed\",\"endLine\":324,\"endColumn\":2},{\"ruleId\":\"no-nested-ternary\",\"severity\":1,\"message\":\"Do not nest ternary expressions.\",\"line\":308,\"column\":14,\"nodeType\":\"ConditionalExpression\",\"messageId\":\"noNestedTernary\",\"endLine\":308,\"endColumn\":97},{\"ruleId\":\"no-nested-ternary\",\"severity\":1,\"message\":\"Do not nest ternary expressions.\",\"line\":308,\"column\":34,\"nodeType\":\"ConditionalExpression\",\"messageId\":\"noNestedTernary\",\"endLine\":308,\"endColumn\":97},{\"ruleId\":\"no-nested-ternary\",\"severity\":1,\"message\":\"Do not nest ternary expressions.\",\"line\":308,\"column\":54,\"nodeType\":\"ConditionalExpression\",\"messageId\":\"noNestedTernary\",\"endLine\":308,\"endColumn\":97}],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":4,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Performance Monitoring System\\n * Tracks and analyzes pipeline performance, memory usage, and system health\\n */\\n\\nimport { createPerformanceMetrics } from '../configuration/types.ts';\\n\\n// Global performance monitor instance\\nlet globalMonitor = null;\\n\\nexport const createPerformanceMonitor = (config = {}) => {\\n  const state = {\\n    config: {\\n      maxHistorySize: config.maxHistorySize || 1000,\\n      memoryCheckInterval: config.memoryCheckInterval || 5000,\\n      alertThresholds: {\\n        latency: config.latencyThreshold || 100, // ms\\n        memory: config.memoryThreshold || 100 * 1024 * 1024, // 100MB\\n        errorRate: config.errorRateThreshold || 0.1 // 10%\\n      },\\n      ...config\\n    },\\n    metrics: new Map(),\\n    history: [],\\n    alerts: [],\\n    startTime: Bun.nanoseconds(),\\n    isMonitoring: false,\\n    intervalId: null\\n  };\\n\\n  const startMonitoring = () => {\\n    if (state.isMonitoring) return;\\n    \\n    state.isMonitoring = true;\\n    state.intervalId = setInterval(() => {\\n      collectSystemMetrics();\\n      checkThresholds();\\n      cleanupHistory();\\n    }, state.config.memoryCheckInterval);\\n    \\n    console.log('📊 Performance monitoring started');\\n  };\\n\\n  const stopMonitoring = () => {\\n    if (!state.isMonitoring) return;\\n    \\n    state.isMonitoring = false;\\n    if (state.intervalId) {\\n      clearInterval(state.intervalId);\\n      state.intervalId = null;\\n    }\\n    \\n    console.log('📊 Performance monitoring stopped');\\n  };\\n\\n  const collectSystemMetrics = () => {\\n    const now = Date.now();\\n    let systemMetrics = {};\\n    \\n    // Bun-specific metrics (also works with Node.js)\\n    if (typeof process !== 'undefined' && process.memoryUsage) {\\n      const memUsage = process.memoryUsage();\\n      systemMetrics = {\\n        memoryUsage: {\\n          rss: memUsage.rss,\\n          heapTotal: memUsage.heapTotal,\\n          heapUsed: memUsage.heapUsed,\\n          external: memUsage.external\\n        },\\n        uptime: process.uptime(),\\n        cpuUsage: process.cpuUsage ? process.cpuUsage() : null,\\n        // Bun-specific timing\\n        highResTime: typeof Bun !== 'undefined' ? Bun.nanoseconds() : Date.now() * 1e6\\n      };\\n    }\\n    \\n    // Browser specific metrics\\n    if (typeof window !== 'undefined' && window.performance) {\\n      systemMetrics = {\\n        ...systemMetrics,\\n        timing: window.performance.timing,\\n        memory: window.performance.memory || null,\\n        navigation: window.performance.navigation || null\\n      };\\n    }\\n    \\n    const metrics = createPerformanceMetrics({\\n      timestamp: now,\\n      systemMetrics,\\n      activeMetrics: state.metrics.size,\\n      totalAlerts: state.alerts.length\\n    });\\n    \\n    state.history.push(metrics);\\n  };\\n\\n  const recordPipelineMetric = (pipelineName, operation, duration, success = true, metadata = {}) => {\\n    const now = Date.now();\\n    \\n    if (!state.metrics.has(pipelineName)) {\\n      state.metrics.set(pipelineName, {\\n        totalOperations: 0,\\n        successfulOperations: 0,\\n        totalDuration: 0,\\n        minDuration: Infinity,\\n        maxDuration: 0,\\n        recentOperations: [],\\n        errors: []\\n      });\\n    }\\n    \\n    const pipelineMetrics = state.metrics.get(pipelineName);\\n    pipelineMetrics.totalOperations++;\\n    \\n    if (success) {\\n      pipelineMetrics.successfulOperations++;\\n      pipelineMetrics.totalDuration += duration;\\n      pipelineMetrics.minDuration = Math.min(pipelineMetrics.minDuration, duration);\\n      pipelineMetrics.maxDuration = Math.max(pipelineMetrics.maxDuration, duration);\\n    } else {\\n      pipelineMetrics.errors.push({\\n        timestamp: now,\\n        operation,\\n        duration,\\n        metadata\\n      });\\n    }\\n    \\n    // Keep recent operations for analysis\\n    pipelineMetrics.recentOperations.push({\\n      timestamp: now,\\n      operation,\\n      duration,\\n      success,\\n      metadata\\n    });\\n    \\n    // Limit recent operations to prevent memory growth\\n    if (pipelineMetrics.recentOperations.length > 100) {\\n      pipelineMetrics.recentOperations.shift();\\n    }\\n    \\n    // Check for performance issues\\n    if (duration > state.config.alertThresholds.latency) {\\n      createAlert('high_latency', `${pipelineName} operation took ${duration}ms`, {\\n        pipelineName,\\n        operation,\\n        duration,\\n        threshold: state.config.alertThresholds.latency\\n      });\\n    }\\n  };\\n\\n  const createAlert = (type, message, data = {}) => {\\n    const alert = {\\n      id: `alert_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`,\\n      type,\\n      message,\\n      timestamp: Date.now(),\\n      data,\\n      acknowledged: false\\n    };\\n    \\n    state.alerts.push(alert);\\n    console.warn(`⚠️ Performance Alert [${type}]: ${message}`);\\n    \\n    // Limit alerts to prevent memory growth\\n    if (state.alerts.length > 1000) {\\n      state.alerts.shift();\\n    }\\n    \\n    return alert.id;\\n  };\\n\\n  const checkThresholds = () => {\\n    // Check memory usage\\n    if (typeof process !== 'undefined' && process.memoryUsage) {\\n      const memUsage = process.memoryUsage();\\n      if (memUsage.heapUsed > state.config.alertThresholds.memory) {\\n        createAlert('high_memory', `Memory usage: ${Math.round(memUsage.heapUsed / 1024 / 1024)}MB`, {\\n          heapUsed: memUsage.heapUsed,\\n          threshold: state.config.alertThresholds.memory\\n        });\\n      }\\n    }\\n    \\n    // Check error rates for each pipeline\\n    state.metrics.forEach((metrics, pipelineName) => {\\n      if (metrics.totalOperations > 10) { // Only check after significant operations\\n        const errorRate = (metrics.totalOperations - metrics.successfulOperations) / metrics.totalOperations;\\n        if (errorRate > state.config.alertThresholds.errorRate) {\\n          createAlert('high_error_rate', `${pipelineName} error rate: ${(errorRate * 100).toFixed(1)}%`, {\\n            pipelineName,\\n            errorRate,\\n            totalOperations: metrics.totalOperations,\\n            successfulOperations: metrics.successfulOperations\\n          });\\n        }\\n      }\\n    });\\n  };\\n\\n  const cleanupHistory = () => {\\n    // Remove old history entries\\n    const cutoffTime = Date.now() - (60 * 60 * 1000); // Keep 1 hour of history\\n    state.history = state.history.filter(entry => entry.timestamp > cutoffTime);\\n    \\n    // Clean up old alerts\\n    const alertCutoffTime = Date.now() - (24 * 60 * 60 * 1000); // Keep 24 hours of alerts\\n    state.alerts = state.alerts.filter(alert => alert.timestamp > alertCutoffTime);\\n  };\\n\\n  const getPipelineStats = (pipelineName) => {\\n    const metrics = state.metrics.get(pipelineName);\\n    if (!metrics) return null;\\n    \\n    const avgDuration = metrics.successfulOperations > 0 \\n      ? metrics.totalDuration / metrics.successfulOperations \\n      : 0;\\n    \\n    const successRate = metrics.totalOperations > 0 \\n      ? metrics.successfulOperations / metrics.totalOperations \\n      : 0;\\n    \\n    return {\\n      name: pipelineName,\\n      totalOperations: metrics.totalOperations,\\n      successfulOperations: metrics.successfulOperations,\\n      successRate,\\n      avgDuration,\\n      minDuration: metrics.minDuration === Infinity ? 0 : metrics.minDuration,\\n      maxDuration: metrics.maxDuration,\\n      recentErrors: metrics.errors.slice(-10), // Last 10 errors\\n      lastOperation: metrics.recentOperations.length > 0 \\n        ? metrics.recentOperations[metrics.recentOperations.length - 1]\\n        : null\\n    };\\n  };\\n\\n  const getAllStats = () => {\\n    const pipelineStats = {};\\n    state.metrics.forEach((_, pipelineName) => {\\n      pipelineStats[pipelineName] = getPipelineStats(pipelineName);\\n    });\\n    \\n    const now = Date.now();\\n    const uptime = now - state.startTime;\\n    \\n    const systemStats = { uptime };\\n    if (typeof process !== 'undefined' && process.memoryUsage) {\\n      systemStats.memory = process.memoryUsage();\\n    }\\n    \\n    return {\\n      system: systemStats,\\n      pipelines: pipelineStats,\\n      alerts: state.alerts.filter(a => !a.acknowledged).slice(-50), // Last 50 unacknowledged\\n      monitoring: {\\n        isActive: state.isMonitoring,\\n        historySize: state.history.length,\\n        startTime: state.startTime,\\n        uptime\\n      }\\n    };\\n  };\\n\\n  const acknowledgeAlert = (alertId) => {\\n    const alert = state.alerts.find(a => a.id === alertId);\\n    if (alert) {\\n      alert.acknowledged = true;\\n      return true;\\n    }\\n    return false;\\n  };\\n\\n  const getHealthScore = () => {\\n    const stats = getAllStats();\\n    let score = 100;\\n    const factors = [];\\n    \\n    // Check pipeline health\\n    Object.values(stats.pipelines).forEach(pipeline => {\\n      if (pipeline.successRate < 0.95) {\\n        const penalty = (0.95 - pipeline.successRate) * 50;\\n        score -= penalty;\\n        factors.push(`${pipeline.name} success rate: ${(pipeline.successRate * 100).toFixed(1)}%`);\\n      }\\n      \\n      if (pipeline.avgDuration > 100) {\\n        const penalty = Math.min(20, (pipeline.avgDuration - 100) / 10);\\n        score -= penalty;\\n        factors.push(`${pipeline.name} avg latency: ${pipeline.avgDuration.toFixed(1)}ms`);\\n      }\\n    });\\n    \\n    // Check memory usage\\n    if (stats.system.memory && stats.system.memory.heapUsed > 200 * 1024 * 1024) {\\n      score -= 10;\\n      factors.push(`High memory usage: ${Math.round(stats.system.memory.heapUsed / 1024 / 1024)}MB`);\\n    }\\n    \\n    // Check alerts\\n    const criticalAlerts = stats.alerts.filter(a => a.type === 'high_memory' || a.type === 'high_error_rate');\\n    score -= criticalAlerts.length * 5;\\n    \\n    return {\\n      score: Math.max(0, Math.round(score)),\\n      grade: score >= 90 ? 'A' : score >= 80 ? 'B' : score >= 70 ? 'C' : score >= 60 ? 'D' : 'F',\\n      factors: factors.slice(0, 5) // Top 5 factors\\n    };\\n  };\\n\\n  return {\\n    startMonitoring,\\n    stopMonitoring,\\n    recordPipelineMetric,\\n    createAlert,\\n    acknowledgeAlert,\\n    getPipelineStats,\\n    getAllStats,\\n    getHealthScore,\\n    isMonitoring: () => state.isMonitoring\\n  };\\n};\\n\\n// Global monitor singleton\\nexport const getGlobalMonitor = () => {\\n  if (!globalMonitor) {\\n    globalMonitor = createPerformanceMonitor();\\n    globalMonitor.startMonitoring();\\n  }\\n  return globalMonitor;\\n};\\n\\n// Utility function to measure async operations\\nexport const measureAsync = async (operation, pipelineName, operationName, monitor = null) => {\\n  const perfMonitor = monitor || getGlobalMonitor();\\n  const startTime = Date.now();\\n  let success = true;\\n  let result;\\n  \\n  try {\\n    result = await operation();\\n  } catch (error) {\\n    success = false;\\n    throw error;\\n  } finally {\\n    const duration = Date.now() - startTime;\\n    perfMonitor.recordPipelineMetric(pipelineName, operationName, duration, success);\\n  }\\n  \\n  return result;\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/core/performance/resource-pool-buffers.js\",\"messages\":[],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/core/performance/resource-pool-canvas.js\",\"messages\":[{\"ruleId\":\"prefer-destructuring\",\"severity\":1,\"message\":\"Use array destructuring.\",\"line\":34,\"column\":9,\"nodeType\":\"AssignmentExpression\",\"messageId\":\"preferDestructuring\",\"endLine\":34,\"endColumn\":50}],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":1,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Canvas Resource Management\\n * Handles canvas element pooling and lifecycle management\\n */\\n\\nimport { ErrorCategory, ErrorSeverity, handleError } from '../../shared/utils/error-handler.js';\\n\\nexport const createMockCanvas = (width, height) => ({\\n  width,\\n  height,\\n  getContext: (type) => {\\n    if (type === '2d') {\\n      return {\\n        clearRect: () => {},\\n        fillRect: () => {},\\n        drawImage: () => {},\\n        getImageData: () => ({ data: new Uint8Array(width * height * 4), width, height }),\\n        putImageData: () => {}\\n      };\\n    }\\n    return null;\\n  }\\n});\\n\\nexport const createCanvasManager = (state, poolConfig) => {\\n  const getCanvas = (width = 640, height = 480) => {\\n    let canvas = null;\\n    \\n    // Try to find a suitable canvas in the pool\\n    for (let i = 0; i < state.canvasPool.length; i++) {\\n      const pooledCanvas = state.canvasPool[i];\\n      if (pooledCanvas.width >= width && pooledCanvas.height >= height) {\\n        // Remove from pool and resize if needed\\n        canvas = state.canvasPool.splice(i, 1)[0];\\n        if (canvas.width !== width || canvas.height !== height) {\\n          canvas.width = width;\\n          canvas.height = height;\\n        }\\n        break;\\n      }\\n    }\\n    \\n    // Create new canvas if none available\\n    if (!canvas) {\\n      if (typeof document !== 'undefined') {\\n        canvas = document.createElement('canvas');\\n        canvas.width = width;\\n        canvas.height = height;\\n        state.metricsData.canvasCreated++;\\n      } else {\\n        // Node.js environment - create mock canvas\\n        canvas = createMockCanvas(width, height);\\n        state.metricsData.canvasCreated++;\\n      }\\n    } else {\\n      state.metricsData.canvasReused++;\\n    }\\n    \\n    state.metricsData.totalAllocations++;\\n    return canvas;\\n  };\\n  \\n  const returnCanvas = (canvas) => {\\n    if (!canvas) return;\\n    \\n    try {\\n      // Clear canvas content\\n      const ctx = canvas.getContext('2d');\\n      if (ctx) {\\n        ctx.clearRect(0, 0, canvas.width, canvas.height);\\n      }\\n      \\n      // Only pool if we haven't exceeded the limit\\n      if (state.canvasPool.length < poolConfig.maxCanvasElements) {\\n        state.canvasPool.push(canvas);\\n      }\\n      \\n      state.metricsData.totalDeallocations++;\\n    } catch (error) {\\n      handleError(\\n        `Error returning canvas to pool: ${error.message}`,\\n        ErrorCategory.MEMORY,\\n        ErrorSeverity.WARNING\\n      );\\n    }\\n  };\\n  \\n  return { getCanvas, returnCanvas };\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/core/performance/resource-pool-config.js\",\"messages\":[],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/core/performance/resource-pool-gc.js\",\"messages\":[{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":17,\"column\":36,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":17,\"endColumn\":37},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":18,\"column\":35,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":18,\"endColumn\":36},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":18,\"column\":39,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":18,\"endColumn\":40},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":19,\"column\":34,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":19,\"endColumn\":35},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":19,\"column\":38,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":19,\"endColumn\":39},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":20,\"column\":33,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":20,\"endColumn\":34}],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":6,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Garbage Collection for Resource Pool\\n * Handles cleanup and memory management\\n */\\n\\nimport { ErrorCategory, ErrorSeverity, handleError } from '../../shared/utils/error-handler.js';\\n\\nexport const createGarbageCollector = (state, poolConfig, canvasManager) => {\\n  const updateMemoryPressure = () => {\\n    const totalPooledItems = \\n      state.canvasPool.length +\\n      Array.from(state.webglContextPool.values()).reduce((sum, pool) => sum + pool.length, 0) +\\n      Array.from(state.imageBufferPool.values()).reduce((sum, pool) => sum + pool.length, 0) +\\n      Array.from(state.typedArrayPool.values()).reduce((sum, pool) => sum + pool.length, 0);\\n    \\n    const maxItems = \\n      poolConfig.maxCanvasElements +\\n      poolConfig.maxWebGLContexts * 2 + // Estimate for different context types\\n      poolConfig.maxImageBuffers * 5 +  // Estimate for different buffer sizes\\n      poolConfig.maxTypedArrays * 10;   // Estimate for different array types\\n    \\n    state.metricsData.memoryPressure = Math.min(1.0, totalPooledItems / maxItems);\\n  };\\n  \\n  const performGarbageCollection = () => {\\n    try {\\n      const now = Date.now();\\n      const maxAge = poolConfig.gcInterval * 2; // Resources older than 2x GC interval\\n      \\n      // Clean old WebGL contexts\\n      for (const [type, contextPool] of state.webglContextPool.entries()) {\\n        const freshContexts = contextPool.filter(info => {\\n          if (!info.inUse && (now - info.created) > maxAge) {\\n            canvasManager.returnCanvas(info.canvas);\\n            return false;\\n          }\\n          return true;\\n        });\\n        state.webglContextPool.set(type, freshContexts);\\n      }\\n      \\n      // Trim pools to reasonable sizes\\n      state.canvasPool.splice(Math.floor(poolConfig.maxCanvasElements * 0.7));\\n      \\n      // Force garbage collection if available\\n      if (globalThis.gc && typeof globalThis.gc === 'function') {\\n        globalThis.gc();\\n      }\\n      \\n      // Update memory pressure metric\\n      updateMemoryPressure();\\n      \\n    } catch (error) {\\n      handleError(\\n        `Error during garbage collection: ${error.message}`,\\n        ErrorCategory.MEMORY,\\n        ErrorSeverity.WARNING\\n      );\\n    }\\n  };\\n  \\n  const startGarbageCollection = () => {\\n    if (state.gcTimer) return;\\n    \\n    state.gcTimer = setInterval(() => {\\n      performGarbageCollection();\\n    }, poolConfig.gcInterval);\\n  };\\n  \\n  const cleanup = () => {\\n    // Stop garbage collection\\n    if (state.gcTimer) {\\n      clearInterval(state.gcTimer);\\n      state.gcTimer = null;\\n    }\\n    \\n    // Clear all pools\\n    state.canvasPool.length = 0;\\n    state.webglContextPool.clear();\\n    state.imageBufferPool.clear();\\n    state.typedArrayPool.clear();\\n    \\n    // Reset metrics\\n    Object.keys(state.metricsData).forEach(key => {\\n      if (typeof state.metricsData[key] === 'number') {\\n        state.metricsData[key] = 0;\\n      }\\n    });\\n  };\\n  \\n  return {\\n    updateMemoryPressure,\\n    performGarbageCollection,\\n    startGarbageCollection,\\n    cleanup\\n  };\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/core/performance/resource-pool-metrics.js\",\"messages\":[],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/core/performance/resource-pool-webgl.js\",\"messages\":[{\"ruleId\":\"prefer-destructuring\",\"severity\":1,\"message\":\"Use array destructuring.\",\"line\":19,\"column\":9,\"nodeType\":\"AssignmentExpression\",\"messageId\":\"preferDestructuring\",\"endLine\":19,\"endColumn\":50}],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":1,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * WebGL Context Resource Management\\n * Handles WebGL context pooling and lifecycle management\\n */\\n\\nimport { ErrorCategory, ErrorSeverity, handleError } from '../../shared/utils/error-handler.js';\\n\\nexport const createWebGLManager = (state, poolConfig, canvasManager) => {\\n  const getWebGLContext = (type = 'webgl2', width = 640, height = 480) => {\\n    const contextPool = state.webglContextPool.get(type) || [];\\n    let contextInfo = null;\\n    \\n    // Try to reuse existing context\\n    for (let i = 0; i < contextPool.length; i++) {\\n      const pooledInfo = contextPool[i];\\n      if (!pooledInfo.inUse && \\n          pooledInfo.canvas.width >= width && \\n          pooledInfo.canvas.height >= height) {\\n        contextInfo = contextPool.splice(i, 1)[0];\\n        contextInfo.inUse = true;\\n        \\n        // Resize canvas if needed\\n        if (contextInfo.canvas.width !== width || contextInfo.canvas.height !== height) {\\n          contextInfo.canvas.width = width;\\n          contextInfo.canvas.height = height;\\n          contextInfo.context.viewport(0, 0, width, height);\\n        }\\n        \\n        state.metricsData.contextsReused++;\\n        break;\\n      }\\n    }\\n    \\n    // Create new context if none available\\n    if (!contextInfo) {\\n      const canvas = canvasManager.getCanvas(width, height);\\n      const context = canvas.getContext(type) || canvas.getContext('webgl');\\n      \\n      if (!context) {\\n        canvasManager.returnCanvas(canvas);\\n        throw new Error(`Failed to create ${type} context`);\\n      }\\n      \\n      contextInfo = {\\n        context,\\n        canvas,\\n        type,\\n        inUse: true,\\n        created: Date.now()\\n      };\\n      \\n      state.metricsData.contextsCreated++;\\n    }\\n    \\n    state.metricsData.totalAllocations++;\\n    return contextInfo;\\n  };\\n  \\n  const returnWebGLContext = (contextInfo) => {\\n    if (!contextInfo) return;\\n    \\n    try {\\n      // Clear WebGL state\\n      const gl = contextInfo.context;\\n      gl.clear(gl.COLOR_BUFFER_BIT | gl.DEPTH_BUFFER_BIT);\\n      gl.useProgram(null);\\n      gl.bindBuffer(gl.ARRAY_BUFFER, null);\\n      gl.bindTexture(gl.TEXTURE_2D, null);\\n      \\n      contextInfo.inUse = false;\\n      \\n      // Return to pool if under limit\\n      const contextPool = state.webglContextPool.get(contextInfo.type) || [];\\n      if (contextPool.length < poolConfig.maxWebGLContexts) {\\n        contextPool.push(contextInfo);\\n        state.webglContextPool.set(contextInfo.type, contextPool);\\n      } else {\\n        // Pool full, clean up resources\\n        canvasManager.returnCanvas(contextInfo.canvas);\\n      }\\n      \\n      state.metricsData.totalDeallocations++;\\n    } catch (error) {\\n      handleError(\\n        `Error returning WebGL context to pool: ${error.message}`,\\n        ErrorCategory.WEBGL,\\n        ErrorSeverity.WARNING\\n      );\\n    }\\n  };\\n  \\n  return { getWebGLContext, returnWebGLContext };\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/core/performance/resource-pool.js\",\"messages\":[],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/core/pipeline/analysis-pipeline.js\",\"messages\":[{\"ruleId\":\"max-lines-per-function\",\"severity\":1,\"message\":\"Arrow function has too many lines (201). Maximum allowed is 150.\",\"line\":11,\"column\":39,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"exceed\",\"endLine\":257,\"endColumn\":2},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":203,\"column\":22,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":203,\"endColumn\":23},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":203,\"column\":56,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":203,\"endColumn\":57},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":203,\"column\":56,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":203,\"endColumn\":57},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":203,\"column\":65,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":203,\"endColumn\":66}],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":5,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Core Analysis Pipeline - Composable processing pipeline\\n * Uses functional composition pattern for chaining analysis modules\\n */\\n\\nimport { createModuleRegistry } from '../integration/module-interface.js';\\nimport { createLogger } from '../../shared/utils/logger.js';\\n\\nconst logger = createLogger({ level: 2 });\\n\\nexport const createAnalysisPipeline = (config = {}) => {\\n  const state = {\\n    modules: [],\\n    registry: createModuleRegistry(),\\n    isInitialized: false,\\n    config: {\\n      enablePerformanceMonitoring: true,\\n      maxConcurrentProcessing: 1,\\n      errorHandling: 'throw', // 'throw' | 'skip' | 'fallback'\\n      ...config\\n    },\\n    stats: {\\n      totalProcessed: 0,\\n      totalErrors: 0,\\n      averagePipelineTime: 0,\\n      lastProcessingTime: 0\\n    }\\n  };\\n\\n  const addModule = (moduleConfig) => {\\n    const { category, algorithm, config: moduleSpecificConfig = {}, optional = false } = moduleConfig;\\n    \\n    if (!category || !algorithm) {\\n      throw new Error('Module config must specify category and algorithm');\\n    }\\n\\n    state.modules.push({\\n      category,\\n      algorithm,\\n      config: moduleSpecificConfig,\\n      optional,\\n      instance: null\\n    });\\n\\n    return pipeline;\\n  };\\n\\n  const removeModule = (category, algorithm = null) => {\\n    const initialLength = state.modules.length;\\n    \\n    if (algorithm) {\\n      state.modules = state.modules.filter(m => \\n        !(m.category === category && m.algorithm === algorithm)\\n      );\\n    } else {\\n      state.modules = state.modules.filter(m => m.category !== category);\\n    }\\n\\n    return state.modules.length !== initialLength;\\n  };\\n\\n  const initialize = async () => {\\n    try {\\n      // Initialize all modules\\n      for (const moduleConfig of state.modules) {\\n        try {\\n          const moduleInstance = await state.registry.load(\\n            moduleConfig.category,\\n            moduleConfig.algorithm,\\n            moduleConfig.config\\n          );\\n          moduleConfig.instance = moduleInstance;\\n          logger.info(`✅ Loaded ${moduleConfig.category}:${moduleConfig.algorithm}`);\\n        } catch (error) {\\n          if (moduleConfig.optional) {\\n            logger.warn(`⚠️ Optional module ${moduleConfig.category}:${moduleConfig.algorithm} failed to load:`, error.message);\\n            moduleConfig.instance = null;\\n          } else {\\n            throw new Error(`Required module ${moduleConfig.category}:${moduleConfig.algorithm} failed to load: ${error.message}`);\\n          }\\n        }\\n      }\\n\\n      state.isInitialized = true;\\n      logger.info(`🚀 Pipeline initialized with ${state.modules.filter(m => m.instance).length} modules`);\\n      \\n      return {\\n        totalModules: state.modules.length,\\n        loadedModules: state.modules.filter(m => m.instance).length,\\n        failedOptionalModules: state.modules.filter(m => !m.instance && m.optional).length\\n      };\\n    } catch (error) {\\n      state.isInitialized = false;\\n      throw error;\\n    }\\n  };\\n\\n  const process = async (input, context = {}) => {\\n    if (!state.isInitialized) {\\n      throw new Error('Pipeline not initialized. Call initialize() first.');\\n    }\\n\\n    const startTime = performance.now();\\n    const results = { input, stages: [], metadata: { processingTime: 0, errors: [] } };\\n    let currentData = input;\\n\\n    try {\\n      // Process through each module in sequence\\n      for (const moduleConfig of state.modules) {\\n        if (!moduleConfig.instance) {\\n          // Skip unavailable optional modules\\n          if (moduleConfig.optional) {\\n            continue;\\n          } else {\\n            throw new Error(`Required module ${moduleConfig.category}:${moduleConfig.algorithm} is not available`);\\n          }\\n        }\\n\\n        const stageStartTime = performance.now();\\n        \\n        try {\\n          const stageResult = await moduleConfig.instance.process(currentData, {\\n            ...context,\\n            pipelineStage: moduleConfig.category,\\n            previousResults: results.stages\\n          });\\n\\n          const stageTime = performance.now() - stageStartTime;\\n\\n          results.stages.push({\\n            category: moduleConfig.category,\\n            algorithm: moduleConfig.algorithm,\\n            result: stageResult,\\n            processingTime: stageTime,\\n            success: true\\n          });\\n\\n          // Update current data for next stage\\n          if (stageResult && typeof stageResult === 'object') {\\n            currentData = { ...currentData, [`${moduleConfig.category}Result`]: stageResult };\\n          }\\n\\n        } catch (stageError) {\\n          const stageTime = performance.now() - stageStartTime;\\n          \\n          results.stages.push({\\n            category: moduleConfig.category,\\n            algorithm: moduleConfig.algorithm,\\n            error: stageError.message,\\n            processingTime: stageTime,\\n            success: false\\n          });\\n\\n          results.metadata.errors.push({\\n            stage: moduleConfig.category,\\n            algorithm: moduleConfig.algorithm,\\n            error: stageError.message\\n          });\\n\\n          // Handle error based on configuration\\n          if (state.config.errorHandling === 'throw') {\\n            throw stageError;\\n          } else if (state.config.errorHandling === 'skip') {\\n            logger.warn(`Skipping failed stage ${moduleConfig.category}:${moduleConfig.algorithm}:`, stageError.message);\\n            continue;\\n          }\\n          // 'fallback' mode continues with original data\\n        }\\n      }\\n\\n      const totalTime = performance.now() - startTime;\\n      results.metadata.processingTime = totalTime;\\n\\n      // Update pipeline statistics\\n      updatePipelineStats(totalTime, results.metadata.errors.length > 0);\\n\\n      return results;\\n\\n    } catch (error) {\\n      const totalTime = performance.now() - startTime;\\n      results.metadata.processingTime = totalTime;\\n      results.metadata.errors.push({ stage: 'pipeline', error: error.message });\\n      \\n      updatePipelineStats(totalTime, true);\\n      throw error;\\n    }\\n  };\\n\\n  const updatePipelineStats = (processingTime, hasError) => {\\n    state.stats.totalProcessed++;\\n    state.stats.lastProcessingTime = processingTime;\\n    \\n    if (hasError) {\\n      state.stats.totalErrors++;\\n    }\\n\\n    // Update rolling average\\n    const weight = 0.1; // Exponential moving average\\n    if (state.stats.averagePipelineTime === 0) {\\n      state.stats.averagePipelineTime = processingTime;\\n    } else {\\n      state.stats.averagePipelineTime = \\n        (1 - weight) * state.stats.averagePipelineTime + weight * processingTime;\\n    }\\n  };\\n\\n  const getModuleInfo = () => {\\n    return state.modules.map(m => ({\\n      category: m.category,\\n      algorithm: m.algorithm,\\n      optional: m.optional,\\n      loaded: !!m.instance,\\n      metadata: m.instance ? m.instance.getMetadata() : null,\\n      performance: m.instance ? m.instance.getPerformanceMetrics() : null\\n    }));\\n  };\\n\\n  const getStats = () => ({\\n    ...state.stats,\\n    errorRate: state.stats.totalProcessed > 0 ? state.stats.totalErrors / state.stats.totalProcessed : 0\\n  });\\n\\n  const cleanup = () => {\\n    for (const moduleConfig of state.modules) {\\n      if (moduleConfig.instance) {\\n        moduleConfig.instance.cleanup();\\n        moduleConfig.instance = null;\\n      }\\n    }\\n    state.registry.clear();\\n    state.isInitialized = false;\\n  };\\n\\n  const registerModule = (category, algorithm, moduleFactory) => {\\n    state.registry.register(category, algorithm, moduleFactory);\\n  };\\n\\n  const getAvailableModules = (category = null) => {\\n    return state.registry.getAvailable(category);\\n  };\\n\\n  // Pipeline interface\\n  const pipeline = {\\n    addModule,\\n    removeModule,\\n    initialize,\\n    process,\\n    cleanup,\\n    registerModule,\\n    getAvailableModules,\\n    getModuleInfo,\\n    getStats,\\n    isReady: () => state.isInitialized\\n  };\\n\\n  return pipeline;\\n};\\n\\n// Helper function to create common pipeline configurations\\nexport const createPipelineConfigurations = () => ({\\n  // Fast processing pipeline - speed optimized\\n  fast: {\\n    modules: [\\n      { category: 'detection', algorithm: 'mediapipe-face', config: { maxFaces: 1 } }\\n    ],\\n    config: {\\n      enablePerformanceMonitoring: true,\\n      errorHandling: 'skip'\\n    }\\n  },\\n\\n  // Accurate processing pipeline - accuracy optimized\\n  accurate: {\\n    modules: [\\n      { category: 'detection', algorithm: 'mtcnn', config: { minFaceSize: 20 } },\\n      { category: 'landmarks', algorithm: 'mediapipe', optional: true }\\n    ],\\n    config: {\\n      enablePerformanceMonitoring: true,\\n      errorHandling: 'throw'\\n    }\\n  },\\n\\n  // Full analysis pipeline - all features\\n  full: {\\n    modules: [\\n      { category: 'detection', algorithm: 'mediapipe-face', config: { maxFaces: 5 } },\\n      { category: 'landmarks', algorithm: 'mediapipe', optional: true },\\n      { category: 'emotion', algorithm: 'ferplus', optional: true },\\n      { category: 'age', algorithm: 'agenet', optional: true }\\n    ],\\n    config: {\\n      enablePerformanceMonitoring: true,\\n      errorHandling: 'skip'\\n    }\\n  },\\n\\n  // API optimized pipeline - balanced performance\\n  api: {\\n    modules: [\\n      { category: 'detection', algorithm: 'mediapipe-face', config: { maxFaces: 3 } },\\n      { category: 'landmarks', algorithm: 'mediapipe', optional: true }\\n    ],\\n    config: {\\n      enablePerformanceMonitoring: true,\\n      errorHandling: 'skip',\\n      maxConcurrentProcessing: 5\\n    }\\n  }\\n});\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/core/pipeline/device-detector.js\",\"messages\":[{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'error' is defined but never used.\",\"line\":120,\"column\":14,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":120,\"endColumn\":19}],\"suppressedMessages\":[],\"errorCount\":1,\"fatalErrorCount\":0,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Device capability detection for pipeline preloader\\n */\\n\\nimport { UsageContexts } from './preloader-config.js';\\n\\nexport const createDeviceDetector = () => {\\n  const deviceInfo = {\\n    isMobile: false,\\n    batteryLevel: 1.0,\\n    isCharging: true,\\n    memoryGB: undefined,\\n    cores: 4,\\n    hasTouch: false\\n  };\\n\\n  const networkInfo = {\\n    effectiveType: '4g',\\n    downlink: 10,\\n    rtt: 100,\\n    saveData: false\\n  };\\n\\n  let currentContext = new Set();\\n\\n  /**\\n   * Detect device capabilities\\n   */\\n  const detectDeviceCapabilities = () => {\\n    // Mobile device detection\\n    deviceInfo.isMobile = /Android|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(\\n      navigator.userAgent\\n    );\\n\\n    // Memory detection (if available)\\n    if (navigator.deviceMemory) {\\n      deviceInfo.memoryGB = navigator.deviceMemory;\\n    }\\n\\n    // Hardware concurrency\\n    deviceInfo.cores = navigator.hardwareConcurrency || 4;\\n\\n    // Touch capability\\n    deviceInfo.hasTouch = 'ontouchstart' in window;\\n  };\\n\\n  /**\\n   * Setup network monitoring\\n   */\\n  const setupNetworkMonitoring = (onContextChange) => {\\n    // Network Information API\\n    if ('connection' in navigator) {\\n      const {connection} = navigator;\\n      \\n      const updateNetworkInfo = () => {\\n        networkInfo.effectiveType = connection.effectiveType || '4g';\\n        networkInfo.downlink = connection.downlink || 10;\\n        networkInfo.rtt = connection.rtt || 100;\\n        networkInfo.saveData = connection.saveData || false;\\n        \\n        updateCurrentContext(onContextChange);\\n      };\\n\\n      connection.addEventListener('change', updateNetworkInfo);\\n      updateNetworkInfo();\\n    }\\n  };\\n\\n  /**\\n   * Setup battery monitoring\\n   */\\n  const setupBatteryMonitoring = (onContextChange) => {\\n    // Battery Status API\\n    if ('getBattery' in navigator) {\\n      navigator.getBattery().then(battery => {\\n        const updateBatteryInfo = () => {\\n          deviceInfo.batteryLevel = battery.level;\\n          deviceInfo.isCharging = battery.charging;\\n          \\n          updateCurrentContext(onContextChange);\\n        };\\n\\n        battery.addEventListener('levelchange', updateBatteryInfo);\\n        battery.addEventListener('chargingchange', updateBatteryInfo);\\n        updateBatteryInfo();\\n      }).catch(() => {\\n        // Battery API not supported or blocked\\n      });\\n    }\\n  };\\n\\n  /**\\n   * Update current usage context\\n   */\\n  const updateCurrentContext = (onContextChange) => {\\n    const newContext = new Set();\\n    \\n    // Device context\\n    if (deviceInfo.isMobile) {\\n      newContext.add(UsageContexts.MOBILE_DEVICE);\\n    }\\n    \\n    if (deviceInfo.batteryLevel < 0.2) {\\n      newContext.add(UsageContexts.BATTERY_CRITICAL);\\n    }\\n\\n    // Network context\\n    if (networkInfo.effectiveType === '4g' && networkInfo.downlink > 5) {\\n      newContext.add(UsageContexts.HIGH_BANDWIDTH);\\n    } else if (networkInfo.effectiveType === '2g' || networkInfo.saveData) {\\n      newContext.add(UsageContexts.LOW_BANDWIDTH);\\n    }\\n\\n    // Usage context - handle localStorage safely\\n    let isFirstVisit = true;\\n    try {\\n      if (typeof localStorage !== 'undefined') {\\n        isFirstVisit = !localStorage.getItem('synopticon_usage_history');\\n      }\\n    } catch (error) {\\n      // localStorage not available (Node.js/test environment)\\n    }\\n    \\n    if (isFirstVisit) {\\n      newContext.add(UsageContexts.FIRST_VISIT);\\n    } else {\\n      newContext.add(UsageContexts.RETURNING_USER);\\n    }\\n\\n    // Check if webcam is active\\n    navigator.mediaDevices?.getUserMedia?.({ video: true })\\n      .then(stream => {\\n        newContext.add(UsageContexts.WEBCAM_ACTIVE);\\n        stream.getTracks().forEach(track => track.stop());\\n        currentContext = newContext;\\n        if (onContextChange) onContextChange();\\n      })\\n      .catch(() => {\\n        currentContext = newContext;\\n        if (onContextChange) onContextChange();\\n      });\\n  };\\n\\n  return {\\n    detectDeviceCapabilities,\\n    setupNetworkMonitoring,\\n    setupBatteryMonitoring,\\n    updateCurrentContext,\\n    getDeviceInfo: () => ({ ...deviceInfo }),\\n    getNetworkInfo: () => ({ ...networkInfo }),\\n    getCurrentContext: () => new Set(currentContext)\\n  };\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/core/pipeline/lazy-pipeline-registry.js\",\"messages\":[{\"ruleId\":\"max-lines-per-function\",\"severity\":1,\"message\":\"Arrow function has too many lines (299). Maximum allowed is 150.\",\"line\":90,\"column\":43,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"exceed\",\"endLine\":524,\"endColumn\":2}],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":1,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Lazy Pipeline Registry\\n * \\n * Provides on-demand loading of pipeline modules with intelligent caching, \\n * retry logic, and comprehensive error handling. Optimized for performance\\n * with metrics tracking and preloading capabilities.\\n * \\n * Features:\\n * - On-demand lazy loading with caching\\n * - Automatic retry with exponential backoff\\n * - Critical pipeline preloading\\n * - Comprehensive metrics and statistics\\n * - Priority-based loading strategies\\n * - Configuration validation\\n * - Cross-platform compatibility\\n * \\n * Performance:\\n * - Cache hits: ~0ms (instant)\\n * - Average load time: varies by pipeline complexity\\n * - Concurrent loading: supported with deduplication\\n * - Memory efficient: configurable cache size limits\\n * \\n * @example\\n * ```javascript\\n * import { createLazyPipelineRegistry } from './src/core/lazy-pipeline-registry.js';\\n * \\n * const registry = createLazyPipelineRegistry({\\n *   maxRetries: 3,\\n *   cacheSize: 10,\\n *   preloadCritical: true\\n * });\\n * \\n * // Load a pipeline (with automatic caching)\\n * const factory = await registry.loadPipeline('mediapipe-face');\\n * const pipeline = factory({ config: 'value' });\\n * \\n * // Preload critical pipelines\\n * await registry.preloadCriticalPipelines(['mediapipe-face']);\\n * \\n * // Monitor performance\\n * const metrics = registry.getMetrics();\\n * console.log(`Cache hit rate: ${metrics.cacheHitRate}%`);\\n * ```\\n */\\n\\nimport { ErrorCategory, ErrorSeverity, handleError } from '../../shared/utils/error-handler.js';\\n\\n// Pipeline module mapping with lazy loading functions\\nconst PIPELINE_LOADERS = {\\n  'mediapipe-face': () => import('../../features/face-detection/mediapipe-face-pipeline.js'),\\n  'mediapipe-face-mesh': () => import('../../features/face-detection/mediapipe-pipeline.js'),\\n  'emotion-analysis': () => import('../../features/emotion-analysis/emotion-analysis-pipeline.js'),\\n  'age-estimation': () => import('../../features/face-detection/age-estimation-pipeline.js'),\\n  'iris-tracking': () => import('../../features/eye-tracking/devices/webcam/pipeline.js'),\\n  'eye-tracking': () => import('../../features/eye-tracking/devices/neon/pipeline.js'),\\n  'webcam-eye-tracking': () => import('../../features/eye-tracking/devices/webcam/pipeline.js'),\\n  'neon-eye-tracking': () => import('../../features/eye-tracking/devices/neon/pipeline.js')\\n};\\n\\n// Factory function extractors - maps pipeline type to export name\\nconst FACTORY_EXTRACTORS = {\\n  'mediapipe-face': (module) => module.createMediaPipeFacePipeline,\\n  'mediapipe-face-mesh': (module) => module.createMediaPipeFaceMeshPipeline,\\n  'emotion-analysis': (module) => module.createEmotionAnalysisPipeline,\\n  'age-estimation': (module) => module.createAgeEstimationPipeline,\\n  'iris-tracking': (module) => module.createIrisTrackingPipeline,\\n  'eye-tracking': (module) => module.createEyeTrackingPipeline,\\n  'webcam-eye-tracking': (module) => module.createIrisTrackingPipeline,\\n  'neon-eye-tracking': (module) => module.createEyeTrackingPipeline\\n};\\n\\n// Critical pipelines that should be preloaded for optimal UX\\nconst CRITICAL_PIPELINES = ['mediapipe-face'];\\n\\n// Pipeline loading priorities (lower number = higher priority)\\nconst LOADING_PRIORITIES = {\\n  'mediapipe-face': 1,\\n  'emotion-analysis': 2,\\n  'age-estimation': 3,\\n  'mediapipe-face-mesh': 4,\\n  'iris-tracking': 5,\\n  'eye-tracking': 6\\n};\\n\\n/**\\n * Create lazy pipeline registry with advanced loading management\\n * @param {Object} config - Registry configuration\\n * @returns {Object} - Registry instance\\n */\\nexport const createLazyPipelineRegistry = (config = {}) => {\\n  // Validate configuration\\n  if (config.cacheSize !== undefined && config.cacheSize < 1) {\\n    throw new Error('Cache size must be positive');\\n  }\\n  if (config.maxRetries !== undefined && config.maxRetries < 0) {\\n    throw new Error('Max retries must be non-negative');\\n  }\\n\\n  const state = {\\n    config: {\\n      maxRetries: config.maxRetries || 3,\\n      retryDelay: config.retryDelay || 1000,\\n      cacheSize: config.cacheSize || 10,\\n      preloadCritical: config.preloadCritical !== false,\\n      enableMetrics: config.enableMetrics !== false,\\n      ...config\\n    },\\n    \\n    // Caching\\n    loadedPipelines: new Map(),\\n    loadingPromises: new Map(),\\n    failedLoads: new Map(),\\n    \\n    // Metrics\\n    metrics: {\\n      totalLoads: 0,\\n      uniqueLoads: 0,\\n      successfulLoads: 0,\\n      failedLoads: 0,\\n      loadFailures: 0,\\n      cacheHits: 0,\\n      averageLoadTime: 0,\\n      loadTimes: []\\n    },\\n    \\n    // Loading state management\\n    loadingStates: new Map(),\\n    stateListeners: new Set()\\n  };\\n\\n  /**\\n   * Update loading state and notify listeners\\n   * @param {string} pipelineType - Pipeline type\\n   * @param {string} newState - New loading state\\n   * @param {Object} metadata - Additional metadata\\n   */\\n  const updateLoadingState = (pipelineType, newState, metadata = {}) => {\\n    const stateData = {\\n      type: pipelineType,\\n      state: newState,\\n      timestamp: Date.now(),\\n      ...metadata\\n    };\\n    \\n    state.loadingStates.set(pipelineType, stateData);\\n    \\n    // Notify all listeners\\n    state.stateListeners.forEach(listener => {\\n      try {\\n        listener(stateData);\\n      } catch (error) {\\n        console.warn('Loading state listener error:', error);\\n      }\\n    });\\n  };\\n\\n  /**\\n   * Load pipeline module with retry logic and error handling\\n   * @param {string} pipelineType - Type of pipeline to load\\n   * @returns {Promise<Function>} - Pipeline factory function\\n   */\\n  const loadPipeline = async (pipelineType) => {\\n    const startTime = Date.now();\\n    \\n    // Validate pipeline type (protect against prototype pollution)\\n    if (!PIPELINE_LOADERS.hasOwnProperty(pipelineType)) {\\n      const error = new Error(`Unknown pipeline type: ${pipelineType}. Available types: ${Object.keys(PIPELINE_LOADERS).join(', ')}`);\\n      handleError(\\n        error.message,\\n        ErrorCategory.VALIDATION,\\n        ErrorSeverity.ERROR,\\n        { pipelineType, availableTypes: Object.keys(PIPELINE_LOADERS) }\\n      );\\n      throw error;\\n    }\\n\\n    // Return cached pipeline factory\\n    if (state.loadedPipelines.has(pipelineType)) {\\n      state.metrics.totalLoads++;\\n      state.metrics.cacheHits++;\\n      updateLoadingState(pipelineType, 'cached', { \\n        loadTime: 0,\\n        cacheHit: true \\n      });\\n      \\n      handleError(\\n        `Pipeline ${pipelineType} loaded from cache`,\\n        ErrorCategory.INITIALIZATION,\\n        ErrorSeverity.INFO,\\n        { pipelineType, cached: true }\\n      );\\n      \\n      return state.loadedPipelines.get(pipelineType);\\n    }\\n\\n    // Return existing loading promise to avoid duplicate loads\\n    if (state.loadingPromises.has(pipelineType)) {\\n      handleError(\\n        `Pipeline ${pipelineType} already loading, returning existing promise`,\\n        ErrorCategory.INITIALIZATION,\\n        ErrorSeverity.INFO,\\n        { pipelineType }\\n      );\\n      return state.loadingPromises.get(pipelineType);\\n    }\\n\\n    // Update metrics\\n    state.metrics.totalLoads++;\\n    updateLoadingState(pipelineType, 'loading', { startTime });\\n\\n    // Create loading promise with retry logic\\n    const loadingPromise = (async () => {\\n      let lastError;\\n      \\n      for (let attempt = 1; attempt <= state.config.maxRetries; attempt++) {\\n        try {\\n          handleError(\\n            `Loading pipeline ${pipelineType} (attempt ${attempt}/${state.config.maxRetries})`,\\n            ErrorCategory.INITIALIZATION,\\n            ErrorSeverity.INFO,\\n            { pipelineType, attempt }\\n          );\\n\\n          // Load the module\\n          const moduleLoader = PIPELINE_LOADERS[pipelineType];\\n          const module = await moduleLoader();\\n          \\n          // Extract factory function\\n          const factoryExtractor = FACTORY_EXTRACTORS[pipelineType];\\n          const pipelineFactory = factoryExtractor(module);\\n          \\n          if (typeof pipelineFactory !== 'function') {\\n            throw new Error(`Pipeline factory for ${pipelineType} is not a function`);\\n          }\\n\\n          // Cache the factory with size management\\n          if (state.loadedPipelines.size >= state.config.cacheSize) {\\n            // Remove oldest entry to make space (LRU-like behavior)\\n            const firstKey = state.loadedPipelines.keys().next().value;\\n            if (firstKey) {\\n              state.loadedPipelines.delete(firstKey);\\n              handleError(\\n                `Cache evicted oldest pipeline: ${firstKey} (cache size: ${state.config.cacheSize})`,\\n                ErrorCategory.INITIALIZATION,\\n                ErrorSeverity.DEBUG,\\n                { evicted: firstKey, pipelineType }\\n              );\\n            }\\n          }\\n          \\n          state.loadedPipelines.set(pipelineType, pipelineFactory);\\n          state.loadingPromises.delete(pipelineType);\\n          state.failedLoads.delete(pipelineType);\\n\\n          // Update metrics\\n          const loadTime = Date.now() - startTime;\\n          state.metrics.successfulLoads++;\\n          state.metrics.uniqueLoads++;\\n          state.metrics.loadTimes.push(loadTime);\\n          \\n          // Update average load time\\n          const totalTime = state.metrics.loadTimes.reduce((sum, time) => sum + time, 0);\\n          state.metrics.averageLoadTime = totalTime / state.metrics.loadTimes.length;\\n\\n          updateLoadingState(pipelineType, 'loaded', { \\n            loadTime,\\n            attempt,\\n            success: true \\n          });\\n\\n          handleError(\\n            `Pipeline ${pipelineType} loaded successfully in ${loadTime}ms (attempt ${attempt})`,\\n            ErrorCategory.INITIALIZATION,\\n            ErrorSeverity.INFO,\\n            { pipelineType, loadTime, attempt }\\n          );\\n\\n          return pipelineFactory;\\n\\n        } catch (error) {\\n          lastError = error;\\n          \\n          handleError(\\n            `Pipeline ${pipelineType} loading failed (attempt ${attempt}): ${error.message}`,\\n            ErrorCategory.INITIALIZATION,\\n            attempt < state.config.maxRetries ? ErrorSeverity.WARNING : ErrorSeverity.ERROR,\\n            { pipelineType, attempt, error: error.message }\\n          );\\n\\n          // Wait before retry (except on last attempt)\\n          if (attempt < state.config.maxRetries) {\\n            const delay = state.config.retryDelay * attempt; // Exponential backoff\\n            await new Promise(resolve => setTimeout(resolve, delay));\\n          }\\n        }\\n      }\\n\\n      // All attempts failed\\n      state.loadingPromises.delete(pipelineType);\\n      state.failedLoads.set(pipelineType, {\\n        error: lastError,\\n        timestamp: Date.now(),\\n        attempts: state.config.maxRetries\\n      });\\n      \\n      state.metrics.failedLoads++;\\n      state.metrics.loadFailures++;\\n      \\n      updateLoadingState(pipelineType, 'failed', { \\n        error: lastError.message,\\n        attempts: state.config.maxRetries,\\n        success: false \\n      });\\n\\n      throw new Error(`Failed to load pipeline ${pipelineType} after ${state.config.maxRetries} attempts: ${lastError.message}`);\\n    })();\\n\\n    // Store loading promise\\n    state.loadingPromises.set(pipelineType, loadingPromise);\\n    \\n    return loadingPromise;\\n  };\\n\\n  /**\\n   * Preload critical pipelines in background\\n   * @param {Array} criticalTypes - Pipeline types to preload\\n   * @returns {Promise<Object>} - Preload results\\n   */\\n  const preloadCriticalPipelines = async (criticalTypes = CRITICAL_PIPELINES) => {\\n    if (!state.config.preloadCritical || criticalTypes.length === 0) {\\n      return { successful: [], failed: [] };\\n    }\\n\\n    handleError(\\n      `Starting preload of ${criticalTypes.length} critical pipelines: ${criticalTypes.join(', ')}`,\\n      ErrorCategory.INITIALIZATION,\\n      ErrorSeverity.INFO,\\n      { criticalTypes }\\n    );\\n\\n    const results = {\\n      successful: [],\\n      failed: [],\\n      totalTime: 0\\n    };\\n\\n    const startTime = Date.now();\\n    \\n    // Sort by priority and load in order\\n    const sortedTypes = [...criticalTypes].sort((a, b) => \\n      (LOADING_PRIORITIES[a] || 999) - (LOADING_PRIORITIES[b] || 999)\\n    );\\n\\n    const preloadPromises = sortedTypes.map(async (type) => {\\n      try {\\n        await loadPipeline(type);\\n        results.successful.push(type);\\n      } catch (error) {\\n        results.failed.push({ type, error: error.message });\\n        // Don't throw - continue with other preloads\\n      }\\n    });\\n\\n    await Promise.allSettled(preloadPromises);\\n    \\n    results.totalTime = Date.now() - startTime;\\n\\n    handleError(\\n      `Critical pipeline preload completed: ${results.successful.length} successful, ${results.failed.length} failed in ${results.totalTime}ms`,\\n      ErrorCategory.INITIALIZATION,\\n      results.failed.length > 0 ? ErrorSeverity.WARNING : ErrorSeverity.INFO,\\n      { results }\\n    );\\n\\n    return results;\\n  };\\n\\n  /**\\n   * Get loading state for a pipeline\\n   * @param {string} pipelineType - Pipeline type\\n   * @returns {Object} - Loading state information\\n   */\\n  const getLoadingState = (pipelineType) => {\\n    return state.loadingStates.get(pipelineType) || {\\n      type: pipelineType,\\n      state: 'idle',\\n      timestamp: null\\n    };\\n  };\\n\\n  /**\\n   * Check if pipeline is loaded\\n   * @param {string} pipelineType - Pipeline type\\n   * @returns {boolean} - True if pipeline is loaded\\n   */\\n  const isPipelineLoaded = (pipelineType) => {\\n    return state.loadedPipelines.has(pipelineType);\\n  };\\n\\n  /**\\n   * Get all loaded pipeline types\\n   * @returns {Array<string>} - List of loaded pipeline types\\n   */\\n  const getLoadedPipelineTypes = () => {\\n    return Array.from(state.loadedPipelines.keys());\\n  };\\n\\n  /**\\n   * Clear pipeline cache (useful for testing or memory management)\\n   * @param {string} pipelineType - Specific pipeline to clear, or undefined for all\\n   */\\n  const clearCache = (pipelineType) => {\\n    if (pipelineType) {\\n      state.loadedPipelines.delete(pipelineType);\\n      state.loadingPromises.delete(pipelineType);\\n      state.failedLoads.delete(pipelineType);\\n      state.loadingStates.delete(pipelineType);\\n      \\n      handleError(\\n        `Cache cleared for pipeline: ${pipelineType}`,\\n        ErrorCategory.INITIALIZATION,\\n        ErrorSeverity.INFO,\\n        { pipelineType }\\n      );\\n    } else {\\n      // Clear all caches\\n      state.loadedPipelines.clear();\\n      state.loadingPromises.clear();\\n      state.failedLoads.clear();\\n      state.loadingStates.clear();\\n      \\n      // Reset metrics\\n      state.metrics = {\\n        totalLoads: 0,\\n        successfulLoads: 0,\\n        failedLoads: 0,\\n        cacheHits: 0,\\n        averageLoadTime: 0,\\n        loadTimes: []\\n      };\\n      \\n      handleError(\\n        'All pipeline caches cleared',\\n        ErrorCategory.INITIALIZATION,\\n        ErrorSeverity.INFO\\n      );\\n    }\\n  };\\n\\n  /**\\n   * Subscribe to loading state changes\\n   * @param {Function} listener - State change listener\\n   * @returns {Function} - Unsubscribe function\\n   */\\n  const onLoadingStateChange = (listener) => {\\n    if (typeof listener !== 'function') {\\n      throw new Error('Loading state listener must be a function');\\n    }\\n    \\n    state.stateListeners.add(listener);\\n    \\n    // Return unsubscribe function\\n    return () => {\\n      state.stateListeners.delete(listener);\\n    };\\n  };\\n\\n  /**\\n   * Get comprehensive metrics about pipeline loading\\n   * @returns {Object} - Loading metrics\\n   */\\n  const getMetrics = () => {\\n    return {\\n      ...state.metrics,\\n      loadedCount: state.loadedPipelines.size,\\n      loadingCount: state.loadingPromises.size,\\n      failedCount: state.failedLoads.size,\\n      successRate: state.metrics.totalLoads > 0 ? \\n        (state.metrics.successfulLoads / state.metrics.totalLoads) * 100 : 0,\\n      cacheHitRate: state.metrics.totalLoads > 0 ?\\n        (state.metrics.cacheHits / state.metrics.totalLoads) * 100 : 0\\n    };\\n  };\\n\\n  // Initialize by preloading critical pipelines if enabled\\n  if (state.config.preloadCritical) {\\n    // Don't await - let it happen in background\\n    preloadCriticalPipelines().catch(error => {\\n      handleError(\\n        `Critical pipeline preload failed: ${error.message}`,\\n        ErrorCategory.INITIALIZATION,\\n        ErrorSeverity.WARNING,\\n        { error: error.message }\\n      );\\n    });\\n  }\\n\\n  return {\\n    // Core loading functionality\\n    loadPipeline,\\n    preloadCriticalPipelines,\\n    \\n    // State management\\n    getLoadingState,\\n    onLoadingStateChange,\\n    isPipelineLoaded,\\n    getLoadedPipelineTypes,\\n    \\n    // Metrics and debugging\\n    getMetrics,\\n    clearCache,\\n    \\n    // Configuration\\n    getConfig: () => ({ ...state.config }),\\n    updateConfig: (updates) => {\\n      state.config = { ...state.config, ...updates };\\n    },\\n    \\n    // Utilities\\n    getAvailablePipelineTypes: () => Object.keys(PIPELINE_LOADERS),\\n    getCriticalPipelineTypes: () => [...CRITICAL_PIPELINES],\\n    getPipelinePriority: (type) => LOADING_PRIORITIES[type] || 999\\n  };\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/core/pipeline/pipeline-composer.js\",\"messages\":[],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/core/pipeline/pipeline-config.js\",\"messages\":[{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'logger' is assigned a value but never used. Allowed unused vars must match /^_/u.\",\"line\":11,\"column\":7,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":11,\"endColumn\":13,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"logger\"},\"fix\":{\"range\":[434,476],\"text\":\"\"},\"desc\":\"Remove unused variable 'logger'.\"}]},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'validateConfig' is assigned a value but never used. Allowed unused vars must match /^_/u.\",\"line\":122,\"column\":7,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":122,\"endColumn\":21,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"validateConfig\"},\"fix\":{\"range\":[3607,5211],\"text\":\"\"},\"desc\":\"Remove unused variable 'validateConfig'.\"}]}],\"suppressedMessages\":[],\"errorCount\":2,\"fatalErrorCount\":0,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Unified Pipeline Configuration Factory\\n * Provides standardized configuration patterns for all pipeline types\\n * Following functional programming patterns with immutable configurations\\n */\\n\\nimport { createConfigValidator } from '../configuration/config-validator.js';\\nimport { createLogger } from '../../shared/utils/logger.js';\\nimport { ErrorCategory, ErrorSeverity, handleError } from '../../shared/utils/error-handler.js';\\n\\nconst logger = createLogger({ level: 2 });\\n\\n// Base configuration common to all pipelines\\nconst BASE_CONFIG = {\\n  confidenceThreshold: 0.5,\\n  smoothingFactor: 0.3,\\n  enableAdvancedFeatures: true,\\n  debug: false,\\n  maxRetries: 3,\\n  timeout: 5000,\\n  enablePerformanceMetrics: true\\n};\\n\\n// Type-specific configuration defaults\\nconst TYPE_SPECIFIC_CONFIGS = {\\n  'age-estimation': {\\n    inputSize: [64, 64],\\n    enableGenderDetection: true,\\n    ageRangeMapping: {\\n      child: [0, 12],\\n      teen: [13, 19],\\n      adult: [20, 64],\\n      senior: [65, 100]\\n    },\\n    modelUrl: null,\\n    batchSize: 1\\n  },\\n  \\n  'emotion-analysis': {\\n    inputSize: [48, 48],\\n    enableValenceArousal: true,\\n    modelUrl: 'https://cdn.jsdelivr.net/gh/oarriaga/face_classification/trained_models/emotion_models/fer2013_mini_XCEPTION.102-0.66.hdf5',\\n    batchSize: 1,\\n    emotionLabels: ['angry', 'disgusted', 'fearful', 'happy', 'sad', 'surprised', 'neutral'],\\n    enableWebGL: true\\n  },\\n  \\n  'mediapipe-face-mesh': {\\n    maxNumFaces: 1,\\n    refineLandmarks: true,\\n    minDetectionConfidence: 0.5,\\n    minTrackingConfidence: 0.5,\\n    selfieMode: false,\\n    enableIris: false,\\n    staticImageMode: false,\\n    enable6DOF: true\\n  },\\n  \\n  'mediapipe-face': {\\n    modelSelection: 0,\\n    minDetectionConfidence: 0.5,\\n    maxFaces: 1,\\n    staticImageMode: false,\\n    enablePoseEstimation: true\\n  },\\n  \\n  'iris-tracking': {\\n    maxNumFaces: 1,\\n    minDetectionConfidence: 0.5,\\n    minTrackingConfidence: 0.5,\\n    refineLandmarks: true,\\n    enableGazeEstimation: true,\\n    smoothingFactor: 0.7,\\n    enablePupilDilation: false,\\n    gazeCalibrationPoints: 9\\n  }\\n};\\n\\n// Configuration validation rules for each type\\nconst VALIDATION_RULES = {\\n  'age-estimation': {\\n    inputSize: { type: 'array', minLength: 2, maxLength: 2 },\\n    confidenceThreshold: { type: 'number', min: 0, max: 1 },\\n    smoothingFactor: { type: 'number', min: 0, max: 1 },\\n    batchSize: { type: 'number', min: 1, max: 32 }\\n  },\\n  \\n  'emotion-analysis': {\\n    inputSize: { type: 'array', minLength: 2, maxLength: 2 },\\n    confidenceThreshold: { type: 'number', min: 0, max: 1 },\\n    smoothingFactor: { type: 'number', min: 0, max: 1 },\\n    batchSize: { type: 'number', min: 1, max: 32 }\\n  },\\n  \\n  'mediapipe-face-mesh': {\\n    maxNumFaces: { type: 'number', min: 1, max: 10 },\\n    minDetectionConfidence: { type: 'number', min: 0, max: 1 },\\n    minTrackingConfidence: { type: 'number', min: 0, max: 1 }\\n  },\\n  \\n  'mediapipe-face': {\\n    modelSelection: { type: 'number', min: 0, max: 1 },\\n    minDetectionConfidence: { type: 'number', min: 0, max: 1 },\\n    maxFaces: { type: 'number', min: 1, max: 10 }\\n  },\\n  \\n  'iris-tracking': {\\n    maxNumFaces: { type: 'number', min: 1, max: 5 },\\n    minDetectionConfidence: { type: 'number', min: 0, max: 1 },\\n    minTrackingConfidence: { type: 'number', min: 0, max: 1 },\\n    smoothingFactor: { type: 'number', min: 0, max: 1 },\\n    gazeCalibrationPoints: { type: 'number', min: 4, max: 25 }\\n  }\\n};\\n\\n/**\\n * Validates configuration object against type-specific rules\\n * @param {string} type - Pipeline type\\n * @param {Object} config - Configuration to validate\\n * @returns {boolean} - True if valid\\n */\\nconst validateConfig = (type, config) => {\\n  const rules = VALIDATION_RULES[type];\\n  if (!rules) return true;\\n  \\n  let isValid = true;\\n  \\n  Object.entries(rules).forEach(([key, rule]) => {\\n    if (config.hasOwnProperty(key)) {\\n      const value = config[key];\\n      \\n      // Type validation\\n      if (rule.type === 'array') {\\n        if (!Array.isArray(value)) {\\n          console.error(`Config validation failed: ${key} must be an array`);\\n          isValid = false;\\n          return;\\n        }\\n        if (rule.minLength && value.length < rule.minLength) {\\n          console.error(`Config validation failed: ${key} array too short (min: ${rule.minLength})`);\\n          isValid = false;\\n        }\\n        if (rule.maxLength && value.length > rule.maxLength) {\\n          console.error(`Config validation failed: ${key} array too long (max: ${rule.maxLength})`);\\n          isValid = false;\\n        }\\n      } else if (rule.type && typeof value !== rule.type) {\\n        console.error(`Config validation failed: ${key} must be ${rule.type}, got ${typeof value}`);\\n        isValid = false;\\n        return;\\n      }\\n      \\n      // Range validation for numbers\\n      if (rule.type === 'number') {\\n        if (rule.min !== undefined && value < rule.min) {\\n          console.error(`Config validation failed: ${key} too small (min: ${rule.min})`);\\n          isValid = false;\\n        }\\n        if (rule.max !== undefined && value > rule.max) {\\n          console.error(`Config validation failed: ${key} too large (max: ${rule.max})`);\\n          isValid = false;\\n        }\\n      }\\n    }\\n  });\\n  \\n  return isValid;\\n};\\n\\n/**\\n * Creates a standardized pipeline configuration\\n * @param {string} type - Pipeline type\\n * @param {Object} userConfig - User-provided configuration overrides\\n * @returns {Object} - Complete configuration object\\n */\\nexport const createPipelineConfig = (type, userConfig = {}, options = {}) => {\\n  // Validate pipeline type\\n  if (!type || typeof type !== 'string') {\\n    throw new Error('Pipeline type is required and must be a string');\\n  }\\n  \\n  // Check if type is supported\\n  const typeSpecific = TYPE_SPECIFIC_CONFIGS[type];\\n  if (!typeSpecific) {\\n    const supportedTypes = Object.keys(TYPE_SPECIFIC_CONFIGS);\\n    throw new Error(`Unsupported pipeline type: ${type}. Supported types: ${supportedTypes.join(', ')}`);\\n  }\\n\\n  // Create validator for this pipeline type\\n  // Face processing pipelines don't need the general PIPELINE schema (which requires 'name')\\n  // Disable strict mode to allow type-specific properties without warnings\\n  const validator = createConfigValidator({ _strictMode: false });\\n\\n  // Only validate user-provided configurations for security issues\\n  // Skip validation for internal/system configurations to avoid false positives\\n  if (!options.skipSecurityValidation && Object.keys(userConfig).length > 0) {\\n    // Validate user configuration first to catch security issues early\\n    try {\\n      const userValidation = validator.validate(userConfig);\\n      \\n      if (userValidation.securityViolations.length > 0) {\\n        handleError(\\n          `Security violations in pipeline configuration: ${userValidation.securityViolations.join(', ')}`,\\n          ErrorCategory.VALIDATION,\\n          ErrorSeverity.ERROR,\\n          { type, violations: userValidation.securityViolations }\\n        );\\n        throw new Error(`Configuration contains security violations: ${userValidation.securityViolations.join('; ')}`);\\n      }\\n\\n      if (userValidation.warnings.length > 0) {\\n        handleError(\\n          `Configuration warnings for pipeline ${type}: ${userValidation.warnings.join(', ')}`,\\n          ErrorCategory.VALIDATION,\\n          ErrorSeverity.WARNING,\\n          { type, warnings: userValidation.warnings }\\n        );\\n      }\\n    } catch (validationError) {\\n      handleError(\\n        `Pipeline configuration validation failed: ${validationError.message}`,\\n        ErrorCategory.VALIDATION,\\n        ErrorSeverity.ERROR,\\n        { type, userConfig }\\n      );\\n      throw validationError;\\n    }\\n  }\\n\\n  // Merge configurations in order of precedence\\n  const mergedConfig = {\\n    ...BASE_CONFIG,\\n    ...typeSpecific,\\n    ...userConfig,\\n    type // Always preserve the type\\n  };\\n  \\n  // Final validation of merged configuration (only check structural validity, not security for internal configs)\\n  if (!options.skipSecurityValidation) {\\n    const finalValidation = validator.validate(mergedConfig);\\n    if (!finalValidation.valid) {\\n      throw new Error(`Final configuration validation failed: ${finalValidation.errors.join('; ')}`);\\n    }\\n  }\\n\\n  // Sanitize configuration to remove any dangerous properties\\n  const sanitizedConfig = validator.sanitizeConfig(mergedConfig);\\n  \\n  handleError(\\n    `Pipeline configuration created successfully for type: ${type}`,\\n    ErrorCategory.INITIALIZATION,\\n    ErrorSeverity.INFO,\\n    { type, configKeys: Object.keys(sanitizedConfig) }\\n  );\\n  \\n  return sanitizedConfig;\\n};\\n\\n/**\\n * Gets default configuration for a pipeline type\\n * @param {string} type - Pipeline type\\n * @returns {Object} - Default configuration\\n */\\nexport const getDefaultConfig = (type) => {\\n  return createPipelineConfig(type);\\n};\\n\\n/**\\n * Updates an existing configuration with new values\\n * @param {Object} currentConfig - Current configuration\\n * @param {Object} updates - Updates to apply\\n * @returns {Object} - New configuration object\\n */\\nexport const updateConfig = (currentConfig, updates = {}) => {\\n  if (!currentConfig.type) {\\n    throw new Error('Cannot update configuration without type information');\\n  }\\n  \\n  return createPipelineConfig(currentConfig.type, {\\n    ...currentConfig,\\n    ...updates\\n  });\\n};\\n\\n/**\\n * Validates if two configurations are compatible for pipeline switching\\n * @param {Object} config1 - First configuration\\n * @param {Object} config2 - Second configuration\\n * @returns {boolean} - True if compatible\\n */\\nexport const areConfigsCompatible = (config1, config2) => {\\n  if (!config1 || !config2) return false;\\n  \\n  // Same type pipelines are always compatible\\n  if (config1.type === config2.type) return true;\\n  \\n  // MediaPipe variants are compatible with each other\\n  const mediaPipeTypes = ['mediapipe-face-mesh', 'mediapipe-face', 'iris-tracking'];\\n  if (mediaPipeTypes.includes(config1.type) && mediaPipeTypes.includes(config2.type)) {\\n    return true;\\n  }\\n  \\n  return false;\\n};\\n\\n/**\\n * Gets configuration schema for a pipeline type (useful for UI generation)\\n * @param {string} type - Pipeline type\\n * @returns {Object} - Configuration schema\\n */\\nexport const getConfigSchema = (type) => {\\n  const typeConfig = TYPE_SPECIFIC_CONFIGS[type];\\n  const validationRules = VALIDATION_RULES[type];\\n  \\n  if (!typeConfig) return null;\\n  \\n  return {\\n    base: BASE_CONFIG,\\n    typeSpecific: typeConfig,\\n    validation: validationRules,\\n    supportedTypes: Object.keys(TYPE_SPECIFIC_CONFIGS)\\n  };\\n};\\n\\n/**\\n * Creates internal pipeline configuration with bypassed security validation\\n * This should only be used by the system itself, not for user-provided configs\\n * @param {string} type - Pipeline type\\n * @param {Object} internalConfig - Internal configuration overrides\\n * @returns {Object} - Complete configuration object\\n */\\nexport const createInternalPipelineConfig = (type, internalConfig = {}) => {\\n  return createPipelineConfig(type, internalConfig, { skipSecurityValidation: true });\\n};\\n\\n// Export supported pipeline types for reference\\nexport const SUPPORTED_PIPELINE_TYPES = Object.keys(TYPE_SPECIFIC_CONFIGS);\\n\\n// Export configuration constants for external use\\nexport { BASE_CONFIG, TYPE_SPECIFIC_CONFIGS, VALIDATION_RULES };\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/core/pipeline/pipeline-events.js\",\"messages\":[],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/core/pipeline/pipeline-preloader.js\",\"messages\":[],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/core/pipeline/preload-scheduler.js\",\"messages\":[],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/core/pipeline/preloader-config.js\",\"messages\":[],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/core/pipeline/usage-tracker.js\",\"messages\":[],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/core/state/adaptive-batching.js\",\"messages\":[],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/core/state/loading-state-manager.js\",\"messages\":[{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'logger' is assigned a value but never used. Allowed unused vars must match /^_/u.\",\"line\":49,\"column\":7,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":49,\"endColumn\":13,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"logger\"},\"fix\":{\"range\":[1725,1767],\"text\":\"\"},\"desc\":\"Remove unused variable 'logger'.\"}]},{\"ruleId\":\"max-lines-per-function\",\"severity\":1,\"message\":\"Arrow function has too many lines (279). Maximum allowed is 150.\",\"line\":79,\"column\":42,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"exceed\",\"endLine\":516,\"endColumn\":2},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'identifier' is assigned a value but never used. Allowed unused vars must match /^_/u.\",\"line\":289,\"column\":17,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":289,\"endColumn\":27,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"identifier\"},\"fix\":{\"range\":[8303,8313],\"text\":\"\"},\"desc\":\"Remove unused variable 'identifier'.\"}]},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'stageStartTime' is assigned a value but never used. Allowed unused vars must match /^_/u.\",\"line\":348,\"column\":9,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":348,\"endColumn\":23}],\"suppressedMessages\":[],\"errorCount\":3,\"fatalErrorCount\":0,\"warningCount\":1,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Loading State Manager\\n * \\n * Centralized management of loading states with advanced progress tracking,\\n * UI integration, and comprehensive analytics. Provides real-time feedback\\n * for pipeline loading operations with cleanup automation.\\n * \\n * Features:\\n * - Centralized loading state management\\n * - Advanced progress tracking with stages\\n * - Automatic resource cleanup and timers\\n * - Real-time listener notifications\\n * - State history for debugging\\n * - Performance metrics collection\\n * - Configurable retention policies\\n * \\n * States: idle, loading, loaded, error, failed, cached, preloading\\n * Progress Stages: initializing, fetching, downloading, parsing, compiling, executing, caching, complete\\n * \\n * @example\\n * ```javascript\\n * import { createLoadingStateManager } from './src/core/loading-state-manager.js';\\n * \\n * const stateManager = createLoadingStateManager({\\n *   enableProgressTracking: true,\\n *   stateRetentionTime: 30000,\\n *   maxStateHistory: 100\\n * });\\n * \\n * // Update loading state\\n * stateManager.updateLoadingState('mediapipe-face', 'loading', { startTime: Date.now() });\\n * \\n * // Track progress\\n * const tracker = stateManager.createProgressTracker('mediapipe-face', ['initializing', 'loading', 'complete']);\\n * tracker.nextStage('Loading MediaPipe...');\\n * tracker.updateProgress(50, 'Halfway loaded');\\n * tracker.complete('Ready');\\n * \\n * // Listen to state changes\\n * const unsubscribe = stateManager.onLoadingStateChange((stateData) => {\\n *   console.log(`${stateData.identifier}: ${stateData.state}`);\\n * });\\n * ```\\n */\\n\\nimport { ErrorCategory, ErrorSeverity, handleError } from '../../shared/utils/error-handler.js';\\nimport { createLogger } from '../../shared/utils/logger.js';\\n\\nconst logger = createLogger({ level: 2 });\\n\\n// Loading state types\\nexport const LoadingStates = {\\n  IDLE: 'idle',\\n  LOADING: 'loading',\\n  LOADED: 'loaded',\\n  ERROR: 'error',\\n  FAILED: 'failed',\\n  CACHED: 'cached',\\n  PRELOADING: 'preloading'\\n};\\n\\n// Progress stages for detailed loading feedback\\nexport const ProgressStages = {\\n  INITIALIZING: 'initializing',\\n  FETCHING: 'fetching',\\n  DOWNLOADING: 'downloading',\\n  PARSING: 'parsing',\\n  COMPILING: 'compiling',\\n  EXECUTING: 'executing',\\n  CACHING: 'caching',\\n  COMPLETE: 'complete'\\n};\\n\\n/**\\n * Create loading state manager with progress tracking\\n * @param {Object} config - Manager configuration\\n * @returns {Object} - State manager instance\\n */\\nexport const createLoadingStateManager = (config = {}) => {\\n  const state = {\\n    config: {\\n      enableProgressTracking: config.enableProgressTracking !== false,\\n      progressUpdateInterval: config.progressUpdateInterval || 100,\\n      stateRetentionTime: config.stateRetentionTime || 30000, // 30 seconds\\n      maxStateHistory: config.maxStateHistory || 100,\\n      ...config\\n    },\\n    \\n    // Current states\\n    currentStates: new Map(),\\n    progressData: new Map(),\\n    \\n    // State history for debugging\\n    stateHistory: [],\\n    \\n    // Listeners\\n    stateListeners: new Set(),\\n    progressListeners: new Set(),\\n    \\n    // Timers for cleanup\\n    cleanupTimers: new Map()\\n  };\\n\\n  /**\\n   * Add state to history with cleanup\\n   * @param {Object} stateChange - State change information\\n   */\\n  const addToHistory = (stateChange) => {\\n    state.stateHistory.push({\\n      ...stateChange,\\n      id: `${stateChange.identifier}_${Date.now()}`\\n    });\\n    \\n    // Limit history size\\n    if (state.stateHistory.length > state.config.maxStateHistory) {\\n      state.stateHistory.shift();\\n    }\\n  };\\n\\n  /**\\n   * Schedule cleanup for completed/failed states\\n   * @param {string} identifier - Resource identifier\\n   */\\n  const scheduleCleanup = (identifier) => {\\n    // Clear existing timer\\n    if (state.cleanupTimers.has(identifier)) {\\n      clearTimeout(state.cleanupTimers.get(identifier));\\n    }\\n    \\n    // Schedule new cleanup\\n    const timer = setTimeout(() => {\\n      state.currentStates.delete(identifier);\\n      state.progressData.delete(identifier);\\n      state.cleanupTimers.delete(identifier);\\n      \\n      handleError(\\n        `Loading state cleaned up for: ${identifier}`,\\n        ErrorCategory.INITIALIZATION,\\n        ErrorSeverity.DEBUG,\\n        { identifier }\\n      );\\n    }, state.config.stateRetentionTime);\\n    \\n    state.cleanupTimers.set(identifier, timer);\\n  };\\n\\n  /**\\n   * Update loading state for a resource\\n   * @param {string} identifier - Resource identifier (e.g. pipeline name)\\n   * @param {string} newState - New loading state\\n   * @param {Object} metadata - Additional metadata\\n   */\\n  const updateLoadingState = (identifier, newState, metadata = {}) => {\\n    if (!identifier || !newState) {\\n      throw new Error('Identifier and state are required');\\n    }\\n\\n    if (!Object.values(LoadingStates).includes(newState)) {\\n      throw new Error(`Invalid loading state: ${newState}`);\\n    }\\n\\n    const timestamp = Date.now();\\n    const previousState = state.currentStates.get(identifier);\\n    \\n    const stateData = {\\n      identifier,\\n      state: newState,\\n      previousState: previousState?.state,\\n      timestamp,\\n      duration: previousState ? timestamp - previousState.timestamp : 0,\\n      ...metadata\\n    };\\n\\n    // Update current state\\n    state.currentStates.set(identifier, stateData);\\n    \\n    // Add to history\\n    addToHistory(stateData);\\n\\n    // Schedule cleanup for terminal states\\n    if ([LoadingStates.LOADED, LoadingStates.FAILED, LoadingStates.CACHED].includes(newState)) {\\n      scheduleCleanup(identifier);\\n    }\\n\\n    // Notify state listeners\\n    state.stateListeners.forEach(listener => {\\n      try {\\n        listener(stateData);\\n      } catch (error) {\\n        console.warn(`Loading state listener error for ${identifier}:`, error);\\n      }\\n    });\\n\\n    handleError(\\n      `Loading state updated: ${identifier} -> ${newState}`,\\n      ErrorCategory.INITIALIZATION,\\n      ErrorSeverity.DEBUG,\\n      { identifier, state: newState, metadata }\\n    );\\n  };\\n\\n  /**\\n   * Update loading progress for a resource\\n   * @param {string} identifier - Resource identifier\\n   * @param {Object} progressInfo - Progress information\\n   */\\n  const updateProgress = (identifier, progressInfo) => {\\n    if (!identifier) {\\n      throw new Error('Identifier is required for progress updates');\\n    }\\n\\n    if (!state.config.enableProgressTracking) {\\n      return; // Progress tracking disabled\\n    }\\n\\n    const timestamp = Date.now();\\n    const currentProgress = state.progressData.get(identifier) || {};\\n    \\n    const updatedProgress = {\\n      ...currentProgress,\\n      ...progressInfo,\\n      identifier,\\n      timestamp,\\n      lastUpdate: timestamp\\n    };\\n\\n    // Validate progress percentage\\n    if (updatedProgress.percentage !== undefined) {\\n      updatedProgress.percentage = Math.max(0, Math.min(100, updatedProgress.percentage));\\n    }\\n\\n    state.progressData.set(identifier, updatedProgress);\\n\\n    // Notify progress listeners\\n    state.progressListeners.forEach(listener => {\\n      try {\\n        listener(updatedProgress);\\n      } catch (error) {\\n        console.warn(`Progress listener error for ${identifier}:`, error);\\n      }\\n    });\\n  };\\n\\n  /**\\n   * Get current loading state for a resource\\n   * @param {string} identifier - Resource identifier\\n   * @returns {Object} - Current loading state\\n   */\\n  const getLoadingState = (identifier) => {\\n    return state.currentStates.get(identifier) || {\\n      identifier,\\n      state: LoadingStates.IDLE,\\n      timestamp: null,\\n      duration: 0\\n    };\\n  };\\n\\n  /**\\n   * Get current progress for a resource\\n   * @param {string} identifier - Resource identifier\\n   * @returns {Object} - Current progress information\\n   */\\n  const getProgress = (identifier) => {\\n    return state.progressData.get(identifier) || {\\n      identifier,\\n      percentage: 0,\\n      stage: ProgressStages.INITIALIZING,\\n      message: 'Initializing...',\\n      timestamp: null\\n    };\\n  };\\n\\n  /**\\n   * Get all current loading states\\n   * @returns {Map} - Map of all current states\\n   */\\n  const getAllLoadingStates = () => {\\n    return new Map(state.currentStates);\\n  };\\n\\n  /**\\n   * Get resources in specific loading states\\n   * @param {Array<string>} states - States to filter by\\n   * @returns {Array} - Resources in specified states\\n   */\\n  const getResourcesInStates = (states = []) => {\\n    const results = [];\\n    \\n    for (const [identifier, stateData] of state.currentStates.entries()) {\\n      if (states.includes(stateData.state)) {\\n        results.push(stateData);\\n      }\\n    }\\n    \\n    return results;\\n  };\\n\\n  /**\\n   * Check if any resources are currently loading\\n   * @returns {boolean} - True if any resources are loading\\n   */\\n  const hasActiveLoading = () => {\\n    return getResourcesInStates([LoadingStates.LOADING, LoadingStates.PRELOADING]).length > 0;\\n  };\\n\\n  /**\\n   * Subscribe to loading state changes\\n   * @param {Function} listener - State change listener\\n   * @returns {Function} - Unsubscribe function\\n   */\\n  const onLoadingStateChange = (listener) => {\\n    if (typeof listener !== 'function') {\\n      throw new Error('Loading state listener must be a function');\\n    }\\n    \\n    state.stateListeners.add(listener);\\n    \\n    return () => {\\n      state.stateListeners.delete(listener);\\n    };\\n  };\\n\\n  /**\\n   * Subscribe to progress updates\\n   * @param {Function} listener - Progress update listener\\n   * @returns {Function} - Unsubscribe function\\n   */\\n  const onProgressUpdate = (listener) => {\\n    if (typeof listener !== 'function') {\\n      throw new Error('Progress listener must be a function');\\n    }\\n    \\n    state.progressListeners.add(listener);\\n    \\n    return () => {\\n      state.progressListeners.delete(listener);\\n    };\\n  };\\n\\n  /**\\n   * Create a progress tracker for a specific resource\\n   * @param {string} identifier - Resource identifier\\n   * @param {Array<string>} stages - Progress stages for this resource\\n   * @returns {Object} - Progress tracker instance\\n   */\\n  const createProgressTracker = (identifier, stages = Object.values(ProgressStages)) => {\\n    let currentStageIndex = 0;\\n    let stageStartTime = Date.now();\\n    \\n    const tracker = {\\n      // Update to next stage\\n      nextStage: (message = '') => {\\n        if (currentStageIndex < stages.length - 1) {\\n          currentStageIndex++;\\n          stageStartTime = Date.now();\\n          \\n          const percentage = Math.round((currentStageIndex / stages.length) * 100);\\n          \\n          updateProgress(identifier, {\\n            stage: stages[currentStageIndex],\\n            percentage,\\n            message: message || `${stages[currentStageIndex]}...`,\\n            stageIndex: currentStageIndex,\\n            totalStages: stages.length\\n          });\\n        }\\n      },\\n      \\n      // Update progress within current stage\\n      updateProgress: (percentage, message = '') => {\\n        const stageProgress = (currentStageIndex / stages.length) * 100;\\n        const withinStageProgress = (percentage / 100) * (100 / stages.length);\\n        const totalPercentage = Math.round(stageProgress + withinStageProgress);\\n        \\n        updateProgress(identifier, {\\n          stage: stages[currentStageIndex],\\n          percentage: totalPercentage,\\n          message: message || `${stages[currentStageIndex]}... ${percentage}%`,\\n          stageIndex: currentStageIndex,\\n          totalStages: stages.length,\\n          stageProgress: percentage\\n        });\\n      },\\n      \\n      // Complete progress tracking\\n      complete: (message = 'Complete') => {\\n        updateProgress(identifier, {\\n          stage: ProgressStages.COMPLETE,\\n          percentage: 100,\\n          message,\\n          stageIndex: stages.length - 1,\\n          totalStages: stages.length,\\n          completed: true\\n        });\\n      },\\n      \\n      // Mark as failed\\n      fail: (error, message = 'Failed') => {\\n        updateProgress(identifier, {\\n          stage: stages[currentStageIndex],\\n          percentage: 0,\\n          message,\\n          error: error.message || error,\\n          failed: true\\n        });\\n      }\\n    };\\n    \\n    // Initialize first stage\\n    tracker.updateProgress(0, `Starting ${stages[0]}...`);\\n    \\n    return tracker;\\n  };\\n\\n  /**\\n   * Get loading statistics\\n   * @returns {Object} - Loading statistics\\n   */\\n  const getStatistics = () => {\\n    const totalStates = state.currentStates.size;\\n    const statesByType = {};\\n    \\n    // Count states by type\\n    for (const stateData of state.currentStates.values()) {\\n      statesByType[stateData.state] = (statesByType[stateData.state] || 0) + 1;\\n    }\\n    \\n    return {\\n      totalResources: totalStates,\\n      statesByType,\\n      hasActiveLoading: hasActiveLoading(),\\n      historySize: state.stateHistory.length,\\n      progressTrackingEnabled: state.config.enableProgressTracking,\\n      activeListeners: {\\n        stateListeners: state.stateListeners.size,\\n        progressListeners: state.progressListeners.size\\n      }\\n    };\\n  };\\n\\n  /**\\n   * Clear all states and progress data\\n   */\\n  const clearAll = () => {\\n    // Clear all timers\\n    for (const timer of state.cleanupTimers.values()) {\\n      clearTimeout(timer);\\n    }\\n    \\n    // Clear state\\n    state.currentStates.clear();\\n    state.progressData.clear();\\n    state.stateHistory = [];\\n    state.cleanupTimers.clear();\\n    \\n    handleError(\\n      'All loading states cleared',\\n      ErrorCategory.INITIALIZATION,\\n      ErrorSeverity.INFO\\n    );\\n  };\\n\\n  /**\\n   * Get state history for debugging\\n   * @param {string} identifier - Optional identifier filter\\n   * @returns {Array} - State history\\n   */\\n  const getStateHistory = (identifier = null) => {\\n    if (identifier) {\\n      return state.stateHistory.filter(entry => entry.identifier === identifier);\\n    }\\n    return [...state.stateHistory];\\n  };\\n\\n  return {\\n    // State management\\n    updateLoadingState,\\n    getLoadingState,\\n    getAllLoadingStates,\\n    getAllStates: () => state.currentStates,\\n    clearState: (identifier) => {\\n      state.currentStates.delete(identifier);\\n      state.progressData.delete(identifier);\\n      if (state.cleanupTimers.has(identifier)) {\\n        clearTimeout(state.cleanupTimers.get(identifier));\\n        state.cleanupTimers.delete(identifier);\\n      }\\n    },\\n    getResourcesInStates,\\n    hasActiveLoading,\\n    \\n    // Progress tracking\\n    updateProgress,\\n    getProgress,\\n    createProgressTracker,\\n    \\n    // Subscriptions\\n    onLoadingStateChange,\\n    onProgressUpdate,\\n    \\n    // Utilities\\n    getStatistics,\\n    getStateHistory,\\n    clearAll,\\n    \\n    // Configuration\\n    getConfig: () => ({ ...state.config }),\\n    updateConfig: (updates) => {\\n      state.config = { ...state.config, ...updates };\\n    },\\n    \\n    // Constants export\\n    LoadingStates,\\n    ProgressStages\\n  };\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/core/state/memory-optimization.js\",\"messages\":[{\"ruleId\":\"max-lines-per-function\",\"severity\":1,\"message\":\"Arrow function has too many lines (218). Maximum allowed is 150.\",\"line\":9,\"column\":38,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"exceed\",\"endLine\":277,\"endColumn\":2}],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":1,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\nimport { createLogger } from '../shared/utils/logger.js';\\n\\nconst logger = createLogger({ level: 2 });\\n * Memory Optimization Module\\n * Enhanced implementation with canvas pooling and buffer management\\n */\\n\\nexport const createMemoryOptimizer = (config = {}) => {\\n  const state = {\\n    isMonitoring: false,\\n    memoryUsage: {\\n      heapUsed: 0,\\n      heapTotal: 0,\\n      external: 0,\\n      rss: 0\\n    },\\n    thresholds: {\\n      warning: config.memoryPressureThreshold || 0.8,\\n      critical: 0.9\\n    },\\n    canvasPool: new Map(), // size -> canvas[]\\n    bufferPool: new Map(), // size -> buffer[]\\n    poolStats: {\\n      canvasHits: 0,\\n      canvasMisses: 0,\\n      bufferHits: 0,\\n      bufferMisses: 0,\\n      totalAllocated: 0,\\n      totalReused: 0\\n    }\\n  };\\n\\n  const startMonitoring = () => {\\n    if (state.isMonitoring) return;\\n    \\n    state.isMonitoring = true;\\n    console.log('📊 Memory monitoring started with pooling optimization');\\n    \\n    // Monitor memory usage every 30 seconds\\n    state.monitoringInterval = setInterval(() => {\\n      updateMemoryStats();\\n      \\n      const usage = state.memoryUsage;\\n      const pressureRatio = usage.heapUsed / usage.heapTotal;\\n      \\n      if (pressureRatio > state.thresholds.critical) {\\n        console.warn('🔴 Critical memory pressure detected:', {\\n          heapUsed: `${Math.round(usage.heapUsed / 1024 / 1024)  }MB`,\\n          heapTotal: `${Math.round(usage.heapTotal / 1024 / 1024)  }MB`,\\n          pressure: `${Math.round(pressureRatio * 100)  }%`\\n        });\\n        performAggressiveCleanup();\\n      } else if (pressureRatio > state.thresholds.warning) {\\n        console.warn('🟡 Memory pressure warning:', {\\n          heapUsed: `${Math.round(usage.heapUsed / 1024 / 1024)  }MB`,\\n          pressure: `${Math.round(pressureRatio * 100)  }%`\\n        });\\n        performMildCleanup();\\n      }\\n    }, 30000);\\n  };\\n\\n  const stopMonitoring = () => {\\n    if (!state.isMonitoring) return;\\n    \\n    state.isMonitoring = false;\\n    if (state.monitoringInterval) {\\n      clearInterval(state.monitoringInterval);\\n      state.monitoringInterval = null;\\n    }\\n  };\\n\\n  const updateMemoryStats = () => {\\n    if (typeof process !== 'undefined' && process.memoryUsage) {\\n      state.memoryUsage = process.memoryUsage();\\n    }\\n  };\\n\\n  const performMildCleanup = () => {\\n    // Trim canvas pool to 50% for each size\\n    for (const [size, canvases] of state.canvasPool.entries()) {\\n      if (canvases.length > 2) {\\n        const keepCount = Math.ceil(canvases.length / 2);\\n        state.canvasPool.set(size, canvases.slice(0, keepCount));\\n      }\\n    }\\n    \\n    // Trim buffer pool to 50%\\n    for (const [size, buffers] of state.bufferPool.entries()) {\\n      if (buffers.length > 2) {\\n        const keepCount = Math.ceil(buffers.length / 2);\\n        state.bufferPool.set(size, buffers.slice(0, keepCount));\\n      }\\n    }\\n    \\n    // Force garbage collection if available\\n    if (typeof global !== 'undefined' && global.gc) {\\n      global.gc();\\n    }\\n  };\\n\\n  const performAggressiveCleanup = () => {\\n    // Clear most of the pools, keeping only 1 item per size\\n    for (const [size, canvases] of state.canvasPool.entries()) {\\n      if (canvases.length > 1) {\\n        state.canvasPool.set(size, canvases.slice(0, 1));\\n      }\\n    }\\n    \\n    for (const [size, buffers] of state.bufferPool.entries()) {\\n      if (buffers.length > 1) {\\n        state.bufferPool.set(size, buffers.slice(0, 1));\\n      }\\n    }\\n    \\n    // Force multiple garbage collections\\n    if (typeof global !== 'undefined' && global.gc) {\\n      global.gc();\\n      setTimeout(() => global.gc(), 100);\\n    }\\n  };\\n\\n  // Canvas pooling for image processing\\n  const getCanvas = (width, height) => {\\n    const size = `${width}x${height}`;\\n    const pool = state.canvasPool.get(size) || [];\\n    \\n    if (pool.length > 0) {\\n      state.poolStats.canvasHits++;\\n      state.poolStats.totalReused++;\\n      return pool.pop();\\n    }\\n    \\n    state.poolStats.canvasMisses++;\\n    state.poolStats.totalAllocated++;\\n    \\n    // Create new canvas (browser environment)\\n    if (typeof document !== 'undefined') {\\n      const canvas = document.createElement('canvas');\\n      canvas.width = width;\\n      canvas.height = height;\\n      return canvas;\\n    }\\n    \\n    // Node.js environment - return a mock canvas-like object\\n    return {\\n      width,\\n      height,\\n      getContext: () => ({\\n        createImageData: (w, h) => ({ data: new Uint8ClampedArray(w * h * 4), width: w, height: h }),\\n        putImageData: () => {},\\n        getImageData: () => ({ data: new Uint8ClampedArray(width * height * 4), width, height })\\n      })\\n    };\\n  };\\n\\n  const returnCanvas = (canvas) => {\\n    const size = `${canvas.width}x${canvas.height}`;\\n    const pool = state.canvasPool.get(size) || [];\\n    \\n    // Limit pool size to prevent memory leaks\\n    if (pool.length < 5) {\\n      // Clear canvas before returning to pool\\n      const ctx = canvas.getContext && canvas.getContext('2d');\\n      if (ctx) {\\n        ctx.clearRect(0, 0, canvas.width, canvas.height);\\n      }\\n      \\n      pool.push(canvas);\\n      state.canvasPool.set(size, pool);\\n    }\\n  };\\n\\n  // Buffer pooling for data processing\\n  const getBuffer = (size) => {\\n    const pool = state.bufferPool.get(size) || [];\\n    \\n    if (pool.length > 0) {\\n      state.poolStats.bufferHits++;\\n      state.poolStats.totalReused++;\\n      const buffer = pool.pop();\\n      buffer.fill(0); // Clear buffer data\\n      return buffer;\\n    }\\n    \\n    state.poolStats.bufferMisses++;\\n    state.poolStats.totalAllocated++;\\n    \\n    return new ArrayBuffer(size);\\n  };\\n\\n  const returnBuffer = (buffer) => {\\n    const size = buffer.byteLength;\\n    const pool = state.bufferPool.get(size) || [];\\n    \\n    // Limit pool size to prevent memory leaks\\n    if (pool.length < 10) {\\n      pool.push(buffer);\\n      state.bufferPool.set(size, pool);\\n    }\\n  };\\n\\n  const createOptimizedBuffer = (streamId, maxSize) => {\\n    return {\\n      data: [],\\n      maxSize,\\n      streamId,\\n      add: (item) => {\\n        if (state.data) {\\n          state.data.push(item);\\n          if (state.data.length > maxSize) {\\n            state.data = state.data.slice(-maxSize);\\n          }\\n        }\\n      },\\n      clear: () => {\\n        if (state.data) {\\n          state.data = [];\\n        }\\n      },\\n      getSize: () => state.data ? state.data.length : 0\\n    };\\n  };\\n\\n  const cleanup = () => {\\n    stopMonitoring();\\n    \\n    // Clear all pools\\n    state.canvasPool.clear();\\n    state.bufferPool.clear();\\n    \\n    // Reset stats\\n    state.poolStats = {\\n      canvasHits: 0,\\n      canvasMisses: 0,\\n      bufferHits: 0,\\n      bufferMisses: 0,\\n      totalAllocated: 0,\\n      totalReused: 0\\n    };\\n    \\n    console.log('🧹 Memory optimizer cleanup completed');\\n  };\\n\\n  const getMemoryStats = () => {\\n    updateMemoryStats();\\n    return state.memoryUsage;\\n  };\\n\\n  const getPoolingStats = () => {\\n    return {\\n      ...state.poolStats,\\n      canvasPoolSizes: Array.from(state.canvasPool.entries()).map(([size, pool]) => ({ size, count: pool.length })),\\n      bufferPoolSizes: Array.from(state.bufferPool.entries()).map(([size, pool]) => ({ size, count: pool.length })),\\n      hitRate: {\\n        canvas: state.poolStats.canvasHits / (state.poolStats.canvasHits + state.poolStats.canvasMisses) || 0,\\n        buffer: state.poolStats.bufferHits / (state.poolStats.bufferHits + state.poolStats.bufferMisses) || 0\\n      },\\n      reuseRate: state.poolStats.totalReused / (state.poolStats.totalAllocated || 1)\\n    };\\n  };\\n\\n  return {\\n    startMonitoring,\\n    stopMonitoring,\\n    createOptimizedBuffer,\\n    getCanvas,\\n    returnCanvas,\\n    getBuffer,\\n    returnBuffer,\\n    cleanup,\\n    getMemoryStats,\\n    getPoolingStats,\\n    isMonitoring: () => state.isMonitoring\\n  };\\n};\\n\\n\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/core/state/streams.js\",\"messages\":[{\"ruleId\":null,\"nodeType\":null,\"fatal\":true,\"severity\":2,\"message\":\"Parsing error: Unexpected token ,\",\"line\":356,\"column\":34}],\"suppressedMessages\":[],\"errorCount\":1,\"fatalErrorCount\":1,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Stream Abstraction Layer\\n * Extends pipeline concept to handle continuous data streams\\n * Following functional programming patterns with factory functions\\n */\\n\\nimport { createPipeline } from '../pipeline/pipeline.ts';\\nimport { createMemoryOptimizer } from './memory-optimization.js';\\nimport { createAdaptiveBatchScheduler } from './adaptive-batching.js';\\n\\n// Stream buffer factory for temporal data management\\nexport const createStreamBuffer = (config = {}) => {\\n  const state = {\\n    maxSize: config.maxSize || 1000,\\n    data: [],\\n    windowMs: config.windowMs || 1000\\n  };\\n\\n  const add = (item) => {\\n    const timestampedItem = {\\n      ...item,\\n      bufferTimestamp: performance.now()\\n    };\\n\\n    state.data.push(timestampedItem);\\n\\n    // Remove old items beyond max size\\n    if (state.data.length > state.maxSize) {\\n      state.data = state.data.slice(-state.maxSize);\\n    }\\n\\n    // Remove items outside time window\\n    const cutoff = performance.now() - state.windowMs;\\n    state.data = state.data.filter(item => item.bufferTimestamp > cutoff);\\n\\n    return timestampedItem;\\n  };\\n\\n  const getLatest = (count = 1) => {\\n    return state.data.slice(-count);\\n  };\\n\\n  const getInWindow = (windowMs = state.windowMs) => {\\n    const cutoff = performance.now() - windowMs;\\n    return state.data.filter(item => item.bufferTimestamp > cutoff);\\n  };\\n\\n  const getClosest = (targetTimestamp, toleranceMs = 50) => {\\n    let closest = null;\\n    let minDiff = Infinity;\\n\\n    for (const item of state.data) {\\n      const diff = Math.abs(item.timestamp - targetTimestamp);\\n      if (diff < minDiff && diff <= toleranceMs) {\\n        minDiff = diff;\\n        closest = item;\\n      }\\n    }\\n\\n    return closest;\\n  };\\n\\n  const clear = () => {\\n    state.data = [];\\n  };\\n\\n  const getSize = () => state.data.length;\\n\\n  return {\\n    add,\\n    getLatest,\\n    getInWindow, \\n    getClosest,\\n    clear,\\n    getSize,\\n    getData: () => [...state.data] // Return copy for immutability\\n  };\\n};\\n\\n// Data stream factory following your functional patterns\\nexport const createDataStream = (config = {}) => {\\n  const state = {\\n    id: config.id || crypto.randomUUID(),\\n    type: config.type || 'generic',\\n    sampleRate: config.sampleRate || 30,\\n    buffer: createStreamBuffer({\\n      maxSize: config.bufferSize || 1000,\\n      windowMs: config.windowMs || 5000\\n    }),\\n    pipeline: null,\\n    processors: config.processors || [],\\n    isActive: false,\\n    metadata: {\\n      ...config.metadata,\\n      createdAt: Date.now(),\\n      totalProcessed: 0,\\n      lastProcessed: null\\n    },\\n    callbacks: {\\n      onData: [],\\n      onError: [],\\n      onStatusChange: []\\n    }\\n  };\\n\\n  // Initialize pipeline if processors provided (except for simple test processors)\\n  if (config.processors && config.processors.length > 0 && config.usePipeline !== false) {\\n    try {\\n      state.pipeline = createPipeline({\\n        processors: config.processors,\\n        ...config.pipelineConfig\\n      });\\n    } catch (error) {\\n      // If pipeline creation fails, use simple processor chain\\n      console.warn('Pipeline creation failed, using simple processor chain:', error);\\n    }\\n  }\\n\\n  const start = async () => {\\n    if (state.isActive) return true;\\n\\n    try {\\n      // Initialize pipeline if it exists\\n      if (state.pipeline && state.pipeline.initialize) {\\n        await state.pipeline.initialize(config.pipelineConfig || {});\\n      }\\n\\n      state.isActive = true;\\n      state.metadata.startedAt = Date.now();\\n      \\n      // Notify status change\\n      state.callbacks.onStatusChange.forEach(cb => {\\n        try {\\n          cb({ status: 'started', stream: state });\\n        } catch (error) {\\n          console.warn('Status change callback error:', error);\\n        }\\n      });\\n\\n      return true;\\n    } catch (error) {\\n      state.callbacks.onError.forEach(cb => {\\n        try {\\n          cb(error);\\n        } catch (cbError) {\\n          console.warn('Error callback failed:', cbError);\\n        }\\n      });\\n      throw error;\\n    }\\n  };\\n\\n  const stop = () => {\\n    if (!state.isActive) return;\\n\\n    state.isActive = false;\\n    state.metadata.stoppedAt = Date.now();\\n\\n    // Cleanup pipeline if it has cleanup method\\n    if (state.pipeline && state.pipeline.cleanup) {\\n      try {\\n        state.pipeline.cleanup();\\n      } catch (error) {\\n        console.warn('Pipeline cleanup error:', error);\\n      }\\n    }\\n\\n    // Notify status change\\n    state.callbacks.onStatusChange.forEach(cb => {\\n      try {\\n        cb({ status: 'stopped', stream: state });\\n      } catch (error) {\\n        console.warn('Status change callback error:', error);\\n      }\\n    });\\n  };\\n\\n  const process = async (data) => {\\n    if (!state.isActive) {\\n      throw new Error(`Stream ${state.id} is not active`);\\n    }\\n\\n    const startTime = performance.now();\\n    \\n    try {\\n      // Add stream metadata to data\\n      const enrichedData = {\\n        ...data,\\n        timestamp: data.timestamp || Date.now(),\\n        streamId: state.id,\\n        streamType: state.type,\\n        sampleRate: state.sampleRate\\n      };\\n\\n      let result = enrichedData;\\n\\n      // Process through pipeline if available\\n      if (state.pipeline) {\\n        result = await state.pipeline.process(enrichedData);\\n      } else if (state.processors && state.processors.length > 0) {\\n        // Simple processor chain for testing\\n        for (const processor of state.processors) {\\n          if (processor.process) {\\n            result = await processor.process(result);\\n          }\\n        }\\n      }\\n\\n      // Add processing metadata\\n      const finalResult = {\\n        ...result,\\n        processingTime: performance.now() - startTime,\\n        streamId: state.id,\\n        streamType: state.type\\n      };\\n\\n      // Add to buffer\\n      state.buffer.add(finalResult);\\n\\n      // Update metadata\\n      state.metadata.totalProcessed++;\\n      state.metadata.lastProcessed = Date.now();\\n\\n      // Notify data callbacks\\n      state.callbacks.onData.forEach(cb => {\\n        try {\\n          cb(finalResult);\\n        } catch (error) {\\n          console.warn('Data callback error:', error);\\n        }\\n      });\\n\\n      return finalResult;\\n\\n    } catch (error) {\\n      // Notify error callbacks\\n      state.callbacks.onError.forEach(cb => {\\n        try {\\n          cb(error);\\n        } catch (cbError) {\\n          console.warn('Error callback failed:', cbError);\\n        }\\n      });\\n      throw error;\\n    }\\n  };\\n\\n  // Event listener pattern\\n  const onData = (callback) => {\\n    state.callbacks.onData.push(callback);\\n    \\n    // Return unsubscribe function\\n    return () => {\\n      const index = state.callbacks.onData.indexOf(callback);\\n      if (index !== -1) {\\n        state.callbacks.onData.splice(index, 1);\\n      }\\n    };\\n  };\\n\\n  const onError = (callback) => {\\n    state.callbacks.onError.push(callback);\\n    \\n    return () => {\\n      const index = state.callbacks.onError.indexOf(callback);\\n      if (index !== -1) {\\n        state.callbacks.onError.splice(index, 1);\\n      }\\n    };\\n  };\\n\\n  const onStatusChange = (callback) => {\\n    state.callbacks.onStatusChange.push(callback);\\n    \\n    return () => {\\n      const index = state.callbacks.onStatusChange.indexOf(callback);\\n      if (index !== -1) {\\n        state.callbacks.onStatusChange.splice(index, 1);\\n      }\\n    };\\n  };\\n\\n  // Getters following functional patterns\\n  const getId = () => state.id;\\n  const getType = () => state.type;\\n  const getSampleRate = () => state.sampleRate;\\n  const isActive = () => state.isActive;\\n  const getBuffer = () => state.buffer;\\n  const getMetadata = () => ({ ...state.metadata }); // Return copy\\n  const getStats = () => ({\\n    id: state.id,\\n    type: state.type,\\n    sampleRate: state.sampleRate,\\n    isActive: state.isActive,\\n    bufferSize: state.buffer.getSize(),\\n    totalProcessed: state.metadata.totalProcessed,\\n    uptime: state.metadata.startedAt ? Date.now() - state.metadata.startedAt : 0\\n  });\\n\\n  return {\\n    // Core methods\\n    start,\\n    stop,\\n    process,\\n    \\n    // Event handlers\\n    onData,\\n    onError,\\n    onStatusChange,\\n    \\n    // Getters\\n    getId,\\n    getType,\\n    getSampleRate,\\n    isActive,\\n    getBuffer,\\n    getMetadata,\\n    getStats\\n  };\\n};\\n\\n// Stream factory registry for different stream types\\nexport const createStreamFactory = () => {\\n  const streamTypes = new Map();\\n  \\n  const register = (type, factory) => {\\n    streamTypes.set(type, factory);\\n  };\\n\\n  const create = (type, config = {}) => {\\n    const factory = streamTypes.get(type);\\n    if (!factory) {\\n      throw new Error(`Unknown stream type: ${type}`);\\n    }\\n    \\n    return factory({\\n      ...config,\\n      type\\n    });\\n  };\\n\\n  const getAvailableTypes = () => Array.from(streamTypes.keys());\\n\\n  return {\\n    register,\\n    create,\\n    getAvailableTypes\\n  };\\n};\\n\\n// Default stream factory instance\\nexport const streamFactory = createStreamFactory();\\n\\n// Register basic stream types\\nstreamFactory.register('generic', createDataStream);\\nstreamFactory.register('video', (,config) => createDataStream({ \\n  ...config, \\n  sampleRate: 30,\\n  bufferSize: 60 \\n}));\\nstreamFactory.register('audio', (,config) => createDataStream({ \\n  ...config, \\n  sampleRate: 16000,\\n  bufferSize: 1600 \\n}));\\nstreamFactory.register('sensor', (,config) => createDataStream({ \\n  ...config, \\n  sampleRate: 100,\\n  bufferSize: 500 \\n}));\\n\\n// Eye tracking stream with high-frequency data support and optimizations\\nstreamFactory.register('eyetracking', (,config) => {\\n  const optimizedConfig = {\\n    ...config, \\n    sampleRate: 200, // 200Hz for eye tracking\\n    bufferSize: 2000, // Larger buffer for high-frequency data\\n    windowMs: 10000, // 10 second window for eye tracking\\n    enableMemoryOptimization: config.enableMemoryOptimization !== false,\\n    enableAdaptiveBatching: config.enableAdaptiveBatching !== false,\\n    metadata: {\\n      ...config.metadata,\\n      streamType: 'eyetracking',\\n      dataTypes: ['gaze', 'eye_state', 'imu', 'events'],\\n      capabilities: ['real_time_streaming', 'semantic_enhancement', 'device_control', 'memory_optimization', 'adaptive_batching']\\n    }\\n  };\\n\\n  const stream = createDataStream(optimizedConfig);\\n\\n  // Add memory optimization if enabled\\n  if (optimizedConfig.enableMemoryOptimization) {\\n    const memoryOptimizer = createMemoryOptimizer({\\n      pool: { maxPoolSize: 500 },\\n      memoryPressureThreshold: 0.85,\\n      gcInterval: 15000\\n    });\\n    \\n    // Override buffer with optimized version\\n    const originalBuffer = stream.getBuffer();\\n    const optimizedBuffer = memoryOptimizer.createOptimizedBuffer(\\n      stream.getId(),\\n      optimizedConfig.bufferSize\\n    );\\n    \\n    // Start memory monitoring\\n    memoryOptimizer.startMonitoring();\\n    \\n    // Extend stream with memory optimization\\n    const originalCleanup = stream.cleanup || (() => {});\\n    stream.cleanup = () => {\\n      memoryOptimizer.cleanup();\\n      originalCleanup();\\n    };\\n    \\n    stream.getMemoryOptimizer = () => memoryOptimizer;\\n  }\\n\\n  // Add adaptive batching if enabled\\n  if (optimizedConfig.enableAdaptiveBatching) {\\n    const batchScheduler = createAdaptiveBatchScheduler({\\n      strategy: 'quality_aware',\\n      targetLatency: 25, // 25ms for eye tracking\\n      maxBatchSize: 15,\\n      minBatchSize: 1,\\n      baseInterval: 5 // 5ms base interval for 200Hz\\n    });\\n    \\n    // Create batch processor for stream data\\n    const batchProcessor = batchScheduler.createBatchProcessor(async (items) => {\\n      return Promise.all(items.map(async item => {\\n        // Process each item through existing stream pipeline\\n        return await stream.process(item);\\n      }));\\n    });\\n    \\n    stream.getBatchScheduler = () => batchScheduler;\\n    stream.addBatchedData = (items) => batchProcessor.addToQueue(items);\\n  }\\n\\n  return stream;\\n});\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/features/emotion-analysis/emotion-analysis-pipeline.js\",\"messages\":[{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'createAnalysisResult' is defined but never used. Allowed unused vars must match /^_/u.\",\"line\":10,\"column\":3,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":10,\"endColumn\":23,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"createAnalysisResult\"},\"fix\":{\"range\":[304,328],\"text\":\"\"},\"desc\":\"Remove unused variable 'createAnalysisResult'.\"}]},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'createEmotionResult' is defined but never used. Allowed unused vars must match /^_/u.\",\"line\":11,\"column\":3,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":11,\"endColumn\":22,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"createEmotionResult\"},\"fix\":{\"range\":[328,351],\"text\":\"\"},\"desc\":\"Remove unused variable 'createEmotionResult'.\"}]},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'faceDetection' is assigned a value but never used. Allowed unused vars must match /^_/u.\",\"line\":23,\"column\":9,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":23,\"endColumn\":22,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"faceDetection\"},\"fix\":{\"range\":[736,763],\"text\":\"\"},\"desc\":\"Remove unused variable 'faceDetection'.\"}]},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'initConfig' is assigned a value but never used. Allowed unused args must match /^_/u.\",\"line\":38,\"column\":24,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":38,\"endColumn\":34,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"initConfig\"},\"fix\":{\"range\":[1123,1138],\"text\":\"\"},\"desc\":\"Remove unused variable 'initConfig'.\"}]},{\"ruleId\":\"func-style\",\"severity\":1,\"message\":\"Expected a function expression.\",\"line\":158,\"column\":1,\"nodeType\":\"FunctionDeclaration\",\"messageId\":\"expression\",\"endLine\":182,\"endColumn\":2},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'initializeFaceDetection' is defined but never used. Allowed unused vars must match /^_/u.\",\"line\":158,\"column\":16,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":158,\"endColumn\":39,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"initializeFaceDetection\"},\"fix\":{\"range\":[4986,5681],\"text\":\"\"},\"desc\":\"Remove unused variable 'initializeFaceDetection'.\"}]},{\"ruleId\":\"no-undef\",\"severity\":2,\"message\":\"'faceDetection' is not defined.\",\"line\":163,\"column\":3,\"nodeType\":\"Identifier\",\"messageId\":\"undef\",\"endLine\":163,\"endColumn\":16},{\"ruleId\":\"no-undef\",\"severity\":2,\"message\":\"'FaceDetection' is not defined.\",\"line\":163,\"column\":23,\"nodeType\":\"Identifier\",\"messageId\":\"undef\",\"endLine\":163,\"endColumn\":36},{\"ruleId\":\"no-undef\",\"severity\":2,\"message\":\"'faceDetection' is not defined.\",\"line\":167,\"column\":3,\"nodeType\":\"Identifier\",\"messageId\":\"undef\",\"endLine\":167,\"endColumn\":16},{\"ruleId\":\"no-undef\",\"severity\":2,\"message\":\"'faceDetection' is not defined.\",\"line\":174,\"column\":3,\"nodeType\":\"Identifier\",\"messageId\":\"undef\",\"endLine\":174,\"endColumn\":16},{\"ruleId\":\"no-undef\",\"severity\":2,\"message\":\"'faceDetection' is not defined.\",\"line\":179,\"column\":3,\"nodeType\":\"Identifier\",\"messageId\":\"undef\",\"endLine\":179,\"endColumn\":16},{\"ruleId\":\"func-style\",\"severity\":1,\"message\":\"Expected a function expression.\",\"line\":185,\"column\":1,\"nodeType\":\"FunctionDeclaration\",\"messageId\":\"expression\",\"endLine\":238,\"endColumn\":2},{\"ruleId\":\"func-style\",\"severity\":1,\"message\":\"Expected a function expression.\",\"line\":241,\"column\":1,\"nodeType\":\"FunctionDeclaration\",\"messageId\":\"expression\",\"endLine\":273,\"endColumn\":2},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'detectFaces' is defined but never used. Allowed unused vars must match /^_/u.\",\"line\":241,\"column\":16,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":241,\"endColumn\":27,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"detectFaces\"},\"fix\":{\"range\":[7453,8567],\"text\":\"\"},\"desc\":\"Remove unused variable 'detectFaces'.\"}]},{\"ruleId\":\"no-undef\",\"severity\":2,\"message\":\"'faceDetection' is not defined.\",\"line\":242,\"column\":8,\"nodeType\":\"Identifier\",\"messageId\":\"undef\",\"endLine\":242,\"endColumn\":21},{\"ruleId\":\"no-undef\",\"severity\":2,\"message\":\"'faceDetection' is not defined.\",\"line\":254,\"column\":9,\"nodeType\":\"Identifier\",\"messageId\":\"undef\",\"endLine\":254,\"endColumn\":22},{\"ruleId\":\"no-undef\",\"severity\":2,\"message\":\"'faceDetection' is not defined.\",\"line\":257,\"column\":19,\"nodeType\":\"Identifier\",\"messageId\":\"undef\",\"endLine\":257,\"endColumn\":32},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '-'. Use parentheses to clarify the intended order of operations.\",\"line\":266,\"column\":51,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":266,\"endColumn\":52},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '-'. Use parentheses to clarify the intended order of operations.\",\"line\":266,\"column\":69,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":266,\"endColumn\":70},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '-'. Use parentheses to clarify the intended order of operations.\",\"line\":267,\"column\":51,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":267,\"endColumn\":52},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '-'. Use parentheses to clarify the intended order of operations.\",\"line\":267,\"column\":70,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":267,\"endColumn\":71},{\"ruleId\":\"func-style\",\"severity\":1,\"message\":\"Expected a function expression.\",\"line\":276,\"column\":1,\"nodeType\":\"FunctionDeclaration\",\"messageId\":\"expression\",\"endLine\":293,\"endColumn\":2},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'extractFaceRegion' is defined but never used. Allowed unused vars must match /^_/u.\",\"line\":276,\"column\":10,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":276,\"endColumn\":27,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"extractFaceRegion\"},\"fix\":{\"range\":[8603,9248],\"text\":\"\"},\"desc\":\"Remove unused variable 'extractFaceRegion'.\"}]},{\"ruleId\":\"func-style\",\"severity\":1,\"message\":\"Expected a function expression.\",\"line\":296,\"column\":1,\"nodeType\":\"FunctionDeclaration\",\"messageId\":\"expression\",\"endLine\":308,\"endColumn\":2},{\"ruleId\":\"func-style\",\"severity\":1,\"message\":\"Expected a function expression.\",\"line\":311,\"column\":1,\"nodeType\":\"FunctionDeclaration\",\"messageId\":\"expression\",\"endLine\":323,\"endColumn\":2}],\"suppressedMessages\":[],\"errorCount\":15,\"fatalErrorCount\":0,\"warningCount\":10,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Real Emotion Analysis Pipeline - No Mocks, No Fallbacks\\n * Pure CNN implementation with MediaPipe face detection integration\\n */\\n\\nimport { createPipeline } from '../../core/pipeline/pipeline.ts';\\nimport { createPipelineConfig } from '../../core/pipeline/pipeline-config.js';\\nimport { \\n  Capability,\\n  createAnalysisResult,\\n  createEmotionResult,\\n  createPerformanceProfile\\n} from '../../core/configuration/types.ts';\\nimport { EMOTION_LABELS, createRealCNNModel } from './real-cnn-model.js';\\n\\n/**\\n * Creates real emotion analysis pipeline with face detection\\n */\\nexport const createEmotionAnalysisPipeline = (userConfig = {}) => {\\n  const config = createPipelineConfig('emotion-analysis', userConfig);\\n  \\n  let cnnModel = null;\\n  const faceDetection = null;\\n  let isInitialized = false;\\n\\n  return createPipeline({\\n    name: 'emotion-analysis',\\n    capabilities: [Capability.EXPRESSION_ANALYSIS],\\n    performance: createPerformanceProfile({\\n      fps: 30,\\n      latency: '5-15ms',\\n      modelSize: '1.2MB',\\n      cpuUsage: 'medium',\\n      memoryUsage: 'low',\\n      batteryImpact: 'low'\\n    }),\\n\\n    initialize: async (initConfig = {}) => {\\n      try {\\n        console.log('🚀 Initializing real emotion analysis pipeline...');\\n        \\n        // Skip MediaPipe initialization on server - client will send pre-cropped faces\\n        console.log('💡 Running in server mode - expecting pre-cropped face images from client');\\n        \\n        // Initialize real CNN model\\n        cnnModel = createRealCNNModel();\\n        await cnnModel.initialize();\\n        \\n        isInitialized = true;\\n        console.log('✅ Real emotion analysis pipeline initialized successfully');\\n        return true;\\n        \\n      } catch (error) {\\n        console.error('❌ Emotion analysis pipeline initialization failed:', error.message);\\n        throw error;\\n      }\\n    },\\n\\n    process: async (frame) => {\\n      if (!isInitialized || !cnnModel) {\\n        throw new Error('Emotion analysis pipeline not initialized');\\n      }\\n\\n      const startTime = performance.now();\\n\\n      try {\\n        // Processing frame with real CNN\\n        \\n        // Convert frame to ImageData if needed\\n        const imageData = await convertFrameToImageData(frame);\\n        \\n        // Assume the entire image is a face (client should send cropped face regions)\\n        const emotionResult = await cnnModel.predictEmotion(imageData);\\n        \\n        console.log('🎯 Pipeline received CNN result:', {\\n          emotion: emotionResult.emotion,\\n          confidence: emotionResult.confidence,\\n          emotions: emotionResult.emotions\\n        });\\n        \\n        const results = [{\\n          bbox: [0, 0, imageData.width, imageData.height], // Full image\\n          emotion: {\\n            emotion: emotionResult.emotion,\\n            confidence: emotionResult.confidence,\\n            probabilities: emotionResult.emotions,\\n            emotions: emotionResult.emotions,\\n            valence: calculateValence(emotionResult.emotions),\\n            arousal: calculateArousal(emotionResult.emotions)\\n          },\\n          confidence: emotionResult.confidence\\n        }];\\n\\n        const processingTime = performance.now() - startTime;\\n        \\n        const analysisResult = {\\n          faces: results,\\n          confidence: results.length > 0 ? Math.max(...results.map(r => r.confidence)) : 0,\\n          processingTime,\\n          timestamp: Date.now(),\\n          source: 'real-emotion-cnn',\\n          metadata: {\\n            emotionLabels: EMOTION_LABELS,\\n            facesDetected: results.length,\\n            model: 'real-cnn-v1.0',\\n            processingPipeline: 'Real CNN'\\n          }\\n        };\\n        \\n        console.log('✅ Pipeline returning result:', {\\n          faceCount: analysisResult.faces.length,\\n          firstFaceEmotion: analysisResult.faces[0]?.emotion?.emotion,\\n          firstFaceConfidence: analysisResult.faces[0]?.emotion?.confidence\\n        });\\n        \\n        return analysisResult;\\n\\n      } catch (error) {\\n        console.error('❌ Pipeline processing error:', error.message);\\n        console.error('❌ Pipeline error stack:', error.stack);\\n        throw error;\\n      }\\n    },\\n\\n    cleanup: async () => {\\n      try {\\n        if (cnnModel) {\\n          await cnnModel.cleanup();\\n          cnnModel = null;\\n        }\\n        \\n// No MediaPipe cleanup needed in server mode\\n        \\n        isInitialized = false;\\n        console.log('✅ Real emotion analysis pipeline cleaned up');\\n        return true;\\n        \\n      } catch (error) {\\n        console.error('Emotion analysis cleanup failed:', error.message);\\n        return false;\\n      }\\n    },\\n\\n    getHealthStatus: () => ({\\n      healthy: isInitialized && !!cnnModel,\\n      runtime: 'browser',\\n      backend: 'real-cnn',\\n      modelLoaded: cnnModel?.isLoaded || false,\\n      faceDetectionAvailable: false // Server mode\\n    }),\\n\\n    getConfig: () => ({ ...config }),\\n    isInitialized: () => isInitialized\\n  });\\n};\\n\\n// Initialize MediaPipe Face Detection\\nasync function initializeFaceDetection() {\\n  if (typeof FaceDetection === 'undefined') {\\n    throw new Error('MediaPipe FaceDetection not available. Include MediaPipe scripts.');\\n  }\\n\\n  faceDetection = new FaceDetection({\\n    locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/face_detection/${file}`\\n  });\\n\\n  faceDetection.setOptions({\\n    model: 'short',\\n    minDetectionConfidence: 0.5\\n  });\\n\\n  // Set up result callback\\n  let detectionResults = null;\\n  faceDetection.onResults((results) => {\\n    detectionResults = results;\\n  });\\n\\n  // Store reference for later use\\n  faceDetection._getResults = () => detectionResults;\\n\\n  console.log('✅ MediaPipe Face Detection initialized');\\n}\\n\\n// Convert various frame formats to ImageData\\nasync function convertFrameToImageData(frame) {\\n  // Check if we're in server environment (Bun) or browser\\n  const isServer = typeof window === 'undefined';\\n  \\n  if (!isServer && frame instanceof ImageData) {\\n    return frame;\\n  }\\n\\n  if (frame.data && frame.width && frame.height) {\\n    // Create ImageData-like structure compatible with server\\n    if (isServer) {\\n      return {\\n        data: new Uint8ClampedArray(frame.data),\\n        width: frame.width,\\n        height: frame.height\\n      };\\n    } else {\\n      return new ImageData(new Uint8ClampedArray(frame.data), frame.width, frame.height);\\n    }\\n  }\\n\\n  if (frame.data instanceof Buffer || frame.data instanceof Uint8Array) {\\n    // For server environment, we can't decode images easily\\n    // Assume this is already decoded pixel data and create a basic structure\\n    if (isServer) {\\n      return {\\n        data: new Uint8ClampedArray(frame.data),\\n        width: frame.width || 640,\\n        height: frame.height || 480\\n      };\\n    } else {\\n      // Browser environment - can decode images\\n      const canvas = document.createElement('canvas');\\n      const ctx = canvas.getContext('2d');\\n      \\n      // Create image from buffer\\n      const blob = new Blob([frame.data]);\\n      const img = new Image();\\n      \\n      return new Promise((resolve, reject) => {\\n        img.onload = () => {\\n          canvas.width = img.width;\\n          canvas.height = img.height;\\n          ctx.drawImage(img, 0, 0);\\n          resolve(ctx.getImageData(0, 0, img.width, img.height));\\n        };\\n        img.onerror = reject;\\n        img.src = URL.createObjectURL(blob);\\n      });\\n    }\\n  }\\n\\n  throw new Error('Unsupported frame format for emotion analysis');\\n}\\n\\n// Detect faces in image\\nasync function detectFaces(imageData) {\\n  if (!faceDetection) {\\n    throw new Error('Face detection not initialized');\\n  }\\n\\n  // Create canvas from ImageData\\n  const canvas = document.createElement('canvas');\\n  canvas.width = imageData.width;\\n  canvas.height = imageData.height;\\n  const ctx = canvas.getContext('2d');\\n  ctx.putImageData(imageData, 0, 0);\\n\\n  // Send to MediaPipe\\n  await faceDetection.send({ image: canvas });\\n  \\n  // Get results\\n  const results = faceDetection._getResults();\\n  \\n  if (!results || !results.detections) {\\n    return [];\\n  }\\n\\n  // Convert MediaPipe detections to face objects\\n  return results.detections.map(detection => ({\\n    bbox: {\\n      x: Math.round(detection.boundingBox.xCenter * imageData.width - (detection.boundingBox.width * imageData.width / 2)),\\n      y: Math.round(detection.boundingBox.yCenter * imageData.height - (detection.boundingBox.height * imageData.height / 2)),\\n      width: Math.round(detection.boundingBox.width * imageData.width),\\n      height: Math.round(detection.boundingBox.height * imageData.height)\\n    },\\n    confidence: detection.score[0]\\n  }));\\n}\\n\\n// Extract face region from image\\nfunction extractFaceRegion(imageData, bbox) {\\n  const canvas = document.createElement('canvas');\\n  canvas.width = bbox.width;\\n  canvas.height = bbox.height;\\n  const ctx = canvas.getContext('2d');\\n\\n  // Create temp canvas with full image\\n  const tempCanvas = document.createElement('canvas');\\n  tempCanvas.width = imageData.width;\\n  tempCanvas.height = imageData.height;\\n  const tempCtx = tempCanvas.getContext('2d');\\n  tempCtx.putImageData(imageData, 0, 0);\\n\\n  // Extract face region\\n  ctx.drawImage(tempCanvas, bbox.x, bbox.y, bbox.width, bbox.height, 0, 0, bbox.width, bbox.height);\\n\\n  return ctx.getImageData(0, 0, bbox.width, bbox.height);\\n}\\n\\n// Calculate valence from emotion probabilities\\nfunction calculateValence(emotions) {\\n  const valenceMap = {\\n    happy: 0.8, surprised: 0.3, neutral: 0.0,\\n    angry: -0.6, disgusted: -0.7, fearful: -0.5, sad: -0.8\\n  };\\n\\n  let valence = 0;\\n  for (const [emotion, probability] of Object.entries(emotions)) {\\n    valence += probability * (valenceMap[emotion] || 0);\\n  }\\n\\n  return Math.round(valence * 1000) / 1000;\\n}\\n\\n// Calculate arousal from emotion probabilities\\nfunction calculateArousal(emotions) {\\n  const arousalMap = {\\n    happy: 0.7, surprised: 0.9, angry: 0.8, fearful: 0.6,\\n    disgusted: 0.4, sad: -0.3, neutral: 0.0\\n  };\\n\\n  let arousal = 0;\\n  for (const [emotion, probability] of Object.entries(emotions)) {\\n    arousal += probability * (arousalMap[emotion] || 0);\\n  }\\n\\n  return Math.round(arousal * 1000) / 1000;\\n}\\n\\nexport { EMOTION_LABELS };\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/features/emotion-analysis/real-cnn-model.js\",\"messages\":[{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'CNN_CONFIG' is assigned a value but never used. Allowed unused vars must match /^_/u.\",\"line\":18,\"column\":7,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":18,\"endColumn\":17,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"CNN_CONFIG\"},\"fix\":{\"range\":[436,787],\"text\":\"\"},\"desc\":\"Remove unused variable 'CNN_CONFIG'.\"}]},{\"ruleId\":\"func-style\",\"severity\":1,\"message\":\"Expected a function expression.\",\"line\":31,\"column\":1,\"nodeType\":\"FunctionDeclaration\",\"messageId\":\"expression\",\"endLine\":56,\"endColumn\":2},{\"ruleId\":\"func-style\",\"severity\":1,\"message\":\"Expected a function expression.\",\"line\":59,\"column\":1,\"nodeType\":\"FunctionDeclaration\",\"messageId\":\"expression\",\"endLine\":72,\"endColumn\":2},{\"ruleId\":\"func-style\",\"severity\":1,\"message\":\"Expected a function expression.\",\"line\":75,\"column\":1,\"nodeType\":\"FunctionDeclaration\",\"messageId\":\"expression\",\"endLine\":87,\"endColumn\":2},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '-'. Use parentheses to clarify the intended order of operations.\",\"line\":83,\"column\":33,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":83,\"endColumn\":34},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '-'. Use parentheses to clarify the intended order of operations.\",\"line\":83,\"column\":37,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":83,\"endColumn\":38},{\"ruleId\":\"func-style\",\"severity\":1,\"message\":\"Expected a function expression.\",\"line\":90,\"column\":1,\"nodeType\":\"FunctionDeclaration\",\"messageId\":\"expression\",\"endLine\":96,\"endColumn\":2},{\"ruleId\":\"func-style\",\"severity\":1,\"message\":\"Expected a function expression.\",\"line\":99,\"column\":1,\"nodeType\":\"FunctionDeclaration\",\"messageId\":\"expression\",\"endLine\":103,\"endColumn\":2},{\"ruleId\":\"func-style\",\"severity\":1,\"message\":\"Expected a function expression.\",\"line\":117,\"column\":1,\"nodeType\":\"FunctionDeclaration\",\"messageId\":\"expression\",\"endLine\":159,\"endColumn\":2},{\"ruleId\":\"max-params\",\"severity\":1,\"message\":\"Function 'conv2d' has too many parameters (7). Maximum allowed is 6.\",\"line\":117,\"column\":1,\"nodeType\":\"FunctionDeclaration\",\"messageId\":\"exceed\",\"endLine\":117,\"endColumn\":16},{\"ruleId\":\"max-depth\",\"severity\":1,\"message\":\"Blocks are nested too deeply (6). Maximum allowed is 5.\",\"line\":135,\"column\":13,\"nodeType\":\"ForStatement\",\"messageId\":\"tooDeeply\",\"endLine\":149,\"endColumn\":14},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":136,\"column\":32,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":136,\"endColumn\":33},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":136,\"column\":41,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":136,\"endColumn\":42},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":137,\"column\":32,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":137,\"endColumn\":33},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":137,\"column\":41,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":137,\"endColumn\":42},{\"ruleId\":\"max-depth\",\"severity\":1,\"message\":\"Blocks are nested too deeply (7). Maximum allowed is 5.\",\"line\":139,\"column\":15,\"nodeType\":\"IfStatement\",\"messageId\":\"tooDeeply\",\"endLine\":148,\"endColumn\":16},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":140,\"column\":66,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":140,\"endColumn\":67},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":140,\"column\":79,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":140,\"endColumn\":80},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":140,\"column\":79,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":140,\"endColumn\":80},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":141,\"column\":49,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":141,\"endColumn\":50},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":141,\"column\":62,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":141,\"endColumn\":63},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":141,\"column\":67,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":141,\"endColumn\":68},{\"ruleId\":\"func-style\",\"severity\":1,\"message\":\"Expected a function expression.\",\"line\":162,\"column\":1,\"nodeType\":\"FunctionDeclaration\",\"messageId\":\"expression\",\"endLine\":200,\"endColumn\":2},{\"ruleId\":\"max-params\",\"severity\":1,\"message\":\"Function 'conv2dMultiChannel' has too many parameters (7). Maximum allowed is 6.\",\"line\":162,\"column\":1,\"nodeType\":\"FunctionDeclaration\",\"messageId\":\"exceed\",\"endLine\":162,\"endColumn\":28},{\"ruleId\":\"max-depth\",\"severity\":1,\"message\":\"Blocks are nested too deeply (6). Maximum allowed is 5.\",\"line\":180,\"column\":13,\"nodeType\":\"ForStatement\",\"messageId\":\"tooDeeply\",\"endLine\":190,\"endColumn\":14},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":181,\"column\":32,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":181,\"endColumn\":33},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":181,\"column\":41,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":181,\"endColumn\":42},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":182,\"column\":32,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":182,\"endColumn\":33},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":182,\"column\":41,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":182,\"endColumn\":42},{\"ruleId\":\"max-depth\",\"severity\":1,\"message\":\"Blocks are nested too deeply (7). Maximum allowed is 5.\",\"line\":184,\"column\":15,\"nodeType\":\"IfStatement\",\"messageId\":\"tooDeeply\",\"endLine\":189,\"endColumn\":16},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":185,\"column\":66,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":185,\"endColumn\":67},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":185,\"column\":79,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":185,\"endColumn\":80},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":185,\"column\":79,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":185,\"endColumn\":80},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":186,\"column\":49,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":186,\"endColumn\":50},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":186,\"column\":62,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":186,\"endColumn\":63},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":186,\"column\":67,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":186,\"endColumn\":68},{\"ruleId\":\"func-style\",\"severity\":1,\"message\":\"Expected a function expression.\",\"line\":203,\"column\":1,\"nodeType\":\"FunctionDeclaration\",\"messageId\":\"expression\",\"endLine\":237,\"endColumn\":2},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":222,\"column\":30,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":222,\"endColumn\":31},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":222,\"column\":39,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":222,\"endColumn\":40},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":223,\"column\":30,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":223,\"endColumn\":31},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":223,\"column\":39,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":223,\"endColumn\":40},{\"ruleId\":\"max-depth\",\"severity\":1,\"message\":\"Blocks are nested too deeply (6). Maximum allowed is 5.\",\"line\":225,\"column\":13,\"nodeType\":\"IfStatement\",\"messageId\":\"tooDeeply\",\"endLine\":227,\"endColumn\":14},{\"ruleId\":\"func-style\",\"severity\":1,\"message\":\"Expected a function expression.\",\"line\":240,\"column\":1,\"nodeType\":\"FunctionDeclaration\",\"messageId\":\"expression\",\"endLine\":255,\"endColumn\":2},{\"ruleId\":\"func-style\",\"severity\":1,\"message\":\"Expected a function expression.\",\"line\":243,\"column\":3,\"nodeType\":\"FunctionDeclaration\",\"messageId\":\"expression\",\"endLine\":251,\"endColumn\":4},{\"ruleId\":\"func-style\",\"severity\":1,\"message\":\"Expected a function expression.\",\"line\":258,\"column\":1,\"nodeType\":\"FunctionDeclaration\",\"messageId\":\"expression\",\"endLine\":272,\"endColumn\":2},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":266,\"column\":35,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":266,\"endColumn\":36},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":266,\"column\":48,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":266,\"endColumn\":49},{\"ruleId\":\"func-style\",\"severity\":1,\"message\":\"Expected a function expression.\",\"line\":275,\"column\":1,\"nodeType\":\"FunctionDeclaration\",\"messageId\":\"expression\",\"endLine\":283,\"endColumn\":2},{\"ruleId\":\"func-style\",\"severity\":1,\"message\":\"Expected a function expression.\",\"line\":286,\"column\":1,\"nodeType\":\"FunctionDeclaration\",\"messageId\":\"expression\",\"endLine\":334,\"endColumn\":2},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":310,\"column\":25,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":310,\"endColumn\":26},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":310,\"column\":33,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":310,\"endColumn\":34},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":314,\"column\":22,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":314,\"endColumn\":23},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":314,\"column\":26,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":314,\"endColumn\":27},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":314,\"column\":26,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":314,\"endColumn\":27},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":314,\"column\":34,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":314,\"endColumn\":35},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":314,\"column\":38,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":314,\"endColumn\":39},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":314,\"column\":46,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":314,\"endColumn\":47},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":323,\"column\":33,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":323,\"endColumn\":34},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":323,\"column\":44,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":323,\"endColumn\":45},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":323,\"column\":44,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":323,\"endColumn\":45},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":324,\"column\":28,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":324,\"endColumn\":29},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":324,\"column\":39,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":324,\"endColumn\":40},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":325,\"column\":34,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":325,\"endColumn\":35},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":325,\"column\":39,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":325,\"endColumn\":40},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":326,\"column\":28,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":326,\"endColumn\":29},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '-'. Use parentheses to clarify the intended order of operations.\",\"line\":329,\"column\":37,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":329,\"endColumn\":38},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '-'. Use parentheses to clarify the intended order of operations.\",\"line\":329,\"column\":41,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":329,\"endColumn\":42},{\"ruleId\":\"func-style\",\"severity\":1,\"message\":\"Expected a function expression.\",\"line\":337,\"column\":1,\"nodeType\":\"FunctionDeclaration\",\"messageId\":\"expression\",\"endLine\":369,\"endColumn\":2},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":358,\"column\":22,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":358,\"endColumn\":23},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":358,\"column\":27,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":358,\"endColumn\":28},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":363,\"column\":26,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":363,\"endColumn\":27},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":363,\"column\":30,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":363,\"endColumn\":31},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":363,\"column\":30,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":363,\"endColumn\":31},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":363,\"column\":38,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":363,\"endColumn\":39},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":363,\"column\":42,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":363,\"endColumn\":43},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":363,\"column\":50,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":363,\"endColumn\":51},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '-'. Use parentheses to clarify the intended order of operations.\",\"line\":364,\"column\":40,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":364,\"endColumn\":41},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '-'. Use parentheses to clarify the intended order of operations.\",\"line\":364,\"column\":44,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":364,\"endColumn\":45}],\"suppressedMessages\":[],\"errorCount\":1,\"fatalErrorCount\":0,\"warningCount\":77,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Real CNN Emotion Recognition Model - Proper Implementation\\n * Complete convolutional neural network with trained weights\\n * Architecture: Conv2D -> ReLU -> MaxPool -> Conv2D -> ReLU -> MaxPool -> Dense -> Output\\n */\\n\\nexport const EMOTION_LABELS = [\\n  'angry',     // 0\\n  'disgusted', // 1\\n  'fearful',   // 2\\n  'happy',     // 3\\n  'sad',       // 4\\n  'surprised', // 5\\n  'neutral'    // 6\\n];\\n\\n// Real CNN architecture parameters\\nconst CNN_CONFIG = {\\n  inputSize: [48, 48],\\n  conv1: { filters: 32, kernelSize: 3, stride: 1 },\\n  pool1: { size: 2, stride: 2 },\\n  conv2: { filters: 64, kernelSize: 3, stride: 1 },\\n  pool2: { size: 2, stride: 2 },\\n  conv3: { filters: 128, kernelSize: 3, stride: 1 },\\n  pool3: { size: 2, stride: 2 },\\n  dense1: { units: 512 },\\n  output: { units: 7 }\\n};\\n\\n// Generate realistic pre-trained weights using proper initialization\\nfunction generateTrainedWeights() {\\n  const weights = {};\\n  \\n  // Conv1 weights: 32 filters, 1 input channel, 3x3 kernel\\n  weights.conv1 = generateConvWeights(32, 1, 3, 3);\\n  weights.conv1_bias = generateBiasWeights(32);\\n  \\n  // Conv2 weights: 64 filters, 32 input channels, 3x3 kernel  \\n  weights.conv2 = generateConvWeights(64, 32, 3, 3);\\n  weights.conv2_bias = generateBiasWeights(64);\\n  \\n  // Conv3 weights: 128 filters, 64 input channels, 3x3 kernel\\n  weights.conv3 = generateConvWeights(128, 64, 3, 3);\\n  weights.conv3_bias = generateBiasWeights(128);\\n  \\n  // Dense1 weights: flattened conv3 output -> 512 units\\n  const conv3_output_size = 128 * 4 * 4; // 128 filters, 4x4 spatial\\n  weights.dense1 = generateDenseWeights(conv3_output_size, 512);\\n  weights.dense1_bias = generateBiasWeights(512);\\n  \\n  // Output weights: 512 -> 7 emotions\\n  weights.output = generateDenseWeights(512, 7);\\n  weights.output_bias = generateBiasWeights(7);\\n  \\n  return weights;\\n}\\n\\n// Generate convolutional layer weights with He initialization\\nfunction generateConvWeights(numFilters, inputChannels, kernelHeight, kernelWidth) {\\n  const totalWeights = numFilters * inputChannels * kernelHeight * kernelWidth;\\n  const weights = new Float32Array(totalWeights);\\n  \\n  // He initialization for ReLU networks\\n  const fanIn = inputChannels * kernelHeight * kernelWidth;\\n  const std = Math.sqrt(2.0 / fanIn);\\n  \\n  for (let i = 0; i < totalWeights; i++) {\\n    weights[i] = gaussianRandom() * std;\\n  }\\n  \\n  return weights;\\n}\\n\\n// Generate dense layer weights with Xavier initialization\\nfunction generateDenseWeights(inputSize, outputSize) {\\n  const totalWeights = inputSize * outputSize;\\n  const weights = new Float32Array(totalWeights);\\n  \\n  // Xavier initialization\\n  const limit = Math.sqrt(6.0 / (inputSize + outputSize));\\n  \\n  for (let i = 0; i < totalWeights; i++) {\\n    weights[i] = (Math.random() * 2 - 1) * limit;\\n  }\\n  \\n  return weights;\\n}\\n\\n// Generate bias weights (small positive values)\\nfunction generateBiasWeights(size) {\\n  const bias = new Float32Array(size);\\n  for (let i = 0; i < size; i++) {\\n    bias[i] = Math.random() * 0.1;\\n  }\\n  return bias;\\n}\\n\\n// Gaussian random number generator (Box-Muller)\\nfunction gaussianRandom() {\\n  const u1 = Math.random();\\n  const u2 = Math.random();\\n  return Math.sqrt(-2.0 * Math.log(u1)) * Math.cos(2.0 * Math.PI * u2);\\n}\\n\\n// Activation functions\\nconst activations = {\\n  relu: (x) => Math.max(0, x),\\n  softmax: (arr) => {\\n    const maxVal = Math.max(...arr);\\n    const exps = arr.map(x => Math.exp(x - maxVal));\\n    const sumExps = exps.reduce((a, b) => a + b, 0);\\n    return exps.map(x => x / sumExps);\\n  }\\n};\\n\\n// Real 2D convolution operation\\nfunction conv2d(input, weights, bias, numFilters, inputChannels, kernelSize, stride = 1) {\\n  const inputHeight = input.length;\\n  const inputWidth = input[0].length;\\n  \\n  const outputHeight = Math.floor((inputHeight - kernelSize) / stride) + 1;\\n  const outputWidth = Math.floor((inputWidth - kernelSize) / stride) + 1;\\n  \\n  const output = Array(numFilters).fill().map(() => \\n    Array(outputHeight).fill().map(() => Array(outputWidth).fill(0))\\n  );\\n  \\n  for (let f = 0; f < numFilters; f++) {\\n    for (let y = 0; y < outputHeight; y++) {\\n      for (let x = 0; x < outputWidth; x++) {\\n        let sum = 0;\\n        \\n        for (let ic = 0; ic < inputChannels; ic++) {\\n          for (let ky = 0; ky < kernelSize; ky++) {\\n            for (let kx = 0; kx < kernelSize; kx++) {\\n              const inputY = y * stride + ky;\\n              const inputX = x * stride + kx;\\n              \\n              if (inputY < inputHeight && inputX < inputWidth) {\\n                const weightIdx = f * inputChannels * kernelSize * kernelSize + \\n                                ic * kernelSize * kernelSize + ky * kernelSize + kx;\\n                \\n                const inputVal = inputChannels === 1 ? \\n                  input[inputY][inputX] : \\n                  input[ic][inputY][inputX];\\n                  \\n                sum += inputVal * weights[weightIdx];\\n              }\\n            }\\n          }\\n        }\\n        \\n        output[f][y][x] = activations.relu(sum + bias[f]);\\n      }\\n    }\\n  }\\n  \\n  return output;\\n}\\n\\n// Multi-channel convolution for deeper layers\\nfunction conv2dMultiChannel(input, weights, bias, numFilters, inputChannels, kernelSize, stride = 1) {\\n  const inputHeight = input[0].length;\\n  const inputWidth = input[0][0].length;\\n  \\n  const outputHeight = Math.floor((inputHeight - kernelSize) / stride) + 1;\\n  const outputWidth = Math.floor((inputWidth - kernelSize) / stride) + 1;\\n  \\n  const output = Array(numFilters).fill().map(() => \\n    Array(outputHeight).fill().map(() => Array(outputWidth).fill(0))\\n  );\\n  \\n  for (let f = 0; f < numFilters; f++) {\\n    for (let y = 0; y < outputHeight; y++) {\\n      for (let x = 0; x < outputWidth; x++) {\\n        let sum = 0;\\n        \\n        for (let ic = 0; ic < inputChannels; ic++) {\\n          for (let ky = 0; ky < kernelSize; ky++) {\\n            for (let kx = 0; kx < kernelSize; kx++) {\\n              const inputY = y * stride + ky;\\n              const inputX = x * stride + kx;\\n              \\n              if (inputY < inputHeight && inputX < inputWidth) {\\n                const weightIdx = f * inputChannels * kernelSize * kernelSize + \\n                                ic * kernelSize * kernelSize + ky * kernelSize + kx;\\n                                \\n                sum += input[ic][inputY][inputX] * weights[weightIdx];\\n              }\\n            }\\n          }\\n        }\\n        \\n        output[f][y][x] = activations.relu(sum + bias[f]);\\n      }\\n    }\\n  }\\n  \\n  return output;\\n}\\n\\n// Max pooling operation\\nfunction maxPool2d(input, poolSize, stride) {\\n  const numChannels = input.length;\\n  const inputHeight = input[0].length;\\n  const inputWidth = input[0][0].length;\\n  \\n  const outputHeight = Math.floor((inputHeight - poolSize) / stride) + 1;\\n  const outputWidth = Math.floor((inputWidth - poolSize) / stride) + 1;\\n  \\n  const output = Array(numChannels).fill().map(() =>\\n    Array(outputHeight).fill().map(() => Array(outputWidth).fill(-Infinity))\\n  );\\n  \\n  for (let c = 0; c < numChannels; c++) {\\n    for (let y = 0; y < outputHeight; y++) {\\n      for (let x = 0; x < outputWidth; x++) {\\n        let maxVal = -Infinity;\\n        \\n        for (let py = 0; py < poolSize; py++) {\\n          for (let px = 0; px < poolSize; px++) {\\n            const inputY = y * stride + py;\\n            const inputX = x * stride + px;\\n            \\n            if (inputY < inputHeight && inputX < inputWidth) {\\n              maxVal = Math.max(maxVal, input[c][inputY][inputX]);\\n            }\\n          }\\n        }\\n        \\n        output[c][y][x] = maxVal;\\n      }\\n    }\\n  }\\n  \\n  return output;\\n}\\n\\n// Flatten multi-dimensional array\\nfunction flatten(tensor) {\\n  const result = [];\\n  \\n  function flattenRecursive(arr) {\\n    for (const element of arr) {\\n      if (Array.isArray(element)) {\\n        flattenRecursive(element);\\n      } else {\\n        result.push(element);\\n      }\\n    }\\n  }\\n  \\n  flattenRecursive(tensor);\\n  return result;\\n}\\n\\n// Dense (fully connected) layer\\nfunction dense(input, weights, bias) {\\n  const inputSize = input.length;\\n  const outputSize = bias.length;\\n  const output = new Float32Array(outputSize);\\n  \\n  for (let i = 0; i < outputSize; i++) {\\n    let sum = 0;\\n    for (let j = 0; j < inputSize; j++) {\\n      sum += input[j] * weights[j * outputSize + i];\\n    }\\n    output[i] = sum + bias[i];\\n  }\\n  \\n  return Array.from(output);\\n}\\n\\n// Preprocess image to 48x48 grayscale for CNN input\\nfunction preprocessImage(imageData) {\\n  const isServer = typeof window === 'undefined';\\n  \\n  if (isServer) {\\n    return preprocessImageServer(imageData);\\n  } else {\\n    return preprocessImageBrowser(imageData);\\n  }\\n}\\n\\n// Server-side preprocessing\\nfunction preprocessImageServer(imageData) {\\n  const { data, width, height } = imageData;\\n  \\n  // Resize to 48x48 using bilinear interpolation\\n  const resized = Array(48).fill().map(() => Array(48).fill(0));\\n  const scaleX = width / 48;\\n  const scaleY = height / 48;\\n  \\n  for (let y = 0; y < 48; y++) {\\n    for (let x = 0; x < 48; x++) {\\n      const srcX = x * scaleX;\\n      const srcY = y * scaleY;\\n      \\n      // Bilinear interpolation\\n      const x1 = Math.floor(srcX);\\n      const y1 = Math.floor(srcY);\\n      const x2 = Math.min(x1 + 1, width - 1);\\n      const y2 = Math.min(y1 + 1, height - 1);\\n      \\n      const dx = srcX - x1;\\n      const dy = srcY - y1;\\n      \\n      // Get RGBA values\\n      const getPixel = (px, py) => {\\n        const idx = (py * width + px) * 4;\\n        const r = data[idx] || 0;\\n        const g = data[idx + 1] || 0;\\n        const b = data[idx + 2] || 0;\\n        return 0.299 * r + 0.587 * g + 0.114 * b; // RGB to grayscale\\n      };\\n      \\n      // Bilinear interpolation\\n      const p1 = getPixel(x1, y1);\\n      const p2 = getPixel(x2, y1);\\n      const p3 = getPixel(x1, y2);\\n      const p4 = getPixel(x2, y2);\\n      \\n      const val = p1 * (1 - dx) * (1 - dy) + \\n                   p2 * dx * (1 - dy) + \\n                   p3 * (1 - dx) * dy + \\n                   p4 * dx * dy;\\n      \\n      // Normalize to [-1, 1] for better training\\n      resized[y][x] = (val / 255.0) * 2 - 1;\\n    }\\n  }\\n  \\n  return resized;\\n}\\n\\n// Browser-side preprocessing (using canvas)\\nfunction preprocessImageBrowser(imageData) {\\n  const canvas = document.createElement('canvas');\\n  canvas.width = 48;\\n  canvas.height = 48;\\n  const ctx = canvas.getContext('2d');\\n  \\n  const tempCanvas = document.createElement('canvas');\\n  tempCanvas.width = imageData.width;\\n  tempCanvas.height = imageData.height;\\n  const tempCtx = tempCanvas.getContext('2d');\\n  tempCtx.putImageData(imageData, 0, 0);\\n  \\n  ctx.imageSmoothingEnabled = true;\\n  ctx.imageSmoothingQuality = 'high';\\n  ctx.drawImage(tempCanvas, 0, 0, 48, 48);\\n  \\n  const resizedData = ctx.getImageData(0, 0, 48, 48);\\n  const grayscale = Array(48).fill().map(() => Array(48).fill(0));\\n  \\n  for (let y = 0; y < 48; y++) {\\n    for (let x = 0; x < 48; x++) {\\n      const idx = (y * 48 + x) * 4;\\n      const r = resizedData.data[idx];\\n      const g = resizedData.data[idx + 1];\\n      const b = resizedData.data[idx + 2];\\n      \\n      const gray = 0.299 * r + 0.587 * g + 0.114 * b;\\n      grayscale[y][x] = (gray / 255.0) * 2 - 1; // Normalize to [-1, 1]\\n    }\\n  }\\n  \\n  return grayscale;\\n}\\n\\n/**\\n * Create real CNN emotion recognition model\\n */\\nexport const createRealCNNModel = () => {\\n  let weights = null;\\n  let isInitialized = false;\\n  \\n  const initialize = async () => {\\n    console.log('🧠 Generating real CNN weights...');\\n    weights = generateTrainedWeights();\\n    isInitialized = true;\\n    console.log('✅ Real CNN initialized with proper architecture');\\n    return true;\\n  };\\n  \\n  const predictEmotion = async (imageData) => {\\n    if (!isInitialized || !weights) {\\n      throw new Error('Real CNN not initialized');\\n    }\\n    \\n    const startTime = performance.now();\\n    \\n    try {\\n      // Preprocess image to 48x48 normalized grayscale\\n      const input = preprocessImage(imageData);\\n      \\n      // CNN Forward Pass\\n      console.log('🔄 Running CNN forward pass...');\\n      \\n      // Layer 1: Conv2D(32, 3x3) + ReLU + MaxPool(2x2)\\n      const conv1_out = conv2d(input, weights.conv1, weights.conv1_bias, 32, 1, 3);\\n      const pool1_out = maxPool2d(conv1_out, 2, 2); // 32 x 23 x 23\\n      \\n      // Layer 2: Conv2D(64, 3x3) + ReLU + MaxPool(2x2)\\n      const conv2_out = conv2dMultiChannel(pool1_out, weights.conv2, weights.conv2_bias, 64, 32, 3);\\n      const pool2_out = maxPool2d(conv2_out, 2, 2); // 64 x 10 x 10\\n      \\n      // Layer 3: Conv2D(128, 3x3) + ReLU + MaxPool(2x2)\\n      const conv3_out = conv2dMultiChannel(pool2_out, weights.conv3, weights.conv3_bias, 128, 64, 3);\\n      const pool3_out = maxPool2d(conv3_out, 2, 2); // 128 x 4 x 4\\n      \\n      // Flatten for dense layers\\n      const flattened = flatten(pool3_out); // 128 * 4 * 4 = 2048\\n      \\n      // Dense layer 1: 2048 -> 512 + ReLU\\n      const dense1_out = dense(flattened, weights.dense1, weights.dense1_bias);\\n      const dense1_relu = dense1_out.map(x => activations.relu(x));\\n      \\n      // Output layer: 512 -> 7 (no activation, raw logits)\\n      const logits = dense(dense1_relu, weights.output, weights.output_bias);\\n      \\n      // Apply softmax for probabilities\\n      const probabilities = activations.softmax(logits);\\n      \\n      // Find dominant emotion\\n      const maxIndex = probabilities.indexOf(Math.max(...probabilities));\\n      const dominantEmotion = EMOTION_LABELS[maxIndex];\\n      const confidence = probabilities[maxIndex];\\n      \\n      // Create emotion distribution\\n      const emotions = {};\\n      EMOTION_LABELS.forEach((label, index) => {\\n        emotions[label] = Math.round(probabilities[index] * 1000) / 1000;\\n      });\\n      \\n      const processingTime = performance.now() - startTime;\\n      \\n      console.log(`🎭 CNN Result: ${dominantEmotion} (${(confidence * 100).toFixed(1)}%) in ${processingTime.toFixed(1)}ms`);\\n      \\n      return {\\n        emotion: dominantEmotion,\\n        confidence: Math.round(confidence * 1000) / 1000,\\n        emotions,\\n        probabilities,\\n        processingTime: Math.round(processingTime * 100) / 100,\\n        source: 'real-cnn-v1',\\n        architecture: 'Conv32->Pool->Conv64->Pool->Conv128->Pool->Dense512->Dense7'\\n      };\\n      \\n    } catch (error) {\\n      console.error('❌ CNN processing failed:', error);\\n      throw new Error(`Real CNN prediction failed: ${error.message}`);\\n    }\\n  };\\n  \\n  const cleanup = async () => {\\n    weights = null;\\n    isInitialized = false;\\n    console.log('✅ Real CNN cleaned up');\\n  };\\n  \\n  return {\\n    initialize,\\n    predictEmotion,\\n    cleanup,\\n    get isLoaded() { return isInitialized; },\\n    get isInitialized() { return isInitialized; }\\n  };\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/features/eye-tracking/common/calibration.js\",\"messages\":[{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":26,\"column\":27,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":26,\"endColumn\":28},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":26,\"column\":32,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":26,\"endColumn\":33},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":26,\"column\":32,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":26,\"endColumn\":33},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":26,\"column\":37,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":26,\"endColumn\":38},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '/' and '-'. Use parentheses to clarify the intended order of operations.\",\"line\":83,\"column\":38,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":83,\"endColumn\":39},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '/' and '-'. Use parentheses to clarify the intended order of operations.\",\"line\":83,\"column\":41,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":83,\"endColumn\":42},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '/'. Use parentheses to clarify the intended order of operations.\",\"line\":125,\"column\":33,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":125,\"endColumn\":34},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '/'. Use parentheses to clarify the intended order of operations.\",\"line\":125,\"column\":76,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":125,\"endColumn\":77},{\"ruleId\":\"max-lines-per-function\",\"severity\":1,\"message\":\"Arrow function has too many lines (248). Maximum allowed is 150.\",\"line\":175,\"column\":49,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"exceed\",\"endLine\":492,\"endColumn\":2}],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":9,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Advanced Calibration Management and Quality Assessment\\n * Comprehensive calibration state management with quality metrics\\n * Following functional programming patterns with factory functions\\n */\\n\\nimport { createCalibrationResult } from '../../../core/configuration/types.ts';\\n\\n// Advanced calibration quality metrics\\nexport const createCalibrationMetrics = () => {\\n  const calculateAccuracy = (calibrationPoints, validationPoints) => {\\n    if (!calibrationPoints || !validationPoints || validationPoints.length === 0) {\\n      return { accuracy: 0, confidence: 0, details: 'insufficient_data' };\\n    }\\n\\n    const distances = validationPoints.map(validation => {\\n      const target = calibrationPoints.find(cal => \\n        Math.abs(cal.targetX - validation.targetX) < 0.1 && \\n        Math.abs(cal.targetY - validation.targetY) < 0.1\\n      );\\n      \\n      if (!target) return null;\\n      \\n      const dx = target.gazeX - validation.gazeX;\\n      const dy = target.gazeY - validation.gazeY;\\n      return Math.sqrt(dx * dx + dy * dy);\\n    }).filter(d => d !== null);\\n\\n    if (distances.length === 0) {\\n      return { accuracy: 0, confidence: 0, details: 'no_matching_points' };\\n    }\\n\\n    const meanError = distances.reduce((sum, d) => sum + d, 0) / distances.length;\\n    const stdError = Math.sqrt(\\n      distances.reduce((sum, d) => sum + Math.pow(d - meanError, 2), 0) / distances.length\\n    );\\n\\n    // Convert to degrees (assuming screen distance ~60cm, screen width ~30cm)\\n    const errorDegrees = meanError * 28.6; // rough conversion to degrees\\n    \\n    let accuracyGrade;\\n    let confidence;\\n    \\n    if (errorDegrees < 0.5) {\\n      accuracyGrade = 'excellent';\\n      confidence = 0.95;\\n    } else if (errorDegrees < 1.0) {\\n      accuracyGrade = 'good';\\n      confidence = 0.85;\\n    } else if (errorDegrees < 2.0) {\\n      accuracyGrade = 'acceptable';\\n      confidence = 0.7;\\n    } else if (errorDegrees < 3.0) {\\n      accuracyGrade = 'poor';\\n      confidence = 0.5;\\n    } else {\\n      accuracyGrade = 'very_poor';\\n      confidence = 0.3;\\n    }\\n\\n    return {\\n      accuracy: Math.max(0, 1 - (errorDegrees / 5.0)), // Normalize to 0-1\\n      confidence,\\n      meanError,\\n      stdError,\\n      errorDegrees,\\n      accuracyGrade,\\n      sampleCount: distances.length,\\n      details: {\\n        distances,\\n        distribution: calculateErrorDistribution(distances)\\n      }\\n    };\\n  };\\n\\n  const calculateErrorDistribution = (distances) => {\\n    const sorted = [...distances].sort((a, b) => a - b);\\n    const n = sorted.length;\\n    \\n    return {\\n      min: sorted[0],\\n      max: sorted[n - 1],\\n      median: n % 2 === 0 ? (sorted[n/2 - 1] + sorted[n/2]) / 2 : sorted[Math.floor(n/2)],\\n      percentile25: sorted[Math.floor(n * 0.25)],\\n      percentile75: sorted[Math.floor(n * 0.75)],\\n      percentile95: sorted[Math.floor(n * 0.95)]\\n    };\\n  };\\n\\n  const assessDataQuality = (gazeData) => {\\n    if (!gazeData || gazeData.length === 0) {\\n      return { quality: 0, issues: ['no_data'], recommendations: ['collect_gaze_data'] };\\n    }\\n\\n    const issues = [];\\n    const recommendations = [];\\n    let qualityScore = 1.0;\\n\\n    // Check data completeness\\n    const validSamples = gazeData.filter(d => d.confidence > 0.5);\\n    const completeness = validSamples.length / gazeData.length;\\n    \\n    if (completeness < 0.8) {\\n      issues.push('low_data_completeness');\\n      recommendations.push('improve_tracking_conditions');\\n      qualityScore *= 0.8;\\n    }\\n\\n    // Check confidence distribution\\n    const avgConfidence = validSamples.reduce((sum, d) => sum + d.confidence, 0) / validSamples.length;\\n    if (avgConfidence < 0.7) {\\n      issues.push('low_confidence');\\n      recommendations.push('recalibrate_device');\\n      qualityScore *= 0.7;\\n    }\\n\\n    // Check temporal stability\\n    const timeGaps = [];\\n    for (let i = 1; i < gazeData.length; i++) {\\n      timeGaps.push(gazeData[i].timestamp - gazeData[i-1].timestamp);\\n    }\\n    \\n    const avgInterval = timeGaps.reduce((sum, gap) => sum + gap, 0) / timeGaps.length;\\n    const expectedInterval = 1000 / 200; // 200Hz = 5ms\\n    const intervalStability = 1 - Math.abs(avgInterval - expectedInterval) / expectedInterval;\\n    \\n    if (intervalStability < 0.8) {\\n      issues.push('unstable_sampling_rate');\\n      recommendations.push('check_system_performance');\\n      qualityScore *= 0.9;\\n    }\\n\\n    // Check spatial distribution\\n    const xValues = validSamples.map(d => d.x);\\n    const yValues = validSamples.map(d => d.y);\\n    \\n    const xRange = Math.max(...xValues) - Math.min(...xValues);\\n    const yRange = Math.max(...yValues) - Math.min(...yValues);\\n    \\n    if (xRange < 0.5 || yRange < 0.5) {\\n      issues.push('limited_spatial_coverage');\\n      recommendations.push('use_full_screen_calibration');\\n      qualityScore *= 0.8;\\n    }\\n\\n    let qualityGrade;\\n    if (qualityScore >= 0.9) qualityGrade = 'excellent';\\n    else if (qualityScore >= 0.8) qualityGrade = 'good';\\n    else if (qualityScore >= 0.7) qualityGrade = 'acceptable';\\n    else if (qualityScore >= 0.6) qualityGrade = 'poor';\\n    else qualityGrade = 'very_poor';\\n\\n    return {\\n      quality: qualityScore,\\n      qualityGrade,\\n      completeness,\\n      avgConfidence,\\n      intervalStability,\\n      spatialCoverage: { xRange, yRange },\\n      issues,\\n      recommendations,\\n      sampleCount: gazeData.length,\\n      validSampleCount: validSamples.length\\n    };\\n  };\\n\\n  return {\\n    calculateAccuracy,\\n    calculateErrorDistribution,\\n    assessDataQuality\\n  };\\n};\\n\\n// Advanced calibration manager\\nexport const createAdvancedCalibrationManager = (config = {}) => {\\n  const state = {\\n    sessions: new Map(),\\n    metrics: createCalibrationMetrics(),\\n    validationStrategy: config.validationStrategy || 'cross_validation',\\n    qualityThreshold: config.qualityThreshold || 0.7,\\n    accuracyThreshold: config.accuracyThreshold || 1.5, // degrees\\n    callbacks: {\\n      onQualityUpdate: [],\\n      onCalibrationComplete: [],\\n      onValidationComplete: [],\\n      onRecommendation: []\\n    }\\n  };\\n\\n  const startCalibrationSession = (sessionId, calibrationPoints) => {\\n    const session = {\\n      sessionId,\\n      startTime: Date.now(),\\n      status: 'collecting',\\n      calibrationPoints: calibrationPoints || generateDefaultCalibrationPoints(),\\n      collectedData: [],\\n      validationData: [],\\n      currentPointIndex: 0,\\n      quality: null,\\n      accuracy: null,\\n      recommendations: []\\n    };\\n\\n    state.sessions.set(sessionId, session);\\n    return session;\\n  };\\n\\n  const generateDefaultCalibrationPoints = () => {\\n    // 9-point calibration grid\\n    const points = [];\\n    for (let y = 0; y < 3; y++) {\\n      for (let x = 0; x < 3; x++) {\\n        points.push({\\n          id: `point_${x}_${y}`,\\n          targetX: 0.1 + (x * 0.4), // 0.1, 0.5, 0.9\\n          targetY: 0.1 + (y * 0.4), // 0.1, 0.5, 0.9\\n          duration: 2000, // 2 seconds per point\\n          samples: []\\n        });\\n      }\\n    }\\n    return points;\\n  };\\n\\n  const addCalibrationData = (sessionId, gazeData) => {\\n    const session = state.sessions.get(sessionId);\\n    if (!session) {\\n      throw new Error(`Calibration session ${sessionId} not found`);\\n    }\\n\\n    const currentPoint = session.calibrationPoints[session.currentPointIndex];\\n    if (!currentPoint) {\\n      throw new Error('No current calibration point');\\n    }\\n\\n    // Add gaze data to current point\\n    currentPoint.samples.push({\\n      ...gazeData,\\n      timestamp: Date.now(),\\n      targetX: currentPoint.targetX,\\n      targetY: currentPoint.targetY\\n    });\\n\\n    session.collectedData.push({\\n      ...gazeData,\\n      targetX: currentPoint.targetX,\\n      targetY: currentPoint.targetY\\n    });\\n\\n    // Check if current point has enough samples\\n    if (currentPoint.samples.length >= 10) { // At least 10 samples per point\\n      session.currentPointIndex++;\\n      \\n      if (session.currentPointIndex >= session.calibrationPoints.length) {\\n        // All points collected, move to validation\\n        session.status = 'validating';\\n        performValidation(sessionId);\\n      }\\n    }\\n\\n    return session;\\n  };\\n\\n  const performValidation = async (sessionId) => {\\n    const session = state.sessions.get(sessionId);\\n    if (!session) {\\n      throw new Error(`Calibration session ${sessionId} not found`);\\n    }\\n\\n    // Perform quality assessment\\n    const quality = state.metrics.assessDataQuality(session.collectedData);\\n    session.quality = quality;\\n\\n    // Generate validation points (subset of calibration points)\\n    const validationPoints = generateValidationPoints(session.calibrationPoints);\\n    \\n    // Calculate accuracy metrics\\n    const accuracy = state.metrics.calculateAccuracy(\\n      session.collectedData,\\n      validationPoints\\n    );\\n    session.accuracy = accuracy;\\n\\n    // Generate recommendations\\n    const recommendations = generateRecommendations(quality, accuracy);\\n    session.recommendations = recommendations;\\n\\n    // Determine final status\\n    if (quality.quality >= state.qualityThreshold && \\n        accuracy.errorDegrees <= state.accuracyThreshold) {\\n      session.status = 'completed';\\n    } else {\\n      session.status = 'needs_recalibration';\\n    }\\n\\n    session.endTime = Date.now();\\n\\n    // Create calibration result\\n    const calibrationResult = createCalibrationResult({\\n      sessionId,\\n      status: session.status,\\n      quality: quality.qualityGrade,\\n      accuracy: accuracy.accuracyGrade,\\n      timestamp: session.endTime,\\n      metrics: {\\n        quality,\\n        accuracy,\\n        duration: session.endTime - session.startTime,\\n        pointCount: session.calibrationPoints.length,\\n        sampleCount: session.collectedData.length\\n      },\\n      recommendations\\n    });\\n\\n    // Notify callbacks\\n    state.callbacks.onCalibrationComplete.forEach(cb => {\\n      try {\\n        cb(calibrationResult);\\n      } catch (error) {\\n        console.warn('Calibration complete callback error:', error);\\n      }\\n    });\\n\\n    if (recommendations.length > 0) {\\n      state.callbacks.onRecommendation.forEach(cb => {\\n        try {\\n          cb({ sessionId, recommendations, quality, accuracy });\\n        } catch (error) {\\n          console.warn('Recommendation callback error:', error);\\n        }\\n      });\\n    }\\n\\n    return calibrationResult;\\n  };\\n\\n  const generateValidationPoints = (calibrationPoints) => {\\n    // Use every other point for validation (cross-validation)\\n    return calibrationPoints.filter((_, index) => index % 2 === 0)\\n      .map(point => ({\\n        targetX: point.targetX,\\n        targetY: point.targetY,\\n        gazeX: point.samples.length > 0 ? \\n          point.samples.reduce((sum, s) => sum + s.x, 0) / point.samples.length : 0,\\n        gazeY: point.samples.length > 0 ? \\n          point.samples.reduce((sum, s) => sum + s.y, 0) / point.samples.length : 0,\\n        confidence: point.samples.length > 0 ?\\n          point.samples.reduce((sum, s) => sum + s.confidence, 0) / point.samples.length : 0\\n      }));\\n  };\\n\\n  const generateRecommendations = (quality, accuracy) => {\\n    const recommendations = [];\\n\\n    // Quality-based recommendations\\n    quality.recommendations.forEach(rec => {\\n      recommendations.push({\\n        type: 'quality',\\n        priority: 'high',\\n        recommendation: rec,\\n        description: getRecommendationDescription(rec)\\n      });\\n    });\\n\\n    // Accuracy-based recommendations\\n    if (accuracy.errorDegrees > 2.0) {\\n      recommendations.push({\\n        type: 'accuracy',\\n        priority: 'high',\\n        recommendation: 'recalibrate_full',\\n        description: 'Calibration accuracy is below acceptable threshold. Perform full recalibration.'\\n      });\\n    } else if (accuracy.errorDegrees > 1.0) {\\n      recommendations.push({\\n        type: 'accuracy',\\n        priority: 'medium',\\n        recommendation: 'recalibrate_partial',\\n        description: 'Consider partial recalibration to improve accuracy.'\\n      });\\n    }\\n\\n    // Environmental recommendations\\n    if (quality.avgConfidence < 0.7) {\\n      recommendations.push({\\n        type: 'environment',\\n        priority: 'medium',\\n        recommendation: 'improve_lighting',\\n        description: 'Low confidence suggests poor lighting conditions. Improve ambient lighting.'\\n      });\\n    }\\n\\n    return recommendations;\\n  };\\n\\n  const getRecommendationDescription = (recommendation) => {\\n    const descriptions = {\\n      'collect_gaze_data': 'Insufficient gaze data collected. Ensure eye tracker is properly positioned.',\\n      'improve_tracking_conditions': 'Low data completeness. Check for obstructions and ensure proper head positioning.',\\n      'recalibrate_device': 'Low confidence levels suggest device needs recalibration.',\\n      'check_system_performance': 'Unstable sampling rate detected. Check system performance and close unnecessary applications.',\\n      'use_full_screen_calibration': 'Limited spatial coverage. Use full screen area for calibration points.'\\n    };\\n    \\n    return descriptions[recommendation] || 'Follow standard calibration procedures.';\\n  };\\n\\n  // Real-time quality monitoring\\n  const monitorRealTimeQuality = (sessionId, recentGazeData) => {\\n    const session = state.sessions.get(sessionId);\\n    if (!session) return null;\\n\\n    const quality = state.metrics.assessDataQuality(recentGazeData);\\n    \\n    // Update session with real-time quality\\n    session.realtimeQuality = quality;\\n\\n    // Notify quality callbacks\\n    state.callbacks.onQualityUpdate.forEach(cb => {\\n      try {\\n        cb({ sessionId, quality, timestamp: Date.now() });\\n      } catch (error) {\\n        console.warn('Quality update callback error:', error);\\n      }\\n    });\\n\\n    return quality;\\n  };\\n\\n  // Session management\\n  const getSession = (sessionId) => {\\n    const session = state.sessions.get(sessionId);\\n    return session ? { ...session } : null;\\n  };\\n\\n  const getAllSessions = () => {\\n    return Array.from(state.sessions.values()).map(session => ({ ...session }));\\n  };\\n\\n  const cleanupSession = (sessionId) => {\\n    return state.sessions.delete(sessionId);\\n  };\\n\\n  // Event handlers\\n  const onQualityUpdate = (callback) => {\\n    state.callbacks.onQualityUpdate.push(callback);\\n    return () => {\\n      const index = state.callbacks.onQualityUpdate.indexOf(callback);\\n      if (index !== -1) state.callbacks.onQualityUpdate.splice(index, 1);\\n    };\\n  };\\n\\n  const onCalibrationComplete = (callback) => {\\n    state.callbacks.onCalibrationComplete.push(callback);\\n    return () => {\\n      const index = state.callbacks.onCalibrationComplete.indexOf(callback);\\n      if (index !== -1) state.callbacks.onCalibrationComplete.splice(index, 1);\\n    };\\n  };\\n\\n  const onRecommendation = (callback) => {\\n    state.callbacks.onRecommendation.push(callback);\\n    return () => {\\n      const index = state.callbacks.onRecommendation.indexOf(callback);\\n      if (index !== -1) state.callbacks.onRecommendation.splice(index, 1);\\n    };\\n  };\\n\\n  return {\\n    // Session management\\n    startCalibrationSession,\\n    addCalibrationData,\\n    performValidation,\\n    monitorRealTimeQuality,\\n    \\n    // Session access\\n    getSession,\\n    getAllSessions,\\n    cleanupSession,\\n    \\n    // Event handlers\\n    onQualityUpdate,\\n    onCalibrationComplete,\\n    onRecommendation,\\n    \\n    // Configuration\\n    setQualityThreshold: (threshold) => { state.qualityThreshold = threshold; },\\n    setAccuracyThreshold: (threshold) => { state.accuracyThreshold = threshold; },\\n    \\n    // Utilities\\n    getMetrics: () => state.metrics\\n  };\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/features/eye-tracking/common/gaze-processing.js\",\"messages\":[{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'createEyeState' is defined but never used. Allowed unused vars must match /^_/u.\",\"line\":7,\"column\":3,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":7,\"endColumn\":17,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"createEyeState\"},\"fix\":{\"range\":[123,138],\"text\":\"\"},\"desc\":\"Remove unused variable 'createEyeState'.\"}]},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'createEyeTrackingResult' is defined but never used. Allowed unused vars must match /^_/u.\",\"line\":8,\"column\":3,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":8,\"endColumn\":26,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"createEyeTrackingResult\"},\"fix\":{\"range\":[137,165],\"text\":\"\"},\"desc\":\"Remove unused variable 'createEyeTrackingResult'.\"}]},{\"ruleId\":\"max-lines-per-function\",\"severity\":1,\"message\":\"Arrow function has too many lines (224). Maximum allowed is 150.\",\"line\":14,\"column\":36,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"exceed\",\"endLine\":306,\"endColumn\":2},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":49,\"column\":25,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":49,\"endColumn\":26},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":49,\"column\":43,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":49,\"endColumn\":44},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":49,\"column\":43,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":49,\"endColumn\":44},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":49,\"column\":59,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":49,\"endColumn\":60},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":50,\"column\":25,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":50,\"endColumn\":26},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":50,\"column\":43,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":50,\"endColumn\":44},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":50,\"column\":43,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":50,\"endColumn\":44},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":50,\"column\":59,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":50,\"endColumn\":60},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":87,\"column\":35,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":87,\"endColumn\":36},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":87,\"column\":40,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":87,\"endColumn\":41},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":87,\"column\":40,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":87,\"endColumn\":41},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":87,\"column\":45,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":87,\"endColumn\":46},{\"ruleId\":\"no-nested-ternary\",\"severity\":1,\"message\":\"Do not nest ternary expressions.\",\"line\":119,\"column\":23,\"nodeType\":\"ConditionalExpression\",\"messageId\":\"noNestedTernary\",\"endLine\":119,\"endColumn\":86}],\"suppressedMessages\":[],\"errorCount\":2,\"fatalErrorCount\":0,\"warningCount\":14,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Gaze Data Processing Utilities\\n * Following functional programming patterns with factory functions\\n */\\n\\nimport { \\n  createEyeState, \\n  createEyeTrackingResult, \\n  createGazeData, \\n  createGazeSemantics \\n} from '../../../core/configuration/types.ts';\\n\\n// Gaze data validation and normalization\\nexport const createGazeProcessor = (config = {}) => {\\n  const state = {\\n    screenWidth: config.screenWidth || 1920,\\n    screenHeight: config.screenHeight || 1080,\\n    confidenceThreshold: config.confidenceThreshold || 0.5,\\n    smoothingFactor: config.smoothingFactor || 0.3,\\n    lastGazePoint: null,\\n    gazeHistory: []\\n  };\\n\\n  // Validate raw gaze data\\n  const validateGazeData = (rawData) => {\\n    if (!rawData) return { valid: false, reason: 'No data provided' };\\n    \\n    if (typeof rawData.x !== 'number' || typeof rawData.y !== 'number') {\\n      return { valid: false, reason: 'Invalid coordinates' };\\n    }\\n    \\n    if (rawData.x < 0 || rawData.x > 1 || rawData.y < 0 || rawData.y > 1) {\\n      return { valid: false, reason: 'Coordinates out of range' };\\n    }\\n    \\n    if (typeof rawData.confidence !== 'number' || rawData.confidence < 0 || rawData.confidence > 1) {\\n      return { valid: false, reason: 'Invalid confidence value' };\\n    }\\n    \\n    return { valid: true };\\n  };\\n\\n  // Apply smoothing to gaze coordinates\\n  const applySmoothing = (currentGaze, previousGaze) => {\\n    if (!previousGaze) return currentGaze;\\n    \\n    const smoothing = state.smoothingFactor;\\n    return {\\n      x: previousGaze.x * (1 - smoothing) + currentGaze.x * smoothing,\\n      y: previousGaze.y * (1 - smoothing) + currentGaze.y * smoothing,\\n      confidence: Math.max(currentGaze.confidence, previousGaze.confidence * 0.9)\\n    };\\n  };\\n\\n  // Calculate screen coordinates\\n  const toScreenCoordinates = (normalizedGaze) => ({\\n    x: Math.round(normalizedGaze.x * state.screenWidth),\\n    y: Math.round(normalizedGaze.y * state.screenHeight)\\n  });\\n\\n  // Determine screen region\\n  const getScreenRegion = (gazeData) => {\\n    const { x, y } = gazeData;\\n    \\n    // Define regions\\n    if (x < 0.33) {\\n      if (y < 0.33) return 'upper_left';\\n      if (y > 0.66) return 'lower_left';\\n      return 'center_left';\\n    } else if (x > 0.66) {\\n      if (y < 0.33) return 'upper_right';\\n      if (y > 0.66) return 'lower_right';\\n      return 'center_right';\\n    } else {\\n      if (y < 0.33) return 'upper_center';\\n      if (y > 0.66) return 'lower_center';\\n      return 'center';\\n    }\\n  };\\n\\n  // Calculate gaze velocity\\n  const calculateVelocity = (currentGaze, previousGaze, timeDelta) => {\\n    if (!previousGaze || timeDelta <= 0) return 0;\\n    \\n    const dx = currentGaze.x - previousGaze.x;\\n    const dy = currentGaze.y - previousGaze.y;\\n    const distance = Math.sqrt(dx * dx + dy * dy);\\n    \\n    return distance / (timeDelta / 1000); // pixels per second\\n  };\\n\\n  // Generate semantic description\\n  const generateSemantics = (gazeData, velocity = 0) => {\\n    const region = getScreenRegion(gazeData);\\n    const {confidence} = gazeData;\\n    \\n    let quality = 'low';\\n    if (confidence > 0.8) quality = 'high_confidence';\\n    else if (confidence > 0.6) quality = 'moderate';\\n    \\n    let interpretation = 'unknown';\\n    if (velocity < 0.1) interpretation = 'focused_attention';\\n    else if (velocity < 0.5) interpretation = 'scanning';\\n    else interpretation = 'rapid_movement';\\n    \\n    let behaviorType = 'unknown';\\n    if (velocity < 0.05) behaviorType = 'fixation';\\n    else if (velocity > 0.3) behaviorType = 'saccade';\\n    else behaviorType = 'smooth_pursuit';\\n    \\n    const screenCoords = toScreenCoordinates(gazeData);\\n    \\n    return createGazeSemantics({\\n      description: `Looking at ${region.replace('_', ' ')} region`,\\n      region,\\n      quality,\\n      interpretation,\\n      behaviorType,\\n      attentionLevel: confidence > 0.7 ? 'high' : confidence > 0.4 ? 'medium' : 'low',\\n      gazePattern: interpretation,\\n      context: {\\n        calibrationQuality: 'unknown', // Will be updated by device manager\\n        trackingStability: velocity < 0.2 ? 'stable' : 'unstable',\\n        deviceHealth: 'unknown',\\n        environmentalConditions: 'unknown'\\n      },\\n      derived: {\\n        screenCoordinates: screenCoords,\\n        confidenceLevel: quality,\\n        gazeVelocity: velocity\\n      }\\n    });\\n  };\\n\\n  // Main processing function\\n  const processGazeData = (rawData) => {\\n    // Validate input\\n    const validation = validateGazeData(rawData);\\n    if (!validation.valid) {\\n      throw new Error(`Invalid gaze data: ${validation.reason}`);\\n    }\\n\\n    // Apply smoothing if enabled\\n    let processedGaze = { ...rawData };\\n    if (state.lastGazePoint && state.smoothingFactor > 0) {\\n      processedGaze = applySmoothing(processedGaze, state.lastGazePoint);\\n    }\\n\\n    // Calculate velocity\\n    let velocity = 0;\\n    if (state.lastGazePoint) {\\n      const timeDelta = rawData.timestamp - state.lastGazePoint.timestamp;\\n      velocity = calculateVelocity(processedGaze, state.lastGazePoint, timeDelta);\\n    }\\n\\n    // Generate semantic data\\n    const semantics = generateSemantics(processedGaze, velocity);\\n\\n    // Create final gaze data object\\n    const gazeData = createGazeData({\\n      ...processedGaze,\\n      semantic: semantics,\\n      metadata: {\\n        velocity,\\n        screenCoordinates: toScreenCoordinates(processedGaze),\\n        region: semantics.region,\\n        smoothed: state.smoothingFactor > 0\\n      }\\n    });\\n\\n    // Update history\\n    state.lastGazePoint = { ...processedGaze, timestamp: rawData.timestamp };\\n    state.gazeHistory.push(gazeData);\\n    \\n    // Keep history size reasonable\\n    if (state.gazeHistory.length > 1000) {\\n      state.gazeHistory = state.gazeHistory.slice(-1000);\\n    }\\n\\n    return gazeData;\\n  };\\n\\n  // Get recent gaze history\\n  const getGazeHistory = (duration = 5000) => {\\n    const cutoff = Date.now() - duration;\\n    return state.gazeHistory.filter(gaze => gaze.timestamp > cutoff);\\n  };\\n\\n  // Calculate fixations from history\\n  const detectFixations = (duration = 5000, threshold = 0.05) => {\\n    const recentGaze = getGazeHistory(duration);\\n    if (recentGaze.length < 10) return [];\\n\\n    const fixations = [];\\n    let currentFixation = null;\\n\\n    for (const gaze of recentGaze) {\\n      if (!currentFixation) {\\n        currentFixation = {\\n          startTime: gaze.timestamp,\\n          x: gaze.x,\\n          y: gaze.y,\\n          points: [gaze],\\n          confidence: gaze.confidence\\n        };\\n        continue;\\n      }\\n\\n      // Check if gaze point is within threshold\\n      const distance = Math.sqrt(\\n        Math.pow(gaze.x - currentFixation.x, 2) + \\n        Math.pow(gaze.y - currentFixation.y, 2)\\n      );\\n\\n      if (distance <= threshold) {\\n        // Continue current fixation\\n        currentFixation.points.push(gaze);\\n        currentFixation.confidence = Math.max(currentFixation.confidence, gaze.confidence);\\n      } else {\\n        // End current fixation and start new one\\n        if (currentFixation.points.length >= 5) { // Minimum 5 points for fixation\\n          fixations.push({\\n            ...currentFixation,\\n            endTime: currentFixation.points[currentFixation.points.length - 1].timestamp,\\n            duration: currentFixation.points[currentFixation.points.length - 1].timestamp - currentFixation.startTime,\\n            dispersion: calculateDispersion(currentFixation.points)\\n          });\\n        }\\n\\n        currentFixation = {\\n          startTime: gaze.timestamp,\\n          x: gaze.x,\\n          y: gaze.y,\\n          points: [gaze],\\n          confidence: gaze.confidence\\n        };\\n      }\\n    }\\n\\n    // Handle final fixation\\n    if (currentFixation && currentFixation.points.length >= 5) {\\n      fixations.push({\\n        ...currentFixation,\\n        endTime: currentFixation.points[currentFixation.points.length - 1].timestamp,\\n        duration: currentFixation.points[currentFixation.points.length - 1].timestamp - currentFixation.startTime,\\n        dispersion: calculateDispersion(currentFixation.points)\\n      });\\n    }\\n\\n    return fixations;\\n  };\\n\\n  // Calculate dispersion of gaze points\\n  const calculateDispersion = (points) => {\\n    if (points.length < 2) return 0;\\n\\n    const avgX = points.reduce((sum, p) => sum + p.x, 0) / points.length;\\n    const avgY = points.reduce((sum, p) => sum + p.y, 0) / points.length;\\n\\n    const variance = points.reduce((sum, p) => {\\n      return sum + Math.pow(p.x - avgX, 2) + Math.pow(p.y - avgY, 2);\\n    }, 0) / points.length;\\n\\n    return Math.sqrt(variance);\\n  };\\n\\n  // Get processing statistics\\n  const getStats = () => ({\\n    totalProcessed: state.gazeHistory.length,\\n    historySize: state.gazeHistory.length,\\n    lastUpdate: state.lastGazePoint?.timestamp || null,\\n    averageConfidence: state.gazeHistory.length > 0 \\n      ? state.gazeHistory.reduce((sum, g) => sum + g.confidence, 0) / state.gazeHistory.length\\n      : 0,\\n    settings: {\\n      smoothingFactor: state.smoothingFactor,\\n      confidenceThreshold: state.confidenceThreshold,\\n      screenResolution: `${state.screenWidth}x${state.screenHeight}`\\n    }\\n  });\\n\\n  return {\\n    processGazeData,\\n    validateGazeData,\\n    getGazeHistory,\\n    detectFixations,\\n    getStats,\\n    \\n    // Configuration\\n    setScreenSize: (width, height) => {\\n      state.screenWidth = width;\\n      state.screenHeight = height;\\n    },\\n    setSmoothing: (factor) => {\\n      state.smoothingFactor = Math.max(0, Math.min(1, factor));\\n    },\\n    setConfidenceThreshold: (threshold) => {\\n      state.confidenceThreshold = Math.max(0, Math.min(1, threshold));\\n    },\\n    \\n    // Utilities\\n    toScreenCoordinates,\\n    getScreenRegion,\\n    generateSemantics\\n  };\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/features/eye-tracking/core/calibration-controller.js\",\"messages\":[{\"ruleId\":\"no-undef\",\"severity\":2,\"message\":\"'session' is not defined.\",\"line\":66,\"column\":67,\"nodeType\":\"Identifier\",\"messageId\":\"undef\",\"endLine\":66,\"endColumn\":74},{\"ruleId\":\"prefer-destructuring\",\"severity\":1,\"message\":\"Use object destructuring.\",\"line\":81,\"column\":7,\"nodeType\":\"AssignmentExpression\",\"messageId\":\"preferDestructuring\",\"endLine\":81,\"endColumn\":42},{\"ruleId\":\"no-param-reassign\",\"severity\":1,\"message\":\"Assignment to function parameter 'sessionId'.\",\"line\":81,\"column\":7,\"nodeType\":\"Identifier\",\"messageId\":\"assignmentToFunctionParam\",\"endLine\":81,\"endColumn\":16}],\"suppressedMessages\":[],\"errorCount\":1,\"fatalErrorCount\":0,\"warningCount\":2,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Eye Tracking Calibration Control Module  \\n * Handles calibration start/stop operations and progress tracking\\n */\\n\\nexport const createCalibrationController = (state, sessionManager, eventNotifier) => {\\n  // Setup calibration update handler for a device\\n  const setupCalibrationUpdateHandler = (device, sessionId) => {\\n    device.onCalibrationUpdate((calibrationResult) => {\\n      const session = state.calibrationSessions.get(sessionId);\\n      if (session) {\\n        const updates = {\\n          lastUpdate: Date.now(),\\n          result: calibrationResult\\n        };\\n        \\n        if (calibrationResult.status === 'completed' || calibrationResult.status === 'failed') {\\n          updates.status = calibrationResult.status;\\n          updates.endTime = Date.now();\\n        }\\n\\n        sessionManager.updateCalibrationSession(sessionId, updates);\\n\\n        // Notify progress callbacks\\n        eventNotifier.notifyCalibrationProgress({\\n          event: 'update',\\n          sessionId,\\n          deviceId: session.deviceId,\\n          calibrationResult,\\n          timestamp: Date.now()\\n        });\\n      }\\n    });\\n  };\\n\\n  // Calibration Control API\\n  const startCalibration = async (deviceId, calibrationConfig = {}) => {\\n    const deviceInfo = state.activeDevices.get(deviceId);\\n    if (!deviceInfo) {\\n      throw new Error(`Device ${deviceId} not connected`);\\n    }\\n\\n    // Start calibration on device\\n    const result = await deviceInfo.device.startCalibration();\\n    \\n    if (result.success) {\\n      // Track calibration session\\n      const session = sessionManager.createCalibrationSession(\\n        deviceId, \\n        result.calibrationId, \\n        calibrationConfig\\n      );\\n\\n      // Setup calibration update handler\\n      setupCalibrationUpdateHandler(deviceInfo.device, session.sessionId);\\n\\n      // Notify start\\n      eventNotifier.notifyCalibrationProgress({\\n        event: 'started',\\n        sessionId: session.sessionId,\\n        deviceId,\\n        timestamp: Date.now()\\n      });\\n    }\\n\\n    return { success: result.success, sessionId: result.success ? session.sessionId : null };\\n  };\\n\\n  const stopCalibration = async (deviceId, sessionId = null) => {\\n    const deviceInfo = state.activeDevices.get(deviceId);\\n    if (!deviceInfo) {\\n      throw new Error(`Device ${deviceId} not connected`);\\n    }\\n\\n    // Find session if not provided\\n    if (!sessionId) {\\n      const activeSession = sessionManager.findActiveCalibrationSession(deviceId);\\n      if (!activeSession) {\\n        throw new Error('No active calibration session found');\\n      }\\n      sessionId = activeSession.sessionId;\\n    }\\n\\n    const session = state.calibrationSessions.get(sessionId);\\n    if (!session) {\\n      throw new Error(`Calibration session ${sessionId} not found`);\\n    }\\n\\n    // Stop calibration on device\\n    const result = await deviceInfo.device.stopCalibration();\\n    \\n    if (result.success) {\\n      // Update session\\n      sessionManager.updateCalibrationSession(sessionId, {\\n        status: result.result.status,\\n        endTime: Date.now(),\\n        result: result.result\\n      });\\n\\n      // Notify progress callbacks\\n      eventNotifier.notifyCalibrationProgress({\\n        event: 'completed',\\n        sessionId,\\n        deviceId: session.deviceId,\\n        result: session.result,\\n        timestamp: Date.now()\\n      });\\n    }\\n\\n    return { success: result.success, session };\\n  };\\n\\n  return {\\n    startCalibration,\\n    stopCalibration\\n  };\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/features/eye-tracking/core/device-manager.js\",\"messages\":[],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/features/eye-tracking/core/event-notifier.js\",\"messages\":[],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/features/eye-tracking/core/recording-controller.js\",\"messages\":[{\"ruleId\":\"prefer-destructuring\",\"severity\":1,\"message\":\"Use object destructuring.\",\"line\":52,\"column\":7,\"nodeType\":\"AssignmentExpression\",\"messageId\":\"preferDestructuring\",\"endLine\":52,\"endColumn\":42},{\"ruleId\":\"no-param-reassign\",\"severity\":1,\"message\":\"Assignment to function parameter 'sessionId'.\",\"line\":52,\"column\":7,\"nodeType\":\"Identifier\",\"messageId\":\"assignmentToFunctionParam\",\"endLine\":52,\"endColumn\":16}],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":2,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Eye Tracking Recording Control Module\\n * Handles recording start/stop operations and progress tracking\\n */\\n\\nexport const createRecordingController = (state, sessionManager, eventNotifier) => {\\n  // Recording Control API\\n  const startRecording = async (deviceId, recordingConfig = {}) => {\\n    const deviceInfo = state.activeDevices.get(deviceId);\\n    if (!deviceInfo) {\\n      throw new Error(`Device ${deviceId} not connected`);\\n    }\\n\\n    const recordingId = recordingConfig.recordingId || `recording-${Date.now()}`;\\n\\n    // Start recording on device\\n    const result = await deviceInfo.device.startRecording(recordingId, recordingConfig);\\n    \\n    if (result.success) {\\n      // Track recording session\\n      const session = sessionManager.createRecordingSession(deviceId, recordingId, recordingConfig);\\n\\n      // Notify progress callbacks\\n      eventNotifier.notifyRecordingProgress({\\n        event: 'started',\\n        sessionId: session.sessionId,\\n        deviceId,\\n        recordingId,\\n        timestamp: Date.now()\\n      });\\n    }\\n\\n    return { \\n      success: result.success, \\n      sessionId: result.success ? `${deviceId}-${recordingId}` : null,\\n      recordingId \\n    };\\n  };\\n\\n  const stopRecording = async (deviceId, sessionId = null) => {\\n    const deviceInfo = state.activeDevices.get(deviceId);\\n    if (!deviceInfo) {\\n      throw new Error(`Device ${deviceId} not connected`);\\n    }\\n\\n    // Find session if not provided\\n    if (!sessionId) {\\n      const activeSession = sessionManager.findActiveRecordingSession(deviceId);\\n      if (!activeSession) {\\n        throw new Error('No active recording session found');\\n      }\\n      sessionId = activeSession.sessionId;\\n    }\\n\\n    const session = state.recordingSessions.get(sessionId);\\n    if (!session) {\\n      throw new Error(`Recording session ${sessionId} not found`);\\n    }\\n\\n    // Stop recording on device\\n    const result = await deviceInfo.device.stopRecording();\\n    \\n    if (result.success) {\\n      // Update session\\n      const updatedSession = sessionManager.updateRecordingSession(sessionId, {\\n        status: 'completed',\\n        endTime: Date.now(),\\n        duration: Date.now() - session.startTime\\n      });\\n\\n      // Notify progress callbacks\\n      eventNotifier.notifyRecordingProgress({\\n        event: 'completed',\\n        sessionId,\\n        deviceId: session.deviceId,\\n        recordingId: session.recordingId,\\n        duration: updatedSession.duration,\\n        timestamp: Date.now()\\n      });\\n    }\\n\\n    return { success: result.success, session };\\n  };\\n\\n  return {\\n    startRecording,\\n    stopRecording\\n  };\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/features/eye-tracking/core/session-manager.js\",\"messages\":[],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/features/eye-tracking/core/streaming-controller.js\",\"messages\":[],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/features/eye-tracking/devices/neon/device.js\",\"messages\":[{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'createEyeTrackingResult' is defined but never used. Allowed unused vars must match /^_/u.\",\"line\":13,\"column\":3,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":13,\"endColumn\":26,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"createEyeTrackingResult\"},\"fix\":{\"range\":[494,522],\"text\":\"\"},\"desc\":\"Remove unused variable 'createEyeTrackingResult'.\"}]},{\"ruleId\":\"max-lines-per-function\",\"severity\":1,\"message\":\"Arrow function has too many lines (415). Maximum allowed is 150.\",\"line\":17,\"column\":39,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"exceed\",\"endLine\":569,\"endColumn\":2},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'wsUrl' is assigned a value but never used. Allowed unused vars must match /^_/u.\",\"line\":50,\"column\":11,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":50,\"endColumn\":16,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"wsUrl\"},\"fix\":{\"range\":[1678,1740],\"text\":\"\"},\"desc\":\"Remove unused variable 'wsUrl'.\"}]},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":230,\"column\":28,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":230,\"endColumn\":29},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":230,\"column\":52,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":230,\"endColumn\":53},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":231,\"column\":28,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":231,\"endColumn\":29},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":231,\"column\":52,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":231,\"endColumn\":53},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":245,\"column\":25,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":245,\"endColumn\":26},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":245,\"column\":41,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":245,\"endColumn\":42},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":250,\"column\":32,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":250,\"endColumn\":33},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":250,\"column\":62,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":250,\"endColumn\":63},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":254,\"column\":32,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":254,\"endColumn\":33},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":254,\"column\":62,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":254,\"endColumn\":63},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'videoData' is defined but never used. Allowed unused args must match /^_/u.\",\"line\":308,\"column\":35,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":308,\"endColumn\":44,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"videoData\"},\"fix\":{\"range\":[8647,8656],\"text\":\"\"},\"desc\":\"Remove unused variable 'videoData'.\"}]},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'imuData' is defined but never used. Allowed unused args must match /^_/u.\",\"line\":312,\"column\":32,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":312,\"endColumn\":39,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"imuData\"},\"fix\":{\"range\":[8751,8758],\"text\":\"\"},\"desc\":\"Remove unused variable 'imuData'.\"}]},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'eventData' is defined but never used. Allowed unused args must match /^_/u.\",\"line\":316,\"column\":33,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":316,\"endColumn\":42,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"eventData\"},\"fix\":{\"range\":[8851,8860],\"text\":\"\"},\"desc\":\"Remove unused variable 'eventData'.\"}]},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'error' is defined but never used.\",\"line\":351,\"column\":16,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":351,\"endColumn\":21},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '/'. Use parentheses to clarify the intended order of operations.\",\"line\":371,\"column\":34,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":371,\"endColumn\":35},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '/'. Use parentheses to clarify the intended order of operations.\",\"line\":371,\"column\":58,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":371,\"endColumn\":59},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":373,\"column\":25,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":373,\"endColumn\":26},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":373,\"column\":56,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":373,\"endColumn\":57},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'error' is defined but never used.\",\"line\":412,\"column\":16,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":412,\"endColumn\":21}],\"suppressedMessages\":[],\"errorCount\":7,\"fatalErrorCount\":0,\"warningCount\":15,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Eye Tracker Device Connection Manager\\n * Connection lifecycle management, auto-reconnection, error recovery\\n * Following functional programming patterns with factory functions\\n */\\n\\nimport { createHttpTransport, createWebSocketTransport } from '../../../../core/integration/transport.ts';\\nimport { createDataStream } from '../../../../core/state/streams.js';\\nimport { createGazeProcessor } from '../../common/gaze-processing.js';\\nimport { \\n  createCalibrationResult, \\n  createDeviceStatus, \\n  createEyeTrackingResult \\n} from '../../../../core/configuration/types.ts';\\n\\n// Eye tracker device factory with connection management\\nexport const createEyeTrackerDevice = (config = {}) => {\\n  const state = {\\n    deviceId: config.deviceId || 'unknown',\\n    address: config.address || (process.env.NEON_DEVICE_ADDRESS || 'localhost'),\\n    port: config.port || 8080,\\n    connectionState: 'disconnected',\\n    wsTransport: null,\\n    httpTransport: null,\\n    gazeStream: null,\\n    gazeProcessor: null,\\n    reconnect: {\\n      enabled: config.autoReconnect !== false,\\n      interval: config.reconnectInterval || 5000,\\n      maxAttempts: config.maxReconnectAttempts || 10,\\n      attempts: 0,\\n      backoffMultiplier: 1.5,\\n      maxInterval: 30000\\n    },\\n    deviceInfo: config.deviceInfo || {},\\n    lastHeartbeat: null,\\n    callbacks: {\\n      onConnectionChange: [],\\n      onGazeData: [],\\n      onDeviceStatus: [],\\n      onError: [],\\n      onCalibrationUpdate: []\\n    },\\n    mockMode: config.mockMode !== false // Default to mock mode for development\\n  };\\n\\n  // Initialize transports\\n  const initializeTransports = () => {\\n    const baseUrl = `http://${state.address}:${state.port}`;\\n    const wsUrl = `ws://${state.address}:${state.port}/websocket`;\\n\\n    // HTTP transport for device control\\n    state.httpTransport = createHttpTransport({\\n      baseUrl,\\n      timeout: 10000\\n    });\\n\\n    // WebSocket transport for real-time streaming\\n    state.wsTransport = createWebSocketTransport({\\n      isServer: false,\\n      autoReconnect: false // We handle reconnection at device level\\n    });\\n\\n    // Initialize gaze processor\\n    state.gazeProcessor = createGazeProcessor({\\n      screenWidth: config.screenWidth || 1920,\\n      screenHeight: config.screenHeight || 1080,\\n      smoothingFactor: config.smoothingFactor || 0.3\\n    });\\n\\n    // Create gaze stream\\n    state.gazeStream = createDataStream({\\n      id: `${state.deviceId}-gaze`,\\n      type: 'eyetracking',\\n      sampleRate: 200,\\n      bufferSize: 2000,\\n      processors: [state.gazeProcessor]\\n    });\\n  };\\n\\n  // Connection management\\n  const connect = async () => {\\n    if (state.connectionState === 'connected' || state.connectionState === 'connecting') {\\n      return true;\\n    }\\n\\n    setConnectionState('connecting');\\n    \\n    try {\\n      if (state.mockMode) {\\n        return await connectMock();\\n      } else {\\n        return await connectReal();\\n      }\\n    } catch (error) {\\n      setConnectionState('error');\\n      notifyError(error);\\n      \\n      // Schedule reconnection if enabled\\n      if (state.reconnect.enabled && state.reconnect.attempts < state.reconnect.maxAttempts) {\\n        scheduleReconnect();\\n      }\\n      \\n      throw error;\\n    }\\n  };\\n\\n  // Real device connection\\n  const connectReal = async () => {\\n    const wsUrl = `ws://${state.address}:${state.port}/websocket`;\\n    \\n    // Test HTTP connection first\\n    const statusResponse = await state.httpTransport.getStatus();\\n    if (!statusResponse.success) {\\n      throw new Error(`HTTP connection failed: ${statusResponse.error}`);\\n    }\\n\\n    // Connect WebSocket for streaming\\n    await state.wsTransport.connect(wsUrl);\\n    \\n    // Setup WebSocket event handlers\\n    setupWebSocketHandlers();\\n    \\n    // Start gaze stream\\n    await state.gazeStream.start();\\n    \\n    setConnectionState('connected');\\n    state.reconnect.attempts = 0;\\n    startHeartbeat();\\n    \\n    return true;\\n  };\\n\\n  // Mock device connection for development\\n  const connectMock = async () => {\\n    // Simulate connection delay - reduced for better test performance\\n    const delay = config.mockConnectionDelay || 100;\\n    await new Promise(resolve => setTimeout(resolve, delay));\\n    \\n    // Setup mock data streaming\\n    setupMockStreaming();\\n    \\n    // Start gaze stream\\n    await state.gazeStream.start();\\n    \\n    setConnectionState('connected');\\n    state.reconnect.attempts = 0;\\n    startMockHeartbeat();\\n    \\n    return true;\\n  };\\n\\n  const disconnect = () => {\\n    setConnectionState('disconnecting');\\n    \\n    // Stop heartbeat\\n    if (state.heartbeatInterval) {\\n      clearInterval(state.heartbeatInterval);\\n      state.heartbeatInterval = null;\\n    }\\n    \\n    // Stop streaming\\n    if (state.mockStreamingInterval) {\\n      clearInterval(state.mockStreamingInterval);\\n      state.mockStreamingInterval = null;\\n    }\\n    \\n    // Stop gaze stream\\n    if (state.gazeStream) {\\n      state.gazeStream.stop();\\n    }\\n    \\n    // Disconnect transports\\n    if (state.wsTransport) {\\n      state.wsTransport.stop();\\n    }\\n    \\n    setConnectionState('disconnected');\\n  };\\n\\n  // Connection state management\\n  const setConnectionState = (newState) => {\\n    const oldState = state.connectionState;\\n    state.connectionState = newState;\\n    \\n    state.callbacks.onConnectionChange.forEach(cb => {\\n      try {\\n        cb({ \\n          deviceId: state.deviceId, \\n          oldState, \\n          newState, \\n          timestamp: Date.now() \\n        });\\n      } catch (error) {\\n        console.warn('Connection change callback error:', error);\\n      }\\n    });\\n  };\\n\\n  // WebSocket event handlers\\n  const setupWebSocketHandlers = () => {\\n    state.wsTransport.onMessage((message) => {\\n      handleStreamingMessage(message);\\n    });\\n    \\n    state.wsTransport.onDisconnect(() => {\\n      if (state.connectionState === 'connected') {\\n        setConnectionState('disconnected');\\n        if (state.reconnect.enabled) {\\n          scheduleReconnect();\\n        }\\n      }\\n    });\\n    \\n    state.wsTransport.onError((error) => {\\n      notifyError(error);\\n    });\\n  };\\n\\n  // Mock streaming for development\\n  const setupMockStreaming = () => {\\n    let gazeX = 0.5;\\n    let gazeY = 0.5;\\n    const direction = { x: 0.02, y: 0.01 };\\n    \\n    state.mockStreamingInterval = setInterval(async () => {\\n      if (state.connectionState !== 'connected') return;\\n      \\n      // Generate realistic gaze movement\\n      gazeX += direction.x + (Math.random() - 0.5) * 0.01;\\n      gazeY += direction.y + (Math.random() - 0.5) * 0.01;\\n      \\n      // Bounce off edges\\n      if (gazeX <= 0 || gazeX >= 1) direction.x *= -1;\\n      if (gazeY <= 0 || gazeY >= 1) direction.y *= -1;\\n      \\n      // Keep in bounds\\n      gazeX = Math.max(0, Math.min(1, gazeX));\\n      gazeY = Math.max(0, Math.min(1, gazeY));\\n      \\n      const mockGazeData = {\\n        timestamp: Date.now(),\\n        x: gazeX,\\n        y: gazeY,\\n        confidence: 0.8 + Math.random() * 0.2,\\n        worn: true,\\n        eyeStates: {\\n          left: {\\n            center: { x: gazeX - 0.01, y: gazeY },\\n            pupilDiameter: 3.2 + Math.sin(Date.now() / 5000) * 0.5\\n          },\\n          right: {\\n            center: { x: gazeX + 0.01, y: gazeY },\\n            pupilDiameter: 3.1 + Math.sin(Date.now() / 5000) * 0.5\\n          }\\n        }\\n      };\\n      \\n      await handleGazeData(mockGazeData);\\n    }, 5); // 200Hz = 5ms interval\\n  };\\n\\n  // Handle incoming streaming messages\\n  const handleStreamingMessage = async (message) => {\\n    try {\\n      switch (message.topic) {\\n        case 'gaze':\\n          await handleGazeData(message.data);\\n          break;\\n        case 'video':\\n          await handleVideoFrame(message.data);\\n          break;\\n        case 'imu':\\n          await handleIMUData(message.data);\\n          break;\\n        case 'events':\\n          await handleEyeEvent(message.data);\\n          break;\\n        default:\\n          console.warn('Unknown message topic:', message.topic);\\n      }\\n    } catch (error) {\\n      notifyError(new Error(`Message handling error: ${error.message}`));\\n    }\\n  };\\n\\n  // Gaze data processing\\n  const handleGazeData = async (rawGazeData) => {\\n    try {\\n      // Process through gaze processor\\n      const processedGaze = await state.gazeStream.process(rawGazeData);\\n      \\n      // Notify callbacks\\n      state.callbacks.onGazeData.forEach(cb => {\\n        try {\\n          cb(processedGaze);\\n        } catch (error) {\\n          console.warn('Gaze data callback error:', error);\\n        }\\n      });\\n      \\n    } catch (error) {\\n      notifyError(new Error(`Gaze processing error: ${error.message}`));\\n    }\\n  };\\n\\n  // Placeholder handlers for other data types\\n  const handleVideoFrame = async (videoData) => {\\n    // Implementation for video frame processing\\n  };\\n  \\n  const handleIMUData = async (imuData) => {\\n    // Implementation for IMU data processing\\n  };\\n  \\n  const handleEyeEvent = async (eventData) => {\\n    // Implementation for eye event processing\\n  };\\n\\n  // Heartbeat management\\n  const startHeartbeat = () => {\\n    state.heartbeatInterval = setInterval(async () => {\\n      try {\\n        if (state.mockMode) {\\n          // Mock heartbeat\\n          state.lastHeartbeat = Date.now();\\n          return;\\n        }\\n        \\n        const response = await state.httpTransport.getStatus();\\n        if (response.success) {\\n          state.lastHeartbeat = Date.now();\\n          \\n          // Update device status\\n          const deviceStatus = createDeviceStatus({\\n            deviceId: state.deviceId,\\n            connectionState: 'connected',\\n            ...response.data\\n          });\\n          \\n          state.callbacks.onDeviceStatus.forEach(cb => {\\n            try {\\n              cb(deviceStatus);\\n            } catch (error) {\\n              console.warn('Device status callback error:', error);\\n            }\\n          });\\n        } else {\\n          throw new Error('Heartbeat failed');\\n        }\\n      } catch (error) {\\n        // Heartbeat failure indicates connection issue\\n        if (state.connectionState === 'connected') {\\n          setConnectionState('disconnected');\\n          if (state.reconnect.enabled) {\\n            scheduleReconnect();\\n          }\\n        }\\n      }\\n    }, 5000); // 5 second heartbeat\\n  };\\n\\n  const startMockHeartbeat = () => {\\n    state.heartbeatInterval = setInterval(() => {\\n      state.lastHeartbeat = Date.now();\\n      \\n      // Generate mock device status\\n      const deviceStatus = createDeviceStatus({\\n        deviceId: state.deviceId,\\n        connectionState: 'connected',\\n        battery: Math.max(0, 100 - (Date.now() % 100000) / 1000),\\n        charging: Math.random() > 0.7,\\n        temperature: 25 + Math.sin(Date.now() / 10000) * 2,\\n        calibration: {\\n          status: 'valid',\\n          timestamp: Date.now() - 300000\\n        }\\n      });\\n      \\n      state.callbacks.onDeviceStatus.forEach(cb => {\\n        try {\\n          cb(deviceStatus);\\n        } catch (error) {\\n          console.warn('Device status callback error:', error);\\n        }\\n      });\\n    }, 5000);\\n  };\\n\\n  // Reconnection management\\n  const scheduleReconnect = () => {\\n    if (state.reconnectTimeout) return; // Already scheduled\\n    \\n    state.reconnect.attempts++;\\n    const delay = Math.min(\\n      state.reconnect.interval * Math.pow(state.reconnect.backoffMultiplier, state.reconnect.attempts - 1),\\n      state.reconnect.maxInterval\\n    );\\n    \\n    console.log(`Scheduling reconnection attempt ${state.reconnect.attempts}/${state.reconnect.maxAttempts} in ${delay}ms`);\\n    \\n    state.reconnectTimeout = setTimeout(async () => {\\n      state.reconnectTimeout = null;\\n      \\n      if (state.reconnect.attempts >= state.reconnect.maxAttempts) {\\n        setConnectionState('failed');\\n        return;\\n      }\\n      \\n      try {\\n        await connect();\\n      } catch (error) {\\n        // connect() handles reconnection scheduling on failure\\n      }\\n    }, delay);\\n  };\\n\\n  // Device control methods\\n  const startRecording = async (recordingId, config = {}) => {\\n    if (state.mockMode) {\\n      // Mock recording start\\n      await new Promise(resolve => setTimeout(resolve, 100));\\n      return { success: true, recordingId };\\n    }\\n    \\n    return await state.httpTransport.startRecording(recordingId, config);\\n  };\\n\\n  const stopRecording = async () => {\\n    if (state.mockMode) {\\n      await new Promise(resolve => setTimeout(resolve, 100));\\n      return { success: true };\\n    }\\n    \\n    return await state.httpTransport.stopRecording();\\n  };\\n\\n  const startCalibration = async () => {\\n    if (state.mockMode) {\\n      await new Promise(resolve => setTimeout(resolve, 100));\\n      return { success: true, calibrationId: 'mock-calibration' };\\n    }\\n    \\n    return await state.httpTransport.startCalibration();\\n  };\\n\\n  const stopCalibration = async () => {\\n    if (state.mockMode) {\\n      await new Promise(resolve => setTimeout(resolve, 100));\\n      const calibrationResult = createCalibrationResult({\\n        status: 'completed',\\n        quality: 'good',\\n        timestamp: Date.now()\\n      });\\n      \\n      state.callbacks.onCalibrationUpdate.forEach(cb => {\\n        try {\\n          cb(calibrationResult);\\n        } catch (error) {\\n          console.warn('Calibration update callback error:', error);\\n        }\\n      });\\n      \\n      return { success: true, result: calibrationResult };\\n    }\\n    \\n    return await state.httpTransport.stopCalibration();\\n  };\\n\\n  // Error handling\\n  const notifyError = (error) => {\\n    state.callbacks.onError.forEach(cb => {\\n      try {\\n        cb(error);\\n      } catch (cbError) {\\n        console.warn('Error callback failed:', cbError);\\n      }\\n    });\\n  };\\n\\n  // Event handlers\\n  const onConnectionChange = (callback) => {\\n    state.callbacks.onConnectionChange.push(callback);\\n    return () => {\\n      const index = state.callbacks.onConnectionChange.indexOf(callback);\\n      if (index !== -1) state.callbacks.onConnectionChange.splice(index, 1);\\n    };\\n  };\\n\\n  const onGazeData = (callback) => {\\n    state.callbacks.onGazeData.push(callback);\\n    return () => {\\n      const index = state.callbacks.onGazeData.indexOf(callback);\\n      if (index !== -1) state.callbacks.onGazeData.splice(index, 1);\\n    };\\n  };\\n\\n  const onDeviceStatus = (callback) => {\\n    state.callbacks.onDeviceStatus.push(callback);\\n    return () => {\\n      const index = state.callbacks.onDeviceStatus.indexOf(callback);\\n      if (index !== -1) state.callbacks.onDeviceStatus.splice(index, 1);\\n    };\\n  };\\n\\n  const onError = (callback) => {\\n    state.callbacks.onError.push(callback);\\n    return () => {\\n      const index = state.callbacks.onError.indexOf(callback);\\n      if (index !== -1) state.callbacks.onError.splice(index, 1);\\n    };\\n  };\\n\\n  const onCalibrationUpdate = (callback) => {\\n    state.callbacks.onCalibrationUpdate.push(callback);\\n    return () => {\\n      const index = state.callbacks.onCalibrationUpdate.indexOf(callback);\\n      if (index !== -1) state.callbacks.onCalibrationUpdate.splice(index, 1);\\n    };\\n  };\\n\\n  // Cleanup\\n  const cleanup = () => {\\n    disconnect();\\n    \\n    if (state.reconnectTimeout) {\\n      clearTimeout(state.reconnectTimeout);\\n      state.reconnectTimeout = null;\\n    }\\n  };\\n\\n  // Initialize transports\\n  initializeTransports();\\n\\n  return {\\n    // Connection management\\n    connect,\\n    disconnect,\\n    \\n    // Device control\\n    startRecording,\\n    stopRecording,\\n    startCalibration,\\n    stopCalibration,\\n    \\n    // Event handlers\\n    onConnectionChange,\\n    onGazeData,\\n    onDeviceStatus,\\n    onError,\\n    onCalibrationUpdate,\\n    \\n    // Status\\n    getConnectionState: () => state.connectionState,\\n    getDeviceId: () => state.deviceId,\\n    getDeviceInfo: () => ({ ...state.deviceInfo }),\\n    getLastHeartbeat: () => state.lastHeartbeat,\\n    getGazeStream: () => state.gazeStream,\\n    isConnected: () => state.connectionState === 'connected',\\n    \\n    // Configuration\\n    setReconnectionConfig: (config) => {\\n      Object.assign(state.reconnect, config);\\n    },\\n    \\n    // Cleanup\\n    cleanup\\n  };\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/features/eye-tracking/devices/neon/discovery.js\",\"messages\":[{\"ruleId\":\"max-lines-per-function\",\"severity\":1,\"message\":\"Arrow function has too many lines (201). Maximum allowed is 150.\",\"line\":8,\"column\":38,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"exceed\",\"endLine\":264,\"endColumn\":2},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":155,\"column\":70,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":155,\"endColumn\":71},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":155,\"column\":86,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":155,\"endColumn\":87},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":161,\"column\":31,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":161,\"endColumn\":32},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":161,\"column\":55,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":161,\"endColumn\":56}],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":5,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Eye Tracker Device Discovery Service\\n * mDNS-based automatic discovery of Pupil Labs Neon devices on network\\n * Following functional programming patterns with factory functions\\n */\\n\\n// Device discovery factory using mDNS service discovery\\nexport const createDeviceDiscovery = (config = {}) => {\\n  const state = {\\n    serviceName: config.serviceName || '_pupil-mobile._tcp',\\n    discoveryTimeout: config.discoveryTimeout || 5000,\\n    isDiscovering: false,\\n    devices: new Map(),\\n    callbacks: {\\n      onDeviceFound: [],\\n      onDeviceUpdated: [],\\n      onDeviceLost: [],\\n      onError: []\\n    }\\n  };\\n\\n  // Mock mDNS implementation for development without hardware\\n  const createMockDevice = (id, name) => ({\\n    id,\\n    name: name || `Mock Neon ${id}`,\\n    address: '192.168.1.100',\\n    port: 8080,\\n    type: 'neon',\\n    capabilities: ['gaze_streaming', 'video_streaming', 'imu_data'],\\n    status: 'available',\\n    lastSeen: Date.now(),\\n    deviceInfo: {\\n      serial: `MOCK-${id}`,\\n      firmware: '1.0.0-mock',\\n      battery: 85,\\n      charging: false,\\n      temperature: 25.5,\\n      calibration: {\\n        status: 'valid',\\n        timestamp: Date.now() - 300000 // 5 minutes ago\\n      }\\n    }\\n  });\\n\\n  // Real mDNS implementation (placeholder for when available)\\n  const discoverRealDevices = async () => {\\n    // Note: This would use Node.js mdns or similar library\\n    // For now, we simulate discovery delay and return empty results\\n    // Reduced timeout for better test performance\\n    const delay = config.realDeviceDiscoveryDelay || 200;\\n    await new Promise(resolve => setTimeout(resolve, delay));\\n    return [];\\n  };\\n\\n  const startDiscovery = async () => {\\n    if (state.isDiscovering) return false;\\n    \\n    state.isDiscovering = true;\\n    state.devices.clear();\\n\\n    try {\\n      // Try real device discovery first\\n      const realDevices = await discoverRealDevices();\\n      \\n      // If no real devices found and in development mode, add mock device\\n      if (realDevices.length === 0 && config.useMockDevices !== false) {\\n        const mockDevice = createMockDevice('mock-001', 'Mock Neon Device');\\n        state.devices.set(mockDevice.id, mockDevice);\\n        \\n        // Notify callbacks\\n        state.callbacks.onDeviceFound.forEach(cb => {\\n          try {\\n            cb(mockDevice);\\n          } catch (error) {\\n            console.warn('Device found callback error:', error);\\n          }\\n        });\\n      }\\n\\n      // Process real devices\\n      for (const device of realDevices) {\\n        state.devices.set(device.id, device);\\n        \\n        state.callbacks.onDeviceFound.forEach(cb => {\\n          try {\\n            cb(device);\\n          } catch (error) {\\n            console.warn('Device found callback error:', error);\\n          }\\n        });\\n      }\\n\\n      return true;\\n    } catch (error) {\\n      state.callbacks.onError.forEach(cb => {\\n        try {\\n          cb(error);\\n        } catch (cbError) {\\n          console.warn('Error callback failed:', cbError);\\n        }\\n      });\\n      throw error;\\n    } finally {\\n      // Auto-stop discovery after timeout\\n      setTimeout(() => {\\n        if (state.isDiscovering) {\\n          stopDiscovery();\\n        }\\n      }, state.discoveryTimeout);\\n    }\\n  };\\n\\n  const stopDiscovery = () => {\\n    state.isDiscovering = false;\\n    // Clean up any ongoing discovery processes\\n  };\\n\\n  const getDiscoveredDevices = () => {\\n    return Array.from(state.devices.values()).map(device => ({ ...device }));\\n  };\\n\\n  const getDeviceById = (deviceId) => {\\n    const device = state.devices.get(deviceId);\\n    return device ? { ...device } : null;\\n  };\\n\\n  const updateDeviceStatus = (deviceId, statusUpdate) => {\\n    const device = state.devices.get(deviceId);\\n    if (device) {\\n      const updatedDevice = {\\n        ...device,\\n        ...statusUpdate,\\n        lastSeen: Date.now()\\n      };\\n      \\n      state.devices.set(deviceId, updatedDevice);\\n      \\n      state.callbacks.onDeviceUpdated.forEach(cb => {\\n        try {\\n          cb(updatedDevice);\\n        } catch (error) {\\n          console.warn('Device updated callback error:', error);\\n        }\\n      });\\n    }\\n  };\\n\\n  // Simulate device status updates for mock devices\\n  const startMockStatusUpdates = () => {\\n    if (config.useMockDevices === false) return;\\n    \\n    setInterval(() => {\\n      for (const device of state.devices.values()) {\\n        if (device.id.startsWith('mock-')) {\\n          const batteryLevel = Math.max(0, device.deviceInfo.battery - Math.random() * 0.5);\\n          updateDeviceStatus(device.id, {\\n            deviceInfo: {\\n              ...device.deviceInfo,\\n              battery: batteryLevel,\\n              charging: batteryLevel < 20 ? Math.random() > 0.5 : false,\\n              temperature: 25 + (Math.random() - 0.5) * 2\\n            }\\n          });\\n        }\\n      }\\n    }, 30000); // Update every 30 seconds\\n  };\\n\\n  // Check for stale devices and mark as lost\\n  const checkDeviceHealth = () => {\\n    const staleThreshold = Date.now() - 60000; // 1 minute\\n    \\n    for (const [deviceId, device] of state.devices.entries()) {\\n      if (device.lastSeen < staleThreshold && device.status !== 'lost') {\\n        const lostDevice = {\\n          ...device,\\n          status: 'lost'\\n        };\\n        \\n        state.devices.set(deviceId, lostDevice);\\n        \\n        state.callbacks.onDeviceLost.forEach(cb => {\\n          try {\\n            cb(lostDevice);\\n          } catch (error) {\\n            console.warn('Device lost callback error:', error);\\n          }\\n        });\\n      }\\n    }\\n  };\\n\\n  // Start health monitoring\\n  const healthCheckInterval = setInterval(checkDeviceHealth, 10000); // Check every 10 seconds\\n\\n  // Event handlers\\n  const onDeviceFound = (callback) => {\\n    state.callbacks.onDeviceFound.push(callback);\\n    return () => {\\n      const index = state.callbacks.onDeviceFound.indexOf(callback);\\n      if (index !== -1) state.callbacks.onDeviceFound.splice(index, 1);\\n    };\\n  };\\n\\n  const onDeviceUpdated = (callback) => {\\n    state.callbacks.onDeviceUpdated.push(callback);\\n    return () => {\\n      const index = state.callbacks.onDeviceUpdated.indexOf(callback);\\n      if (index !== -1) state.callbacks.onDeviceUpdated.splice(index, 1);\\n    };\\n  };\\n\\n  const onDeviceLost = (callback) => {\\n    state.callbacks.onDeviceLost.push(callback);\\n    return () => {\\n      const index = state.callbacks.onDeviceLost.indexOf(callback);\\n      if (index !== -1) state.callbacks.onDeviceLost.splice(index, 1);\\n    };\\n  };\\n\\n  const onError = (callback) => {\\n    state.callbacks.onError.push(callback);\\n    return () => {\\n      const index = state.callbacks.onError.indexOf(callback);\\n      if (index !== -1) state.callbacks.onError.splice(index, 1);\\n    };\\n  };\\n\\n  // Cleanup function\\n  const cleanup = () => {\\n    stopDiscovery();\\n    clearInterval(healthCheckInterval);\\n    state.devices.clear();\\n  };\\n\\n  // Start mock status updates if using mock devices\\n  if (config.useMockDevices !== false) {\\n    startMockStatusUpdates();\\n  }\\n\\n  return {\\n    // Discovery control\\n    startDiscovery,\\n    stopDiscovery,\\n    \\n    // Device access\\n    getDiscoveredDevices,\\n    getDeviceById,\\n    updateDeviceStatus,\\n    \\n    // Event handlers\\n    onDeviceFound,\\n    onDeviceUpdated,\\n    onDeviceLost,\\n    onError,\\n    \\n    // Status\\n    isDiscovering: () => state.isDiscovering,\\n    getDeviceCount: () => state.devices.size,\\n    \\n    // Cleanup\\n    cleanup\\n  };\\n};\\n\\n// Discovery factory registry for different device types\\nexport const createDiscoveryFactory = () => {\\n  const discoveryTypes = new Map();\\n  \\n  const register = (type, factory) => {\\n    discoveryTypes.set(type, factory);\\n  };\\n  \\n  const create = (type, config = {}) => {\\n    const factory = discoveryTypes.get(type);\\n    if (!factory) {\\n      throw new Error(`Unknown discovery type: ${type}`);\\n    }\\n    return factory(config);\\n  };\\n  \\n  const getAvailableTypes = () => Array.from(discoveryTypes.keys());\\n  \\n  return {\\n    register,\\n    create,\\n    getAvailableTypes\\n  };\\n};\\n\\n// Default discovery factory instance\\nexport const discoveryFactory = createDiscoveryFactory();\\n\\n// Register eye tracker discovery\\ndiscoveryFactory.register('eyetracker', createDeviceDiscovery);\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/features/eye-tracking/devices/neon/index.js\",\"messages\":[],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/features/eye-tracking/devices/neon/pipeline.js\",\"messages\":[{\"ruleId\":\"max-lines-per-function\",\"severity\":1,\"message\":\"Arrow function has too many lines (304). Maximum allowed is 150.\",\"line\":16,\"column\":42,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"exceed\",\"endLine\":405,\"endColumn\":2},{\"ruleId\":\"no-undef\",\"severity\":2,\"message\":\"'eyeTracker' is not defined.\",\"line\":93,\"column\":13,\"nodeType\":\"Identifier\",\"messageId\":\"undef\",\"endLine\":93,\"endColumn\":23},{\"ruleId\":\"no-undef\",\"severity\":2,\"message\":\"'eyeTracker' is not defined.\",\"line\":94,\"column\":32,\"nodeType\":\"Identifier\",\"messageId\":\"undef\",\"endLine\":94,\"endColumn\":42},{\"ruleId\":\"prefer-destructuring\",\"severity\":1,\"message\":\"Use array destructuring.\",\"line\":97,\"column\":9,\"nodeType\":\"AssignmentExpression\",\"messageId\":\"preferDestructuring\",\"endLine\":97,\"endColumn\":46},{\"ruleId\":\"no-undef\",\"severity\":2,\"message\":\"'currentDeviceId' is not defined.\",\"line\":97,\"column\":9,\"nodeType\":\"Identifier\",\"messageId\":\"undef\",\"endLine\":97,\"endColumn\":24},{\"ruleId\":\"no-undef\",\"severity\":2,\"message\":\"'eyeTracker' is not defined.\",\"line\":99,\"column\":34,\"nodeType\":\"Identifier\",\"messageId\":\"undef\",\"endLine\":99,\"endColumn\":44},{\"ruleId\":\"no-undef\",\"severity\":2,\"message\":\"'currentDeviceId' is not defined.\",\"line\":99,\"column\":61,\"nodeType\":\"Identifier\",\"messageId\":\"undef\",\"endLine\":99,\"endColumn\":76},{\"ruleId\":\"no-undef\",\"severity\":2,\"message\":\"'eyeTracker' is not defined.\",\"line\":118,\"column\":5,\"nodeType\":\"Identifier\",\"messageId\":\"undef\",\"endLine\":118,\"endColumn\":15},{\"ruleId\":\"no-undef\",\"severity\":2,\"message\":\"'lastGazeData' is not defined.\",\"line\":119,\"column\":7,\"nodeType\":\"Identifier\",\"messageId\":\"undef\",\"endLine\":119,\"endColumn\":19},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":125,\"column\":60,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":125,\"endColumn\":61},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":125,\"column\":95,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":125,\"endColumn\":96},{\"ruleId\":\"no-undef\",\"severity\":2,\"message\":\"'eyeTracker' is not defined.\",\"line\":131,\"column\":5,\"nodeType\":\"Identifier\",\"messageId\":\"undef\",\"endLine\":131,\"endColumn\":15},{\"ruleId\":\"no-undef\",\"severity\":2,\"message\":\"'currentDeviceId' is not defined.\",\"line\":134,\"column\":9,\"nodeType\":\"Identifier\",\"messageId\":\"undef\",\"endLine\":134,\"endColumn\":24},{\"ruleId\":\"no-undef\",\"severity\":2,\"message\":\"'currentDeviceId' is not defined.\",\"line\":138,\"column\":9,\"nodeType\":\"Identifier\",\"messageId\":\"undef\",\"endLine\":138,\"endColumn\":24},{\"ruleId\":\"no-undef\",\"severity\":2,\"message\":\"'eyeTracker' is not defined.\",\"line\":143,\"column\":5,\"nodeType\":\"Identifier\",\"messageId\":\"undef\",\"endLine\":143,\"endColumn\":15},{\"ruleId\":\"no-undef\",\"severity\":2,\"message\":\"'isCalibrated' is not defined.\",\"line\":145,\"column\":9,\"nodeType\":\"Identifier\",\"messageId\":\"undef\",\"endLine\":145,\"endColumn\":21},{\"ruleId\":\"no-undef\",\"severity\":2,\"message\":\"'currentDeviceId' is not defined.\",\"line\":168,\"column\":10,\"nodeType\":\"Identifier\",\"messageId\":\"undef\",\"endLine\":168,\"endColumn\":25},{\"ruleId\":\"no-undef\",\"severity\":2,\"message\":\"'eyeTracker' is not defined.\",\"line\":172,\"column\":28,\"nodeType\":\"Identifier\",\"messageId\":\"undef\",\"endLine\":172,\"endColumn\":38},{\"ruleId\":\"no-undef\",\"severity\":2,\"message\":\"'currentDeviceId' is not defined.\",\"line\":172,\"column\":56,\"nodeType\":\"Identifier\",\"messageId\":\"undef\",\"endLine\":172,\"endColumn\":71},{\"ruleId\":\"no-undef\",\"severity\":2,\"message\":\"'eyeTracker' is not defined.\",\"line\":180,\"column\":34,\"nodeType\":\"Identifier\",\"messageId\":\"undef\",\"endLine\":180,\"endColumn\":44},{\"ruleId\":\"no-undef\",\"severity\":2,\"message\":\"'currentDeviceId' is not defined.\",\"line\":180,\"column\":61,\"nodeType\":\"Identifier\",\"messageId\":\"undef\",\"endLine\":180,\"endColumn\":76},{\"ruleId\":\"no-undef\",\"severity\":2,\"message\":\"'isCalibrated' is not defined.\",\"line\":182,\"column\":11,\"nodeType\":\"Identifier\",\"messageId\":\"undef\",\"endLine\":182,\"endColumn\":23},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'options' is assigned a value but never used. Allowed unused args must match /^_/u.\",\"line\":199,\"column\":37,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":199,\"endColumn\":44,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"options\"},\"fix\":{\"range\":[6510,6524],\"text\":\"\"},\"desc\":\"Remove unused variable 'options'.\"}]},{\"ruleId\":\"no-undef\",\"severity\":2,\"message\":\"'lastGazeData' is not defined.\",\"line\":209,\"column\":22,\"nodeType\":\"Identifier\",\"messageId\":\"undef\",\"endLine\":209,\"endColumn\":34},{\"ruleId\":\"no-nested-ternary\",\"severity\":1,\"message\":\"Do not nest ternary expressions.\",\"line\":216,\"column\":19,\"nodeType\":\"ConditionalExpression\",\"messageId\":\"noNestedTernary\",\"endLine\":216,\"endColumn\":82},{\"ruleId\":\"prefer-destructuring\",\"severity\":1,\"message\":\"Use object destructuring.\",\"line\":220,\"column\":9,\"nodeType\":\"AssignmentExpression\",\"messageId\":\"preferDestructuring\",\"endLine\":220,\"endColumn\":41},{\"ruleId\":\"no-undef\",\"severity\":2,\"message\":\"'isCalibrated' is not defined.\",\"line\":236,\"column\":23,\"nodeType\":\"Identifier\",\"messageId\":\"undef\",\"endLine\":236,\"endColumn\":35},{\"ruleId\":\"no-undef\",\"severity\":2,\"message\":\"'currentDeviceId' is not defined.\",\"line\":238,\"column\":21,\"nodeType\":\"Identifier\",\"messageId\":\"undef\",\"endLine\":238,\"endColumn\":36},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":279,\"column\":14,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":279,\"endColumn\":15},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":279,\"column\":37,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":279,\"endColumn\":38},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":280,\"column\":14,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":280,\"endColumn\":15},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":280,\"column\":37,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":280,\"endColumn\":38},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":281,\"column\":23,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":281,\"endColumn\":24},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":281,\"column\":39,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":281,\"endColumn\":40},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":284,\"column\":36,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":284,\"endColumn\":37},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":284,\"column\":53,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":284,\"endColumn\":54},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":285,\"column\":37,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":285,\"endColumn\":38},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":285,\"column\":54,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":285,\"endColumn\":55},{\"ruleId\":\"no-undef\",\"severity\":2,\"message\":\"'isCalibrated' is not defined.\",\"line\":300,\"column\":5,\"nodeType\":\"Identifier\",\"messageId\":\"undef\",\"endLine\":300,\"endColumn\":17},{\"ruleId\":\"no-undef\",\"severity\":2,\"message\":\"'currentDeviceId' is not defined.\",\"line\":301,\"column\":5,\"nodeType\":\"Identifier\",\"messageId\":\"undef\",\"endLine\":301,\"endColumn\":20},{\"ruleId\":\"no-undef\",\"severity\":2,\"message\":\"'lastGazeData' is not defined.\",\"line\":302,\"column\":24,\"nodeType\":\"Identifier\",\"messageId\":\"undef\",\"endLine\":302,\"endColumn\":36},{\"ruleId\":\"no-undef\",\"severity\":2,\"message\":\"'lastGazeData' is not defined.\",\"line\":303,\"column\":24,\"nodeType\":\"Identifier\",\"messageId\":\"undef\",\"endLine\":303,\"endColumn\":36},{\"ruleId\":\"no-undef\",\"severity\":2,\"message\":\"'currentDeviceId' is not defined.\",\"line\":308,\"column\":10,\"nodeType\":\"Identifier\",\"messageId\":\"undef\",\"endLine\":308,\"endColumn\":25},{\"ruleId\":\"no-undef\",\"severity\":2,\"message\":\"'eyeTracker' is not defined.\",\"line\":312,\"column\":26,\"nodeType\":\"Identifier\",\"messageId\":\"undef\",\"endLine\":312,\"endColumn\":36},{\"ruleId\":\"no-undef\",\"severity\":2,\"message\":\"'currentDeviceId' is not defined.\",\"line\":312,\"column\":52,\"nodeType\":\"Identifier\",\"messageId\":\"undef\",\"endLine\":312,\"endColumn\":67},{\"ruleId\":\"no-undef\",\"severity\":2,\"message\":\"'currentDeviceId' is not defined.\",\"line\":321,\"column\":10,\"nodeType\":\"Identifier\",\"messageId\":\"undef\",\"endLine\":321,\"endColumn\":25},{\"ruleId\":\"no-undef\",\"severity\":2,\"message\":\"'eyeTracker' is not defined.\",\"line\":325,\"column\":26,\"nodeType\":\"Identifier\",\"messageId\":\"undef\",\"endLine\":325,\"endColumn\":36},{\"ruleId\":\"no-undef\",\"severity\":2,\"message\":\"'currentDeviceId' is not defined.\",\"line\":325,\"column\":51,\"nodeType\":\"Identifier\",\"messageId\":\"undef\",\"endLine\":325,\"endColumn\":66}],\"suppressedMessages\":[],\"errorCount\":32,\"fatalErrorCount\":0,\"warningCount\":16,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Eye Tracking Pipeline Wrapper\\n * Integrates the eye tracking system with the main pipeline orchestrator\\n * Following functional programming patterns with factory functions\\n */\\n\\nimport { createPipeline } from '../../../../core/pipeline/pipeline.js';\\nimport { createPipelineConfig } from '../../../../core/pipeline/pipeline-config.js';\\nimport { createImageProcessor } from '../../../../core/engine/image-processor.js';\\nimport { getGlobalResourcePool } from '../../../../core/performance/resource-pool.js';\\nimport { createEyeTracker } from '../../index.js';\\nimport { Capability, createEyeTrackingResult, createGazeData, createPerformanceProfile } from '../../../../core/configuration/types.js';\\nimport { ErrorCategory, ErrorSeverity, handleError } from '../../../../shared/utils/error-handler.js';\\n\\n// Eye tracking pipeline factory\\nexport const createEyeTrackingPipeline = (userConfig = {}) => {\\n  // Use unified configuration system\\n  const config = createPipelineConfig('eye-tracking', userConfig);\\n\\n  const state = {\\n    eyeTracker: null,\\n    currentDeviceId: null,\\n    isCalibrated: false,\\n    lastGazeData: null,\\n    imageProcessor: null,\\n    resourcePool: null,\\n    isInitialized: false,\\n    config,\\n    // Pipeline-specific state\\n    connected: false,\\n    streaming: false,\\n    sessionActive: false,\\n    calibrationStatus: 'not_started',\\n    lastProcessingTime: 0,\\n    totalFramesProcessed: 0,\\n    averageConfidence: 0,\\n    deviceInfo: null\\n  };\\n\\n  // Initialize the eye tracking system\\n  const initialize = async (initConfig = {}) => {\\n    if (state.isInitialized) return true;\\n\\n    try {\\n      handleError(\\n        'Initializing Eye Tracking pipeline',\\n        ErrorCategory.INITIALIZATION,\\n        ErrorSeverity.INFO,\\n        { config: state.config }\\n      );\\n\\n      // Initialize shared resources\\n      state.resourcePool = getGlobalResourcePool();\\n      state.imageProcessor = createImageProcessor({ resourcePool: state.resourcePool });\\n\\n      // Merge pipeline config with options\\n      const eyeTrackerConfig = {\\n        useMockDevices: state.config.useMockDevices !== false,\\n        autoStart: true,\\n        enableSynchronization: true,\\n        ...initConfig.eyeTracking\\n      };\\n\\n      state.eyeTracker = createEyeTracker(eyeTrackerConfig);\\n      await state.eyeTracker.initialize();\\n\\n      // Setup event handlers for pipeline integration\\n      setupEventHandlers();\\n\\n      state.isInitialized = true;\\n      console.log('✅ Eye tracking pipeline initialized successfully');\\n\\n      // Auto-connect if enabled\\n      if (state.config.autoConnect !== false) {\\n        await autoConnectToDevice();\\n      }\\n\\n      return true;\\n    } catch (error) {\\n      handleError(\\n        `Eye tracking pipeline initialization failed: ${error.message}`,\\n        ErrorCategory.INITIALIZATION,\\n        ErrorSeverity.ERROR,\\n        { error }\\n      );\\n      throw new Error(`Eye tracking pipeline initialization failed: ${error.message}`);\\n    }\\n  };\\n\\n  // Auto-connect to first available device\\n  const autoConnectToDevice = async () => {\\n    try {\\n      await eyeTracker.autoConnectToFirstDevice();\\n      const connectedDevices = eyeTracker.getConnectedDevices();\\n      \\n      if (connectedDevices.length > 0) {\\n        currentDeviceId = connectedDevices[0];\\n        state.connected = true;\\n        state.deviceInfo = await eyeTracker.getDeviceStatus(currentDeviceId);\\n        \\n        // Start streaming\\n        await startStreaming();\\n        \\n        // Auto-calibrate if enabled\\n        if (config.autoCalibrate !== false) {\\n          await performCalibration();\\n        }\\n      }\\n    } catch (error) {\\n      console.warn('Auto-connect to eye tracker failed:', error.message);\\n      // Continue without device - can use mock data\\n    }\\n  };\\n\\n  // Setup event handlers for pipeline integration\\n  const setupEventHandlers = () => {\\n    // Handle gaze data\\n    eyeTracker.onGazeData((gazeData) => {\\n      lastGazeData = gazeData;\\n      state.streaming = true;\\n      \\n      // Update statistics\\n      state.totalFramesProcessed++;\\n      if (gazeData.confidence) {\\n        state.averageConfidence = (state.averageConfidence * (state.totalFramesProcessed - 1) + \\n          gazeData.confidence) / state.totalFramesProcessed;\\n      }\\n    });\\n\\n    // Handle device connection changes\\n    eyeTracker.onDeviceStatusChange((event) => {\\n      if (event.event === 'connected') {\\n        state.connected = true;\\n        currentDeviceId = event.deviceId;\\n      } else if (event.event === 'disconnected') {\\n        state.connected = false;\\n        state.streaming = false;\\n        currentDeviceId = null;\\n      }\\n    });\\n\\n    // Handle calibration updates\\n    eyeTracker.onCalibrationProgress((update) => {\\n      if (update.event === 'completed') {\\n        isCalibrated = true;\\n        state.calibrationStatus = 'completed';\\n      } else if (update.event === 'started') {\\n        state.calibrationStatus = 'in_progress';\\n      }\\n    });\\n  };\\n\\n  // Start gaze data streaming\\n  const startStreaming = async () => {\\n    if (!state.connected || state.streaming) return;\\n\\n    try {\\n      // Streaming is handled automatically by device connection\\n      state.streaming = true;\\n      console.log('Eye tracking streaming started');\\n    } catch (error) {\\n      console.warn('Failed to start eye tracking streaming:', error);\\n    }\\n  };\\n\\n  // Perform calibration\\n  const performCalibration = async () => {\\n    if (!currentDeviceId) return false;\\n\\n    try {\\n      state.calibrationStatus = 'starting';\\n      const result = await eyeTracker.startCalibration(currentDeviceId);\\n      \\n      if (result.success) {\\n        // Wait for calibration to complete (auto-handled by mock devices)\\n        // Reduced for better test performance\\n        const calibrationDelay = state.config.mockCalibrationDelay || 200;\\n        await new Promise(resolve => setTimeout(resolve, calibrationDelay));\\n        \\n        const stopResult = await eyeTracker.stopCalibration(currentDeviceId, result.sessionId);\\n        if (stopResult.success) {\\n          isCalibrated = true;\\n          state.calibrationStatus = 'completed';\\n          console.log('Eye tracking calibration completed');\\n          return true;\\n        }\\n      }\\n      \\n      state.calibrationStatus = 'failed';\\n      return false;\\n    } catch (error) {\\n      console.warn('Eye tracking calibration failed:', error);\\n      state.calibrationStatus = 'failed';\\n      return false;\\n    }\\n  };\\n\\n  // Main processing function - integrates with pipeline interface\\n  const process = async (imageData, options = {}) => {\\n    const startTime = performance.now();\\n\\n    try {\\n      // Ensure system is ready\\n      if (!state.initialized) {\\n        throw new Error('Eye tracking pipeline not initialized');\\n      }\\n\\n      // Get current gaze data\\n      let gazeData = lastGazeData;\\n      let confidence = 0;\\n      let quality = 'no_data';\\n\\n      if (gazeData && state.streaming) {\\n        // Use real gaze data\\n        confidence = gazeData.confidence || 0;\\n        quality = confidence > 0.8 ? 'high' : confidence > 0.6 ? 'medium' : 'low';\\n      } else if (config.useMockDevices !== false) {\\n        // Generate mock gaze data for testing\\n        gazeData = generateMockGazeData();\\n        confidence = gazeData.confidence;\\n        quality = 'mock';\\n      } else {\\n        // No data available\\n        gazeData = null;\\n        confidence = 0;\\n        quality = 'unavailable';\\n      }\\n\\n      // Create standardized result\\n      const result = createEyeTrackingResult({\\n        timestamp: Date.now(),\\n        source: 'eye_tracking_pipeline',\\n        gazeData: gazeData ? [gazeData] : [],\\n        deviceStatus: {\\n          connected: state.connected,\\n          calibrated: isCalibrated,\\n          streaming: state.streaming,\\n          deviceId: currentDeviceId\\n        },\\n        quality: {\\n          level: quality,\\n          confidence,\\n          dataAvailable: gazeData !== null\\n        },\\n        metadata: {\\n          processingTime: performance.now() - startTime,\\n          totalFramesProcessed: state.totalFramesProcessed,\\n          averageConfidence: state.averageConfidence,\\n          calibrationStatus: state.calibrationStatus\\n        }\\n      });\\n\\n      state.lastProcessingTime = performance.now() - startTime;\\n      return result;\\n\\n    } catch (error) {\\n      console.warn('Eye tracking pipeline processing error:', error);\\n      \\n      // Return error result\\n      return createEyeTrackingResult({\\n        timestamp: Date.now(),\\n        source: 'eye_tracking_pipeline',\\n        gazeData: [],\\n        error: error.message,\\n        quality: { level: 'error', confidence: 0, dataAvailable: false },\\n        metadata: {\\n          processingTime: performance.now() - startTime,\\n          error: true\\n        }\\n      });\\n    }\\n  };\\n\\n  // Generate mock gaze data for testing\\n  const generateMockGazeData = () => {\\n    const time = Date.now() / 1000;\\n    return createGazeData({\\n      timestamp: Date.now(),\\n      x: 0.5 + Math.sin(time * 0.5) * 0.2,\\n      y: 0.5 + Math.cos(time * 0.3) * 0.15,\\n      confidence: 0.8 + Math.random() * 0.2,\\n      worn: true,\\n      eyeStates: {\\n        left: { pupilDiameter: 3.2 + Math.sin(time) * 0.2 },\\n        right: { pupilDiameter: 3.1 + Math.sin(time) * 0.2 }\\n      }\\n    });\\n  };\\n\\n  // Get pipeline capabilities\\n  const getCapabilities = () => [\\n    Capability.EYE_TRACKING,\\n    Capability.GAZE_ESTIMATION,\\n    Capability.DEVICE_CONTROL\\n  ];\\n\\n  // Get pipeline status\\n  const getStatus = () => ({\\n    ...state,\\n    isCalibrated,\\n    currentDeviceId,\\n    lastGazeAvailable: lastGazeData !== null,\\n    lastGazeTimestamp: lastGazeData?.timestamp || null\\n  });\\n\\n  // Start recording session\\n  const startRecording = async (recordingId) => {\\n    if (!currentDeviceId) {\\n      throw new Error('No eye tracking device connected');\\n    }\\n\\n    const result = await eyeTracker.startRecording(currentDeviceId, { recordingId });\\n    if (result.success) {\\n      state.sessionActive = true;\\n    }\\n    return result;\\n  };\\n\\n  // Stop recording session\\n  const stopRecording = async () => {\\n    if (!currentDeviceId || !state.sessionActive) {\\n      return { success: false, reason: 'No active recording session' };\\n    }\\n\\n    const result = await eyeTracker.stopRecording(currentDeviceId);\\n    if (result.success) {\\n      state.sessionActive = false;\\n    }\\n    return result;\\n  };\\n\\n  // Cleanup pipeline resources\\n  const cleanup = () => {\\n    try {\\n      if (state.sessionActive && state.currentDeviceId) {\\n        state.eyeTracker.stopRecording(state.currentDeviceId);\\n      }\\n      \\n      if (state.eyeTracker) {\\n        state.eyeTracker.shutdown();\\n      }\\n      \\n      // Clean up image processor cache\\n      if (state.imageProcessor) {\\n        state.imageProcessor.cleanup();\\n      }\\n      \\n      // Reset state\\n      state.eyeTracker = null;\\n      state.currentDeviceId = null;\\n      state.isCalibrated = false;\\n      state.lastGazeData = null;\\n      state.isInitialized = false;\\n      state.connected = false;\\n      state.streaming = false;\\n      state.sessionActive = false;\\n      state.calibrationStatus = 'not_started';\\n      \\n      console.log('🧹 Eye tracking pipeline cleaned up');\\n    } catch (error) {\\n      console.warn('⚠️ Eye tracking pipeline cleanup error:', error);\\n    }\\n  };\\n\\n  // Return standardized pipeline interface\\n  return createPipeline({\\n    name: 'eye-tracking',\\n    capabilities: [\\n      Capability.EYE_TRACKING,\\n      Capability.GAZE_ESTIMATION,\\n      Capability.DEVICE_CONTROL\\n    ],\\n    performance: createPerformanceProfile({\\n      fps: 30,\\n      latency: '5-15ms',\\n      modelSize: 'Variable (hardware)',\\n      cpuUsage: 'low',\\n      memoryUsage: 'medium',\\n      batteryImpact: 'high' // Hardware device\\n    }),\\n    initialize,\\n    process,\\n    cleanup,\\n    getConfig: () => state.config,\\n    updateConfig: (updates) => {\\n      state.config = { ...state.config, ...updates };\\n    },\\n    isInitialized: () => state.isInitialized,\\n    getHealthStatus: () => ({\\n      healthy: state.eyeTracker && state.eyeTracker.getStatus().connected,\\n      runtime: 'universal', // Works in both browser and Node.js\\n      backend: 'pupil-labs-neon',\\n      modelLoaded: !!state.eyeTracker,\\n      deviceConnected: state.eyeTracker ? state.eyeTracker.getStatus().connected : false\\n    }),\\n    \\n    // Eye tracking specific methods\\n    startRecording,\\n    stopRecording,\\n    performCalibration,\\n    getCapabilities,\\n    getStatus,\\n    getEyeTracker: () => state.eyeTracker\\n  });\\n};\\n\\n// Factory function for pipeline registration\\nexport const createEyeTrackingPipelineFactory = () => ({\\n  name: 'eye-tracking',\\n  description: 'Pupil Labs Neon eye tracker integration pipeline',\\n  capabilities: [Capability.EYE_TRACKING, Capability.GAZE_ESTIMATION, Capability.DEVICE_CONTROL],\\n  create: createEyeTrackingPipeline,\\n  requiresHardware: false, // Can work with mock devices\\n  supportsRealtime: true,\\n  supportsCalibration: true\\n});\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/features/eye-tracking/devices/neon/streaming.js\",\"messages\":[{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'createDataStream' is defined but never used. Allowed unused vars must match /^_/u.\",\"line\":7,\"column\":10,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":7,\"endColumn\":26,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"createDataStream\"},\"fix\":{\"range\":[210,227],\"text\":\"\"},\"desc\":\"Remove unused variable 'createDataStream'.\"}]},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'streamFactory' is defined but never used. Allowed unused vars must match /^_/u.\",\"line\":7,\"column\":28,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":7,\"endColumn\":41,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"streamFactory\"},\"fix\":{\"range\":[226,241],\"text\":\"\"},\"desc\":\"Remove unused variable 'streamFactory'.\"}]},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'createGazeData' is defined but never used. Allowed unused vars must match /^_/u.\",\"line\":11,\"column\":35,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":11,\"endColumn\":49,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"createGazeData\"},\"fix\":{\"range\":[525,541],\"text\":\"\"},\"desc\":\"Remove unused variable 'createGazeData'.\"}]},{\"ruleId\":\"max-lines-per-function\",\"severity\":1,\"message\":\"Arrow function has too many lines (295). Maximum allowed is 150.\",\"line\":14,\"column\":43,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"exceed\",\"endLine\":405,\"endColumn\":2},{\"ruleId\":\"prefer-destructuring\",\"severity\":1,\"message\":\"Use array destructuring.\",\"line\":309,\"column\":11,\"nodeType\":\"VariableDeclarator\",\"messageId\":\"preferDestructuring\",\"endLine\":309,\"endColumn\":30}],\"suppressedMessages\":[],\"errorCount\":3,\"fatalErrorCount\":0,\"warningCount\":2,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Eye Tracking Real-time Streaming Integration\\n * Integrates eye tracking streams with existing multimodal synchronization\\n * Following functional programming patterns with factory functions\\n */\\n\\nimport { createDataStream, streamFactory } from '../../../../core/state/streams.js';\\nimport { createSynchronizationEngine } from '../../../../core/orchestration/synchronization.js';\\nimport { createEyeTrackerDevice } from './device.js';\\nimport { createDeviceDiscovery } from './discovery.js';\\nimport { createEyeTrackingResult, createGazeData } from '../../../../core/configuration/types.ts';\\n\\n// Eye tracking stream orchestrator factory\\nexport const createEyeTrackingStreaming = (config = {}) => {\\n  const state = {\\n    devices: new Map(),\\n    streams: new Map(),\\n    discovery: null,\\n    synchronization: null,\\n    isActive: false,\\n    callbacks: {\\n      onGazeData: [],\\n      onDeviceConnection: [],\\n      onStreamUpdate: [],\\n      onError: []\\n    },\\n    streamConfig: {\\n      sampleRate: config.sampleRate || 200,\\n      bufferSize: config.bufferSize || 2000,\\n      syncTolerance: config.syncTolerance || 10, // 10ms tolerance\\n      enableQualityMonitoring: config.enableQualityMonitoring !== false\\n    }\\n  };\\n\\n  // Initialize discovery service\\n  const initializeDiscovery = () => {\\n    state.discovery = createDeviceDiscovery({\\n      useMockDevices: config.useMockDevices !== false,\\n      discoveryTimeout: config.discoveryTimeout || 10000\\n    });\\n\\n    // Handle device discovery\\n    state.discovery.onDeviceFound((device) => {\\n      console.log(`Eye tracker discovered: ${device.name} (${device.id})`);\\n      \\n      state.callbacks.onDeviceConnection.forEach(cb => {\\n        try {\\n          cb({ event: 'discovered', device });\\n        } catch (error) {\\n          console.warn('Device connection callback error:', error);\\n        }\\n      });\\n    });\\n\\n    state.discovery.onDeviceUpdated((device) => {\\n      // Update device status in existing connections\\n      const eyeTracker = state.devices.get(device.id);\\n      if (eyeTracker) {\\n        // Notify about device status updates\\n        state.callbacks.onDeviceConnection.forEach(cb => {\\n          try {\\n            cb({ event: 'updated', device });\\n          } catch (error) {\\n            console.warn('Device connection callback error:', error);\\n          }\\n        });\\n      }\\n    });\\n\\n    state.discovery.onError((error) => {\\n      notifyError(new Error(`Discovery error: ${error.message}`));\\n    });\\n  };\\n\\n  // Initialize synchronization engine\\n  const initializeSynchronization = () => {\\n    state.synchronization = createSynchronizationEngine({\\n      tolerance: state.streamConfig.syncTolerance,\\n      strategy: config.syncStrategy || 'hardware_timestamp',\\n      bufferSize: 100\\n    });\\n\\n    // Handle synchronized data\\n    state.synchronization.onSynchronizedData((syncedStreams) => {\\n      const eyeTrackingData = syncedStreams.filter(stream => stream.streamType === 'eyetracking');\\n      \\n      if (eyeTrackingData.length > 0) {\\n        const result = createEyeTrackingResult({\\n          timestamp: syncedStreams[0]?.timestamp || Date.now(),\\n          gazeData: eyeTrackingData,\\n          synchronizedWith: syncedStreams.filter(s => s.streamType !== 'eyetracking').map(s => s.streamType),\\n          quality: calculateSyncQuality(syncedStreams)\\n        });\\n\\n        state.callbacks.onStreamUpdate.forEach(cb => {\\n          try {\\n            cb(result);\\n          } catch (error) {\\n            console.warn('Stream update callback error:', error);\\n          }\\n        });\\n      }\\n    });\\n  };\\n\\n  // Calculate synchronization quality\\n  const calculateSyncQuality = (streams) => {\\n    if (streams.length < 2) return 1.0;\\n    \\n    const timestamps = streams.map(s => s.timestamp);\\n    const maxDiff = Math.max(...timestamps) - Math.min(...timestamps);\\n    \\n    // Quality decreases as time difference increases\\n    return Math.max(0, 1 - (maxDiff / state.streamConfig.syncTolerance));\\n  };\\n\\n  // Connect to eye tracker device\\n  const connectDevice = async (deviceId) => {\\n    if (state.devices.has(deviceId)) {\\n      throw new Error(`Device ${deviceId} already connected`);\\n    }\\n\\n    let deviceInfo = state.discovery ? state.discovery.getDeviceById(deviceId) : null;\\n    if (!deviceInfo && config.useMockDevices !== false) {\\n      // Create mock device info for testing\\n      deviceInfo = {\\n        id: deviceId,\\n        address: process.env.NEON_DEVICE_ADDRESS || 'localhost',\\n        port: 8080,\\n        name: `Mock Device ${deviceId}`\\n      };\\n    } else if (!deviceInfo) {\\n      throw new Error(`Device ${deviceId} not found`);\\n    }\\n\\n    const eyeTracker = createEyeTrackerDevice({\\n      deviceId: deviceInfo.id,\\n      address: deviceInfo.address,\\n      port: deviceInfo.port,\\n      mockMode: config.useMockDevices !== false,\\n      autoReconnect: true,\\n      ...config.deviceConfig\\n    });\\n\\n    // Setup device event handlers\\n    setupDeviceHandlers(eyeTracker);\\n\\n    // Connect to device\\n    await eyeTracker.connect();\\n\\n    // Store device and create stream\\n    state.devices.set(deviceId, eyeTracker);\\n    \\n    const gazeStream = eyeTracker.getGazeStream();\\n    state.streams.set(deviceId, gazeStream);\\n\\n    // Register stream with synchronization engine if available\\n    if (state.synchronization) {\\n      state.synchronization.addStream(`eyetracking-${deviceId}`, gazeStream);\\n    }\\n\\n    state.callbacks.onDeviceConnection.forEach(cb => {\\n      try {\\n        cb({ event: 'connected', device: deviceInfo, deviceId });\\n      } catch (error) {\\n        console.warn('Device connection callback error:', error);\\n      }\\n    });\\n\\n    return eyeTracker;\\n  };\\n\\n  // Setup device event handlers\\n  const setupDeviceHandlers = (eyeTracker) => {\\n    eyeTracker.onGazeData((gazeData) => {\\n      // Forward gaze data to callbacks\\n      state.callbacks.onGazeData.forEach(cb => {\\n        try {\\n          cb(gazeData);\\n        } catch (error) {\\n          console.warn('Gaze data callback error:', error);\\n        }\\n      });\\n\\n      // Add to synchronization if active and not using synchronization callbacks\\n      if (!state.synchronization && state.callbacks.onStreamUpdate.length > 0) {\\n        // Direct streaming without synchronization\\n        const result = createEyeTrackingResult({\\n          timestamp: gazeData.timestamp,\\n          gazeData: [gazeData],\\n          synchronizedWith: [],\\n          quality: 1.0\\n        });\\n\\n        state.callbacks.onStreamUpdate.forEach(cb => {\\n          try {\\n            cb(result);\\n          } catch (error) {\\n            console.warn('Stream update callback error:', error);\\n          }\\n        });\\n      }\\n    });\\n\\n    eyeTracker.onConnectionChange((change) => {\\n      state.callbacks.onDeviceConnection.forEach(cb => {\\n        try {\\n          cb({ \\n            event: 'connection_change', \\n            deviceId: change.deviceId,\\n            oldState: change.oldState,\\n            newState: change.newState \\n          });\\n        } catch (error) {\\n          console.warn('Device connection callback error:', error);\\n        }\\n      });\\n    });\\n\\n    eyeTracker.onError((error) => {\\n      notifyError(new Error(`Device ${eyeTracker.getDeviceId()} error: ${error.message}`));\\n    });\\n  };\\n\\n  // Disconnect device\\n  const disconnectDevice = (deviceId) => {\\n    const eyeTracker = state.devices.get(deviceId);\\n    if (!eyeTracker) {\\n      throw new Error(`Device ${deviceId} not connected`);\\n    }\\n\\n    // Remove from synchronization\\n    if (state.synchronization) {\\n      state.synchronization.removeStream(`eyetracking-${deviceId}`);\\n    }\\n\\n    // Cleanup device\\n    eyeTracker.cleanup();\\n\\n    // Remove from state\\n    state.devices.delete(deviceId);\\n    state.streams.delete(deviceId);\\n\\n    state.callbacks.onDeviceConnection.forEach(cb => {\\n      try {\\n        cb({ event: 'disconnected', deviceId });\\n      } catch (error) {\\n        console.warn('Device connection callback error:', error);\\n      }\\n    });\\n  };\\n\\n  // Start streaming system\\n  const start = async () => {\\n    if (state.isActive) return;\\n\\n    // Initialize components\\n    initializeDiscovery();\\n    if (config.enableSynchronization !== false) {\\n      initializeSynchronization();\\n    }\\n\\n    // Start discovery\\n    if (state.discovery) {\\n      await state.discovery.startDiscovery();\\n    }\\n\\n    state.isActive = true;\\n  };\\n\\n  // Stop streaming system\\n  const stop = () => {\\n    if (!state.isActive) return;\\n\\n    // Stop discovery\\n    if (state.discovery) {\\n      state.discovery.stopDiscovery();\\n      state.discovery.cleanup();\\n    }\\n\\n    // Disconnect all devices\\n    for (const deviceId of state.devices.keys()) {\\n      try {\\n        disconnectDevice(deviceId);\\n      } catch (error) {\\n        console.warn(`Error disconnecting device ${deviceId}:`, error);\\n      }\\n    }\\n\\n    // Stop synchronization\\n    if (state.synchronization) {\\n      state.synchronization.stop();\\n    }\\n\\n    state.isActive = false;\\n  };\\n\\n  // Auto-connect to first discovered device\\n  const autoConnect = async () => {\\n    if (!state.discovery) {\\n      throw new Error('Discovery not initialized');\\n    }\\n\\n    const devices = state.discovery.getDiscoveredDevices();\\n    if (devices.length === 0) {\\n      throw new Error('No devices discovered');\\n    }\\n\\n    const device = devices[0];\\n    return await connectDevice(device.id);\\n  };\\n\\n  // Get streaming statistics\\n  const getStats = () => ({\\n    isActive: state.isActive,\\n    connectedDevices: state.devices.size,\\n    activeStreams: state.streams.size,\\n    discoveredDevices: state.discovery ? state.discovery.getDeviceCount() : 0,\\n    syncEngine: state.synchronization ? state.synchronization.getStats() : null,\\n    streamConfig: { ...state.streamConfig }\\n  });\\n\\n  // Error handling\\n  const notifyError = (error) => {\\n    state.callbacks.onError.forEach(cb => {\\n      try {\\n        cb(error);\\n      } catch (cbError) {\\n        console.warn('Error callback failed:', cbError);\\n      }\\n    });\\n  };\\n\\n  // Event handlers\\n  const onGazeData = (callback) => {\\n    state.callbacks.onGazeData.push(callback);\\n    return () => {\\n      const index = state.callbacks.onGazeData.indexOf(callback);\\n      if (index !== -1) state.callbacks.onGazeData.splice(index, 1);\\n    };\\n  };\\n\\n  const onDeviceConnection = (callback) => {\\n    state.callbacks.onDeviceConnection.push(callback);\\n    return () => {\\n      const index = state.callbacks.onDeviceConnection.indexOf(callback);\\n      if (index !== -1) state.callbacks.onDeviceConnection.splice(index, 1);\\n    };\\n  };\\n\\n  const onStreamUpdate = (callback) => {\\n    state.callbacks.onStreamUpdate.push(callback);\\n    return () => {\\n      const index = state.callbacks.onStreamUpdate.indexOf(callback);\\n      if (index !== -1) state.callbacks.onStreamUpdate.splice(index, 1);\\n    };\\n  };\\n\\n  const onError = (callback) => {\\n    state.callbacks.onError.push(callback);\\n    return () => {\\n      const index = state.callbacks.onError.indexOf(callback);\\n      if (index !== -1) state.callbacks.onError.splice(index, 1);\\n    };\\n  };\\n\\n  return {\\n    // Control\\n    start,\\n    stop,\\n    \\n    // Device management\\n    connectDevice,\\n    disconnectDevice,\\n    autoConnect,\\n    \\n    // Discovery\\n    getDiscoveredDevices: () => state.discovery ? state.discovery.getDiscoveredDevices() : [],\\n    getConnectedDevices: () => Array.from(state.devices.keys()),\\n    getDevice: (deviceId) => state.devices.get(deviceId),\\n    \\n    // Synchronization\\n    getSynchronizationEngine: () => state.synchronization,\\n    addExternalStream: (streamId, stream) => {\\n      if (state.synchronization) {\\n        state.synchronization.addStream(streamId, stream);\\n      }\\n    },\\n    \\n    // Event handlers\\n    onGazeData,\\n    onDeviceConnection,\\n    onStreamUpdate,\\n    onError,\\n    \\n    // Status\\n    isActive: () => state.isActive,\\n    getStats,\\n    \\n    // Configuration\\n    updateConfig: (newConfig) => {\\n      Object.assign(state.streamConfig, newConfig);\\n    }\\n  };\\n};\\n\\n// Convenience factory for quick setup\\nexport const createEyeTrackingSystem = (config = {}) => {\\n  const system = createEyeTrackingStreaming(config);\\n  \\n  // Auto-start if requested\\n  if (config.autoStart) {\\n    system.start().then(() => {\\n      if (config.autoConnect) {\\n        system.autoConnect().catch(error => {\\n          console.warn('Auto-connect failed:', error);\\n        });\\n      }\\n    }).catch(error => {\\n      console.error('System start failed:', error);\\n    });\\n  }\\n  \\n  return system;\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/features/eye-tracking/devices/webcam/index.js\",\"messages\":[],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/features/eye-tracking/devices/webcam/pipeline.js\",\"messages\":[{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'calculateEyeAspectRatio' is defined but never used. Allowed unused vars must match /^_/u.\",\"line\":12,\"column\":3,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":12,\"endColumn\":26,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"calculateEyeAspectRatio\"},\"fix\":{\"range\":[499,526],\"text\":\"\"},\"desc\":\"Remove unused variable 'calculateEyeAspectRatio'.\"}]},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'checkMediaPipeAvailability' is defined but never used. Allowed unused vars must match /^_/u.\",\"line\":13,\"column\":3,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":13,\"endColumn\":29,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"checkMediaPipeAvailability\"},\"fix\":{\"range\":[526,556],\"text\":\"\"},\"desc\":\"Remove unused variable 'checkMediaPipeAvailability'.\"}]},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'createMediaPipeBase' is defined but never used. Allowed unused vars must match /^_/u.\",\"line\":14,\"column\":3,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":14,\"endColumn\":22,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"createMediaPipeBase\"},\"fix\":{\"range\":[556,579],\"text\":\"\"},\"desc\":\"Remove unused variable 'createMediaPipeBase'.\"}]},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'createMediaPipeLoader' is defined but never used. Allowed unused vars must match /^_/u.\",\"line\":15,\"column\":3,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":15,\"endColumn\":24,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"createMediaPipeLoader\"},\"fix\":{\"range\":[579,604],\"text\":\"\"},\"desc\":\"Remove unused variable 'createMediaPipeLoader'.\"}]},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'extractIrisLandmarks' is defined but never used. Allowed unused vars must match /^_/u.\",\"line\":16,\"column\":3,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":16,\"endColumn\":23,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"extractIrisLandmarks\"},\"fix\":{\"range\":[604,628],\"text\":\"\"},\"desc\":\"Remove unused variable 'extractIrisLandmarks'.\"}]},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'EXTENDED_IRIS_LANDMARKS' is assigned a value but never used. Allowed unused vars must match /^_/u.\",\"line\":30,\"column\":7,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":30,\"endColumn\":30,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"EXTENDED_IRIS_LANDMARKS\"},\"fix\":{\"range\":[1074,1747],\"text\":\"\"},\"desc\":\"Remove unused variable 'EXTENDED_IRIS_LANDMARKS'.\"}]},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'eyeModel' is assigned a value but never used. Allowed unused args must match /^_/u.\",\"line\":69,\"column\":66,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":69,\"endColumn\":74,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"eyeModel\"},\"fix\":{\"range\":[2283,2308],\"text\":\"\"},\"desc\":\"Remove unused variable 'eyeModel'.\"}]},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":105,\"column\":39,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":105,\"endColumn\":40},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":105,\"column\":47,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":105,\"endColumn\":48},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":105,\"column\":47,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":105,\"endColumn\":48},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":105,\"column\":55,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":105,\"endColumn\":56},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":105,\"column\":63,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":105,\"endColumn\":64},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":105,\"column\":71,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":105,\"endColumn\":72},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'error' is defined but never used.\",\"line\":130,\"column\":12,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":130,\"endColumn\":17},{\"ruleId\":\"prefer-destructuring\",\"severity\":1,\"message\":\"Use array destructuring.\",\"line\":142,\"column\":11,\"nodeType\":\"VariableDeclarator\",\"messageId\":\"preferDestructuring\",\"endLine\":142,\"endColumn\":52},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '/' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":272,\"column\":36,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":272,\"endColumn\":37},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '/' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":272,\"column\":42,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":272,\"endColumn\":43},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '/' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":273,\"column\":37,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":273,\"endColumn\":38},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '/' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":273,\"column\":43,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":273,\"endColumn\":44},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":314,\"column\":13,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":314,\"endColumn\":14},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":314,\"column\":44,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":314,\"endColumn\":45},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":314,\"column\":44,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":314,\"endColumn\":45},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":314,\"column\":58,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":314,\"endColumn\":59},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":318,\"column\":13,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":318,\"endColumn\":14},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":318,\"column\":45,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":318,\"endColumn\":46},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":318,\"column\":45,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":318,\"endColumn\":46},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":318,\"column\":59,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":318,\"endColumn\":60},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":322,\"column\":13,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":322,\"endColumn\":14},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":322,\"column\":42,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":322,\"endColumn\":43},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":322,\"column\":42,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":322,\"endColumn\":43},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":322,\"column\":56,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":322,\"endColumn\":57},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":326,\"column\":40,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":326,\"endColumn\":41},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":326,\"column\":66,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":326,\"endColumn\":67},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":326,\"column\":66,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":326,\"endColumn\":67},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":326,\"column\":80,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":326,\"endColumn\":81},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":327,\"column\":41,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":327,\"endColumn\":42},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":327,\"column\":68,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":327,\"endColumn\":69},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":327,\"column\":68,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":327,\"endColumn\":69},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":327,\"column\":82,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":327,\"endColumn\":83},{\"ruleId\":\"max-lines-per-function\",\"severity\":1,\"message\":\"Arrow function has too many lines (178). Maximum allowed is 150.\",\"line\":394,\"column\":43,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"exceed\",\"endLine\":602,\"endColumn\":2},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'initConfig' is assigned a value but never used. Allowed unused args must match /^_/u.\",\"line\":408,\"column\":29,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":408,\"endColumn\":39,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"initConfig\"},\"fix\":{\"range\":[14075,14090],\"text\":\"\"},\"desc\":\"Remove unused variable 'initConfig'.\"}]}],\"suppressedMessages\":[],\"errorCount\":9,\"fatalErrorCount\":0,\"warningCount\":32,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * MediaPipe Iris Tracking Pipeline\\n * Specialized pipeline for high-precision eye tracking and gaze estimation\\n */\\n\\nimport { createPipeline } from '../../../../core/pipeline/pipeline.js';\\nimport { createPipelineConfig } from '../../../../core/pipeline/pipeline-config.js';\\nimport { createImageProcessor } from '../../../../core/engine/image-processor.js';\\nimport { getGlobalResourcePool } from '../../../../core/performance/resource-pool.js';\\nimport { \\n  IRIS_LANDMARKS as SHARED_IRIS_LANDMARKS,\\n  calculateEyeAspectRatio,\\n  checkMediaPipeAvailability,\\n  createMediaPipeBase,\\n  createMediaPipeLoader,\\n  extractIrisLandmarks\\n} from '../../../../core/integration/mediapipe-commons.js';\\nimport { \\n  Capability,\\n  createAnalysisResult,\\n  createEyeResult,\\n  createPerformanceProfile\\n} from '../../../../core/configuration/types.js';\\nimport { ErrorCategory, ErrorSeverity, handleError } from '../../../../shared/utils/error-handler.js';\\n\\n// Use shared iris landmarks from MediaPipe commons\\nconst IRIS_LANDMARKS = SHARED_IRIS_LANDMARKS;\\n\\n// Extended iris landmark definitions\\nconst EXTENDED_IRIS_LANDMARKS = {\\n  // Inherit from shared landmarks\\n  ...SHARED_IRIS_LANDMARKS,\\n  \\n  // Eye contour landmarks\\n  leftEyeContour: [\\n    33, 7, 163, 144, 145, 153, 154, 155, 133, 173, 157, 158, 159, 160, 161, 246\\n  ],\\n  rightEyeContour: [\\n    362, 382, 381, 380, 374, 373, 390, 249, 263, 466, 388, 387, 386, 385, 384, 398\\n  ],\\n  \\n  // Key reference points\\n  leftEyeInner: 133,      // Inner corner\\n  leftEyeOuter: 33,       // Outer corner\\n  rightEyeInner: 362,     // Inner corner\\n  rightEyeOuter: 263,     // Outer corner\\n  \\n  // Eyelid landmarks for openness calculation\\n  leftEyeTop: 159,\\n  leftEyeBottom: 145,\\n  rightEyeTop: 386,\\n  rightEyeBottom: 374\\n};\\n\\n// 3D eye model for gaze vector calculation (approximate)\\nconst EYE_3D_MODEL = {\\n  eyeballRadius: 12.0,    // mm\\n  irisRadius: 5.9,        // mm\\n  pupilRadius: 2.0,       // mm\\n  eyeDepth: 4.0,          // mm from surface to center\\n  interPupillaryDistance: 63.0, // mm (average IPD)\\n  \\n  // 3D positions relative to face center\\n  leftEyePosition: [-31.5, 20.0, -15.0],    // mm\\n  rightEyePosition: [31.5, 20.0, -15.0]     // mm\\n};\\n\\n// Gaze estimation using 3D eye model\\nconst estimateGazeVector = (irisCenter, eyeCorners, eyePosition, eyeModel = EYE_3D_MODEL) => {\\n  try {\\n    if (!irisCenter || !eyeCorners || eyeCorners.length < 2) {\\n      return [0, 0, -1]; // Default forward gaze\\n    }\\n    \\n    // Calculate eye coordinate system\\n    const [innerCorner, outerCorner] = eyeCorners;\\n    \\n    // Eye width and height for normalization\\n    const eyeWidth = Math.abs(outerCorner.x - innerCorner.x);\\n    const eyeHeight = eyeWidth * 0.6; // Approximate eye aspect ratio\\n    \\n    if (eyeWidth < 0.001) {\\n      return [0, 0, -1];\\n    }\\n    \\n    // Normalize iris position relative to eye corners\\n    const eyeCenter = {\\n      x: (innerCorner.x + outerCorner.x) / 2,\\n      y: (innerCorner.y + outerCorner.y) / 2\\n    };\\n    \\n    // Calculate iris displacement from eye center\\n    const irisDisplacementX = (irisCenter.x - eyeCenter.x) / eyeWidth;\\n    const irisDisplacementY = (irisCenter.y - eyeCenter.y) / eyeHeight;\\n    \\n    // Convert 2D iris displacement to 3D gaze vector\\n    // This is a simplified model - more sophisticated approaches use corneal reflection\\n    const maxGazeAngle = Math.PI / 6; // 30 degrees maximum\\n    \\n    const gazeX = irisDisplacementX * Math.sin(maxGazeAngle);\\n    const gazeY = -irisDisplacementY * Math.sin(maxGazeAngle); // Negative for screen coordinates\\n    const gazeZ = -Math.cos(Math.abs(gazeX) + Math.abs(gazeY)); // Forward component\\n    \\n    // Normalize gaze vector\\n    const magnitude = Math.sqrt(gazeX * gazeX + gazeY * gazeY + gazeZ * gazeZ);\\n    \\n    return [\\n      gazeX / magnitude,\\n      gazeY / magnitude,\\n      gazeZ / magnitude\\n    ];\\n    \\n  } catch (error) {\\n    console.warn('Gaze estimation failed:', error);\\n    return [0, 0, -1];\\n  }\\n};\\n\\n// Calculate eye openness from eyelid landmarks\\nconst calculateEyeOpenness = (topLandmark, bottomLandmark, eyeWidth) => {\\n  try {\\n    if (!topLandmark || !bottomLandmark || eyeWidth <= 0) {\\n      return 1.0; // Default to open\\n    }\\n    \\n    const eyeHeight = Math.abs(topLandmark.y - bottomLandmark.y);\\n    const openness = eyeHeight / (eyeWidth * 0.3); // Normal eye height ratio\\n    \\n    return Math.max(0, Math.min(1, openness));\\n  } catch (error) {\\n    return 1.0;\\n  }\\n};\\n\\n// Extract detailed eye information from MediaPipe Iris results\\nconst extractEyeTracking = (results, config) => {\\n  if (!results || !results.multiFaceLandmarks || results.multiFaceLandmarks.length === 0) {\\n    return createEyeResult({ confidence: 0 });\\n  }\\n\\n  try {\\n    const landmarks = results.multiFaceLandmarks[0]; // Single face mode\\n    \\n    // Extract iris landmarks\\n    const leftIrisLandmarks = IRIS_LANDMARKS.leftIris.map(idx => \\n      idx < landmarks.length ? landmarks[idx] : null\\n    ).filter(Boolean);\\n    \\n    const rightIrisLandmarks = IRIS_LANDMARKS.rightIris.map(idx => \\n      idx < landmarks.length ? landmarks[idx] : null\\n    ).filter(Boolean);\\n    \\n    // Get eye contours\\n    const leftEyeContour = IRIS_LANDMARKS.leftEyeContour.map(idx =>\\n      idx < landmarks.length ? [landmarks[idx].x, landmarks[idx].y] : null\\n    ).filter(Boolean);\\n    \\n    const rightEyeContour = IRIS_LANDMARKS.rightEyeContour.map(idx =>\\n      idx < landmarks.length ? [landmarks[idx].x, landmarks[idx].y] : null\\n    ).filter(Boolean);\\n    \\n    // Get key reference points\\n    const leftEyeCenter = landmarks[IRIS_LANDMARKS.leftEyeCenter] || { x: 0, y: 0, z: 0 };\\n    const rightEyeCenter = landmarks[IRIS_LANDMARKS.rightEyeCenter] || { x: 0, y: 0, z: 0 };\\n    \\n    const leftEyeInner = landmarks[IRIS_LANDMARKS.leftEyeInner] || { x: 0, y: 0 };\\n    const leftEyeOuter = landmarks[IRIS_LANDMARKS.leftEyeOuter] || { x: 0, y: 0 };\\n    const rightEyeInner = landmarks[IRIS_LANDMARKS.rightEyeInner] || { x: 0, y: 0 };\\n    const rightEyeOuter = landmarks[IRIS_LANDMARKS.rightEyeOuter] || { x: 0, y: 0 };\\n    \\n    // Calculate eye dimensions\\n    const leftEyeWidth = Math.abs(leftEyeOuter.x - leftEyeInner.x);\\n    const rightEyeWidth = Math.abs(rightEyeOuter.x - rightEyeInner.x);\\n    \\n    // Calculate eye openness\\n    const leftEyeTop = landmarks[IRIS_LANDMARKS.leftEyeTop] || { x: 0, y: 0 };\\n    const leftEyeBottom = landmarks[IRIS_LANDMARKS.leftEyeBottom] || { x: 0, y: 0 };\\n    const rightEyeTop = landmarks[IRIS_LANDMARKS.rightEyeTop] || { x: 0, y: 0 };\\n    const rightEyeBottom = landmarks[IRIS_LANDMARKS.rightEyeBottom] || { x: 0, y: 0 };\\n    \\n    const leftOpenness = calculateEyeOpenness(leftEyeTop, leftEyeBottom, leftEyeWidth);\\n    const rightOpenness = calculateEyeOpenness(rightEyeTop, rightEyeBottom, rightEyeWidth);\\n    \\n    // Estimate gaze vectors\\n    let leftGaze = [0, 0, -1];\\n    let rightGaze = [0, 0, -1];\\n    \\n    if (config.enableGazeEstimation) {\\n      leftGaze = estimateGazeVector(\\n        leftEyeCenter,\\n        [leftEyeInner, leftEyeOuter],\\n        EYE_3D_MODEL.leftEyePosition\\n      );\\n      \\n      rightGaze = estimateGazeVector(\\n        rightEyeCenter,\\n        [rightEyeInner, rightEyeOuter],\\n        EYE_3D_MODEL.rightEyePosition\\n      );\\n    }\\n    \\n    // Calculate convergence point (basic implementation)\\n    const convergenceDistance = 600; // mm (approximate screen distance)\\n    const convergencePoint = [\\n      (leftEyeCenter.x + rightEyeCenter.x) / 2,\\n      (leftEyeCenter.y + rightEyeCenter.y) / 2,\\n      convergenceDistance\\n    ];\\n    \\n    // Calculate combined gaze direction\\n    const gazeDirection = [\\n      (leftGaze[0] + rightGaze[0]) / 2,\\n      (leftGaze[1] + rightGaze[1]) / 2,\\n      (leftGaze[2] + rightGaze[2]) / 2\\n    ];\\n    \\n    return createEyeResult({\\n      left: {\\n        center: [leftEyeCenter.x, leftEyeCenter.y],\\n        pupil: [leftEyeCenter.x, leftEyeCenter.y], // Iris center as pupil approximation\\n        landmarks: leftEyeContour,\\n        gazeVector: leftGaze,\\n        openness: leftOpenness\\n      },\\n      right: {\\n        center: [rightEyeCenter.x, rightEyeCenter.y],\\n        pupil: [rightEyeCenter.x, rightEyeCenter.y],\\n        landmarks: rightEyeContour,\\n        gazeVector: rightGaze,\\n        openness: rightOpenness\\n      },\\n      convergencePoint,\\n      gazeDirection,\\n      metadata: {\\n        irisLandmarksDetected: leftIrisLandmarks.length + rightIrisLandmarks.length,\\n        averageOpenness: (leftOpenness + rightOpenness) / 2,\\n        eyeDistance: Math.abs(leftEyeCenter.x - rightEyeCenter.x)\\n      }\\n    });\\n\\n  } catch (error) {\\n    console.warn('Iris eye tracking extraction failed:', error);\\n    return createEyeResult({ confidence: 0 });\\n  }\\n};\\n\\n// Gaze point estimation on screen\\nexport const estimateScreenGazePoint = (eyeResult, screenDimensions, cameraPosition = { x: 0.5, y: 0.5 }) => {\\n  try {\\n    if (!eyeResult || !eyeResult.gazeDirection) {\\n      return null;\\n    }\\n    \\n    const [gazeX, gazeY, gazeZ] = eyeResult.gazeDirection;\\n    \\n    // Simple screen intersection calculation\\n    // Assumes screen is perpendicular to camera at fixed distance\\n    const screenDistance = 600; // mm\\n    const screenWidth = screenDimensions.width || 1920;\\n    const screenHeight = screenDimensions.height || 1080;\\n    \\n    // Project gaze ray to screen plane\\n    if (Math.abs(gazeZ) < 0.1) {\\n      return null; // Nearly parallel gaze\\n    }\\n    \\n    const t = screenDistance / Math.abs(gazeZ);\\n    const intersectionX = gazeX * t;\\n    const intersectionY = gazeY * t;\\n    \\n    // Convert to screen coordinates\\n    const screenX = (intersectionX / 300 + cameraPosition.x) * screenWidth;\\n    const screenY = (-intersectionY / 200 + cameraPosition.y) * screenHeight;\\n    \\n    return {\\n      x: Math.max(0, Math.min(screenWidth, screenX)),\\n      y: Math.max(0, Math.min(screenHeight, screenY)),\\n      confidence: eyeResult.metadata?.averageOpenness || 0.5\\n    };\\n    \\n  } catch (error) {\\n    console.warn('Screen gaze estimation failed:', error);\\n    return null;\\n  }\\n};\\n\\n// Create eye tracking smoothing filter\\nexport const createEyeTrackingFilter = (config = {}) => {\\n  const state = {\\n    initialized: false,\\n    leftGaze: [0, 0, -1],\\n    rightGaze: [0, 0, -1],\\n    gazeDirection: [0, 0, -1],\\n    leftOpenness: 1.0,\\n    rightOpenness: 1.0,\\n    alpha: config.smoothingFactor || 0.6\\n  };\\n\\n  const update = (eyeResult) => {\\n    if (!state.initialized) {\\n      state.leftGaze = [...eyeResult.left.gazeVector];\\n      state.rightGaze = [...eyeResult.right.gazeVector];\\n      state.gazeDirection = [...eyeResult.gazeDirection];\\n      state.leftOpenness = eyeResult.left.openness;\\n      state.rightOpenness = eyeResult.right.openness;\\n      state.initialized = true;\\n      return eyeResult;\\n    }\\n    \\n    const {alpha} = state;\\n    \\n    // Smooth gaze vectors\\n    const smoothedLeftGaze = state.leftGaze.map((prev, i) => \\n      alpha * eyeResult.left.gazeVector[i] + (1 - alpha) * prev\\n    );\\n    \\n    const smoothedRightGaze = state.rightGaze.map((prev, i) => \\n      alpha * eyeResult.right.gazeVector[i] + (1 - alpha) * prev\\n    );\\n    \\n    const smoothedGazeDirection = state.gazeDirection.map((prev, i) => \\n      alpha * eyeResult.gazeDirection[i] + (1 - alpha) * prev\\n    );\\n    \\n    // Smooth openness\\n    const smoothedLeftOpenness = alpha * eyeResult.left.openness + (1 - alpha) * state.leftOpenness;\\n    const smoothedRightOpenness = alpha * eyeResult.right.openness + (1 - alpha) * state.rightOpenness;\\n    \\n    // Update state\\n    state.leftGaze = smoothedLeftGaze;\\n    state.rightGaze = smoothedRightGaze;\\n    state.gazeDirection = smoothedGazeDirection;\\n    state.leftOpenness = smoothedLeftOpenness;\\n    state.rightOpenness = smoothedRightOpenness;\\n    \\n    // Return smoothed result\\n    return createEyeResult({\\n      left: {\\n        ...eyeResult.left,\\n        gazeVector: smoothedLeftGaze,\\n        openness: smoothedLeftOpenness\\n      },\\n      right: {\\n        ...eyeResult.right,\\n        gazeVector: smoothedRightGaze,\\n        openness: smoothedRightOpenness\\n      },\\n      convergencePoint: eyeResult.convergencePoint,\\n      gazeDirection: smoothedGazeDirection,\\n      metadata: eyeResult.metadata\\n    });\\n  };\\n\\n  const reset = () => {\\n    state.initialized = false;\\n  };\\n\\n  return { update, reset, isInitialized: () => state.initialized };\\n};\\n\\n/**\\n * Create MediaPipe Iris Tracking Pipeline\\n * \\n * Factory function that creates a high-precision eye tracking and gaze estimation\\n * pipeline using MediaPipe Iris. Provides detailed iris landmarks, gaze vectors,\\n * and screen gaze point estimation.\\n * \\n * @param {Object} config - Pipeline configuration\\n * @param {number} [config.maxNumFaces=1] - Maximum faces to track (iris works best with 1)\\n * @param {boolean} [config.refineLandmarks=true] - Enable refined landmark detection\\n * @param {number} [config.minDetectionConfidence=0.5] - Minimum detection confidence\\n * @param {number} [config.minTrackingConfidence=0.5] - Minimum tracking confidence\\n * @param {boolean} [config.enableGazeEstimation=true] - Enable 3D gaze vector estimation\\n * @param {number} [config.smoothingFactor=0.7] - Temporal smoothing factor\\n * @returns {Object} Pipeline instance with process, initialize, and cleanup methods\\n * \\n * @example\\n * const pipeline = createIrisTrackingPipeline({\\n *   maxNumFaces: 1,\\n *   enableGazeEstimation: true,\\n *   smoothingFactor: 0.8\\n * });\\n * \\n * await pipeline.initialize();\\n * const result = await pipeline.process(videoFrame);\\n * const gazePoint = estimateScreenGazePoint(result.eyes, { width: 1920, height: 1080 });\\n * await pipeline.cleanup();\\n */\\n/**\\n * Creates standardized Iris Tracking pipeline\\n * @param {Object} userConfig - User configuration overrides\\n * @returns {Object} - Iris Tracking pipeline instance\\n */\\nexport const createIrisTrackingPipeline = (userConfig = {}) => {\\n  // Use unified configuration system\\n  const config = createPipelineConfig('iris-tracking', userConfig);\\n  \\n  const state = {\\n    iris: null,\\n    eyeTrackingFilter: null,\\n    mediaPipeLoader: null,\\n    imageProcessor: null,\\n    resourcePool: null,\\n    isInitialized: false,\\n    config\\n  };\\n\\n  const initialize = async (initConfig = {}) => {\\n    try {\\n      handleError(\\n        'Initializing MediaPipe Iris tracking pipeline',\\n        ErrorCategory.INITIALIZATION,\\n        ErrorSeverity.INFO,\\n        { config: state.config }\\n      );\\n\\n      // Initialize shared resources\\n      state.resourcePool = getGlobalResourcePool();\\n      state.imageProcessor = createImageProcessor({ resourcePool: state.resourcePool });\\n      \\n      // Import dependency loader\\n      const { createMediaPipeLoader } = await import('../../../../shared/utils/dependency-loader.js');\\n      state.mediaPipeLoader = createMediaPipeLoader();\\n\\n      // Load Iris with configuration\\n      state.iris = await state.mediaPipeLoader.loadIris({\\n        maxNumFaces: state.config.maxNumFaces,\\n        minDetectionConfidence: state.config.minDetectionConfidence,\\n        minTrackingConfidence: state.config.minTrackingConfidence\\n      });\\n      \\n      // Initialize smoothing filter\\n      state.eyeTrackingFilter = createEyeTrackingFilter({\\n        smoothingFactor: state.config.smoothingFactor\\n      });\\n\\n      state.isInitialized = true;\\n      console.log('✅ MediaPipe Iris tracking pipeline initialized');\\n      return true;\\n    } catch (error) {\\n      handleError(\\n        `MediaPipe Iris initialization failed: ${error.message}`,\\n        ErrorCategory.INITIALIZATION,\\n        ErrorSeverity.ERROR,\\n        { error }\\n      );\\n      throw new Error(`MediaPipe Iris initialization failed: ${error.message}`);\\n    }\\n  };\\n\\n  const process = async (frame) => {\\n    if (!state.isInitialized) {\\n      await initialize();\\n    }\\n\\n    try {\\n      const startTime = Date.now();\\n      \\n      // Send frame to MediaPipe Iris\\n      const results = await new Promise((resolve, reject) => {\\n        state.iris.onResults(resolve);\\n        state.iris.send({ image: frame });\\n        \\n        // Set timeout to prevent hanging - configurable for test environments\\n        const timeout = state.config.processingTimeout || 3000;\\n        setTimeout(() => reject(new Error('Iris processing timeout')), timeout);\\n      });\\n      \\n      // Extract eye tracking information\\n      const eyeResult = extractEyeTracking(results, state.config);\\n      \\n      // Apply smoothing if enabled\\n      const smoothedResult = state.eyeTrackingFilter ? \\n        state.eyeTrackingFilter.update(eyeResult) : eyeResult;\\n      \\n      const processingTime = Date.now() - startTime;\\n      \\n      return createAnalysisResult({\\n        faces: [], // Iris pipeline focuses on eyes\\n        eyes: smoothedResult,\\n        confidence: smoothedResult.metadata?.averageOpenness || 0.5,\\n        metadata: {\\n          processingTime,\\n          frameTimestamp: Date.now(),\\n          pipelineName: 'mediapipe-iris',\\n          irisDetected: (smoothedResult.metadata?.irisLandmarksDetected || 0) > 0,\\n          gazeEstimationEnabled: state.config.enableGazeEstimation,\\n          smoothingApplied: !!state.eyeTrackingFilter\\n        }\\n      });\\n\\n    } catch (error) {\\n      handleError(\\n        `MediaPipe Iris processing failed: ${error.message}`,\\n        ErrorCategory.PROCESSING,\\n        ErrorSeverity.ERROR,\\n        { error }\\n      );\\n      throw new Error(`MediaPipe Iris processing failed: ${error.message}`);\\n    }\\n  };\\n\\n  const cleanup = () => {\\n    try {\\n      if (state.mediaPipeLoader) {\\n        state.mediaPipeLoader.cleanup();\\n        state.mediaPipeLoader = null;\\n      }\\n      if (state.eyeTrackingFilter) {\\n        state.eyeTrackingFilter.reset();\\n      }\\n      state.iris = null;\\n      state.isInitialized = false;\\n      console.log('🧹 MediaPipe Iris tracking pipeline cleaned up');\\n    } catch (error) {\\n      console.warn('⚠️ MediaPipe Iris cleanup error:', error);\\n    }\\n  };\\n\\n  const pipeline = createPipeline({\\n    name: 'mediapipe-iris',\\n    capabilities: [\\n      Capability.EYE_TRACKING\\n    ],\\n    performance: createPerformanceProfile({\\n      fps: 30,\\n      latency: '25-40ms',\\n      modelSize: '3MB',\\n      cpuUsage: 'medium',\\n      memoryUsage: 'low',\\n      batteryImpact: 'medium'\\n    }),\\n\\n    initialize,\\n    process,\\n    cleanup,\\n    getConfig: () => state.config,\\n    updateConfig: (updates) => {\\n      state.config = { ...state.config, ...updates };\\n    },\\n    isInitialized: () => state.isInitialized,\\n    getHealthStatus: () => ({\\n      healthy: state.isInitialized,\\n      runtime: 'browser', // MediaPipe Iris browser-only\\n      backend: 'mediapipe-iris',\\n      modelLoaded: !!state.iris,\\n      smoothingEnabled: !!state.eyeTrackingFilter\\n    })\\n  });\\n\\n  // Extend pipeline with custom methods\\n  return {\\n    ...pipeline,\\n    getConfig: () => state.config,\\n    isInitialized: () => state.isInitialized,\\n    // Override getHealthStatus to match test expectations\\n    getHealthStatus: () => ({\\n      healthy: state.isInitialized,\\n      runtime: 'browser',\\n      backend: 'mediapipe-iris',\\n      modelLoaded: !!state.iris,\\n      smoothingEnabled: !!state.eyeTrackingFilter\\n    }),\\n    updateConfig: (updates) => {\\n      state.config = { ...state.config, ...updates };\\n    },\\n    getStats: () => ({\\n      runtime: 'browser',\\n      backend: 'mediapipe-iris',\\n      config: { ...state.config },\\n      initialized: state.isInitialized,\\n      performance: {\\n        fps: 30,\\n        latency: '25-40ms',\\n        modelSize: '3MB',\\n        cpuUsage: 'medium',\\n        memoryUsage: 'low'\\n      },\\n      capabilities: ['iris-tracking', 'gaze-estimation', 'eye-tracking']\\n    }),\\n    getInfo: () => ({\\n      name: 'iris-tracking',\\n      version: '1.0.0',\\n      type: 'eye-tracking',\\n      capabilities: ['iris-tracking', 'gaze-estimation', 'eye-tracking'],\\n      performance: {\\n        fps: 30,\\n        latency: '25-40ms',\\n        modelSize: '3MB',\\n        cpuUsage: 'medium',\\n        memoryUsage: 'low',\\n        batteryImpact: 'medium'\\n      },\\n      requirements: {\\n        webgl: false,\\n        mediaApi: true,\\n        hardware: 'camera',\\n        mediapipe: true\\n      }\\n    })\\n  };\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/features/eye-tracking/index.js\",\"messages\":[{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'discoveryFactory' is defined but never used. Allowed unused vars must match /^_/u.\",\"line\":7,\"column\":33,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":7,\"endColumn\":49,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"discoveryFactory\"},\"fix\":{\"range\":[197,215],\"text\":\"\"},\"desc\":\"Remove unused variable 'discoveryFactory'.\"}]},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'createCalibrationResult' is defined but never used. Allowed unused vars must match /^_/u.\",\"line\":12,\"column\":3,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":12,\"endColumn\":26,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"createCalibrationResult\"},\"fix\":{\"range\":[499,523],\"text\":\"\"},\"desc\":\"Remove unused variable 'createCalibrationResult'.\"}]},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'createEyeTrackingResult' is defined but never used. Allowed unused vars must match /^_/u.\",\"line\":14,\"column\":3,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":14,\"endColumn\":26,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"createEyeTrackingResult\"},\"fix\":{\"range\":[545,573],\"text\":\"\"},\"desc\":\"Remove unused variable 'createEyeTrackingResult'.\"}]},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'createGazeData' is defined but never used. Allowed unused vars must match /^_/u.\",\"line\":15,\"column\":3,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":15,\"endColumn\":17,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"createGazeData\"},\"fix\":{\"range\":[573,592],\"text\":\"\"},\"desc\":\"Remove unused variable 'createGazeData'.\"}]}],\"suppressedMessages\":[],\"errorCount\":4,\"fatalErrorCount\":0,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Eye Tracking Module - Main API Interface\\n * Complete Device Control API Implementation\\n * Following functional programming patterns with factory functions\\n */\\n\\nimport { createDeviceDiscovery, discoveryFactory } from './devices/neon/discovery.js';\\nimport { createEyeTrackerDevice } from './devices/neon/device.js';\\nimport { createGazeProcessor } from './common/gaze-processing.js';\\nimport { createEyeTrackingStreaming, createEyeTrackingSystem } from './devices/neon/streaming.js';\\nimport { \\n  createCalibrationResult, \\n  createDeviceStatus, \\n  createEyeTrackingResult, \\n  createGazeData \\n} from '../../core/configuration/types.ts';\\n\\n// Import modular components\\nimport { createDeviceManager } from './core/device-manager.js';\\nimport { createSessionManager } from './core/session-manager.js';\\nimport { createRecordingController } from './core/recording-controller.js';\\nimport { createCalibrationController } from './core/calibration-controller.js';\\nimport { createStreamingController } from './core/streaming-controller.js';\\nimport { createEventNotifier } from './core/event-notifier.js';\\n\\n// Main eye tracking API factory\\nexport const createEyeTrackingAPI = (config = {}) => {\\n  const state = {\\n    system: null,\\n    activeDevices: new Map(),\\n    calibrationSessions: new Map(),\\n    recordingSessions: new Map(),\\n    createDeviceStatus,\\n    callbacks: {\\n      onSystemReady: [],\\n      onDeviceStatusChange: [],\\n      onCalibrationProgress: [],\\n      onRecordingProgress: [],\\n      onError: []\\n    }\\n  };\\n\\n  // Create modular components\\n  const eventNotifier = createEventNotifier(state);\\n  const sessionManager = createSessionManager(state);\\n  const recordingController = createRecordingController(state, sessionManager, eventNotifier);\\n  const calibrationController = createCalibrationController(state, sessionManager, eventNotifier);\\n  const streamingController = createStreamingController(state);\\n  const deviceManager = createDeviceManager(state, { cleanupDeviceSessions: sessionManager.cleanupDeviceSessions });\\n\\n  // Initialize the eye tracking system\\n  const initialize = async (systemConfig = {}) => {\\n    if (state.system) {\\n      throw new Error('Eye tracking system already initialized');\\n    }\\n\\n    state.system = createEyeTrackingSystem({\\n      ...config,\\n      ...systemConfig,\\n      enableSynchronization: true,\\n      autoStart: false // We control startup\\n    });\\n\\n    // Setup system event handlers\\n    setupSystemHandlers();\\n\\n    // Start the system\\n    await state.system.start();\\n\\n    // Notify callbacks\\n    state.callbacks.onSystemReady.forEach(cb => {\\n      try {\\n        cb({ timestamp: Date.now(), config: systemConfig });\\n      } catch (error) {\\n        console.warn('System ready callback error:', error);\\n      }\\n    });\\n\\n    return true;\\n  };\\n\\n  // Setup system event handlers\\n  const setupSystemHandlers = () => {\\n    state.system.onDeviceConnection((event) => {\\n      deviceManager.handleDeviceConnectionEvent(event);\\n    });\\n\\n    state.system.onError((error) => {\\n      eventNotifier.notifyError(error);\\n    });\\n  };\\n\\n  // System API\\n  const getSystemStats = () => {\\n    if (!state.system) {\\n      return { initialized: false };\\n    }\\n\\n    return {\\n      initialized: true,\\n      ...state.system.getStats(),\\n      activeSessions: {\\n        recordings: state.recordingSessions.size,\\n        calibrations: state.calibrationSessions.size\\n      }\\n    };\\n  };\\n\\n  const shutdown = async () => {\\n    if (!state.system) return;\\n\\n    // Stop all active sessions\\n    for (const session of state.recordingSessions.values()) {\\n      if (session.status === 'recording') {\\n        try {\\n          await recordingController.stopRecording(session.deviceId, session.sessionId);\\n        } catch (error) {\\n          console.warn('Error stopping recording during shutdown:', error);\\n        }\\n      }\\n    }\\n\\n    for (const session of state.calibrationSessions.values()) {\\n      if (session.status === 'in_progress') {\\n        try {\\n          await calibrationController.stopCalibration(session.deviceId, session.sessionId);\\n        } catch (error) {\\n          console.warn('Error stopping calibration during shutdown:', error);\\n        }\\n      }\\n    }\\n\\n    // Stop the system\\n    state.system.stop();\\n    state.system = null;\\n    state.activeDevices.clear();\\n    state.calibrationSessions.clear();\\n    state.recordingSessions.clear();\\n  };\\n\\n  return {\\n    // System control\\n    initialize,\\n    shutdown,\\n    \\n    // Device discovery - delegated to deviceManager\\n    discoverDevices: deviceManager.discoverDevices,\\n    getDiscoveredDevices: deviceManager.getDiscoveredDevices,\\n    \\n    // Device connection - delegated to deviceManager  \\n    connectToDevice: deviceManager.connectToDevice,\\n    disconnectFromDevice: deviceManager.disconnectFromDevice,\\n    autoConnectToFirstDevice: deviceManager.autoConnectToFirstDevice,\\n    \\n    // Device status - delegated to deviceManager\\n    getDeviceStatus: deviceManager.getDeviceStatus,\\n    getConnectedDevices: deviceManager.getConnectedDevices,\\n    \\n    // Recording control - delegated to recordingController\\n    startRecording: recordingController.startRecording,\\n    stopRecording: recordingController.stopRecording,\\n    getRecordingSessions: sessionManager.getRecordingSessions,\\n    \\n    // Calibration control - delegated to calibrationController\\n    startCalibration: calibrationController.startCalibration,\\n    stopCalibration: calibrationController.stopCalibration,\\n    getCalibrationSessions: sessionManager.getCalibrationSessions,\\n    \\n    // Streaming - delegated to streamingController\\n    getGazeStream: streamingController.getGazeStream,\\n    onGazeData: streamingController.onGazeData,\\n    \\n    // Event handlers - delegated to eventNotifier\\n    onSystemReady: eventNotifier.onSystemReady,\\n    onDeviceStatusChange: eventNotifier.onDeviceStatusChange,\\n    onCalibrationProgress: eventNotifier.onCalibrationProgress,\\n    onRecordingProgress: eventNotifier.onRecordingProgress,\\n    onError: eventNotifier.onError,\\n    \\n    // System status\\n    getSystemStats\\n  };\\n};\\n\\n// Export all components for direct use\\nexport {\\n  createDeviceDiscovery,\\n  createEyeTrackerDevice,\\n  createGazeProcessor,\\n  createEyeTrackingStreaming,\\n  createEyeTrackingSystem\\n};\\n\\n// Default API instance factory\\nexport const createEyeTracker = (config = {}) => {\\n  return createEyeTrackingAPI(config);\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/features/face-detection/age-estimation-pipeline.js\",\"messages\":[{\"ruleId\":null,\"nodeType\":null,\"fatal\":true,\"severity\":2,\"message\":\"Parsing error: Unexpected token BaseAgeDetector\",\"line\":7,\"column\":8}],\"suppressedMessages\":[],\"errorCount\":1,\"fatalErrorCount\":1,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Age Estimation Pipeline\\n */\\n\\nimport createAgeEstimationPipeline, {\\n  AgeUtils,\\n  type BaseAgeDetector,\\n  type AgeDetectorConfiguration,\\n  type AgeResult,\\n  type GenderResult,\\n  createDefaultAgeConfiguration,\\n  DEFAULT_AGE_RANGES\\n} from './age-estimation/index.ts';\\n\\n// Export the main factory function\\nexport { createAgeEstimationPipeline };\\n\\n// Export utilities\\nexport { AgeUtils };\\n\\n// Export types for TypeScript consumers\\nexport type {\\n  BaseAgeDetector,\\n  AgeDetectorConfiguration,\\n  AgeResult,\\n  GenderResult\\n};\\n\\n// Export configuration utilities\\nexport {\\n  createDefaultAgeConfiguration,\\n  DEFAULT_AGE_RANGES\\n};\\n\\n// Default export\\n\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/features/face-detection/mediapipe-face-pipeline.js\",\"messages\":[{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'MEDIAPIPE_LANDMARKS' is defined but never used. Allowed unused vars must match /^_/u.\",\"line\":12,\"column\":3,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":12,\"endColumn\":22,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"MEDIAPIPE_LANDMARKS\"},\"fix\":{\"range\":[488,508],\"text\":\"\"},\"desc\":\"Remove unused variable 'MEDIAPIPE_LANDMARKS'.\"}]},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'checkMediaPipeAvailability' is defined but never used. Allowed unused vars must match /^_/u.\",\"line\":14,\"column\":3,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":14,\"endColumn\":29,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"checkMediaPipeAvailability\"},\"fix\":{\"range\":[535,565],\"text\":\"\"},\"desc\":\"Remove unused variable 'checkMediaPipeAvailability'.\"}]},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'createMediaPipeBase' is defined but never used. Allowed unused vars must match /^_/u.\",\"line\":15,\"column\":3,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":15,\"endColumn\":22,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"createMediaPipeBase\"},\"fix\":{\"range\":[565,588],\"text\":\"\"},\"desc\":\"Remove unused variable 'createMediaPipeBase'.\"}]},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'bbox' is defined but never used. Allowed unused args must match /^_/u.\",\"line\":36,\"column\":38,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":36,\"endColumn\":42,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"bbox\"},\"fix\":{\"range\":[1185,1191],\"text\":\"\"},\"desc\":\"Remove unused variable 'bbox'.\"}]},{\"ruleId\":\"prefer-destructuring\",\"severity\":1,\"message\":\"Use array destructuring.\",\"line\":44,\"column\":11,\"nodeType\":\"VariableDeclarator\",\"messageId\":\"preferDestructuring\",\"endLine\":44,\"endColumn\":35},{\"ruleId\":\"prefer-destructuring\",\"severity\":1,\"message\":\"Use array destructuring.\",\"line\":45,\"column\":11,\"nodeType\":\"VariableDeclarator\",\"messageId\":\"preferDestructuring\",\"endLine\":45,\"endColumn\":35},{\"ruleId\":\"prefer-destructuring\",\"severity\":1,\"message\":\"Use array destructuring.\",\"line\":46,\"column\":11,\"nodeType\":\"VariableDeclarator\",\"messageId\":\"preferDestructuring\",\"endLine\":46,\"endColumn\":33},{\"ruleId\":\"prefer-destructuring\",\"severity\":1,\"message\":\"Use array destructuring.\",\"line\":47,\"column\":11,\"nodeType\":\"VariableDeclarator\",\"messageId\":\"preferDestructuring\",\"endLine\":47,\"endColumn\":38},{\"ruleId\":\"prefer-destructuring\",\"severity\":1,\"message\":\"Use array destructuring.\",\"line\":48,\"column\":11,\"nodeType\":\"VariableDeclarator\",\"messageId\":\"preferDestructuring\",\"endLine\":48,\"endColumn\":32},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'chin' is assigned a value but never used. Allowed unused vars must match /^_/u.\",\"line\":48,\"column\":11,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":48,\"endColumn\":15,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"chin\"},\"fix\":{\"range\":[1677,1705],\"text\":\"\"},\"desc\":\"Remove unused variable 'chin'.\"}]},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '-'. Use parentheses to clarify the intended order of operations.\",\"line\":71,\"column\":68,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":71,\"endColumn\":69},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '-'. Use parentheses to clarify the intended order of operations.\",\"line\":71,\"column\":86,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":71,\"endColumn\":87},{\"ruleId\":\"max-lines-per-function\",\"severity\":1,\"message\":\"Arrow function has too many lines (254). Maximum allowed is 150.\",\"line\":154,\"column\":44,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"exceed\",\"endLine\":471,\"endColumn\":2},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'initConfig' is assigned a value but never used. Allowed unused args must match /^_/u.\",\"line\":171,\"column\":29,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":171,\"endColumn\":39,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"initConfig\"},\"fix\":{\"range\":[5299,5314],\"text\":\"\"},\"desc\":\"Remove unused variable 'initConfig'.\"}]},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'error' is defined but never used.\",\"line\":208,\"column\":16,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":208,\"endColumn\":21},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'input' is defined but never used. Allowed unused args must match /^_/u.\",\"line\":212,\"column\":24,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":212,\"endColumn\":29,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"input\"},\"fix\":{\"range\":[6802,6807],\"text\":\"\"},\"desc\":\"Remove unused variable 'input'.\"}]},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":218,\"column\":26,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":218,\"endColumn\":27},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":218,\"column\":37,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":218,\"endColumn\":38},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":219,\"column\":26,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":219,\"endColumn\":27},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":219,\"column\":47,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":219,\"endColumn\":48}],\"suppressedMessages\":[],\"errorCount\":8,\"fatalErrorCount\":0,\"warningCount\":12,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * MediaPipe Face Detection Pipeline Implementation\\n * Pure MediaPipe implementation - NO TensorFlow dependencies\\n * Works in both browser and Node.js environments\\n */\\n\\nimport { createPipeline } from '../../core/pipeline/pipeline.ts';\\nimport { createPipelineConfig } from '../../core/pipeline/pipeline-config.js';\\nimport { createImageProcessor } from '../../core/engine/image-processor.js';\\nimport { getGlobalResourcePool } from '../../core/performance/resource-pool.js';\\nimport { \\n  MEDIAPIPE_LANDMARKS,\\n  calculateFaceBoundingBox,\\n  checkMediaPipeAvailability,\\n  createMediaPipeBase,\\n  createMediaPipeLoader,\\n  extractKeyPoints\\n} from '../../core/integration/mediapipe-commons.js';\\nimport { \\n  Capability,\\n  createAnalysisResult,\\n  createFaceResult,\\n  createPerformanceProfile,\\n  createPose3DOF\\n} from '../../core/configuration/types.ts';\\nimport { ErrorCategory, ErrorSeverity, handleError } from '../../shared/utils/error-handler.js';\\nimport { \\n  checkFeatures, \\n  createUniversalCanvas, \\n  detectRuntime, \\n  imageToMediaPipe,\\n  loadMediaPipe \\n} from '../../shared/utils/runtime-detector.js';\\n\\n// 3DOF pose estimation from MediaPipe landmarks\\nconst estimatePose3DOF = (landmarks, bbox) => {\\n  if (!landmarks || landmarks.length < 6) {\\n    return createPose3DOF({ confidence: 0 });\\n  }\\n\\n  try {\\n    // Extract key landmarks from MediaPipe Face Mesh (468 total landmarks)\\n    // Using specific landmark indices for key facial features\\n    const rightEye = landmarks[33];  // Right eye outer corner\\n    const leftEye = landmarks[263];  // Left eye outer corner\\n    const noseTip = landmarks[1];    // Nose tip\\n    const mouthCenter = landmarks[13]; // Upper lip center\\n    const chin = landmarks[175];     // Chin point\\n\\n    // Calculate face center and dimensions\\n    const faceCenter = {\\n      x: (rightEye.x + leftEye.x) / 2,\\n      y: (rightEye.y + leftEye.y) / 2,\\n      z: (rightEye.z + leftEye.z) / 2\\n    };\\n\\n    // Calculate eye distance for scale\\n    const eyeDistance = Math.sqrt(\\n      Math.pow(leftEye.x - rightEye.x, 2) + \\n      Math.pow(leftEye.y - rightEye.y, 2)\\n    );\\n\\n    // Estimate roll (rotation around Z axis)\\n    const roll = Math.atan2(leftEye.y - rightEye.y, leftEye.x - rightEye.x) * (180 / Math.PI);\\n\\n    // Estimate pitch (rotation around X axis) \\n    const noseMouthDistance = Math.sqrt(\\n      Math.pow(mouthCenter.x - noseTip.x, 2) + \\n      Math.pow(mouthCenter.y - noseTip.y, 2)\\n    );\\n    const pitch = Math.atan2(noseMouthDistance, eyeDistance * 0.5) * (180 / Math.PI) - 90;\\n\\n    // Estimate yaw (rotation around Y axis)\\n    const faceWidth = eyeDistance;\\n    const noseOffsetX = noseTip.x - faceCenter.x;\\n    const yaw = Math.asin(Math.max(-1, Math.min(1, noseOffsetX / (faceWidth * 0.5)))) * (180 / Math.PI);\\n\\n    // Calculate confidence based on landmark quality\\n    const landmarkConfidence = landmarks.length > 100 ? 0.9 : 0.7;\\n    const poseConfidence = Math.min(1.0, landmarkConfidence * (eyeDistance > 0.05 ? 1.0 : 0.5));\\n\\n    return createPose3DOF({\\n      roll,\\n      pitch, \\n      yaw,\\n      confidence: poseConfidence,\\n      center: faceCenter,\\n      scale: eyeDistance\\n    });\\n\\n  } catch (error) {\\n    handleError(\\n      `3DOF pose estimation failed: ${error.message}`,\\n      ErrorCategory.PROCESSING,\\n      ErrorSeverity.WARNING,\\n      { landmarkCount: landmarks?.length }\\n    );\\n    return createPose3DOF({ confidence: 0 });\\n  }\\n};\\n\\n// Process MediaPipe results into standardized format\\nconst processMediaPipeResults = (results, imageWidth = 640, imageHeight = 480) => {\\n  if (!results?.multiFaceLandmarks || results.multiFaceLandmarks.length === 0) {\\n    return [];\\n  }\\n\\n  return results.multiFaceLandmarks.map((landmarks, index) => {\\n    try {\\n      // Convert normalized coordinates to pixel coordinates\\n      const pixelLandmarks = landmarks.map(landmark => ({\\n        x: landmark.x * imageWidth,\\n        y: landmark.y * imageHeight,\\n        z: landmark.z || 0\\n      }));\\n\\n      // Calculate bounding box\\n      const bbox = calculateFaceBoundingBox(pixelLandmarks);\\n      \\n      // Extract key points\\n      const keyPoints = extractKeyPoints(landmarks);\\n      \\n      // Estimate 3DOF pose\\n      const pose3DOF = estimatePose3DOF(landmarks, bbox);\\n\\n      // Calculate confidence score\\n      const confidence = landmarks.length >= 468 ? 0.95 : 0.8;\\n\\n      return createFaceResult({\\n        id: index,\\n        bbox,\\n        landmarks: pixelLandmarks,\\n        keyPoints,\\n        pose3DOF,\\n        confidence,\\n        source: 'mediapipe-face-mesh'\\n      });\\n\\n    } catch (error) {\\n      handleError(\\n        `Face result processing failed: ${error.message}`,\\n        ErrorCategory.PROCESSING,\\n        ErrorSeverity.WARNING,\\n        { faceIndex: index }\\n      );\\n      return null;\\n    }\\n  }).filter(result => result !== null);\\n};\\n\\n/**\\n * Create MediaPipe Face Detection Pipeline\\n */\\nexport const createMediaPipeFacePipeline = (config = {}) => {\\n  // Pipeline state\\n  const state = {\\n    isInitialized: false,\\n    mediapipe: null,\\n    faceMesh: null,\\n    resourcePool: null,\\n    imageProcessor: null,\\n    lastResults: null,\\n    canvas: null,\\n    ctx: null,\\n    runtime: detectRuntime(),\\n    features: checkFeatures(),\\n    config: createPipelineConfig('mediapipe-face', config)\\n  };\\n\\n  // Initialize MediaPipe Face Detection\\n  const initialize = async (initConfig = {}) => {\\n    try {\\n      state.resourcePool = getGlobalResourcePool();\\n      state.imageProcessor = createImageProcessor({ resourcePool: state.resourcePool });\\n      \\n      handleError(\\n        `Initializing MediaPipe Face Detection pipeline for ${state.runtime} environment`,\\n        ErrorCategory.INITIALIZATION,\\n        ErrorSeverity.INFO,\\n        { runtime: state.runtime }\\n      );\\n      \\n      // Load MediaPipe\\n      state.mediapipe = await loadMediaPipe();\\n      if (!state.mediapipe) {\\n        throw new Error('Failed to load MediaPipe');\\n      }\\n\\n      console.log(`📊 MediaPipe loaded successfully`);\\n\\n      // Initialize MediaPipe Face Mesh\\n      try {\\n        const mediapipeLoader = createMediaPipeLoader();\\n        state.faceMesh = await mediapipeLoader.loadFaceMesh({\\n          maxNumFaces: state.config.maxFaces || 1,\\n          refineLandmarks: state.config.refineLandmarks !== false,\\n          minDetectionConfidence: state.config.minDetectionConfidence || 0.5,\\n          minTrackingConfidence: state.config.minTrackingConfidence || 0.5\\n        });\\n\\n        // Set up result handling\\n        state.faceMesh.onResults((results) => {\\n          state.lastResults = results;\\n        });\\n\\n        console.log('✅ MediaPipe Face Mesh initialized successfully');\\n\\n      } catch (error) {\\n        console.warn('MediaPipe Face Mesh not available, using mock implementation');\\n        // Mock implementation for testing environments\\n        state.faceMesh = {\\n          send: async (input) => {\\n            // Generate mock results for testing\\n            state.lastResults = {\\n              multiFaceLandmarks: [{\\n                // Mock 468 landmarks with key points\\n                ...Array.from({ length: 468 }, (_, i) => ({\\n                  x: 0.4 + (i % 20) * 0.01,\\n                  y: 0.3 + Math.floor(i / 20) * 0.01, \\n                  z: 0\\n                }))\\n              }]\\n            };\\n          },\\n          onResults: (callback) => {\\n            state.resultsCallback = callback;\\n          },\\n          close: () => {}\\n        };\\n      }\\n      \\n      // Create canvas for Node.js environment\\n      if (state.features.isNode) {\\n        state.canvas = await createUniversalCanvas(640, 480);\\n        state.ctx = state.canvas.getContext('2d');\\n      }\\n      \\n      state.isInitialized = true;\\n      console.log(`✅ MediaPipe Face pipeline initialized successfully in ${state.runtime} environment`);\\n      \\n      return true;\\n    } catch (error) {\\n      handleError(\\n        `MediaPipe Face pipeline initialization failed: ${error.message}`,\\n        ErrorCategory.INITIALIZATION,\\n        ErrorSeverity.ERROR,\\n        { runtime: state.runtime, error: error.message }\\n      );\\n      throw new Error(`MediaPipe Face pipeline initialization failed: ${error.message}`);\\n    }\\n  };\\n\\n  // Process input through MediaPipe\\n  const process = async (input) => {\\n    if (!state.isInitialized) {\\n      await initialize();\\n    }\\n\\n    try {\\n      const startTime = Date.now();\\n      \\n      // Convert input to MediaPipe format\\n      const processedInput = await imageToMediaPipe(input);\\n      \\n      // Send to MediaPipe for processing\\n      await state.faceMesh.send({ image: processedInput });\\n      \\n      // Wait for results (in real implementation, this would be event-driven)\\n      // For now, we'll use the last results stored\\n      const results = state.lastResults;\\n      \\n      if (!results) {\\n        return createAnalysisResult({\\n          faces: [],\\n          processingTime: Date.now() - startTime,\\n          source: 'mediapipe-face-mesh',\\n          confidence: 0\\n        });\\n      }\\n\\n      // Process results\\n      const faces = processMediaPipeResults(\\n        results,\\n        processedInput.width || 640,\\n        processedInput.height || 480\\n      );\\n\\n      const processingTime = Date.now() - startTime;\\n      \\n      // Update performance metrics\\n      if (state.resourcePool) {\\n        state.resourcePool.updateMetrics('processing_time', processingTime);\\n        state.resourcePool.updateMetrics('faces_detected', faces.length);\\n      }\\n\\n      handleError(\\n        `Processed ${faces.length} faces in ${processingTime}ms`,\\n        ErrorCategory.PROCESSING,\\n        ErrorSeverity.DEBUG,\\n        { faceCount: faces.length, processingTime }\\n      );\\n\\n      return createAnalysisResult({\\n        faces,\\n        processingTime,\\n        source: 'mediapipe-face-mesh',\\n        confidence: faces.length > 0 ? faces[0].confidence : 0,\\n        metadata: {\\n          landmarkCount: results.multiFaceLandmarks?.[0]?.length || 0,\\n          runtime: state.runtime\\n        }\\n      });\\n\\n    } catch (error) {\\n      handleError(\\n        `MediaPipe Face processing failed: ${error.message}`,\\n        ErrorCategory.PROCESSING,\\n        ErrorSeverity.ERROR,\\n        { error: error.message }\\n      );\\n      \\n      return createAnalysisResult({\\n        faces: [],\\n        processingTime: 0,\\n        source: 'mediapipe-face-mesh',\\n        confidence: 0,\\n        error: error.message\\n      });\\n    }\\n  };\\n\\n  // Cleanup resources\\n  const cleanup = async () => {\\n    try {\\n      if (state.faceMesh && state.faceMesh.close) {\\n        await state.faceMesh.close();\\n      }\\n      \\n      if (state.imageProcessor && state.imageProcessor.cleanup) {\\n        await state.imageProcessor.cleanup();\\n      }\\n\\n      state.isInitialized = false;\\n      state.faceMesh = null;\\n      state.lastResults = null;\\n\\n      handleError(\\n        'MediaPipe Face pipeline cleaned up successfully',\\n        ErrorCategory.CLEANUP,\\n        ErrorSeverity.INFO\\n      );\\n    } catch (error) {\\n      handleError(\\n        `MediaPipe Face pipeline cleanup failed: ${error.message}`,\\n        ErrorCategory.CLEANUP,\\n        ErrorSeverity.WARNING,\\n        { error: error.message }\\n      );\\n    }\\n  };\\n\\n  // Create the pipeline using the base pipeline factory\\n  const pipeline = createPipeline({\\n    name: 'mediapipe-face-detection',\\n    version: '1.0.0',\\n    description: 'MediaPipe-based face detection with 3DOF pose estimation',\\n    \\n    // Core capabilities\\n    capabilities: [\\n      Capability.FACE_DETECTION,\\n      Capability.FACIAL_LANDMARKS,\\n      Capability.POSE_3DOF,\\n      Capability.REAL_TIME\\n    ],\\n    \\n    // Performance profile\\n    performance: createPerformanceProfile({\\n      fps: 30,\\n      latency: '15-30ms',\\n      memoryUsage: 'low',\\n      cpuUsage: 'low',\\n      accuracy: 'high'\\n    }),\\n\\n    // Pipeline functions\\n    initialize,\\n    process,\\n    cleanup,\\n\\n    // Configuration and metadata\\n    getConfig: () => state.config,\\n    updateConfig: (updates) => {\\n      state.config = createPipelineConfig('mediapipe-face', { ...state.config, ...updates });\\n      return state.config;\\n    },\\n\\n    // Status and diagnostics\\n    getStatus: () => ({\\n      initialized: state.isInitialized,\\n      runtime: state.runtime,\\n      features: state.features,\\n      mediapipeLoaded: !!state.mediapipe,\\n      faceMeshLoaded: !!state.faceMesh\\n    }),\\n\\n    // Check if pipeline is initialized\\n    isInitialized: () => state.isInitialized,\\n    \\n    // Health status for monitoring\\n    getHealthStatus: () => ({\\n      healthy: state.isInitialized,\\n      runtime: state.runtime,\\n      backend: 'mediapipe-face',\\n      modelLoaded: !!state.faceMesh,\\n      mediapipeAvailable: !!state.mediapipe\\n    })\\n  });\\n\\n  // Extend pipeline with custom methods\\n  return {\\n    ...pipeline,\\n    getConfig: () => state.config,\\n    isInitialized: () => state.isInitialized,\\n    // Override getHealthStatus to match test expectations\\n    getHealthStatus: () => ({\\n      healthy: state.isInitialized,\\n      runtime: state.runtime,\\n      backend: 'mediapipe-face',\\n      modelLoaded: !!state.faceMesh,\\n      mediapipeAvailable: !!state.mediapipe\\n    }),\\n    updateConfig: (updates) => {\\n      state.config = createPipelineConfig('mediapipe-face', { ...state.config, ...updates });\\n      return state.config;\\n    },\\n    getStats: () => ({\\n      runtime: state.runtime,\\n      backend: 'mediapipe-face',\\n      config: { ...state.config },\\n      initialized: state.isInitialized,\\n      performance: {\\n        fps: 30,\\n        latency: '15-30ms',\\n        modelSize: '2.5MB',\\n        cpuUsage: 'low',\\n        memoryUsage: 'low'\\n      },\\n      capabilities: ['face-detection', 'facial-landmarks', 'pose-3dof']\\n    }),\\n    getInfo: () => ({\\n      name: 'mediapipe-face-detection',\\n      version: '1.0.0',\\n      type: 'face-detection',\\n      capabilities: ['face-detection', 'facial-landmarks', 'pose-3dof'],\\n      performance: {\\n        fps: 30,\\n        latency: '15-30ms',\\n        modelSize: '2.5MB',\\n        cpuUsage: 'low',\\n        memoryUsage: 'low',\\n        batteryImpact: 'low'\\n      },\\n      requirements: {\\n        webgl: false,\\n        mediaApi: true,\\n        hardware: 'camera',\\n        mediapipe: true\\n      }\\n    })\\n  };\\n};\\n\\n// Modern MediaPipe implementation only\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/features/face-detection/mediapipe-pipeline.js\",\"messages\":[{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'IRIS_LANDMARKS' is defined but never used. Allowed unused vars must match /^_/u.\",\"line\":11,\"column\":3,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":11,\"endColumn\":17,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"IRIS_LANDMARKS\"},\"fix\":{\"range\":[447,462],\"text\":\"\"},\"desc\":\"Remove unused variable 'IRIS_LANDMARKS'.\"}]},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'MEDIAPIPE_LANDMARKS' is defined but never used. Allowed unused vars must match /^_/u.\",\"line\":12,\"column\":3,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":12,\"endColumn\":22,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"MEDIAPIPE_LANDMARKS\"},\"fix\":{\"range\":[461,484],\"text\":\"\"},\"desc\":\"Remove unused variable 'MEDIAPIPE_LANDMARKS'.\"}]},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'calculateFaceBoundingBox' is defined but never used. Allowed unused vars must match /^_/u.\",\"line\":13,\"column\":3,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":13,\"endColumn\":27,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"calculateFaceBoundingBox\"},\"fix\":{\"range\":[484,512],\"text\":\"\"},\"desc\":\"Remove unused variable 'calculateFaceBoundingBox'.\"}]},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'extractKeyPoints' is defined but never used. Allowed unused vars must match /^_/u.\",\"line\":17,\"column\":3,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":17,\"endColumn\":19,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"extractKeyPoints\"},\"fix\":{\"range\":[590,610],\"text\":\"\"},\"desc\":\"Remove unused variable 'extractKeyPoints'.\"}]},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'r12' is assigned a value but never used. Allowed unused vars must match /^_/u.\",\"line\":120,\"column\":17,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":120,\"endColumn\":20,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"r12\"},\"fix\":{\"range\":[3883,3886],\"text\":\"\"},\"desc\":\"Remove unused variable 'r12'.\"}]},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'r13' is assigned a value but never used. Allowed unused vars must match /^_/u.\",\"line\":120,\"column\":22,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":120,\"endColumn\":25,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"r13\"},\"fix\":{\"range\":[3888,3891],\"text\":\"\"},\"desc\":\"Remove unused variable 'r13'.\"}]},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'r22' is assigned a value but never used. Allowed unused vars must match /^_/u.\",\"line\":120,\"column\":36,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":120,\"endColumn\":39,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"r22\"},\"fix\":{\"range\":[3902,3905],\"text\":\"\"},\"desc\":\"Remove unused variable 'r22'.\"}]},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'r23' is assigned a value but never used. Allowed unused vars must match /^_/u.\",\"line\":120,\"column\":41,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":120,\"endColumn\":44,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"r23\"},\"fix\":{\"range\":[3907,3910],\"text\":\"\"},\"desc\":\"Remove unused variable 'r23'.\"}]},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":124,\"column\":49,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":124,\"endColumn\":50},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":124,\"column\":54,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":124,\"endColumn\":55},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":124,\"column\":54,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":124,\"endColumn\":55},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":124,\"column\":59,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":124,\"endColumn\":60},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'rows' is assigned a value but never used. Allowed unused vars must match /^_/u.\",\"line\":144,\"column\":11,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":144,\"endColumn\":15,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"rows\"},\"fix\":{\"range\":[4690,4712],\"text\":\"\"},\"desc\":\"Remove unused variable 'rows'.\"}]},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'cols' is assigned a value but never used. Allowed unused vars must match /^_/u.\",\"line\":145,\"column\":11,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":145,\"endColumn\":15,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"cols\"},\"fix\":{\"range\":[4717,4742],\"text\":\"\"},\"desc\":\"Remove unused variable 'cols'.\"}]},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'error' is defined but never used.\",\"line\":150,\"column\":12,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":150,\"endColumn\":17},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'objectPoints' is defined but never used. Allowed unused args must match /^_/u.\",\"line\":155,\"column\":47,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":155,\"endColumn\":59,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"objectPoints\"},\"fix\":{\"range\":[4977,4991],\"text\":\"\"},\"desc\":\"Remove unused variable 'objectPoints'.\"}]},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'solution' is defined but never used. Allowed unused args must match /^_/u.\",\"line\":155,\"column\":61,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":155,\"endColumn\":69,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"solution\"},\"fix\":{\"range\":[4991,5001],\"text\":\"\"},\"desc\":\"Remove unused variable 'solution'.\"}]},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'u' is assigned a value but never used. Allowed unused vars must match /^_/u.\",\"line\":162,\"column\":14,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":162,\"endColumn\":15,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"u\"},\"fix\":{\"range\":[5183,5184],\"text\":\"\"},\"desc\":\"Remove unused variable 'u'.\"}]},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'v' is assigned a value but never used. Allowed unused vars must match /^_/u.\",\"line\":162,\"column\":17,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":162,\"endColumn\":18,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"v\"},\"fix\":{\"range\":[5184,5187],\"text\":\"\"},\"desc\":\"Remove unused variable 'v'.\"}]},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '/'. Use parentheses to clarify the intended order of operations.\",\"line\":170,\"column\":40,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":170,\"endColumn\":41},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '/'. Use parentheses to clarify the intended order of operations.\",\"line\":170,\"column\":51,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":170,\"endColumn\":52},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'error' is defined but never used.\",\"line\":171,\"column\":12,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":171,\"endColumn\":17},{\"ruleId\":\"max-lines-per-function\",\"severity\":1,\"message\":\"Arrow function has too many lines (159). Maximum allowed is 150.\",\"line\":395,\"column\":48,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"exceed\",\"endLine\":596,\"endColumn\":2},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'initConfig' is assigned a value but never used. Allowed unused args must match /^_/u.\",\"line\":423,\"column\":24,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":423,\"endColumn\":34,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"initConfig\"},\"fix\":{\"range\":[14205,14220],\"text\":\"\"},\"desc\":\"Remove unused variable 'initConfig'.\"}]},{\"ruleId\":\"no-undef\",\"severity\":2,\"message\":\"'mediaPipeConfig' is not defined.\",\"line\":506,\"column\":21,\"nodeType\":\"Identifier\",\"messageId\":\"undef\",\"endLine\":506,\"endColumn\":36},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'irisResults' is assigned a value but never used. Allowed unused vars must match /^_/u.\",\"line\":508,\"column\":13,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":508,\"endColumn\":24},{\"ruleId\":\"no-undef\",\"severity\":2,\"message\":\"'mediaPipeConfig' is not defined.\",\"line\":528,\"column\":29,\"nodeType\":\"Identifier\",\"messageId\":\"undef\",\"endLine\":528,\"endColumn\":44}],\"suppressedMessages\":[],\"errorCount\":20,\"fatalErrorCount\":0,\"warningCount\":7,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * MediaPipe Face Mesh Pipeline Implementation\\n * Provides 468 facial landmarks with 6DOF pose estimation and eye tracking\\n */\\n\\nimport { createPipeline } from '../../core/pipeline/pipeline.ts';\\nimport { createPipelineConfig } from '../../core/pipeline/pipeline-config.js';\\nimport { createImageProcessor } from '../../core/engine/image-processor.js';\\nimport { getGlobalResourcePool } from '../../core/performance/resource-pool.js';\\nimport { \\n  IRIS_LANDMARKS,\\n  MEDIAPIPE_LANDMARKS,\\n  calculateFaceBoundingBox,\\n  checkMediaPipeAvailability,\\n  createMediaPipeBase,\\n  createMediaPipeLoader,\\n  extractKeyPoints\\n} from '../../core/integration/mediapipe-commons.js';\\nimport { \\n  Capability,\\n  createAnalysisResult,\\n  createEyeResult,\\n  createFaceResult,\\n  createPerformanceProfile,\\n  createPose6DOF\\n} from '../../core/configuration/types.ts';\\nimport { ErrorCategory, ErrorSeverity, handleError } from '../../shared/utils/error-handler.js';\\n\\n// Use MediaPipe commons for shared configuration\\n\\n// 3D canonical face model points for PnP pose estimation\\nconst CANONICAL_3D_FACE_MODEL = {\\n  // Key points for pose estimation (in millimeters, centered at nose)\\n  noseTip: [0.0, 0.0, 0.0],           // Reference point\\n  chinBottom: [0.0, -58.0, -14.0],    // Bottom of chin\\n  leftEyeLeftCorner: [-35.0, 20.0, -15.0],  // Left eye outer corner\\n  rightEyeRightCorner: [35.0, 20.0, -15.0], // Right eye outer corner  \\n  leftMouthCorner: [-20.0, -25.0, -8.0],    // Left mouth corner\\n  rightMouthCorner: [20.0, -25.0, -8.0],    // Right mouth corner\\n  \\n  // Additional points for accuracy\\n  foreheadCenter: [0.0, 45.0, -10.0],\\n  leftCheek: [-30.0, -10.0, -20.0],\\n  rightCheek: [30.0, -10.0, -20.0]\\n};\\n\\n// MediaPipe landmark indices for key facial points\\nconst MEDIAPIPE_LANDMARK_INDICES = {\\n  noseTip: 1,\\n  chinBottom: 175,\\n  leftEyeLeftCorner: 33,\\n  rightEyeRightCorner: 362,\\n  leftMouthCorner: 61,\\n  rightMouthCorner: 291,\\n  foreheadCenter: 9,\\n  leftCheek: 234,\\n  rightCheek: 454,\\n  \\n  // Eye-specific landmarks for iris tracking\\n  leftEyeCenter: 468,   // Iris center\\n  rightEyeCenter: 473,  // Iris center\\n  leftEyeTop: 159,\\n  leftEyeBottom: 145,\\n  rightEyeTop: 386,\\n  rightEyeBottom: 374,\\n  \\n  // Additional eye landmarks for gaze estimation\\n  leftEyeInner: 133,\\n  leftEyeOuter: 33,\\n  rightEyeInner: 362,\\n  rightEyeOuter: 263\\n};\\n\\n// Camera intrinsic parameters (estimated for typical webcam)\\nconst DEFAULT_CAMERA_MATRIX = {\\n  fx: 500.0,  // Focal length X\\n  fy: 500.0,  // Focal length Y  \\n  cx: 320.0,  // Principal point X (image center)\\n  cy: 240.0,  // Principal point Y (image center)\\n  width: 640,\\n  height: 480\\n};\\n\\n// Perspective-n-Point pose estimation using basic algorithm\\nconst solvePnP = (imagePoints, objectPoints, cameraMatrix) => {\\n  // Simplified PnP implementation using least squares approach\\n  // For production, consider using OpenCV.js or more robust implementation\\n  \\n  if (imagePoints.length < 4 || objectPoints.length < 4) {\\n    return null;\\n  }\\n  \\n  try {\\n    // Convert points to homogeneous coordinates\\n    const n = imagePoints.length;\\n    \\n    // Construct coefficient matrix for DLT (Direct Linear Transform)\\n    const A = [];\\n    \\n    for (let i = 0; i < n; i++) {\\n      const [u, v] = imagePoints[i];\\n      const [X, Y, Z] = objectPoints[i];\\n      \\n      // Normalize image coordinates\\n      const x = (u - cameraMatrix.cx) / cameraMatrix.fx;\\n      const y = (v - cameraMatrix.cy) / cameraMatrix.fy;\\n      \\n      // Add two rows per point to coefficient matrix\\n      A.push([X, Y, Z, 1, 0, 0, 0, 0, -x*X, -x*Y, -x*Z, -x]);\\n      A.push([0, 0, 0, 0, X, Y, Z, 1, -y*X, -y*Y, -y*Z, -y]);\\n    }\\n    \\n    // Solve using SVD approximation (simplified)\\n    // In practice, you'd use proper SVD implementation\\n    const solution = solveDLTSimplified(A);\\n    \\n    if (!solution) return null;\\n    \\n    // Extract rotation and translation from solution\\n    const [r11, r12, r13, tx, r21, r22, r23, ty, r31, r32, r33, tz] = solution;\\n    \\n    // Convert rotation matrix to Euler angles\\n    const yaw = Math.atan2(r21, r11);\\n    const pitch = Math.atan2(-r31, Math.sqrt(r32*r32 + r33*r33));\\n    const roll = Math.atan2(r32, r33);\\n    \\n    return {\\n      rotation: { yaw, pitch, roll },\\n      translation: { x: tx, y: ty, z: tz },\\n      confidence: calculatePoseConfidence(imagePoints, objectPoints, solution)\\n    };\\n    \\n  } catch (error) {\\n    console.warn('PnP pose estimation failed:', error);\\n    return null;\\n  }\\n};\\n\\n// Simplified DLT solver (for demonstration - use proper linear algebra library in production)\\nconst solveDLTSimplified = (A) => {\\n  // This is a simplified implementation\\n  // For production, use a proper linear algebra library like ml-matrix\\n  try {\\n    const rows = A.length;\\n    const cols = A[0].length;\\n    \\n    // Simple least squares approximation\\n    // Return identity-like solution as fallback\\n    return [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0];\\n  } catch (error) {\\n    return null;\\n  }\\n};\\n\\nconst calculatePoseConfidence = (imagePoints, objectPoints, solution) => {\\n  // Calculate reprojection error to estimate confidence\\n  try {\\n    let totalError = 0;\\n    const n = imagePoints.length;\\n    \\n    for (let i = 0; i < n; i++) {\\n      const [u, v] = imagePoints[i];\\n      // Project 3D point back to image using estimated pose\\n      // Calculate distance between original and reprojected point\\n      // This is simplified - proper implementation would do full reprojection\\n      totalError += 1.0; // Placeholder\\n    }\\n    \\n    const avgError = totalError / n;\\n    return Math.max(0, Math.min(1, 1.0 - avgError / 50.0));\\n  } catch (error) {\\n    return 0.5; // Default confidence\\n  }\\n};\\n\\n// Extract 6DOF pose from MediaPipe landmarks\\nconst estimate6DOFPose = (landmarks, cameraMatrix = DEFAULT_CAMERA_MATRIX) => {\\n  if (!landmarks || landmarks.length < 468) {\\n    return createPose6DOF({ confidence: 0 });\\n  }\\n\\n  try {\\n    // Extract key 2D landmark points\\n    const imagePoints = [];\\n    const objectPoints = [];\\n    \\n    // Map MediaPipe landmarks to 3D model points\\n    const keyPoints = [\\n      'noseTip', 'chinBottom', 'leftEyeLeftCorner', 'rightEyeRightCorner',\\n      'leftMouthCorner', 'rightMouthCorner', 'foreheadCenter'\\n    ];\\n    \\n    keyPoints.forEach(pointName => {\\n      const landmarkIdx = MEDIAPIPE_LANDMARK_INDICES[pointName];\\n      if (landmarkIdx < landmarks.length) {\\n        const landmark = landmarks[landmarkIdx];\\n        imagePoints.push([landmark.x, landmark.y]);\\n        objectPoints.push(CANONICAL_3D_FACE_MODEL[pointName]);\\n      }\\n    });\\n    \\n    // Solve PnP for pose estimation\\n    const poseResult = solvePnP(imagePoints, objectPoints, cameraMatrix);\\n    \\n    if (!poseResult) {\\n      return createPose6DOF({ confidence: 0 });\\n    }\\n    \\n    return createPose6DOF({\\n      rotation: {\\n        yaw: poseResult.rotation.yaw,\\n        pitch: poseResult.rotation.pitch, \\n        roll: poseResult.rotation.roll\\n      },\\n      translation: {\\n        x: poseResult.translation.x,\\n        y: poseResult.translation.y,\\n        z: poseResult.translation.z\\n      },\\n      confidence: poseResult.confidence\\n    });\\n\\n  } catch (error) {\\n    console.warn('6DOF pose estimation failed:', error);\\n    return createPose6DOF({ confidence: 0 });\\n  }\\n};\\n\\n// Extract eye tracking information from MediaPipe landmarks  \\nconst extractEyeTracking = (landmarks) => {\\n  if (!landmarks || landmarks.length < 468) {\\n    return createEyeResult({ confidence: 0 });\\n  }\\n\\n  try {\\n    // Get eye landmark indices\\n    const leftEyeCenter = landmarks[MEDIAPIPE_LANDMARK_INDICES.leftEyeCenter] || { x: 0, y: 0, z: 0 };\\n    const rightEyeCenter = landmarks[MEDIAPIPE_LANDMARK_INDICES.rightEyeCenter] || { x: 0, y: 0, z: 0 };\\n    \\n    const leftEyeTop = landmarks[MEDIAPIPE_LANDMARK_INDICES.leftEyeTop] || { x: 0, y: 0, z: 0 };\\n    const leftEyeBottom = landmarks[MEDIAPIPE_LANDMARK_INDICES.leftEyeBottom] || { x: 0, y: 0, z: 0 };\\n    const rightEyeTop = landmarks[MEDIAPIPE_LANDMARK_INDICES.rightEyeTop] || { x: 0, y: 0, z: 0 };\\n    const rightEyeBottom = landmarks[MEDIAPIPE_LANDMARK_INDICES.rightEyeBottom] || { x: 0, y: 0, z: 0 };\\n    \\n    // Calculate eye openness\\n    const leftOpenness = Math.abs(leftEyeTop.y - leftEyeBottom.y) * 10; // Scale factor\\n    const rightOpenness = Math.abs(rightEyeTop.y - rightEyeBottom.y) * 10;\\n    \\n    // Simple gaze vector estimation (requires more sophisticated algorithm for accuracy)\\n    const leftGaze = [0, 0, -1]; // Default forward gaze\\n    const rightGaze = [0, 0, -1]; // Default forward gaze\\n    \\n    // Estimate convergence point (basic implementation)\\n    const convergencePoint = [\\n      (leftEyeCenter.x + rightEyeCenter.x) / 2,\\n      (leftEyeCenter.y + rightEyeCenter.y) / 2,\\n      -100 // Estimated distance in mm\\n    ];\\n    \\n    return createEyeResult({\\n      left: {\\n        center: [leftEyeCenter.x, leftEyeCenter.y],\\n        pupil: [leftEyeCenter.x, leftEyeCenter.y], // Iris center as pupil approximation\\n        landmarks: extractEyeLandmarks(landmarks, 'left'),\\n        gazeVector: leftGaze,\\n        openness: Math.min(1.0, leftOpenness)\\n      },\\n      right: {\\n        center: [rightEyeCenter.x, rightEyeCenter.y],\\n        pupil: [rightEyeCenter.x, rightEyeCenter.y],\\n        landmarks: extractEyeLandmarks(landmarks, 'right'),\\n        gazeVector: rightGaze,\\n        openness: Math.min(1.0, rightOpenness)\\n      },\\n      convergencePoint,\\n      gazeDirection: [0, 0, -1] // Average gaze direction\\n    });\\n\\n  } catch (error) {\\n    console.warn('Eye tracking extraction failed:', error);\\n    return createEyeResult({ confidence: 0 });\\n  }\\n};\\n\\n// Extract detailed eye landmarks\\nconst extractEyeLandmarks = (landmarks, eye) => {\\n  // MediaPipe provides detailed eye contours\\n  // Return simplified landmark set for now\\n  const eyeLandmarks = [];\\n  \\n  if (eye === 'left') {\\n    // Left eye landmarks (simplified selection)\\n    const leftEyeIndices = [33, 7, 163, 144, 145, 153, 154, 155, 133, 173, 157, 158, 159, 160, 161, 246];\\n    leftEyeIndices.forEach(idx => {\\n      if (idx < landmarks.length) {\\n        const lm = landmarks[idx];\\n        eyeLandmarks.push([lm.x, lm.y]);\\n      }\\n    });\\n  } else {\\n    // Right eye landmarks (simplified selection)  \\n    const rightEyeIndices = [362, 382, 381, 380, 374, 373, 390, 249, 263, 466, 388, 387, 386, 385, 384, 398];\\n    rightEyeIndices.forEach(idx => {\\n      if (idx < landmarks.length) {\\n        const lm = landmarks[idx];\\n        eyeLandmarks.push([lm.x, lm.y]);\\n      }\\n    });\\n  }\\n  \\n  return eyeLandmarks;\\n};\\n\\n// Convert MediaPipe results to standardized format\\nconst processMediaPipeResults = (results, enableIris = false) => {\\n  if (!results || !results.multiFaceLandmarks || results.multiFaceLandmarks.length === 0) {\\n    return [];\\n  }\\n\\n  return results.multiFaceLandmarks.map((faceLandmarks, index) => {\\n    // Calculate bounding box from landmarks\\n    const xs = faceLandmarks.map(lm => lm.x);\\n    const ys = faceLandmarks.map(lm => lm.y);\\n    const minX = Math.min(...xs);\\n    const maxX = Math.max(...xs);\\n    const minY = Math.min(...ys);\\n    const maxY = Math.max(...ys);\\n    \\n    const bbox = [minX, minY, maxX - minX, maxY - minY];\\n    \\n    // Convert landmarks to our format\\n    const landmarks = faceLandmarks.map((lm, idx) => ({\\n      id: idx,\\n      x: lm.x,\\n      y: lm.y,\\n      z: lm.z || 0,\\n      visibility: lm.visibility || 1.0\\n    }));\\n    \\n    // Estimate 6DOF pose\\n    const pose = estimate6DOFPose(faceLandmarks);\\n    \\n    // Extract eye tracking if enabled\\n    const eyes = enableIris ? extractEyeTracking(faceLandmarks) : null;\\n    \\n    // Calculate overall confidence based on landmark visibility\\n    const avgVisibility = faceLandmarks\\n      .reduce((sum, lm) => sum + (lm.visibility || 1.0), 0) / faceLandmarks.length;\\n    \\n    return createFaceResult({\\n      bbox,\\n      landmarks,\\n      pose,\\n      confidence: avgVisibility,\\n      id: index,\\n      eyes\\n    });\\n  });\\n};\\n\\n/**\\n * Create MediaPipe Face Mesh Pipeline\\n * \\n * Factory function that creates a comprehensive facial analysis pipeline using\\n * MediaPipe Face Mesh. Provides 468 facial landmarks with 6DOF pose estimation,\\n * eye tracking, and detailed facial geometry analysis.\\n * \\n * @param {Object} config - Pipeline configuration\\n * @param {number} [config.maxNumFaces=1] - Maximum number of faces to detect\\n * @param {boolean} [config.refineLandmarks=true] - Enable refined landmark detection\\n * @param {number} [config.minDetectionConfidence=0.5] - Minimum detection confidence\\n * @param {number} [config.minTrackingConfidence=0.5] - Minimum tracking confidence\\n * @param {boolean} [config.selfieMode=false] - Enable selfie mode (flip horizontally)\\n * @param {boolean} [config.enableIris=false] - Enable iris tracking integration\\n * @param {boolean} [config.staticImageMode=false] - Process static images vs video\\n * @returns {Object} Pipeline instance with process, initialize, and cleanup methods\\n * \\n * @example\\n * const pipeline = createMediaPipeFaceMeshPipeline({\\n *   maxNumFaces: 1,\\n *   refineLandmarks: true,\\n *   enableIris: true\\n * });\\n * \\n * await pipeline.initialize();\\n * const result = await pipeline.process(videoFrame);\\n * console.log(`Detected ${result.faces.length} faces with ${result.faces[0]?.landmarks.length} landmarks`);\\n * await pipeline.cleanup();\\n */\\n/**\\n * Creates standardized MediaPipe Face Mesh pipeline\\n * @param {Object} userConfig - User configuration overrides\\n * @returns {Object} - MediaPipe Face Mesh pipeline instance\\n */\\nexport const createMediaPipeFaceMeshPipeline = (userConfig = {}) => {\\n  // Use unified configuration system\\n  const config = createPipelineConfig('mediapipe-face-mesh', userConfig);\\n  \\n  let faceMesh = null;\\n  let iris = null;\\n  let mediaPipeLoader = null;\\n  let imageProcessor = null;\\n  let resourcePool = null;\\n\\n  return createPipeline({\\n    name: 'mediapipe-face-mesh',\\n    capabilities: [\\n      Capability.FACE_DETECTION,\\n      Capability.POSE_ESTIMATION_6DOF,\\n      Capability.LANDMARK_DETECTION,\\n      Capability.EYE_TRACKING\\n    ],\\n    performance: createPerformanceProfile({\\n      fps: 30,\\n      latency: '30-50ms',\\n      modelSize: '11MB',\\n      cpuUsage: 'medium',\\n      memoryUsage: 'medium',\\n      batteryImpact: 'medium'\\n    }),\\n\\n    // Standardized initialization\\n    initialize: async (initConfig = {}) => {\\n      try {\\n        resourcePool = getGlobalResourcePool();\\n        imageProcessor = createImageProcessor({ resourcePool });\\n        \\n        // Check MediaPipe availability\\n        const availability = checkMediaPipeAvailability();\\n        if (!availability.FaceMesh) {\\n          throw new Error('MediaPipe Face Mesh not available');\\n        }\\n        \\n        // Use MediaPipe commons loader\\n        mediaPipeLoader = createMediaPipeLoader();\\n\\n        // Load Face Mesh with standardized configuration\\n        faceMesh = await mediaPipeLoader.loadModel('FaceMesh', createMediaPipeBase({\\n          maxNumFaces: config.maxNumFaces,\\n          refineLandmarks: config.refineLandmarks,\\n          minDetectionConfidence: config.minDetectionConfidence,\\n          minTrackingConfidence: config.minTrackingConfidence\\n        }));\\n\\n        // Load Iris if enabled\\n        if (config.enableIris) {\\n          try {\\n            iris = await mediaPipeLoader.loadModel('Iris', createMediaPipeBase({\\n              maxNumFaces: config.maxNumFaces,\\n              minDetectionConfidence: config.minDetectionConfidence,\\n              minTrackingConfidence: config.minTrackingConfidence\\n            }));\\n            \\n            handleError(\\n              'MediaPipe Iris tracking enabled',\\n              ErrorCategory.INITIALIZATION,\\n              ErrorSeverity.INFO\\n            );\\n          } catch (irisError) {\\n            handleError(\\n              `MediaPipe Iris not available: ${irisError.message}`,\\n              ErrorCategory.INITIALIZATION,\\n              ErrorSeverity.WARNING\\n            );\\n            iris = null;\\n          }\\n        }\\n\\n        handleError(\\n          'MediaPipe Face Mesh pipeline initialized successfully',\\n          ErrorCategory.INITIALIZATION,\\n          ErrorSeverity.INFO,\\n          { config: { ...config, type: undefined } }\\n        );\\n        \\n        return true;\\n      } catch (error) {\\n        handleError(\\n          `MediaPipe initialization failed: ${error.message}`,\\n          ErrorCategory.INITIALIZATION,\\n          ErrorSeverity.ERROR,\\n          { config }\\n        );\\n        throw error;\\n      }\\n    },\\n\\n    // Process video frame\\n    process: async (frame) => {\\n      if (!faceMesh) {\\n        throw new Error('MediaPipe Face Mesh not initialized');\\n      }\\n\\n      try {\\n        // Send frame to MediaPipe\\n        const results = await new Promise((resolve, reject) => {\\n          faceMesh.onResults(resolve);\\n          faceMesh.send({ image: frame });\\n          \\n          // Set timeout to prevent hanging\\n          setTimeout(() => reject(new Error('MediaPipe processing timeout')), 5000);\\n        });\\n        \\n        // Process additional iris tracking if available\\n        let irisResults = null;\\n        if (iris && mediaPipeConfig.enableIris) {\\n          try {\\n            irisResults = await new Promise((resolve, reject) => {\\n              iris.onResults(resolve);\\n              iris.send({ image: frame });\\n              setTimeout(() => reject(new Error('Iris tracking timeout')), 2000);\\n            });\\n          } catch (irisError) {\\n            console.warn('Iris tracking failed:', irisError.message);\\n          }\\n        }\\n        \\n        // Convert to standardized format\\n        const faces = processMediaPipeResults(results, !!iris);\\n        \\n        return createAnalysisResult({\\n          faces,\\n          confidence: faces.length > 0 ? faces[0].confidence : 0,\\n          source: 'mediapipe-face-mesh',\\n          metadata: {\\n            totalLandmarks: faces.reduce((sum, face) => sum + face.landmarks.length, 0),\\n            irisEnabled: !!iris,\\n            processingMode: mediaPipeConfig.refineLandmarks ? 'refined' : 'standard'\\n          }\\n        });\\n\\n      } catch (error) {\\n        throw new Error(`MediaPipe processing failed: ${error.message}`);\\n      }\\n    },\\n\\n    // Standardized cleanup with resource pool integration\\n    cleanup: async () => {\\n      try {\\n        if (mediaPipeLoader) {\\n          await mediaPipeLoader.cleanup();\\n          mediaPipeLoader = null;\\n        }\\n        \\n        // Clean up image processor cache\\n        if (imageProcessor) {\\n          imageProcessor.cleanup();\\n        }\\n        \\n        faceMesh = null;\\n        iris = null;\\n        imageProcessor = null;\\n        \\n        handleError(\\n          'MediaPipe Face Mesh pipeline cleaned up successfully',\\n          ErrorCategory.INITIALIZATION,\\n          ErrorSeverity.INFO\\n        );\\n        \\n        return true;\\n      } catch (error) {\\n        handleError(\\n          `MediaPipe cleanup failed: ${error.message}`,\\n          ErrorCategory.INITIALIZATION,\\n          ErrorSeverity.WARNING\\n        );\\n        return false;\\n      }\\n    },\\n\\n    // Standardized health status\\n    getHealthStatus: () => ({\\n      healthy: !!faceMesh && !!imageProcessor,\\n      runtime: 'browser',\\n      backend: 'mediapipe-face-mesh',\\n      modelLoaded: !!faceMesh,\\n      irisEnabled: !!iris,\\n      refinedLandmarks: config.refineLandmarks,\\n      resourcePoolAvailable: !!resourcePool,\\n      maxFaces: config.maxNumFaces\\n    }),\\n\\n    // Standardized configuration access\\n    getConfig: () => ({ ...config }),\\n    \\n    // Configuration update method\\n    updateConfig: (updates) => {\\n      const newConfig = createPipelineConfig('mediapipe-face-mesh', { ...config, ...updates });\\n      Object.assign(config, newConfig);\\n      return config;\\n    },\\n\\n    // Check if pipeline is initialized\\n    isInitialized: () => !!faceMesh && !!imageProcessor\\n  });\\n};\\n\\n// Simplified MediaPipe pipeline (Face Mesh only)\\nexport const createMediaPipePipeline = (config = {}) => {\\n  return createMediaPipeFaceMeshPipeline(config);\\n};\\n\\n// Specialized Iris tracking pipeline\\nexport const createMediaPipeIrisPipeline = (config = {}) => {\\n  return createMediaPipeFaceMeshPipeline({ \\n    ...config, \\n    enableIris: true,\\n    maxNumFaces: 1 // Iris tracking works best with single face\\n  });\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/features/media-streaming/device-discovery-pipeline.js\",\"messages\":[{\"ruleId\":\"no-duplicate-imports\",\"severity\":2,\"message\":\"'os' import is duplicated.\",\"line\":10,\"column\":1,\"nodeType\":\"ImportDeclaration\",\"messageId\":\"import\",\"endLine\":10,\"endColumn\":40},{\"ruleId\":\"max-lines-per-function\",\"severity\":1,\"message\":\"Arrow function has too many lines (283). Maximum allowed is 150.\",\"line\":17,\"column\":46,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"exceed\",\"endLine\":372,\"endColumn\":2},{\"ruleId\":\"prefer-destructuring\",\"severity\":1,\"message\":\"Use array destructuring.\",\"line\":148,\"column\":19,\"nodeType\":\"VariableDeclarator\",\"messageId\":\"preferDestructuring\",\"endLine\":148,\"endColumn\":53},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'error' is defined but never used.\",\"line\":176,\"column\":20,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":176,\"endColumn\":25}],\"suppressedMessages\":[],\"errorCount\":2,\"fatalErrorCount\":0,\"warningCount\":2,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Device Discovery Pipeline\\n * Discovers and enumerates available media devices (cameras/microphones)\\n * Following functional programming patterns with factory functions\\n */\\n\\nimport { createPipeline } from '../../core/pipeline/pipeline.ts';\\nimport { createAnalysisResult, createErrorResult } from '../../core/configuration/types.ts';\\nimport os from 'os';\\nimport { networkInterfaces } from 'os';\\n\\n/**\\n * Create device discovery pipeline for media devices\\n * @param {Object} config - Pipeline configuration\\n * @returns {Object} Device discovery pipeline\\n */\\nexport const createDeviceDiscoveryPipeline = (config = {}) => {\\n  const state = {\\n    discoveredDevices: new Map(),\\n    lastDiscovery: 0,\\n    discoveryInterval: config.discoveryInterval || 5000, // 5 seconds\\n    capabilities: new Map(), // device -> capabilities cache\\n    networkInfo: null\\n  };\\n\\n  // Get local network information\\n  const getNetworkInfo = () => {\\n    if (state.networkInfo) return state.networkInfo;\\n    \\n    const interfaces = networkInterfaces();\\n    const primaryInterface = Object.values(interfaces)\\n      .flat()\\n      .find(iface => !iface.internal && iface.family === 'IPv4');\\n    \\n    state.networkInfo = {\\n      computerId: os.hostname(),\\n      ipAddress: primaryInterface?.address || 'localhost',\\n      platform: os.platform(),\\n      arch: os.arch(),\\n      port: config.streamingPort || 8080\\n    };\\n    \\n    return state.networkInfo;\\n  };\\n\\n  // Browser-side device enumeration\\n  const enumerateMediaDevices = async () => {\\n    if (typeof navigator !== 'undefined' && navigator.mediaDevices) {\\n      try {\\n        // Request permissions first to get device labels\\n        const stream = await navigator.mediaDevices.getUserMedia({ \\n          video: true, \\n          audio: true \\n        });\\n        \\n        const devices = await navigator.mediaDevices.enumerateDevices();\\n        \\n        // Stop the permission stream\\n        stream.getTracks().forEach(track => track.stop());\\n        \\n        return devices.map(device => ({\\n          id: device.deviceId,\\n          label: device.label || `${device.kind} ${device.deviceId.slice(0, 8)}`,\\n          type: device.kind, // 'videoinput', 'audioinput', 'audiooutput'\\n          groupId: device.groupId,\\n          platform: 'browser'\\n        }));\\n      } catch (error) {\\n        console.warn('Failed to enumerate media devices:', error);\\n        return [];\\n      }\\n    }\\n    \\n    // Server-side enumeration (mock for now, can be extended with native modules)\\n    return await enumerateSystemDevices();\\n  };\\n\\n  // Server-side device enumeration (simplified mock)\\n  const enumerateSystemDevices = async () => {\\n    // This would use native modules like node-webrtc or system calls\\n    // For now, providing mock devices for testing\\n    const mockDevices = [\\n      {\\n        id: 'default_camera',\\n        label: 'Default Camera',\\n        type: 'videoinput',\\n        groupId: 'group1',\\n        platform: 'system'\\n      },\\n      {\\n        id: 'default_microphone', \\n        label: 'Default Microphone',\\n        type: 'audioinput',\\n        groupId: 'group1',\\n        platform: 'system'\\n      }\\n    ];\\n\\n    // Add platform-specific devices\\n    const platform = os.platform();\\n    if (platform === 'darwin') {\\n      mockDevices.push({\\n        id: 'facetime_camera',\\n        label: 'FaceTime HD Camera',\\n        type: 'videoinput',\\n        groupId: 'group2',\\n        platform: 'system'\\n      });\\n    }\\n\\n    return mockDevices;\\n  };\\n\\n  // Detect device capabilities\\n  const detectDeviceCapabilities = async (device) => {\\n    const cached = state.capabilities.get(device.id);\\n    if (cached && Date.now() - cached.timestamp < 30000) {\\n      return cached.capabilities;\\n    }\\n\\n    let capabilities = {\\n      supportedResolutions: [],\\n      supportedFrameRates: [],\\n      supportedFormats: [],\\n      maxResolution: null,\\n      features: []\\n    };\\n\\n    try {\\n      if (device.type === 'videoinput' && typeof navigator !== 'undefined') {\\n        // Test different video constraints to determine capabilities\\n        const testConstraints = [\\n          { width: 1920, height: 1080 },\\n          { width: 1280, height: 720 },\\n          { width: 640, height: 480 }\\n        ];\\n\\n        for (const constraint of testConstraints) {\\n          try {\\n            const stream = await navigator.mediaDevices.getUserMedia({\\n              video: {\\n                deviceId: device.id,\\n                width: { exact: constraint.width },\\n                height: { exact: constraint.height }\\n              }\\n            });\\n\\n            const track = stream.getVideoTracks()[0];\\n            const settings = track.getSettings();\\n            \\n            capabilities.supportedResolutions.push({\\n              width: settings.width,\\n              height: settings.height\\n            });\\n\\n            if (!capabilities.maxResolution || \\n                settings.width * settings.height > \\n                capabilities.maxResolution.width * capabilities.maxResolution.height) {\\n              capabilities.maxResolution = {\\n                width: settings.width,\\n                height: settings.height\\n              };\\n            }\\n\\n            // Test frame rates\\n            if (track.getCapabilities) {\\n              const caps = track.getCapabilities();\\n              capabilities.supportedFrameRates = caps.frameRate?.max ? \\n                [15, 30, Math.min(60, caps.frameRate.max)] : [15, 30];\\n            } else {\\n              capabilities.supportedFrameRates = [15, 30];\\n            }\\n\\n            stream.getTracks().forEach(track => track.stop());\\n            break; // Successfully tested, break out\\n          } catch (error) {\\n            // Continue to next resolution\\n          }\\n        }\\n      } else if (device.type === 'audioinput') {\\n        capabilities = {\\n          supportedSampleRates: [16000, 44100, 48000],\\n          supportedChannels: [1, 2],\\n          supportedFormats: ['opus', 'aac', 'pcm'],\\n          maxSampleRate: 48000,\\n          features: ['noise_suppression', 'echo_cancellation']\\n        };\\n      }\\n\\n      // Cache capabilities\\n      state.capabilities.set(device.id, {\\n        capabilities,\\n        timestamp: Date.now()\\n      });\\n\\n    } catch (error) {\\n      console.warn(`Failed to detect capabilities for device ${device.id}:`, error);\\n      \\n      // Fallback capabilities\\n      if (device.type === 'videoinput') {\\n        capabilities = {\\n          supportedResolutions: [{ width: 640, height: 480 }],\\n          supportedFrameRates: [15, 30],\\n          maxResolution: { width: 640, height: 480 },\\n          features: ['basic_video']\\n        };\\n      }\\n    }\\n\\n    return capabilities;\\n  };\\n\\n  // Check device status and health\\n  const checkDeviceStatus = async (device) => {\\n    try {\\n      if (typeof navigator !== 'undefined' && navigator.mediaDevices) {\\n        // Quick test to see if device is accessible\\n        const constraints = device.type === 'videoinput' ? \\n          { video: { deviceId: device.id } } : \\n          { audio: { deviceId: device.id } };\\n\\n        const stream = await navigator.mediaDevices.getUserMedia(constraints);\\n        const tracks = stream.getTracks();\\n        const isActive = tracks.length > 0 && tracks[0].readyState === 'live';\\n        \\n        tracks.forEach(track => track.stop());\\n        \\n        return {\\n          status: isActive ? 'available' : 'unavailable',\\n          lastChecked: Date.now(),\\n          error: null\\n        };\\n      }\\n      \\n      // Server-side status check (simplified)\\n      return {\\n        status: 'available',\\n        lastChecked: Date.now(),\\n        error: null\\n      };\\n    } catch (error) {\\n      return {\\n        status: 'unavailable',\\n        lastChecked: Date.now(),\\n        error: error.message\\n      };\\n    }\\n  };\\n\\n  // Main pipeline processing function\\n  const processDiscoveryRequest = async (request = {}) => {\\n    try {\\n      const { forceRefresh = false, includeCapabilities = true } = request;\\n      const now = Date.now();\\n      \\n      // Check if we need to refresh discovery\\n      if (!forceRefresh && \\n          now - state.lastDiscovery < state.discoveryInterval && \\n          state.discoveredDevices.size > 0) {\\n        \\n        // Return cached results\\n        const cachedDevices = Array.from(state.discoveredDevices.values());\\n        return createAnalysisResult({\\n          status: 'success',\\n          data: {\\n            devices: cachedDevices,\\n            networkInfo: getNetworkInfo(),\\n            timestamp: state.lastDiscovery,\\n            source: 'cache'\\n          },\\n          id: `device-discovery_${now}`,\\n          source: 'device-discovery',\\n          processingTime: 1,\\n          timestamp: now\\n        });\\n      }\\n\\n      console.log('🔍 Discovering media devices...');\\n      const startTime = performance.now();\\n\\n      // Enumerate all media devices\\n      const rawDevices = await enumerateMediaDevices();\\n      console.log(`📱 Found ${rawDevices.length} raw devices`);\\n\\n      // Enrich devices with capabilities and status\\n      const enrichedDevices = await Promise.all(\\n        rawDevices.map(async device => {\\n          console.log(`🔧 Analyzing device: ${device.label}`);\\n          \\n          const [capabilities, status] = await Promise.all([\\n            includeCapabilities ? detectDeviceCapabilities(device) : {},\\n            checkDeviceStatus(device)\\n          ]);\\n\\n          return {\\n            ...device,\\n            capabilities,\\n            status,\\n            networkInfo: getNetworkInfo(),\\n            discoveredAt: now\\n          };\\n        })\\n      );\\n\\n      // Update cache\\n      state.discoveredDevices.clear();\\n      enrichedDevices.forEach(device => {\\n        state.discoveredDevices.set(device.id, device);\\n      });\\n      state.lastDiscovery = now;\\n\\n      const processingTime = performance.now() - startTime;\\n      console.log(`✅ Device discovery completed in ${processingTime.toFixed(2)}ms`);\\n\\n      return createAnalysisResult({\\n        status: 'success',\\n        data: {\\n          devices: enrichedDevices,\\n          networkInfo: getNetworkInfo(),\\n          timestamp: now,\\n          source: 'fresh_discovery',\\n          statistics: {\\n            totalDevices: enrichedDevices.length,\\n            videoDevices: enrichedDevices.filter(d => d.type === 'videoinput').length,\\n            audioDevices: enrichedDevices.filter(d => d.type === 'audioinput').length,\\n            availableDevices: enrichedDevices.filter(d => d.status.status === 'available').length\\n          }\\n        },\\n        id: `device-discovery_${now}`,\\n        source: 'device-discovery',\\n        processingTime,\\n        timestamp: now\\n      });\\n\\n    } catch (error) {\\n      console.error('Device discovery failed:', error);\\n      \\n      return createAnalysisResult({\\n        status: 'failed',\\n        error: createErrorResult(error.message, 'device-discovery'),\\n        id: `device-discovery_${Date.now()}`,\\n        source: 'device-discovery',\\n        processingTime: 0,\\n        timestamp: Date.now()\\n      });\\n    }\\n  };\\n\\n  // Create the pipeline\\n  return createPipeline({\\n    name: 'device-discovery',\\n    version: '1.0.0',\\n    capabilities: ['device_enumeration', 'capability_detection', 'status_monitoring'],\\n    performance: {\\n      fps: 1, // Low frequency discovery\\n      latency: '100-500ms',\\n      cpuUsage: 'low',\\n      batteryImpact: 'minimal'\\n    },\\n    description: 'Discovers and analyzes available media devices',\\n    \\n    // Main processing function\\n    process: processDiscoveryRequest,\\n    \\n    // Optional cleanup\\n    cleanup: async () => {\\n      state.discoveredDevices.clear();\\n      state.capabilities.clear();\\n      state.networkInfo = null;\\n    }\\n  });\\n};\\n\\n/**\\n * Convenience function to create and initialize device discovery\\n * @param {Object} config - Configuration options\\n * @returns {Promise<Object>} Initialized pipeline\\n */\\nexport const createDeviceDiscoverySystem = async (config = {}) => {\\n  const pipeline = createDeviceDiscoveryPipeline(config);\\n  \\n  if (config.autoInitialize !== false) {\\n    await pipeline.initialize();\\n  }\\n  \\n  return pipeline;\\n};\\n\\n/**\\n * Quick discovery function for immediate use\\n * @param {Object} options - Discovery options\\n * @returns {Promise<Object>} Discovery results\\n */\\nexport const discoverDevices = async (options = {}) => {\\n  const pipeline = createDeviceDiscoveryPipeline(options);\\n  await pipeline.initialize();\\n  \\n  const result = await pipeline.process(options);\\n  await pipeline.cleanup();\\n  \\n  return result;\\n};\\n\\n\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/features/media-streaming/media-streaming-pipeline.js\",\"messages\":[{\"ruleId\":null,\"nodeType\":null,\"fatal\":true,\"severity\":2,\"message\":\"Parsing error: Unexpected token }\",\"line\":69,\"column\":5}],\"suppressedMessages\":[],\"errorCount\":1,\"fatalErrorCount\":1,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Media Streaming Pipeline\\n * Handles video and audio streaming with quality control\\n * Following functional programming patterns with factory functions\\n */\\n\\nimport { createPipeline } from '../../core/pipeline/pipeline.ts';\\nimport { createQualityController } from './quality-controller.js';\\nimport { createPipelineState } from './pipeline-state.js';\\nimport { createStreamOperations } from './stream-operations.js';\\nimport { createPipelineInterface } from './pipeline-interface.js';\\n\\n/**\\n * Create media streaming pipeline for a specific device\\n * @param {Object} deviceInfo - Device information from discovery\\n * @param {Object} config - Pipeline configuration\\n * @returns {Object} Media streaming pipeline\\n */\\nexport const createMediaStreamingPipeline = (deviceInfo, config = {}) => {\\n  const state = createPipelineState(deviceInfo, config);\\n\\n  // Initialize quality controller if enabled\\n  if (config.enableQualityControl !== false) {\\n    state.qualityController = createQualityController({\\n      deviceId: deviceInfo.id,\\n      deviceType: deviceInfo.type,\\n      initialQuality: state.quality,\\n      adaptationEnabled: config.adaptiveQuality !== false\\n    });\\n  }\\n  \\n  // Create modular operations and interface\\n  const operations = createStreamOperations(state);\\n  const pipeline = createPipelineInterface(state, operations);\\n  \\n  // Create pipeline process function\\n  const process = async (input) => {\\n    if (!input || !input.action) {\\n      throw new Error('Invalid input: action is required');\\n    }\\n    \\n    switch (input.action) {\\n      case 'START_STREAM':\\n        return operations.startStream();\\n      case 'STOP_STREAM':\\n        return operations.stopStream();\\n      case 'CHANGE_QUALITY':\\n        const quality = input.parameters?.quality || 'medium';\\n        return operations.changeQuality(quality);\\n      default:\\n        throw new Error(`Unknown action: ${input.action}`);\\n    }\\n  };\\n  \\n  return {\\n    ...pipeline,\\n    process,\\n    initialize: async () => {\\n      console.log(`📹 Initializing media streaming pipeline for device: ${deviceInfo.label || deviceInfo.id}`);\\n      return true;\\n    }\\n  };\\n        if (qualityInfo.recommendedQuality !== state.quality) {\\n          changeQuality(qualityInfo.recommendedQuality).catch(error => {\\n            console.warn('Automatic quality change failed:', error);\\n          });\\n        }\\n      }\\n    });\\n  }\\n\\n  // Quality profiles synchronized with quality controller\\n  const QUALITY_PROFILES = {\\n    ultra: {\\n      video: { width: 3840, height: 2160, fps: 60, bitrate: '25M' },\\n      audio: { sampleRate: 48000, channels: 2, bitrate: '320k' }\\n    },\\n    high: {\\n      video: { width: 1920, height: 1080, fps: 30, bitrate: '8M' },\\n      audio: { sampleRate: 48000, channels: 2, bitrate: '256k' }\\n    },\\n    medium: {\\n      video: { width: 1280, height: 720, fps: 30, bitrate: '4M' },\\n      audio: { sampleRate: 44100, channels: 2, bitrate: '192k' }\\n    },\\n    low: {\\n      video: { width: 854, height: 480, fps: 24, bitrate: '1M' },\\n      audio: { sampleRate: 22050, channels: 1, bitrate: '96k' }\\n    },\\n    mobile: {\\n      video: { width: 640, height: 360, fps: 15, bitrate: '500k' },\\n      audio: { sampleRate: 16000, channels: 1, bitrate: '64k' }\\n    }\\n  };\\n\\n  // Initialize media capture\\n  const initializeMediaCapture = async (requestedQuality = 'medium') => {\\n    if (state.mediaStream) {\\n      // Stop existing stream\\n      state.mediaStream.getTracks().forEach(track => track.stop());\\n    }\\n\\n    const profile = QUALITY_PROFILES[requestedQuality];\\n    if (!profile) {\\n      throw new Error(`Invalid quality profile: ${requestedQuality}`);\\n    }\\n\\n    try {\\n      const constraints = {};\\n\\n      // Configure video constraints\\n      if (deviceInfo.type === 'videoinput') {\\n        constraints.video = {\\n          deviceId: { exact: deviceInfo.id },\\n          width: { ideal: profile.video.width },\\n          height: { ideal: profile.video.height },\\n          frameRate: { ideal: profile.video.fps }\\n        };\\n      }\\n\\n      // Configure audio constraints  \\n      if (deviceInfo.type === 'audioinput') {\\n        constraints.audio = {\\n          deviceId: { exact: deviceInfo.id },\\n          sampleRate: { ideal: profile.audio.sampleRate },\\n          channelCount: { ideal: profile.audio.channels },\\n          noiseSuppression: true,\\n          echoCancellation: true,\\n          autoGainControl: true\\n        };\\n      }\\n\\n      console.log(`🎥 Initializing media capture for ${deviceInfo.label} at ${requestedQuality} quality`);\\n      state.mediaStream = await navigator.mediaDevices.getUserMedia(constraints);\\n      state.quality = requestedQuality;\\n\\n      // Set up frame capture for video streams\\n      if (constraints.video) {\\n        await setupVideoFrameCapture();\\n      }\\n\\n      // Set up audio capture for audio streams\\n      if (constraints.audio) {\\n        await setupAudioCapture();\\n      }\\n\\n      console.log(`✅ Media capture initialized successfully`);\\n      return true;\\n\\n    } catch (error) {\\n      console.error('Failed to initialize media capture:', error);\\n      throw new Error(`Media capture failed: ${error.message}`);\\n    }\\n  };\\n\\n  // Set up video frame capture using canvas\\n  const setupVideoFrameCapture = async () => {\\n    if (typeof document === 'undefined') {\\n      console.warn('Video frame capture not available in server environment');\\n      return;\\n    }\\n\\n    const video = document.createElement('video');\\n    const canvas = document.createElement('canvas');\\n    const ctx = canvas.getContext('2d');\\n\\n    video.srcObject = state.mediaStream;\\n    video.autoplay = true;\\n    video.muted = true;\\n\\n    return new Promise((resolve) => {\\n      video.onloadedmetadata = () => {\\n        canvas.width = video.videoWidth;\\n        canvas.height = video.videoHeight;\\n        \\n        state.videoElement = video;\\n        state.canvas = canvas;\\n        state.canvasContext = ctx;\\n        \\n        resolve();\\n      };\\n    });\\n  };\\n\\n  // Set up audio capture using Web Audio API\\n  const setupAudioCapture = async () => {\\n    if (typeof window === 'undefined' || !window.AudioContext) {\\n      console.warn('Audio capture not available in this environment');\\n      return;\\n    }\\n\\n    const audioContext = new (window.AudioContext || window.webkitAudioContext)();\\n    const source = audioContext.createMediaStreamSource(state.mediaStream);\\n    const analyser = audioContext.createAnalyser();\\n    \\n    analyser.fftSize = 2048;\\n    source.connect(analyser);\\n\\n    state.audioContext = audioContext;\\n    state.audioAnalyser = analyser;\\n    state.audioBuffer = new Float32Array(analyser.frequencyBinCount);\\n  };\\n\\n  // Capture current video frame\\n  const captureVideoFrame = () => {\\n    if (!state.canvasContext || !state.videoElement) {\\n      throw new Error('Video capture not initialized');\\n    }\\n\\n    const { canvas, canvasContext: ctx, videoElement: video } = state;\\n    \\n    // Draw current video frame to canvas\\n    ctx.drawImage(video, 0, 0, canvas.width, canvas.height);\\n    \\n    // Get image data\\n    const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);\\n    const frameData = {\\n      data: imageData.data,\\n      width: canvas.width,\\n      height: canvas.height,\\n      format: 'rgba',\\n      timestamp: Date.now(),\\n      frameNumber: state.stats.framesProcessed + 1\\n    };\\n\\n    // Update statistics\\n    updateFrameStats(frameData);\\n    \\n    return frameData;\\n  };\\n\\n  // Capture current audio data\\n  const captureAudioData = () => {\\n    if (!state.audioAnalyser) {\\n      throw new Error('Audio capture not initialized');\\n    }\\n\\n    state.audioAnalyser.getFloatFrequencyData(state.audioBuffer);\\n    \\n    return {\\n      frequencyData: new Float32Array(state.audioBuffer),\\n      sampleRate: state.audioContext.sampleRate,\\n      timestamp: Date.now(),\\n      format: 'float32'\\n    };\\n  };\\n\\n  // Update streaming statistics\\n  const updateFrameStats = (frameData) => {\\n    const now = Date.now();\\n    const frameSize = frameData.data ? frameData.data.byteLength : 0;\\n    \\n    state.stats.framesProcessed++;\\n    state.stats.bytesStreamed += frameSize;\\n    \\n    // Calculate average frame size\\n    state.stats.averageFrameSize = \\n      (state.stats.averageFrameSize * (state.stats.framesProcessed - 1) + frameSize) / \\n      state.stats.framesProcessed;\\n\\n    // Calculate FPS\\n    if (state.stats.lastFrameTime > 0) {\\n      const deltaTime = now - state.stats.lastFrameTime;\\n      const currentFPS = 1000 / deltaTime;\\n      state.stats.currentFPS = \\n        (state.stats.currentFPS * 0.9) + (currentFPS * 0.1); // Smooth FPS\\n    }\\n    state.stats.lastFrameTime = now;\\n\\n    // Add to buffer\\n    state.frameBuffer.add(frameData);\\n\\n    // Update quality controller with stream metrics\\n    if (state.qualityController) {\\n      state.qualityController.updateStreamMetrics({\\n        frameSize,\\n        fps: state.stats.currentFPS,\\n        bytesStreamed: state.stats.bytesStreamed,\\n        framesProcessed: state.stats.framesProcessed,\\n        averageFrameSize: state.stats.averageFrameSize,\\n        timestamp: now\\n      });\\n    }\\n  };\\n\\n  // Change streaming quality\\n  const changeQuality = async (newQuality) => {\\n    if (!QUALITY_PROFILES[newQuality]) {\\n      throw new Error(`Invalid quality: ${newQuality}`);\\n    }\\n\\n    if (newQuality === state.quality) {\\n      return { success: true, message: 'Quality unchanged' };\\n    }\\n\\n    console.log(`📊 Changing quality from ${state.quality} to ${newQuality}`);\\n    \\n    try {\\n      const wasStreaming = state.isStreaming;\\n      \\n      if (wasStreaming) {\\n        await stopStreaming();\\n      }\\n      \\n      await initializeMediaCapture(newQuality);\\n      \\n      if (wasStreaming) {\\n        await startStreaming();\\n      }\\n\\n      // Notify callbacks\\n      state.callbacks.onQualityChange.forEach(callback => {\\n        try {\\n          callback({ oldQuality: state.quality, newQuality });\\n        } catch (error) {\\n          console.warn('Quality change callback error:', error);\\n        }\\n      });\\n\\n      return { \\n        success: true, \\n        oldQuality: state.quality, \\n        newQuality,\\n        profile: QUALITY_PROFILES[newQuality]\\n      };\\n    } catch (error) {\\n      console.error('Quality change failed:', error);\\n      throw error;\\n    }\\n  };\\n\\n  // Start streaming\\n  const startStreaming = async () => {\\n    if (state.isStreaming) {\\n      return { success: true, message: 'Already streaming' };\\n    }\\n\\n    if (!state.mediaStream) {\\n      await initializeMediaCapture();\\n    }\\n\\n    state.isStreaming = true;\\n    console.log(`🎬 Started streaming ${deviceInfo.label} at ${state.quality} quality`);\\n    \\n    return { \\n      success: true, \\n      deviceId: deviceInfo.id,\\n      quality: state.quality,\\n      profile: QUALITY_PROFILES[state.quality]\\n    };\\n  };\\n\\n  // Stop streaming\\n  const stopStreaming = async () => {\\n    if (!state.isStreaming) {\\n      return { success: true, message: 'Not streaming' };\\n    }\\n\\n    state.isStreaming = false;\\n    \\n    if (state.mediaStream) {\\n      state.mediaStream.getTracks().forEach(track => track.stop());\\n      state.mediaStream = null;\\n    }\\n\\n    // Clean up audio context\\n    if (state.audioContext && state.audioContext.state !== 'closed') {\\n      await state.audioContext.close();\\n      state.audioContext = null;\\n    }\\n\\n    console.log(`🛑 Stopped streaming ${deviceInfo.label}`);\\n    return { success: true, deviceId: deviceInfo.id };\\n  };\\n\\n  // Get current streaming status\\n  const getStreamingStatus = () => ({\\n    isStreaming: state.isStreaming,\\n    deviceId: deviceInfo.id,\\n    deviceLabel: deviceInfo.label,\\n    deviceType: deviceInfo.type,\\n    quality: state.quality,\\n    profile: QUALITY_PROFILES[state.quality],\\n    stats: { ...state.stats },\\n    bufferSize: state.frameBuffer.getSize(),\\n    capabilities: deviceInfo.capabilities\\n  });\\n\\n  // Main pipeline processing function\\n  const processStreamCommand = async (command) => {\\n    try {\\n      const { action, parameters = {} } = command;\\n      let result;\\n\\n      switch (action) {\\n        case 'START_STREAM':\\n          result = await startStreaming();\\n          break;\\n\\n        case 'STOP_STREAM':\\n          result = await stopStreaming();\\n          break;\\n\\n        case 'CHANGE_QUALITY':\\n          result = await changeQuality(parameters.quality);\\n          break;\\n\\n        case 'GET_FRAME':\\n          if (deviceInfo.type === 'videoinput') {\\n            result = captureVideoFrame();\\n          } else {\\n            throw new Error('Cannot capture frame from non-video device');\\n          }\\n          break;\\n\\n        case 'GET_AUDIO_DATA':\\n          if (deviceInfo.type === 'audioinput') {\\n            result = captureAudioData();\\n          } else {\\n            throw new Error('Cannot capture audio from non-audio device');\\n          }\\n          break;\\n\\n        case 'GET_STATUS':\\n          result = getStreamingStatus();\\n          break;\\n\\n        case 'UPDATE_CONFIG':\\n          Object.assign(config, parameters);\\n          result = { success: true, config: { ...config } };\\n          break;\\n\\n        default:\\n          throw new Error(`Unknown command: ${action}`);\\n      }\\n\\n      return createAnalysisResult({\\n        status: 'success',\\n        data: {\\n          command: action,\\n          result,\\n          deviceId: deviceInfo.id,\\n          timestamp: Date.now()\\n        },\\n        id: `media-stream_${deviceInfo.id}_${Date.now()}`,\\n        source: `media-stream-${deviceInfo.id}`,\\n        processingTime: 1,\\n        timestamp: Date.now()\\n      });\\n\\n    } catch (error) {\\n      console.error(`Stream command ${command.action} failed:`, error);\\n      \\n      return createAnalysisResult({\\n        status: 'failed',\\n        error: createErrorResult(error.message, `media-stream-${deviceInfo.id}`),\\n        id: `media-stream_${deviceInfo.id}_${Date.now()}`,\\n        source: `media-stream-${deviceInfo.id}`,\\n        processingTime: 1,\\n        timestamp: Date.now()\\n      });\\n    }\\n  };\\n\\n  // Event subscription methods\\n  const onFrame = (callback) => {\\n    state.callbacks.onFrame.push(callback);\\n    return () => {\\n      const index = state.callbacks.onFrame.indexOf(callback);\\n      if (index !== -1) state.callbacks.onFrame.splice(index, 1);\\n    };\\n  };\\n\\n  const onError = (callback) => {\\n    state.callbacks.onError.push(callback);\\n    return () => {\\n      const index = state.callbacks.onError.indexOf(callback);\\n      if (index !== -1) state.callbacks.onError.splice(index, 1);\\n    };\\n  };\\n\\n  const onQualityChange = (callback) => {\\n    state.callbacks.onQualityChange.push(callback);\\n    return () => {\\n      const index = state.callbacks.onQualityChange.indexOf(callback);\\n      if (index !== -1) state.callbacks.onQualityChange.splice(index, 1);\\n    };\\n  };\\n\\n  // Create the pipeline\\n  const pipeline = createPipeline({\\n    name: `media-stream-${deviceInfo.id}`,\\n    version: '1.0.0',\\n    capabilities: ['video_streaming', 'audio_streaming', 'quality_adaptation'],\\n    performance: {\\n      fps: deviceInfo.capabilities?.maxFrameRate || 30,\\n      latency: '50-100ms',\\n      cpuUsage: 'medium',\\n      batteryImpact: 'medium'\\n    },\\n    description: `Media streaming pipeline for ${deviceInfo.label}`,\\n    \\n    // Pipeline initialization\\n    initialize: async (initConfig = {}) => {\\n      Object.assign(config, initConfig);\\n      if (config.autoStart) {\\n        await initializeMediaCapture(config.quality || 'medium');\\n      }\\n      return true;\\n    },\\n    \\n    // Main processing function\\n    process: processStreamCommand,\\n    \\n    // Cleanup function\\n    cleanup: async () => {\\n      await stopStreaming();\\n      state.frameBuffer.clear();\\n      state.callbacks.onFrame = [];\\n      state.callbacks.onError = [];\\n      state.callbacks.onQualityChange = [];\\n    }\\n  });\\n\\n  // Add custom methods to pipeline\\n  return {\\n    ...pipeline,\\n    \\n    // Device info\\n    getDeviceInfo: () => ({ ...deviceInfo }),\\n    getDeviceId: () => deviceInfo.id,\\n    getDeviceType: () => deviceInfo.type,\\n    \\n    // Stream control\\n    startStreaming,\\n    stopStreaming,\\n    changeQuality,\\n    \\n    // Data capture\\n    captureFrame: captureVideoFrame,\\n    captureAudioData,\\n    \\n    // Status and stats\\n    getStatus: getStreamingStatus,\\n    getStats: () => ({ ...state.stats }),\\n    getBuffer: () => state.frameBuffer,\\n    \\n    // Quality profiles and control\\n    getQualityProfiles: () => ({ ...QUALITY_PROFILES }),\\n    getCurrentQuality: () => state.quality,\\n    getQualityController: () => state.qualityController,\\n    \\n    // Quality controller methods\\n    updateNetworkStats: (networkStats) => {\\n      if (state.qualityController) {\\n        state.qualityController.updateNetworkStats(networkStats);\\n      }\\n    },\\n    getQualityMetrics: () => {\\n      return state.qualityController ? \\n        state.qualityController.getQualityInfo() : null;\\n    },\\n    setAdaptationEnabled: (enabled) => {\\n      if (state.qualityController) {\\n        state.qualityController.setAdaptiveMode(enabled);\\n      }\\n    },\\n    \\n    // Event handlers\\n    onFrame,\\n    onError,\\n    onQualityChange,\\n    \\n    // Stream state\\n    isStreaming: () => state.isStreaming,\\n    getMediaStream: () => state.mediaStream\\n  };\\n};\\n\\n/**\\n * Convenience function to create streaming pipeline for multiple devices\\n * @param {Array} devices - Array of device info objects\\n * @param {Object} config - Common configuration\\n * @returns {Map} Map of deviceId -> pipeline\\n */\\nexport const createMultiDeviceStreaming = (devices, config = {}) => {\\n  const pipelines = new Map();\\n  \\n  devices.forEach(device => {\\n    const pipeline = createMediaStreamingPipeline(device, config);\\n    pipelines.set(device.id, pipeline);\\n  });\\n  \\n  return pipelines;\\n};\\n\\n\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/features/media-streaming/multi-device-coordinator.js\",\"messages\":[{\"ruleId\":\"max-lines-per-function\",\"severity\":1,\"message\":\"Arrow function has too many lines (381). Maximum allowed is 150.\",\"line\":15,\"column\":45,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"exceed\",\"endLine\":520,\"endColumn\":2},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'streamConfig' is assigned a value but never used. Allowed unused args must match /^_/u.\",\"line\":122,\"column\":40,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":122,\"endColumn\":52,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"streamConfig\"},\"fix\":{\"range\":[3866,3885],\"text\":\"\"},\"desc\":\"Remove unused variable 'streamConfig'.\"}]},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'stats' is assigned a value but never used. Allowed unused vars must match /^_/u.\",\"line\":335,\"column\":15,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":335,\"endColumn\":20,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"stats\"},\"fix\":{\"range\":[10278,10312],\"text\":\"\"},\"desc\":\"Remove unused variable 'stats'.\"}]}],\"suppressedMessages\":[],\"errorCount\":2,\"fatalErrorCount\":0,\"warningCount\":1,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Multi-Device Streaming Coordinator\\n * Manages streaming across multiple devices with centralized control\\n * Following functional programming patterns with factory functions\\n */\\n\\nimport { createMediaStreamingPipeline } from './media-streaming-pipeline.js';\\nimport { createQualityController } from './quality-controller.js';\\n\\n/**\\n * Create multi-device streaming coordinator\\n * @param {Object} config - Coordinator configuration\\n * @returns {Object} Multi-device coordinator\\n */\\nexport const createMultiDeviceCoordinator = (config = {}) => {\\n  const state = {\\n    devices: new Map(), // deviceId -> device info\\n    pipelines: new Map(), // deviceId -> streaming pipeline\\n    activeStreams: new Set(), // Set of active stream IDs\\n    globalQualityController: null,\\n    networkStats: {\\n      totalBandwidth: 0,\\n      averageLatency: 0,\\n      packetLoss: 0,\\n      lastUpdated: null\\n    },\\n    groupSettings: {\\n      syncStreaming: config.syncStreaming !== false,\\n      globalQualityControl: config.globalQualityControl !== false,\\n      loadBalancing: config.loadBalancing !== false\\n    },\\n    callbacks: {\\n      onDeviceAdded: [],\\n      onDeviceRemoved: [],\\n      onStreamStarted: [],\\n      onStreamStopped: [],\\n      onQualityChanged: [],\\n      onError: []\\n    }\\n  };\\n\\n  // Initialize global quality controller if enabled\\n  if (state.groupSettings.globalQualityControl) {\\n    state.globalQualityController = createQualityController({\\n      deviceId: 'global',\\n      deviceType: 'coordinator',\\n      initialQuality: config.defaultQuality || 'medium',\\n      adaptationEnabled: config.globalAdaptation !== false,\\n      onQualityChange: (qualityInfo) => {\\n        // Apply quality changes to all active streams\\n        if (config.syncQualityChanges !== false) {\\n          applyGlobalQualityChange(qualityInfo.recommendedQuality);\\n        }\\n      }\\n    });\\n  }\\n\\n  // Add device to coordinator\\n  const addDevice = async (deviceInfo) => {\\n    const deviceId = deviceInfo.id;\\n    \\n    if (state.devices.has(deviceId)) {\\n      console.warn(`Device ${deviceId} already exists, updating info`);\\n    }\\n\\n    // Store device info\\n    state.devices.set(deviceId, { ...deviceInfo });\\n\\n    // Create streaming pipeline for device\\n    const pipeline = createMediaStreamingPipeline(deviceInfo, {\\n      ...config.pipelineConfig,\\n      enableQualityControl: !state.groupSettings.globalQualityControl, // Use local if no global\\n      adaptiveQuality: config.adaptiveQuality !== false\\n    });\\n\\n    state.pipelines.set(deviceId, pipeline);\\n\\n    // Subscribe to pipeline events\\n    pipeline.onError((error) => {\\n      notifyCallbacks('onError', { deviceId, error });\\n    });\\n\\n    pipeline.onQualityChange((qualityChange) => {\\n      notifyCallbacks('onQualityChanged', { deviceId, ...qualityChange });\\n    });\\n\\n    console.log(`📱 Added device: ${deviceInfo.label} (${deviceId})`);\\n    notifyCallbacks('onDeviceAdded', { deviceId, deviceInfo });\\n\\n    return { success: true, deviceId, pipelineCreated: true };\\n  };\\n\\n  // Remove device from coordinator\\n  const removeDevice = async (deviceId) => {\\n    if (!state.devices.has(deviceId)) {\\n      throw new Error(`Device ${deviceId} not found`);\\n    }\\n\\n    // Stop streaming if active\\n    if (state.activeStreams.has(deviceId)) {\\n      await stopStream(deviceId);\\n    }\\n\\n    // Cleanup pipeline\\n    const pipeline = state.pipelines.get(deviceId);\\n    if (pipeline && pipeline.cleanup) {\\n      await pipeline.cleanup();\\n    }\\n\\n    // Remove from state\\n    const deviceInfo = state.devices.get(deviceId);\\n    state.devices.delete(deviceId);\\n    state.pipelines.delete(deviceId);\\n\\n    console.log(`🗑️ Removed device: ${deviceInfo.label} (${deviceId})`);\\n    notifyCallbacks('onDeviceRemoved', { deviceId, deviceInfo });\\n\\n    return { success: true, deviceId };\\n  };\\n\\n  // Start streaming for specific device\\n  const startStream = async (deviceId, streamConfig = {}) => {\\n    const pipeline = state.pipelines.get(deviceId);\\n    if (!pipeline) {\\n      throw new Error(`Pipeline not found for device: ${deviceId}`);\\n    }\\n\\n    if (state.activeStreams.has(deviceId)) {\\n      return { success: true, message: 'Stream already active', deviceId };\\n    }\\n\\n    try {\\n      // Apply global quality if enabled\\n      if (state.groupSettings.globalQualityControl && state.globalQualityController) {\\n        const globalInfo = state.globalQualityController.getQualityInfo();\\n        if (globalInfo && globalInfo.currentQuality) {\\n          await pipeline.changeQuality(globalInfo.currentQuality);\\n        }\\n      }\\n\\n      // Start the stream\\n      const result = await pipeline.startStreaming();\\n      \\n      if (result.success) {\\n        state.activeStreams.add(deviceId);\\n        notifyCallbacks('onStreamStarted', { deviceId, ...result });\\n        \\n        // Update load balancing if enabled\\n        if (state.groupSettings.loadBalancing) {\\n          await rebalanceStreams();\\n        }\\n      }\\n\\n      return result;\\n    } catch (error) {\\n      console.error(`Failed to start stream for ${deviceId}:`, error);\\n      notifyCallbacks('onError', { deviceId, error, operation: 'startStream' });\\n      throw error;\\n    }\\n  };\\n\\n  // Stop streaming for specific device\\n  const stopStream = async (deviceId) => {\\n    const pipeline = state.pipelines.get(deviceId);\\n    if (!pipeline) {\\n      throw new Error(`Pipeline not found for device: ${deviceId}`);\\n    }\\n\\n    if (!state.activeStreams.has(deviceId)) {\\n      return { success: true, message: 'Stream not active', deviceId };\\n    }\\n\\n    try {\\n      const result = await pipeline.stopStreaming();\\n      \\n      if (result.success) {\\n        state.activeStreams.delete(deviceId);\\n        notifyCallbacks('onStreamStopped', { deviceId, ...result });\\n        \\n        // Update load balancing if enabled\\n        if (state.groupSettings.loadBalancing) {\\n          await rebalanceStreams();\\n        }\\n      }\\n\\n      return result;\\n    } catch (error) {\\n      console.error(`Failed to stop stream for ${deviceId}:`, error);\\n      notifyCallbacks('onError', { deviceId, error, operation: 'stopStream' });\\n      throw error;\\n    }\\n  };\\n\\n  // Start streaming for multiple devices\\n  const startMultipleStreams = async (deviceIds, streamConfig = {}) => {\\n    const results = {};\\n    \\n    if (state.groupSettings.syncStreaming) {\\n      // Start all streams simultaneously\\n      const promises = deviceIds.map(deviceId => \\n        startStream(deviceId, streamConfig).catch(error => ({ deviceId, error }))\\n      );\\n      \\n      const streamResults = await Promise.all(promises);\\n      \\n      streamResults.forEach(result => {\\n        if (result.error) {\\n          results[result.deviceId] = { success: false, error: result.error };\\n        } else {\\n          results[result.deviceId] = result;\\n        }\\n      });\\n    } else {\\n      // Start streams sequentially\\n      for (const deviceId of deviceIds) {\\n        try {\\n          results[deviceId] = await startStream(deviceId, streamConfig);\\n        } catch (error) {\\n          results[deviceId] = { success: false, error };\\n        }\\n      }\\n    }\\n\\n    const successful = Object.values(results).filter(r => r.success).length;\\n    console.log(`🎬 Started ${successful}/${deviceIds.length} streams`);\\n\\n    return {\\n      success: successful > 0,\\n      results,\\n      totalRequested: deviceIds.length,\\n      successful\\n    };\\n  };\\n\\n  // Stop streaming for multiple devices\\n  const stopMultipleStreams = async (deviceIds) => {\\n    const results = {};\\n    \\n    // Stop all streams simultaneously\\n    const promises = deviceIds.map(deviceId => \\n      stopStream(deviceId).catch(error => ({ deviceId, error }))\\n    );\\n    \\n    const streamResults = await Promise.all(promises);\\n    \\n    streamResults.forEach(result => {\\n      if (result.error) {\\n        results[result.deviceId] = { success: false, error: result.error };\\n      } else {\\n        results[result.deviceId] = result;\\n      }\\n    });\\n\\n    const successful = Object.values(results).filter(r => r.success).length;\\n    console.log(`🛑 Stopped ${successful}/${deviceIds.length} streams`);\\n\\n    return {\\n      success: successful > 0,\\n      results,\\n      totalRequested: deviceIds.length,\\n      successful\\n    };\\n  };\\n\\n  // Apply quality change to all active streams\\n  const applyGlobalQualityChange = async (newQuality) => {\\n    const activeDeviceIds = Array.from(state.activeStreams);\\n    const results = {};\\n\\n    console.log(`📊 Applying global quality change to ${newQuality} for ${activeDeviceIds.length} streams`);\\n\\n    for (const deviceId of activeDeviceIds) {\\n      const pipeline = state.pipelines.get(deviceId);\\n      if (pipeline) {\\n        try {\\n          results[deviceId] = await pipeline.changeQuality(newQuality);\\n        } catch (error) {\\n          results[deviceId] = { success: false, error };\\n          console.warn(`Quality change failed for ${deviceId}:`, error);\\n        }\\n      }\\n    }\\n\\n    return results;\\n  };\\n\\n  // Rebalance streams based on network conditions\\n  const rebalanceStreams = async () => {\\n    if (!state.groupSettings.loadBalancing || state.activeStreams.size === 0) {\\n      return { success: true, message: 'No rebalancing needed' };\\n    }\\n\\n    console.log('⚖️ Rebalancing streams based on network conditions');\\n\\n    // Get network statistics\\n    updateNetworkStats();\\n    \\n    // Simple load balancing: reduce quality if too many active streams\\n    const activeCount = state.activeStreams.size;\\n    let targetQuality = 'medium';\\n\\n    if (activeCount > 6) {\\n      targetQuality = 'mobile';\\n    } else if (activeCount > 4) {\\n      targetQuality = 'low';\\n    } else if (activeCount > 2) {\\n      targetQuality = 'medium';\\n    } else {\\n      targetQuality = 'high';\\n    }\\n\\n    // Apply quality changes if using global control\\n    if (state.groupSettings.globalQualityControl) {\\n      await applyGlobalQualityChange(targetQuality);\\n    }\\n\\n    return { \\n      success: true, \\n      activeStreams: activeCount, \\n      targetQuality,\\n      message: 'Rebalancing completed'\\n    };\\n  };\\n\\n  // Update network statistics\\n  const updateNetworkStats = () => {\\n    const pipelines = Array.from(state.pipelines.values());\\n    let totalBandwidth = 0;\\n    let totalLatency = 0;\\n    let maxPacketLoss = 0;\\n    let activeCount = 0;\\n\\n    pipelines.forEach(pipeline => {\\n      if (pipeline.isStreaming()) {\\n        const stats = pipeline.getStats();\\n        const metrics = pipeline.getQualityMetrics();\\n        \\n        if (metrics) {\\n          totalBandwidth += metrics.networkStats?.bandwidth || 0;\\n          totalLatency += metrics.networkStats?.latency || 0;\\n          maxPacketLoss = Math.max(maxPacketLoss, metrics.networkStats?.packetLoss || 0);\\n          activeCount++;\\n        }\\n      }\\n    });\\n\\n    state.networkStats = {\\n      totalBandwidth,\\n      averageLatency: activeCount > 0 ? totalLatency / activeCount : 0,\\n      packetLoss: maxPacketLoss,\\n      lastUpdated: Date.now()\\n    };\\n\\n    // Update global quality controller with aggregated stats\\n    if (state.globalQualityController) {\\n      state.globalQualityController.updateNetworkStats(state.networkStats);\\n    }\\n  };\\n\\n  // Notification helper\\n  const notifyCallbacks = (eventType, data) => {\\n    const callbacks = state.callbacks[eventType] || [];\\n    callbacks.forEach(callback => {\\n      try {\\n        callback(data);\\n      } catch (error) {\\n        console.warn(`Callback error for ${eventType}:`, error);\\n      }\\n    });\\n  };\\n\\n  // Event subscription methods\\n  const onDeviceAdded = (callback) => {\\n    state.callbacks.onDeviceAdded.push(callback);\\n    return () => {\\n      const index = state.callbacks.onDeviceAdded.indexOf(callback);\\n      if (index !== -1) state.callbacks.onDeviceAdded.splice(index, 1);\\n    };\\n  };\\n\\n  const onDeviceRemoved = (callback) => {\\n    state.callbacks.onDeviceRemoved.push(callback);\\n    return () => {\\n      const index = state.callbacks.onDeviceRemoved.indexOf(callback);\\n      if (index !== -1) state.callbacks.onDeviceRemoved.splice(index, 1);\\n    };\\n  };\\n\\n  const onStreamStarted = (callback) => {\\n    state.callbacks.onStreamStarted.push(callback);\\n    return () => {\\n      const index = state.callbacks.onStreamStarted.indexOf(callback);\\n      if (index !== -1) state.callbacks.onStreamStarted.splice(index, 1);\\n    };\\n  };\\n\\n  const onStreamStopped = (callback) => {\\n    state.callbacks.onStreamStopped.push(callback);\\n    return () => {\\n      const index = state.callbacks.onStreamStopped.indexOf(callback);\\n      if (index !== -1) state.callbacks.onStreamStopped.splice(index, 1);\\n    };\\n  };\\n\\n  const onQualityChanged = (callback) => {\\n    state.callbacks.onQualityChanged.push(callback);\\n    return () => {\\n      const index = state.callbacks.onQualityChanged.indexOf(callback);\\n      if (index !== -1) state.callbacks.onQualityChanged.splice(index, 1);\\n    };\\n  };\\n\\n  const onError = (callback) => {\\n    state.callbacks.onError.push(callback);\\n    return () => {\\n      const index = state.callbacks.onError.indexOf(callback);\\n      if (index !== -1) state.callbacks.onError.splice(index, 1);\\n    };\\n  };\\n\\n  // Getters\\n  const getDevices = () => Array.from(state.devices.values());\\n  const getDevice = (deviceId) => state.devices.get(deviceId);\\n  const getPipeline = (deviceId) => state.pipelines.get(deviceId);\\n  const getActiveStreams = () => Array.from(state.activeStreams);\\n  const getNetworkStats = () => ({ ...state.networkStats });\\n  const getGroupSettings = () => ({ ...state.groupSettings });\\n  \\n  const getCoordinatorStatus = () => ({\\n    totalDevices: state.devices.size,\\n    activeStreams: state.activeStreams.size,\\n    networkStats: state.networkStats,\\n    groupSettings: state.groupSettings,\\n    globalQualityEnabled: !!state.globalQualityController,\\n    lastUpdate: Date.now()\\n  });\\n\\n  // Cleanup coordinator\\n  const cleanup = async () => {\\n    console.log('🧹 Cleaning up multi-device coordinator...');\\n    \\n    // Stop all active streams\\n    const activeDeviceIds = Array.from(state.activeStreams);\\n    if (activeDeviceIds.length > 0) {\\n      await stopMultipleStreams(activeDeviceIds);\\n    }\\n\\n    // Cleanup all pipelines\\n    for (const [deviceId, pipeline] of state.pipelines.entries()) {\\n      try {\\n        if (pipeline.cleanup) {\\n          await pipeline.cleanup();\\n        }\\n      } catch (error) {\\n        console.warn(`Cleanup failed for device ${deviceId}:`, error);\\n      }\\n    }\\n\\n    // Clear state\\n    state.devices.clear();\\n    state.pipelines.clear();\\n    state.activeStreams.clear();\\n    \\n    // Clear callbacks\\n    Object.keys(state.callbacks).forEach(key => {\\n      state.callbacks[key] = [];\\n    });\\n\\n    console.log('✅ Multi-device coordinator cleanup completed');\\n  };\\n\\n  // Start network monitoring\\n  const startNetworkMonitoring = (intervalMs = 5000) => {\\n    const monitoringInterval = setInterval(() => {\\n      updateNetworkStats();\\n    }, intervalMs);\\n\\n    return () => clearInterval(monitoringInterval);\\n  };\\n\\n  return {\\n    // Device management\\n    addDevice,\\n    removeDevice,\\n    getDevices,\\n    getDevice,\\n    getPipeline,\\n    \\n    // Stream control\\n    startStream,\\n    stopStream,\\n    startMultipleStreams,\\n    stopMultipleStreams,\\n    \\n    // Quality control\\n    applyGlobalQualityChange,\\n    rebalanceStreams,\\n    \\n    // Network and stats\\n    updateNetworkStats,\\n    getNetworkStats,\\n    startNetworkMonitoring,\\n    \\n    // Status and configuration\\n    getActiveStreams,\\n    getGroupSettings,\\n    getCoordinatorStatus,\\n    \\n    // Event handlers\\n    onDeviceAdded,\\n    onDeviceRemoved,\\n    onStreamStarted,\\n    onStreamStopped,\\n    onQualityChanged,\\n    onError,\\n    \\n    // Lifecycle\\n    cleanup\\n  };\\n};\\n\\n\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/features/media-streaming/pipeline-interface.js\",\"messages\":[],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/features/media-streaming/pipeline-state.js\",\"messages\":[],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/features/media-streaming/quality-controller.js\",\"messages\":[{\"ruleId\":\"max-lines-per-function\",\"severity\":1,\"message\":\"Arrow function has too many lines (323). Maximum allowed is 150.\",\"line\":89,\"column\":40,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"exceed\",\"endLine\":559,\"endColumn\":2},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":128,\"column\":47,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":128,\"endColumn\":48},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":128,\"column\":65,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":128,\"endColumn\":66},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":128,\"column\":65,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":128,\"endColumn\":66},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":128,\"column\":90,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":128,\"endColumn\":91},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":129,\"column\":43,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":129,\"endColumn\":44},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":129,\"column\":61,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":129,\"endColumn\":62},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":129,\"column\":61,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":129,\"endColumn\":62},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":129,\"column\":84,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":129,\"endColumn\":85},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":130,\"column\":49,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":130,\"endColumn\":50},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":130,\"column\":67,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":130,\"endColumn\":68},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":130,\"column\":67,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":130,\"endColumn\":68},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":130,\"column\":93,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":130,\"endColumn\":94},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":131,\"column\":41,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":131,\"endColumn\":42},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":131,\"column\":59,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":131,\"endColumn\":60},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":131,\"column\":59,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":131,\"endColumn\":60},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":131,\"column\":81,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":131,\"endColumn\":82},{\"ruleId\":\"max-len\",\"severity\":1,\"message\":\"This line has a length of 166. Maximum allowed is 150.\",\"line\":181,\"column\":1,\"nodeType\":\"Program\",\"messageId\":\"max\",\"endLine\":181,\"endColumn\":167},{\"ruleId\":\"consistent-return\",\"severity\":1,\"message\":\"Arrow function expected no return value.\",\"line\":239,\"column\":7,\"nodeType\":\"ReturnStatement\",\"messageId\":\"unexpectedReturnValue\",\"endLine\":239,\"endColumn\":19},{\"ruleId\":\"consistent-return\",\"severity\":1,\"message\":\"Arrow function expected no return value.\",\"line\":242,\"column\":5,\"nodeType\":\"ReturnStatement\",\"messageId\":\"unexpectedReturnValue\",\"endLine\":242,\"endColumn\":18},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":478,\"column\":28,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":478,\"endColumn\":29},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":478,\"column\":44,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":478,\"endColumn\":45},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":479,\"column\":35,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":479,\"endColumn\":36},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":479,\"column\":51,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":479,\"endColumn\":52}],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":24,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Quality Controller\\n * Handles adaptive quality control, bandwidth monitoring, and optimization\\n * Following functional programming patterns with factory functions\\n */\\n\\n/**\\n * Quality profiles for different streaming scenarios\\n */\\nexport const QUALITY_PROFILES = {\\n  ultra: {\\n    name: 'Ultra HD',\\n    video: { \\n      width: 3840, height: 2160, fps: 60, bitrate: '25M', \\n      codec: 'vp9', keyFrameInterval: 2000\\n    },\\n    audio: { \\n      sampleRate: 48000, channels: 2, bitrate: '320k', \\n      codec: 'opus', profile: 'fullband'\\n    },\\n    priority: 5,\\n    minBandwidth: 30000000, // 30 Mbps\\n    cpuIntensive: true\\n  },\\n  high: {\\n    name: 'Full HD',\\n    video: { \\n      width: 1920, height: 1080, fps: 30, bitrate: '8M',\\n      codec: 'vp9', keyFrameInterval: 2000\\n    },\\n    audio: { \\n      sampleRate: 48000, channels: 2, bitrate: '192k',\\n      codec: 'opus', profile: 'fullband'\\n    },\\n    priority: 4,\\n    minBandwidth: 10000000, // 10 Mbps\\n    cpuIntensive: false\\n  },\\n  medium: {\\n    name: 'HD',\\n    video: { \\n      width: 1280, height: 720, fps: 30, bitrate: '4M',\\n      codec: 'vp9', keyFrameInterval: 2000\\n    },\\n    audio: { \\n      sampleRate: 44100, channels: 2, bitrate: '128k',\\n      codec: 'opus', profile: 'mediumband'\\n    },\\n    priority: 3,\\n    minBandwidth: 5000000, // 5 Mbps\\n    cpuIntensive: false\\n  },\\n  low: {\\n    name: 'SD',\\n    video: { \\n      width: 640, height: 480, fps: 15, bitrate: '1M',\\n      codec: 'h264', keyFrameInterval: 4000\\n    },\\n    audio: { \\n      sampleRate: 22050, channels: 1, bitrate: '64k',\\n      codec: 'aac', profile: 'narrowband'\\n    },\\n    priority: 2,\\n    minBandwidth: 1500000, // 1.5 Mbps\\n    cpuIntensive: false\\n  },\\n  mobile: {\\n    name: 'Mobile Optimized',\\n    video: { \\n      width: 480, height: 360, fps: 15, bitrate: '500k',\\n      codec: 'h264', keyFrameInterval: 6000\\n    },\\n    audio: { \\n      sampleRate: 16000, channels: 1, bitrate: '32k',\\n      codec: 'aac', profile: 'narrowband'\\n    },\\n    priority: 1,\\n    minBandwidth: 750000, // 750 Kbps\\n    cpuIntensive: false,\\n    batteryOptimized: true\\n  }\\n};\\n\\n/**\\n * Create quality controller for adaptive streaming\\n * @param {Object} config - Configuration options\\n * @returns {Object} Quality controller instance\\n */\\nexport const createQualityController = (config = {}) => {\\n  const state = {\\n    currentProfile: config.defaultProfile || 'medium',\\n    targetProfile: config.defaultProfile || 'medium',\\n    adaptiveMode: config.adaptiveMode !== false,\\n    networkStats: {\\n      bandwidth: 0,\\n      latency: 0,\\n      packetLoss: 0,\\n      jitter: 0,\\n      lastMeasurement: 0\\n    },\\n    qualityHistory: [],\\n    adaptationRules: {\\n      bandwidthThreshold: config.bandwidthThreshold || 0.8, // 80% of available\\n      latencyThreshold: config.latencyThreshold || 200, // 200ms\\n      packetLossThreshold: config.packetLossThreshold || 0.02, // 2%\\n      stabilityPeriod: config.stabilityPeriod || 5000, // 5 seconds\\n      adaptationCooldown: config.adaptationCooldown || 3000 // 3 seconds\\n    },\\n    callbacks: {\\n      onQualityChange: [],\\n      onAdaptation: [],\\n      onNetworkUpdate: []\\n    },\\n    lastAdaptation: 0,\\n    measurementInterval: null\\n  };\\n\\n  /**\\n   * Update network statistics\\n   * @param {Object} stats - Network measurement stats\\n   */\\n  const updateNetworkStats = (stats) => {\\n    const now = Date.now();\\n    \\n    // Update network stats with smoothing\\n    const smoothing = 0.3; // 30% new value, 70% old value\\n    state.networkStats = {\\n      bandwidth: state.networkStats.bandwidth * (1 - smoothing) + (stats.bandwidth || 0) * smoothing,\\n      latency: state.networkStats.latency * (1 - smoothing) + (stats.latency || 0) * smoothing,\\n      packetLoss: state.networkStats.packetLoss * (1 - smoothing) + (stats.packetLoss || 0) * smoothing,\\n      jitter: state.networkStats.jitter * (1 - smoothing) + (stats.jitter || 0) * smoothing,\\n      lastMeasurement: now\\n    };\\n\\n    // Notify network update callbacks\\n    state.callbacks.onNetworkUpdate.forEach(callback => {\\n      try {\\n        callback(state.networkStats);\\n      } catch (error) {\\n        console.warn('Network update callback error:', error);\\n      }\\n    });\\n\\n    // Trigger adaptation check if in adaptive mode\\n    if (state.adaptiveMode) {\\n      checkAdaptation();\\n    }\\n  };\\n\\n  /**\\n   * Check if quality adaptation is needed\\n   */\\n  const checkAdaptation = () => {\\n    const now = Date.now();\\n    \\n    // Respect cooldown period\\n    if (now - state.lastAdaptation < state.adaptationRules.adaptationCooldown) {\\n      return;\\n    }\\n\\n    const currentProfile = QUALITY_PROFILES[state.currentProfile];\\n    const { networkStats, adaptationRules } = state;\\n\\n    let recommendedProfile = state.currentProfile;\\n    let adaptationReason = null;\\n\\n    // Check bandwidth constraint\\n    if (networkStats.bandwidth > 0) {\\n      const requiredBandwidth = currentProfile.minBandwidth;\\n      const availableBandwidth = networkStats.bandwidth * adaptationRules.bandwidthThreshold;\\n      \\n      if (availableBandwidth < requiredBandwidth) {\\n        // Need to downgrade\\n        recommendedProfile = findLowerQualityProfile(state.currentProfile);\\n        adaptationReason = `bandwidth_constraint: ${Math.round(availableBandwidth/1000)}kbps < ${Math.round(requiredBandwidth/1000)}kbps`;\\n      } else if (availableBandwidth > requiredBandwidth * 1.5) {\\n        // Can potentially upgrade\\n        const higherProfile = findHigherQualityProfile(state.currentProfile);\\n        if (higherProfile && QUALITY_PROFILES[higherProfile].minBandwidth <= availableBandwidth) {\\n          recommendedProfile = higherProfile;\\n          adaptationReason = `bandwidth_available: ${Math.round(availableBandwidth/1000)}kbps > ${Math.round(QUALITY_PROFILES[higherProfile].minBandwidth/1000)}kbps`;\\n        }\\n      }\\n    }\\n\\n    // Check latency constraint\\n    if (networkStats.latency > adaptationRules.latencyThreshold) {\\n      const lowerProfile = findLowerQualityProfile(state.currentProfile);\\n      if (lowerProfile && (!adaptationReason || recommendedProfile === state.currentProfile)) {\\n        recommendedProfile = lowerProfile;\\n        adaptationReason = `high_latency: ${Math.round(networkStats.latency)}ms > ${adaptationRules.latencyThreshold}ms`;\\n      }\\n    }\\n\\n    // Check packet loss constraint\\n    if (networkStats.packetLoss > adaptationRules.packetLossThreshold) {\\n      const lowerProfile = findLowerQualityProfile(state.currentProfile);\\n      if (lowerProfile && (!adaptationReason || recommendedProfile === state.currentProfile)) {\\n        recommendedProfile = lowerProfile;\\n        adaptationReason = `packet_loss: ${(networkStats.packetLoss * 100).toFixed(2)}% > ${(adaptationRules.packetLossThreshold * 100).toFixed(2)}%`;\\n      }\\n    }\\n\\n    // Apply adaptation if needed\\n    if (recommendedProfile !== state.currentProfile && adaptationReason) {\\n      console.log(`📊 Quality adaptation: ${state.currentProfile} → ${recommendedProfile} (${adaptationReason})`);\\n      \\n      state.targetProfile = recommendedProfile;\\n      state.lastAdaptation = now;\\n      \\n      // Add to history\\n      state.qualityHistory.push({\\n        timestamp: now,\\n        from: state.currentProfile,\\n        to: recommendedProfile,\\n        reason: adaptationReason,\\n        networkStats: { ...networkStats }\\n      });\\n\\n      // Keep history limited\\n      if (state.qualityHistory.length > 50) {\\n        state.qualityHistory = state.qualityHistory.slice(-25);\\n      }\\n\\n      // Notify adaptation callbacks\\n      state.callbacks.onAdaptation.forEach(callback => {\\n        try {\\n          callback({\\n            from: state.currentProfile,\\n            to: recommendedProfile,\\n            reason: adaptationReason,\\n            networkStats: { ...networkStats }\\n          });\\n        } catch (error) {\\n          console.warn('Adaptation callback error:', error);\\n        }\\n      });\\n\\n      return true;\\n    }\\n\\n    return false;\\n  };\\n\\n  /**\\n   * Find a lower quality profile\\n   */\\n  const findLowerQualityProfile = (currentProfile) => {\\n    const currentPriority = QUALITY_PROFILES[currentProfile]?.priority || 0;\\n    \\n    let bestProfile = null;\\n    let bestPriority = -1;\\n    \\n    for (const [profileName, profile] of Object.entries(QUALITY_PROFILES)) {\\n      if (profile.priority < currentPriority && profile.priority > bestPriority) {\\n        bestProfile = profileName;\\n        bestPriority = profile.priority;\\n      }\\n    }\\n    \\n    return bestProfile;\\n  };\\n\\n  /**\\n   * Find a higher quality profile\\n   */\\n  const findHigherQualityProfile = (currentProfile) => {\\n    const currentPriority = QUALITY_PROFILES[currentProfile]?.priority || 0;\\n    \\n    let bestProfile = null;\\n    let bestPriority = Infinity;\\n    \\n    for (const [profileName, profile] of Object.entries(QUALITY_PROFILES)) {\\n      if (profile.priority > currentPriority && profile.priority < bestPriority) {\\n        bestProfile = profileName;\\n        bestPriority = profile.priority;\\n      }\\n    }\\n    \\n    return bestProfile;\\n  };\\n\\n  /**\\n   * Manually set quality profile\\n   * @param {string} profileName - Target quality profile\\n   * @param {Object} options - Options\\n   */\\n  const setQuality = async (profileName, options = {}) => {\\n    if (!QUALITY_PROFILES[profileName]) {\\n      throw new Error(`Invalid quality profile: ${profileName}`);\\n    }\\n\\n    const oldProfile = state.currentProfile;\\n    state.currentProfile = profileName;\\n    state.targetProfile = profileName;\\n\\n    // Disable adaptive mode if manual override\\n    if (options.disableAdaptive) {\\n      state.adaptiveMode = false;\\n    }\\n\\n    console.log(`📊 Manual quality change: ${oldProfile} → ${profileName}`);\\n\\n    // Add to history\\n    state.qualityHistory.push({\\n      timestamp: Date.now(),\\n      from: oldProfile,\\n      to: profileName,\\n      reason: 'manual_override',\\n      networkStats: { ...state.networkStats }\\n    });\\n\\n    // Notify callbacks\\n    state.callbacks.onQualityChange.forEach(callback => {\\n      try {\\n        callback({\\n          from: oldProfile,\\n          to: profileName,\\n          profile: QUALITY_PROFILES[profileName],\\n          manual: true\\n        });\\n      } catch (error) {\\n        console.warn('Quality change callback error:', error);\\n      }\\n    });\\n\\n    return QUALITY_PROFILES[profileName];\\n  };\\n\\n  /**\\n   * Apply target quality (called by streaming pipeline)\\n   */\\n  const applyTargetQuality = () => {\\n    if (state.targetProfile !== state.currentProfile) {\\n      const oldProfile = state.currentProfile;\\n      state.currentProfile = state.targetProfile;\\n\\n      // Notify callbacks\\n      state.callbacks.onQualityChange.forEach(callback => {\\n        try {\\n          callback({\\n            from: oldProfile,\\n            to: state.currentProfile,\\n            profile: QUALITY_PROFILES[state.currentProfile],\\n            adaptive: true\\n          });\\n        } catch (error) {\\n          console.warn('Quality change callback error:', error);\\n        }\\n      });\\n\\n      return QUALITY_PROFILES[state.currentProfile];\\n    }\\n    return null;\\n  };\\n\\n  /**\\n   * Get current quality information\\n   */\\n  const getQualityInfo = () => ({\\n    current: state.currentProfile,\\n    target: state.targetProfile,\\n    profile: QUALITY_PROFILES[state.currentProfile],\\n    targetProfile: QUALITY_PROFILES[state.targetProfile],\\n    adaptiveMode: state.adaptiveMode,\\n    networkStats: { ...state.networkStats },\\n    lastAdaptation: state.lastAdaptation,\\n    adaptationHistory: [...state.qualityHistory.slice(-10)] // Last 10 adaptations\\n  });\\n\\n  /**\\n   * Get quality statistics\\n   */\\n  const getQualityStats = () => {\\n    const now = Date.now();\\n    const recentHistory = state.qualityHistory.filter(h => now - h.timestamp < 300000); // Last 5 minutes\\n    \\n    return {\\n      totalAdaptations: state.qualityHistory.length,\\n      recentAdaptations: recentHistory.length,\\n      averageQuality: calculateAverageQuality(recentHistory),\\n      stabilityScore: calculateStabilityScore(recentHistory),\\n      networkHealth: calculateNetworkHealth(state.networkStats),\\n      currentProfile: {\\n        name: state.currentProfile,\\n        ...QUALITY_PROFILES[state.currentProfile]\\n      }\\n    };\\n  };\\n\\n  /**\\n   * Calculate average quality over time\\n   */\\n  const calculateAverageQuality = (history) => {\\n    if (history.length === 0) {\\n      return QUALITY_PROFILES[state.currentProfile].priority;\\n    }\\n\\n    const totalPriority = history.reduce((sum, h) => {\\n      return sum + (QUALITY_PROFILES[h.to]?.priority || 0);\\n    }, 0);\\n\\n    return totalPriority / history.length;\\n  };\\n\\n  /**\\n   * Calculate stability score (lower is better)\\n   */\\n  const calculateStabilityScore = (history) => {\\n    if (history.length < 2) return 1.0;\\n\\n    let changes = 0;\\n    for (let i = 1; i < history.length; i++) {\\n      if (history[i].from !== history[i-1].to) {\\n        changes++;\\n      }\\n    }\\n\\n    return Math.max(0, 1 - (changes / history.length));\\n  };\\n\\n  /**\\n   * Calculate network health score\\n   */\\n  const calculateNetworkHealth = (stats) => {\\n    let score = 1.0;\\n\\n    // Bandwidth health (assume 10Mbps is excellent)\\n    if (stats.bandwidth > 0) {\\n      const bandwidthScore = Math.min(1.0, stats.bandwidth / 10000000);\\n      score *= bandwidthScore;\\n    }\\n\\n    // Latency health (lower is better)\\n    const latencyScore = Math.max(0, 1 - (stats.latency / 500)); // 500ms is poor\\n    score *= latencyScore;\\n\\n    // Packet loss health\\n    const lossScore = Math.max(0, 1 - (stats.packetLoss / 0.05)); // 5% is poor\\n    score *= lossScore;\\n\\n    return Math.max(0, Math.min(1, score));\\n  };\\n\\n  /**\\n   * Start automatic network monitoring\\n   */\\n  const startNetworkMonitoring = (interval = 5000) => {\\n    if (state.measurementInterval) {\\n      clearInterval(state.measurementInterval);\\n    }\\n\\n    state.measurementInterval = setInterval(() => {\\n      // Simulate network measurements (in real implementation, would use actual measurements)\\n      const mockStats = generateMockNetworkStats();\\n      updateNetworkStats(mockStats);\\n    }, interval);\\n\\n    console.log('📊 Started network monitoring');\\n  };\\n\\n  /**\\n   * Stop automatic network monitoring\\n   */\\n  const stopNetworkMonitoring = () => {\\n    if (state.measurementInterval) {\\n      clearInterval(state.measurementInterval);\\n      state.measurementInterval = null;\\n    }\\n    console.log('📊 Stopped network monitoring');\\n  };\\n\\n  /**\\n   * Generate mock network stats (replace with real measurements)\\n   */\\n  const generateMockNetworkStats = () => {\\n    // Simulate varying network conditions\\n    const baseLatency = 50 + Math.random() * 100; // 50-150ms\\n    const baseBandwidth = 5000000 + Math.random() * 10000000; // 5-15 Mbps\\n    const packetLoss = Math.random() * 0.03; // 0-3%\\n    \\n    return {\\n      bandwidth: baseBandwidth,\\n      latency: baseLatency,\\n      packetLoss,\\n      jitter: Math.random() * 20 // 0-20ms jitter\\n    };\\n  };\\n\\n  /**\\n   * Event subscription methods\\n   */\\n  const onQualityChange = (callback) => {\\n    state.callbacks.onQualityChange.push(callback);\\n    return () => {\\n      const index = state.callbacks.onQualityChange.indexOf(callback);\\n      if (index !== -1) state.callbacks.onQualityChange.splice(index, 1);\\n    };\\n  };\\n\\n  const onAdaptation = (callback) => {\\n    state.callbacks.onAdaptation.push(callback);\\n    return () => {\\n      const index = state.callbacks.onAdaptation.indexOf(callback);\\n      if (index !== -1) state.callbacks.onAdaptation.splice(index, 1);\\n    };\\n  };\\n\\n  const onNetworkUpdate = (callback) => {\\n    state.callbacks.onNetworkUpdate.push(callback);\\n    return () => {\\n      const index = state.callbacks.onNetworkUpdate.indexOf(callback);\\n      if (index !== -1) state.callbacks.onNetworkUpdate.splice(index, 1);\\n    };\\n  };\\n\\n  /**\\n   * Cleanup resources\\n   */\\n  const cleanup = () => {\\n    stopNetworkMonitoring();\\n    state.callbacks.onQualityChange = [];\\n    state.callbacks.onAdaptation = [];\\n    state.callbacks.onNetworkUpdate = [];\\n    state.qualityHistory = [];\\n  };\\n\\n  return {\\n    // Quality control\\n    setQuality,\\n    applyTargetQuality,\\n    getQualityInfo,\\n    getQualityStats,\\n    \\n    // Network monitoring\\n    updateNetworkStats,\\n    startNetworkMonitoring,\\n    stopNetworkMonitoring,\\n    \\n    // Adaptive features\\n    checkAdaptation,\\n    \\n    // Event handlers\\n    onQualityChange,\\n    onAdaptation,\\n    onNetworkUpdate,\\n    \\n    // Configuration\\n    setAdaptiveMode: (enabled) => { state.adaptiveMode = enabled; },\\n    isAdaptiveMode: () => state.adaptiveMode,\\n    \\n    // Utilities\\n    getAvailableProfiles: () => Object.keys(QUALITY_PROFILES),\\n    getProfile: (name) => QUALITY_PROFILES[name],\\n    \\n    // Cleanup\\n    cleanup\\n  };\\n};\\n\\n\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/features/media-streaming/stream-operations.js\",\"messages\":[],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/features/multi-device/device-manager.js\",\"messages\":[],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/features/multi-device/event-system.js\",\"messages\":[],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/features/multi-device/multi-device-coordinator.js\",\"messages\":[],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/features/multi-device/network-monitor.js\",\"messages\":[{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'stats' is assigned a value but never used. Allowed unused vars must match /^_/u.\",\"line\":23,\"column\":15,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":23,\"endColumn\":20,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"stats\"},\"fix\":{\"range\":[590,624],\"text\":\"\"},\"desc\":\"Remove unused variable 'stats'.\"}]}],\"suppressedMessages\":[],\"errorCount\":1,\"fatalErrorCount\":0,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Network monitoring and statistics for multi-device coordinator\\n */\\n\\nexport const createNetworkMonitor = (deviceManager, qualityController) => {\\n  let networkStats = {\\n    totalBandwidth: 0,\\n    averageLatency: 0,\\n    packetLoss: 0,\\n    lastUpdated: null\\n  };\\n\\n  // Update network statistics\\n  const updateNetworkStats = () => {\\n    const pipelines = deviceManager.getAllPipelines();\\n    let totalBandwidth = 0;\\n    let totalLatency = 0;\\n    let maxPacketLoss = 0;\\n    let activeCount = 0;\\n\\n    for (const pipeline of pipelines.values()) {\\n      if (pipeline.isStreaming()) {\\n        const stats = pipeline.getStats();\\n        const metrics = pipeline.getQualityMetrics();\\n        \\n        if (metrics) {\\n          totalBandwidth += metrics.networkStats?.bandwidth || 0;\\n          totalLatency += metrics.networkStats?.latency || 0;\\n          maxPacketLoss = Math.max(maxPacketLoss, metrics.networkStats?.packetLoss || 0);\\n          activeCount++;\\n        }\\n      }\\n    }\\n\\n    networkStats = {\\n      totalBandwidth,\\n      averageLatency: activeCount > 0 ? totalLatency / activeCount : 0,\\n      packetLoss: maxPacketLoss,\\n      lastUpdated: Date.now()\\n    };\\n\\n    // Update global quality controller with aggregated stats\\n    if (qualityController) {\\n      qualityController.updateNetworkStats(networkStats);\\n    }\\n  };\\n\\n  // Start network monitoring\\n  const startNetworkMonitoring = (intervalMs = 5000) => {\\n    const monitoringInterval = setInterval(() => {\\n      updateNetworkStats();\\n    }, intervalMs);\\n\\n    return () => clearInterval(monitoringInterval);\\n  };\\n\\n  // Get current network statistics\\n  const getNetworkStats = () => ({ ...networkStats });\\n\\n  return {\\n    updateNetworkStats,\\n    startNetworkMonitoring,\\n    getNetworkStats\\n  };\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/features/multi-device/stream-manager.js\",\"messages\":[{\"ruleId\":\"max-lines-per-function\",\"severity\":1,\"message\":\"Arrow function has too many lines (171). Maximum allowed is 150.\",\"line\":5,\"column\":36,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"exceed\",\"endLine\":230,\"endColumn\":2},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'streamConfig' is assigned a value but never used. Allowed unused args must match /^_/u.\",\"line\":9,\"column\":40,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":9,\"endColumn\":52,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"streamConfig\"},\"fix\":{\"range\":[301,320],\"text\":\"\"},\"desc\":\"Remove unused variable 'streamConfig'.\"}]}],\"suppressedMessages\":[],\"errorCount\":1,\"fatalErrorCount\":0,\"warningCount\":1,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Stream management for multi-device coordinator\\n */\\n\\nexport const createStreamManager = (deviceManager, qualityController, config, notifyCallbacks) => {\\n  const activeStreams = new Set(); // Set of active stream IDs\\n\\n  // Start streaming for specific device\\n  const startStream = async (deviceId, streamConfig = {}) => {\\n    const pipeline = deviceManager.getPipeline(deviceId);\\n    if (!pipeline) {\\n      throw new Error(`Pipeline not found for device: ${deviceId}`);\\n    }\\n\\n    if (activeStreams.has(deviceId)) {\\n      return { success: true, message: 'Stream already active', deviceId };\\n    }\\n\\n    try {\\n      // Apply global quality if enabled\\n      if (config.groupSettings?.globalQualityControl && qualityController) {\\n        const globalInfo = qualityController.getQualityInfo();\\n        if (globalInfo && globalInfo.currentQuality) {\\n          await pipeline.changeQuality(globalInfo.currentQuality);\\n        }\\n      }\\n\\n      // Start the stream\\n      const result = await pipeline.startStreaming();\\n      \\n      if (result.success) {\\n        activeStreams.add(deviceId);\\n        notifyCallbacks('onStreamStarted', { deviceId, ...result });\\n        \\n        // Update load balancing if enabled\\n        if (config.groupSettings?.loadBalancing) {\\n          await rebalanceStreams();\\n        }\\n      }\\n\\n      return result;\\n    } catch (error) {\\n      console.error(`Failed to start stream for ${deviceId}:`, error);\\n      notifyCallbacks('onError', { deviceId, error, operation: 'startStream' });\\n      throw error;\\n    }\\n  };\\n\\n  // Stop streaming for specific device\\n  const stopStream = async (deviceId) => {\\n    const pipeline = deviceManager.getPipeline(deviceId);\\n    if (!pipeline) {\\n      throw new Error(`Pipeline not found for device: ${deviceId}`);\\n    }\\n\\n    if (!activeStreams.has(deviceId)) {\\n      return { success: true, message: 'Stream not active', deviceId };\\n    }\\n\\n    try {\\n      const result = await pipeline.stopStreaming();\\n      \\n      if (result.success) {\\n        activeStreams.delete(deviceId);\\n        notifyCallbacks('onStreamStopped', { deviceId, ...result });\\n        \\n        // Update load balancing if enabled\\n        if (config.groupSettings?.loadBalancing) {\\n          await rebalanceStreams();\\n        }\\n      }\\n\\n      return result;\\n    } catch (error) {\\n      console.error(`Failed to stop stream for ${deviceId}:`, error);\\n      notifyCallbacks('onError', { deviceId, error, operation: 'stopStream' });\\n      throw error;\\n    }\\n  };\\n\\n  // Start streaming for multiple devices\\n  const startMultipleStreams = async (deviceIds, streamConfig = {}) => {\\n    const results = {};\\n    \\n    if (config.groupSettings?.syncStreaming) {\\n      // Start all streams simultaneously\\n      const promises = deviceIds.map(deviceId => \\n        startStream(deviceId, streamConfig).catch(error => ({ deviceId, error }))\\n      );\\n      \\n      const streamResults = await Promise.all(promises);\\n      \\n      streamResults.forEach(result => {\\n        if (result.error) {\\n          results[result.deviceId] = { success: false, error: result.error };\\n        } else {\\n          results[result.deviceId] = result;\\n        }\\n      });\\n    } else {\\n      // Start streams sequentially\\n      for (const deviceId of deviceIds) {\\n        try {\\n          results[deviceId] = await startStream(deviceId, streamConfig);\\n        } catch (error) {\\n          results[deviceId] = { success: false, error };\\n        }\\n      }\\n    }\\n\\n    const successful = Object.values(results).filter(r => r.success).length;\\n    console.log(`🎬 Started ${successful}/${deviceIds.length} streams`);\\n\\n    return {\\n      success: successful > 0,\\n      results,\\n      totalRequested: deviceIds.length,\\n      successful\\n    };\\n  };\\n\\n  // Stop streaming for multiple devices\\n  const stopMultipleStreams = async (deviceIds) => {\\n    const results = {};\\n    \\n    // Stop all streams simultaneously\\n    const promises = deviceIds.map(deviceId => \\n      stopStream(deviceId).catch(error => ({ deviceId, error }))\\n    );\\n    \\n    const streamResults = await Promise.all(promises);\\n    \\n    streamResults.forEach(result => {\\n      if (result.error) {\\n        results[result.deviceId] = { success: false, error: result.error };\\n      } else {\\n        results[result.deviceId] = result;\\n      }\\n    });\\n\\n    const successful = Object.values(results).filter(r => r.success).length;\\n    console.log(`🛑 Stopped ${successful}/${deviceIds.length} streams`);\\n\\n    return {\\n      success: successful > 0,\\n      results,\\n      totalRequested: deviceIds.length,\\n      successful\\n    };\\n  };\\n\\n  // Apply quality change to all active streams\\n  const applyGlobalQualityChange = async (newQuality) => {\\n    const activeDeviceIds = Array.from(activeStreams);\\n    const results = {};\\n\\n    console.log(`📊 Applying global quality change to ${newQuality} for ${activeDeviceIds.length} streams`);\\n\\n    for (const deviceId of activeDeviceIds) {\\n      const pipeline = deviceManager.getPipeline(deviceId);\\n      if (pipeline) {\\n        try {\\n          results[deviceId] = await pipeline.changeQuality(newQuality);\\n        } catch (error) {\\n          results[deviceId] = { success: false, error };\\n          console.warn(`Quality change failed for ${deviceId}:`, error);\\n        }\\n      }\\n    }\\n\\n    return results;\\n  };\\n\\n  // Rebalance streams based on network conditions\\n  const rebalanceStreams = async () => {\\n    if (!config.groupSettings?.loadBalancing || activeStreams.size === 0) {\\n      return { success: true, message: 'No rebalancing needed' };\\n    }\\n\\n    console.log('⚖️ Rebalancing streams based on network conditions');\\n\\n    // Simple load balancing: reduce quality if too many active streams\\n    const activeCount = activeStreams.size;\\n    let targetQuality = 'medium';\\n\\n    if (activeCount > 6) {\\n      targetQuality = 'mobile';\\n    } else if (activeCount > 4) {\\n      targetQuality = 'low';\\n    } else if (activeCount > 2) {\\n      targetQuality = 'medium';\\n    } else {\\n      targetQuality = 'high';\\n    }\\n\\n    // Apply quality changes if using global control\\n    if (config.groupSettings?.globalQualityControl) {\\n      await applyGlobalQualityChange(targetQuality);\\n    }\\n\\n    return { \\n      success: true, \\n      activeStreams: activeCount, \\n      targetQuality,\\n      message: 'Rebalancing completed'\\n    };\\n  };\\n\\n  // Stop all active streams for cleanup\\n  const stopAllStreams = async () => {\\n    const activeDeviceIds = Array.from(activeStreams);\\n    if (activeDeviceIds.length > 0) {\\n      await stopMultipleStreams(activeDeviceIds);\\n    }\\n  };\\n\\n  // Get active streams\\n  const getActiveStreams = () => Array.from(activeStreams);\\n\\n  return {\\n    startStream,\\n    stopStream,\\n    startMultipleStreams,\\n    stopMultipleStreams,\\n    applyGlobalQualityChange,\\n    rebalanceStreams,\\n    stopAllStreams,\\n    getActiveStreams\\n  };\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/features/speech-analysis/analysis-engine.js\",\"messages\":[{\"ruleId\":\"max-lines-per-function\",\"severity\":1,\"message\":\"Arrow function has too many lines (287). Maximum allowed is 150.\",\"line\":23,\"column\":37,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"exceed\",\"endLine\":402,\"endColumn\":2},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":138,\"column\":39,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":138,\"endColumn\":40},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":138,\"column\":75,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":138,\"endColumn\":76},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":158,\"column\":41,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":158,\"endColumn\":42},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":158,\"column\":73,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":158,\"endColumn\":74},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'oldPrompt' is assigned a value but never used. Allowed unused vars must match /^_/u.\",\"line\":290,\"column\":11,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":290,\"endColumn\":20}],\"suppressedMessages\":[],\"errorCount\":1,\"fatalErrorCount\":0,\"warningCount\":5,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Multi-Prompt Analysis Engine\\n * Processes speech transcripts using multiple analysis prompts concurrently\\n * Following functional programming patterns with factory functions\\n */\\n\\nimport { createLLMClient } from './llm-client.js';\\nimport {\\n  createAnalysisPromptResult,\\n  createSpeechAnalysisResult,\\n  createSpeechEvent\\n} from '../../core/configuration/types.ts';\\n\\n// Default analysis prompts\\nconst DEFAULT_PROMPTS = [\\n  'Analyse sentiment, show as 5 keywords, nothing else.',\\n  'Identify most controversial statement and respond with a counterargument.'\\n];\\n\\nconst DEFAULT_SYSTEM_PROMPT = 'You are a helpful AI assistant analyzing speech from conversations. IMPORTANT: Always consider both the provided conversation context AND the current speech segment in your analysis. Keep all responses to 25 words or less.';\\n\\n// Create analysis engine factory\\nexport const createAnalysisEngine = (config = {}) => {\\n  const state = {\\n    llmClient: null,\\n    isInitialized: false,\\n    prompts: config.prompts || [...DEFAULT_PROMPTS],\\n    systemPrompt: config.systemPrompt || DEFAULT_SYSTEM_PROMPT,\\n    maxConcurrency: config.maxConcurrency || 3,\\n    analysisTimeout: config.analysisTimeout || 30000,\\n    \\n    // Analysis queue and processing\\n    analysisQueue: [],\\n    isProcessing: false,\\n    processingPromises: new Map(),\\n    \\n    // Performance metrics\\n    metrics: {\\n      totalAnalyses: 0,\\n      successfulAnalyses: 0,\\n      failedAnalyses: 0,\\n      averageLatency: 0,\\n      promptPerformance: new Map()\\n    },\\n\\n    // Event callbacks\\n    callbacks: {\\n      onAnalysisStart: [],\\n      onAnalysisComplete: [],\\n      onAnalysisError: [],\\n      onQueueUpdate: []\\n    }\\n  };\\n\\n  // Initialize the analysis engine\\n  const initialize = async (llmConfig = {}) => {\\n    if (state.isInitialized) {\\n      console.warn('Analysis engine already initialized');\\n      return true;\\n    }\\n\\n    console.log('🔄 Initializing analysis engine...');\\n\\n    try {\\n      // Initialize LLM client\\n      state.llmClient = createLLMClient({\\n        ...llmConfig,\\n        defaultSystemPrompt: state.systemPrompt\\n      });\\n\\n      await state.llmClient.initialize();\\n\\n      // Setup LLM event handlers\\n      state.llmClient.onError((error) => {\\n        notifyCallbacks('onAnalysisError', createSpeechEvent({\\n          type: 'llm_error',\\n          data: { error: error.message },\\n          severity: 'error'\\n        }));\\n      });\\n\\n      state.isInitialized = true;\\n      console.log('✅ Analysis engine initialized successfully');\\n      return true;\\n\\n    } catch (error) {\\n      console.error('Analysis engine initialization failed:', error);\\n      throw new Error(`Analysis engine initialization failed: ${error.message}`);\\n    }\\n  };\\n\\n  // Analyze speech text with all configured prompts\\n  const analyzeText = async (text, context = '', options = {}) => {\\n    if (!state.isInitialized || !state.llmClient) {\\n      throw new Error('Analysis engine not initialized');\\n    }\\n\\n    if (!text || !text.trim()) {\\n      throw new Error('No text provided for analysis');\\n    }\\n\\n    const analysisId = `analysis_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;\\n    const startTime = performance.now();\\n    \\n    console.log(`🔄 Starting analysis ${analysisId} for: \\\"${text.substring(0, 50)}...\\\"`);\\n\\n    // Notify analysis start\\n    notifyCallbacks('onAnalysisStart', createSpeechEvent({\\n      type: 'analysis_start',\\n      data: { \\n        analysisId,\\n        text: text.substring(0, 100) + (text.length > 100 ? '...' : ''),\\n        promptCount: state.prompts.length \\n      }\\n    }));\\n\\n    try {\\n      // Use current prompts or provided prompts\\n      const prompts = options.prompts || state.prompts;\\n      const systemPrompt = options.systemPrompt || state.systemPrompt;\\n\\n      if (prompts.length === 0) {\\n        throw new Error('No analysis prompts configured');\\n      }\\n\\n      // Generate analyses using LLM client\\n      const analyses = await state.llmClient.generateMultipleAnalyses(\\n        prompts, \\n        text, \\n        systemPrompt\\n      );\\n\\n      // Update metrics\\n      const latency = performance.now() - startTime;\\n      state.metrics.totalAnalyses++;\\n      state.metrics.successfulAnalyses++;\\n      state.metrics.averageLatency = \\n        (state.metrics.averageLatency * (state.metrics.totalAnalyses - 1) + latency) / \\n        state.metrics.totalAnalyses;\\n\\n      // Update per-prompt performance\\n      analyses.forEach((analysis, index) => {\\n        const prompt = prompts[index];\\n        if (!state.metrics.promptPerformance.has(prompt)) {\\n          state.metrics.promptPerformance.set(prompt, {\\n            totalRuns: 0,\\n            successfulRuns: 0,\\n            averageLatency: 0\\n          });\\n        }\\n        \\n        const promptMetrics = state.metrics.promptPerformance.get(prompt);\\n        promptMetrics.totalRuns++;\\n        if (!analysis.error) {\\n          promptMetrics.successfulRuns++;\\n        }\\n        promptMetrics.averageLatency = \\n          (promptMetrics.averageLatency * (promptMetrics.totalRuns - 1) + analysis.processingTime) / \\n          promptMetrics.totalRuns;\\n      });\\n\\n      // Create analysis result\\n      const result = createSpeechAnalysisResult({\\n        text,\\n        context,\\n        analyses,\\n        conversationContext: options.conversationContext || {},\\n        processingTime: latency,\\n        llmModel: state.llmClient.getStatus().activeBackend,\\n        systemPrompt\\n      });\\n\\n      console.log(`✅ Analysis ${analysisId} completed in ${latency.toFixed(2)}ms`);\\n\\n      // Notify completion\\n      notifyCallbacks('onAnalysisComplete', createSpeechEvent({\\n        type: 'analysis_complete',\\n        data: { \\n          analysisId,\\n          result,\\n          latency: latency.toFixed(2)\\n        }\\n      }));\\n\\n      return result;\\n\\n    } catch (error) {\\n      const latency = performance.now() - startTime;\\n      state.metrics.totalAnalyses++;\\n      state.metrics.failedAnalyses++;\\n\\n      console.error(`❌ Analysis ${analysisId} failed:`, error.message);\\n\\n      // Notify error\\n      notifyCallbacks('onAnalysisError', createSpeechEvent({\\n        type: 'analysis_error',\\n        data: { \\n          analysisId,\\n          error: error.message,\\n          text: text.substring(0, 100),\\n          latency: latency.toFixed(2)\\n        },\\n        severity: 'error'\\n      }));\\n\\n      throw error;\\n    }\\n  };\\n\\n  // Batch analyze multiple texts\\n  const analyzeTextBatch = async (texts, contexts = [], options = {}) => {\\n    if (!Array.isArray(texts) || texts.length === 0) {\\n      throw new Error('No texts provided for batch analysis');\\n    }\\n\\n    console.log(`🔄 Starting batch analysis of ${texts.length} texts...`);\\n\\n    const batchId = `batch_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;\\n    const results = [];\\n\\n    try {\\n      // Process texts with respect to concurrency limits\\n      const maxConcurrent = Math.min(texts.length, state.maxConcurrency);\\n      \\n      for (let i = 0; i < texts.length; i += maxConcurrent) {\\n        const batch = texts.slice(i, i + maxConcurrent);\\n        const batchContexts = contexts.slice(i, i + maxConcurrent);\\n        \\n        const batchPromises = batch.map(async (text, index) => {\\n          const context = batchContexts[index] || '';\\n          const textOptions = {\\n            ...options,\\n            conversationContext: {\\n              ...options.conversationContext,\\n              chunkIndex: i + index,\\n              totalChunks: texts.length\\n            }\\n          };\\n\\n          try {\\n            return await analyzeText(text, context, textOptions);\\n          } catch (error) {\\n            console.warn(`Batch analysis failed for text ${i + index + 1}:`, error.message);\\n            return createSpeechAnalysisResult({\\n              text,\\n              context,\\n              analyses: [createAnalysisPromptResult({\\n                prompt: 'Batch analysis failed',\\n                result: `Error: ${error.message}`,\\n                error: error.message\\n              })],\\n              processingTime: 0,\\n              llmModel: 'error'\\n            });\\n          }\\n        });\\n\\n        const batchResults = await Promise.all(batchPromises);\\n        results.push(...batchResults);\\n      }\\n\\n      console.log(`✅ Batch analysis ${batchId} completed: ${results.length} results`);\\n      return results;\\n\\n    } catch (error) {\\n      console.error(`❌ Batch analysis ${batchId} failed:`, error.message);\\n      throw error;\\n    }\\n  };\\n\\n  // Update analysis prompts\\n  const updatePrompts = (newPrompts) => {\\n    if (!Array.isArray(newPrompts) || newPrompts.length === 0) {\\n      throw new Error('Invalid prompts: must be non-empty array');\\n    }\\n\\n    const oldPrompts = [...state.prompts];\\n    state.prompts = newPrompts.map(p => p.trim()).filter(p => p.length > 0);\\n\\n    console.log(`📝 Updated analysis prompts: ${oldPrompts.length} → ${state.prompts.length}`);\\n    return true;\\n  };\\n\\n  // Update system prompt\\n  const updateSystemPrompt = (newSystemPrompt) => {\\n    if (!newSystemPrompt || !newSystemPrompt.trim()) {\\n      throw new Error('Invalid system prompt: must be non-empty string');\\n    }\\n\\n    const oldPrompt = state.systemPrompt;\\n    state.systemPrompt = newSystemPrompt.trim();\\n\\n    console.log('🤖 Updated system prompt');\\n    return true;\\n  };\\n\\n  // Reset prompts to defaults\\n  const resetToDefaults = () => {\\n    state.prompts = [...DEFAULT_PROMPTS];\\n    state.systemPrompt = DEFAULT_SYSTEM_PROMPT;\\n    console.log('↺ Reset to default prompts and system prompt');\\n    return true;\\n  };\\n\\n  // Get engine status\\n  const getStatus = () => ({\\n    isInitialized: state.isInitialized,\\n    promptCount: state.prompts.length,\\n    systemPromptLength: state.systemPrompt.length,\\n    llmStatus: state.llmClient ? state.llmClient.getStatus() : null,\\n    metrics: {\\n      ...state.metrics,\\n      promptPerformance: Object.fromEntries(state.metrics.promptPerformance)\\n    },\\n    queueLength: state.analysisQueue.length,\\n    isProcessing: state.isProcessing\\n  });\\n\\n  // Get current configuration\\n  const getConfiguration = () => ({\\n    prompts: [...state.prompts],\\n    systemPrompt: state.systemPrompt,\\n    maxConcurrency: state.maxConcurrency,\\n    analysisTimeout: state.analysisTimeout\\n  });\\n\\n  // Cleanup resources\\n  const cleanup = async () => {\\n    console.log('🧹 Cleaning up analysis engine...');\\n\\n    if (state.llmClient) {\\n      await state.llmClient.cleanup();\\n      state.llmClient = null;\\n    }\\n\\n    // Clear any pending operations\\n    state.analysisQueue.length = 0;\\n    state.processingPromises.clear();\\n    state.isProcessing = false;\\n    state.isInitialized = false;\\n\\n    console.log('✅ Analysis engine cleanup complete');\\n  };\\n\\n  // Event subscription methods\\n  const onAnalysisStart = (callback) => subscribeCallback('onAnalysisStart', callback);\\n  const onAnalysisComplete = (callback) => subscribeCallback('onAnalysisComplete', callback);\\n  const onAnalysisError = (callback) => subscribeCallback('onAnalysisError', callback);\\n  const onQueueUpdate = (callback) => subscribeCallback('onQueueUpdate', callback);\\n\\n  // Helper functions\\n  const subscribeCallback = (eventType, callback) => {\\n    state.callbacks[eventType].push(callback);\\n    return () => {\\n      const index = state.callbacks[eventType].indexOf(callback);\\n      if (index !== -1) state.callbacks[eventType].splice(index, 1);\\n    };\\n  };\\n\\n  const notifyCallbacks = (eventType, event) => {\\n    state.callbacks[eventType].forEach(callback => {\\n      try {\\n        callback(event);\\n      } catch (error) {\\n        console.warn(`Analysis engine ${eventType} callback error:`, error);\\n      }\\n    });\\n  };\\n\\n  return {\\n    // Core functionality\\n    initialize,\\n    analyzeText,\\n    analyzeTextBatch,\\n    cleanup,\\n\\n    // Configuration\\n    updatePrompts,\\n    updateSystemPrompt,\\n    resetToDefaults,\\n    getConfiguration,\\n\\n    // Status and metrics\\n    getStatus,\\n    isInitialized: () => state.isInitialized,\\n    getMetrics: () => ({ ...state.metrics }),\\n\\n    // Event handlers\\n    onAnalysisStart,\\n    onAnalysisComplete,\\n    onAnalysisError,\\n    onQueueUpdate,\\n\\n    // Access to underlying components\\n    getLLMClient: () => state.llmClient,\\n    \\n    // Utility methods\\n    getPrompts: () => [...state.prompts],\\n    getSystemPrompt: () => state.systemPrompt,\\n    getPromptPerformance: (prompt) => state.metrics.promptPerformance.get(prompt) || null\\n  };\\n};\\n\\n// Prompt validation utilities\\nexport const validatePrompt = (prompt) => {\\n  if (typeof prompt !== 'string') {\\n    return { valid: false, error: 'Prompt must be a string' };\\n  }\\n\\n  if (prompt.trim().length === 0) {\\n    return { valid: false, error: 'Prompt cannot be empty' };\\n  }\\n\\n  if (prompt.length > 1000) {\\n    return { valid: false, error: 'Prompt too long (max 1000 characters)' };\\n  }\\n\\n  return { valid: true };\\n};\\n\\nexport const validatePrompts = (prompts) => {\\n  if (!Array.isArray(prompts)) {\\n    return { valid: false, error: 'Prompts must be an array' };\\n  }\\n\\n  if (prompts.length === 0) {\\n    return { valid: false, error: 'Must provide at least one prompt' };\\n  }\\n\\n  if (prompts.length > 10) {\\n    return { valid: false, error: 'Too many prompts (max 10)' };\\n  }\\n\\n  for (let i = 0; i < prompts.length; i++) {\\n    const validation = validatePrompt(prompts[i]);\\n    if (!validation.valid) {\\n      return { valid: false, error: `Prompt ${i + 1}: ${validation.error}` };\\n    }\\n  }\\n\\n  return { valid: true };\\n};\\n\\n// Prompt suggestion utilities\\nexport const suggestPrompts = (domain = 'general') => {\\n  const suggestions = {\\n    general: [\\n      'Analyse sentiment, show as 5 keywords, nothing else.',\\n      'Identify most controversial statement and respond with a counterargument.',\\n      'Extract key themes and topics mentioned.',\\n      'Assess emotional tone and intensity level.',\\n      'Identify any requests, questions, or action items.'\\n    ],\\n    \\n    educational: [\\n      'Identify learning objectives and key concepts.',\\n      'Assess comprehension level and engagement.',\\n      'Extract questions or areas of confusion.',\\n      'Identify examples or analogies used.',\\n      'Evaluate teaching effectiveness indicators.'\\n    ],\\n    \\n    business: [\\n      'Identify action items and decisions made.',\\n      'Extract key metrics, numbers, and KPIs mentioned.',\\n      'Assess meeting effectiveness and engagement.',\\n      'Identify risks, issues, or concerns raised.',\\n      'Extract next steps and deadlines.'\\n    ],\\n    \\n    therapy: [\\n      'Assess emotional state and mood indicators.',\\n      'Identify coping mechanisms mentioned.',\\n      'Extract goals and progress indicators.',\\n      'Identify concerns or stress factors.',\\n      'Assess therapeutic progress and insights.'\\n    ],\\n    \\n    research: [\\n      'Extract hypotheses and research questions.',\\n      'Identify methodology and approaches discussed.',\\n      'Extract findings and observations.',\\n      'Identify limitations and future work.',\\n      'Assess research validity and significance.'\\n    ]\\n  };\\n\\n  return suggestions[domain] || suggestions.general;\\n};\\n\\n// Export default factory\\n// Export default factory (already exported above as const)\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/features/speech-analysis/analytics/interaction-analyzer.js\",\"messages\":[{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'wordCounts' is assigned a value but never used. Allowed unused vars must match /^_/u.\",\"line\":95,\"column\":11,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":95,\"endColumn\":21,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"wordCounts\"},\"fix\":{\"range\":[3073,3151],\"text\":\"\"},\"desc\":\"Remove unused variable 'wordCounts'.\"}]},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '-'. Use parentheses to clarify the intended order of operations.\",\"line\":143,\"column\":18,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":143,\"endColumn\":19},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '-'. Use parentheses to clarify the intended order of operations.\",\"line\":143,\"column\":28,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":143,\"endColumn\":29}],\"suppressedMessages\":[],\"errorCount\":1,\"fatalErrorCount\":0,\"warningCount\":2,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Interaction Analysis Module\\n * Handles turn-taking, interruptions, and response time analysis\\n */\\n\\nexport const createInteractionAnalyzer = (state) => {\\n  // Analyze turn-taking patterns\\n  const analyzeTurnTaking = () => {\\n    const {interactions} = state.metrics;\\n    const turnSequence = [];\\n    const responseTimes = [];\\n    let interruptions = 0;\\n\\n    // Sort all chunks by timestamp across participants\\n    const allChunks = [];\\n    for (const [participantId, chunks] of state.rawData.participants.entries()) {\\n      chunks.forEach(chunk => {\\n        allChunks.push({ ...chunk, participantId });\\n      });\\n    }\\n    allChunks.sort((a, b) => a.timestamp - b.timestamp);\\n\\n    // Analyze turn sequences\\n    let currentSpeaker = null;\\n    let turnStartTime = null;\\n    let previousTurnEndTime = null;\\n\\n    for (let i = 0; i < allChunks.length; i++) {\\n      const chunk = allChunks[i];\\n      \\n      if (chunk.participantId !== currentSpeaker) {\\n        // Turn change detected\\n        \\n        if (currentSpeaker !== null && turnStartTime !== null) {\\n          // Complete previous turn\\n          const turnDuration = chunk.timestamp - turnStartTime;\\n          turnSequence.push({\\n            speaker: currentSpeaker,\\n            startTime: turnStartTime,\\n            endTime: chunk.timestamp,\\n            duration: turnDuration\\n          });\\n\\n          // Calculate response time if there's a gap\\n          if (previousTurnEndTime && turnStartTime > previousTurnEndTime) {\\n            const responseTime = turnStartTime - previousTurnEndTime;\\n            responseTimes.push(responseTime);\\n          }\\n\\n          previousTurnEndTime = chunk.timestamp;\\n        }\\n\\n        // Start new turn\\n        currentSpeaker = chunk.participantId;\\n        turnStartTime = chunk.timestamp;\\n      }\\n\\n      // Check for interruptions (overlapping speech)\\n      if (i > 0) {\\n        const prevChunk = allChunks[i - 1];\\n        const timeDiff = chunk.timestamp - prevChunk.timestamp;\\n        \\n        // If chunks are very close in time but from different speakers\\n        if (timeDiff < 500 && chunk.participantId !== prevChunk.participantId) {\\n          interruptions++;\\n        }\\n      }\\n    }\\n\\n    // Complete final turn\\n    if (currentSpeaker !== null && turnStartTime !== null) {\\n      const lastChunk = allChunks[allChunks.length - 1];\\n      turnSequence.push({\\n        speaker: currentSpeaker,\\n        startTime: turnStartTime,\\n        endTime: lastChunk.timestamp,\\n        duration: lastChunk.timestamp - turnStartTime\\n      });\\n    }\\n\\n    // Update metrics\\n    interactions.turnTaking = turnSequence.slice(-50); // Keep recent turns\\n    interactions.responseTimes = responseTimes.slice(-20); // Keep recent response times\\n    interactions.interruptions = interruptions;\\n\\n    return interactions;\\n  };\\n\\n  // Calculate engagement level\\n  const calculateEngagement = () => {\\n    const participantCount = state.rawData.participants.size;\\n    if (participantCount <= 1) return 'high';\\n\\n    const speakingTimes = Array.from(state.metrics.speakingTime.byParticipant.values());\\n    const wordCounts = Array.from(state.metrics.wordCount.byParticipant.values());\\n    \\n    // Calculate participation balance\\n    const participationBalance = calculateParticipationBalance(speakingTimes);\\n    \\n    // Calculate interaction frequency\\n    const interactionFrequency = calculateInteractionFrequency();\\n    \\n    // Calculate response promptness\\n    const responsePromptness = calculateResponsePromptness();\\n\\n    // Combine metrics to determine engagement level\\n    let engagementScore = 0;\\n    \\n    // High participation balance is good (0.7-1.0 = +2, 0.4-0.7 = +1, <0.4 = 0)\\n    if (participationBalance >= 0.7) engagementScore += 2;\\n    else if (participationBalance >= 0.4) engagementScore += 1;\\n    \\n    // High interaction frequency is good\\n    if (interactionFrequency >= 0.8) engagementScore += 2;\\n    else if (interactionFrequency >= 0.5) engagementScore += 1;\\n    \\n    // Good response promptness is good\\n    if (responsePromptness >= 0.7) engagementScore += 2;\\n    else if (responsePromptness >= 0.4) engagementScore += 1;\\n\\n    // Determine engagement level\\n    if (engagementScore >= 5) return 'high';\\n    if (engagementScore >= 3) return 'medium';\\n    return 'low';\\n  };\\n\\n  // Calculate participation balance (how evenly distributed speaking time is)\\n  const calculateParticipationBalance = (speakingTimes) => {\\n    if (speakingTimes.length <= 1) return 1;\\n\\n    const totalTime = speakingTimes.reduce((sum, time) => sum + time, 0);\\n    if (totalTime === 0) return 0;\\n\\n    // Calculate normalized speaking times\\n    const normalizedTimes = speakingTimes.map(time => time / totalTime);\\n    \\n    // Calculate Gini coefficient (measure of inequality)\\n    const n = normalizedTimes.length;\\n    const sortedTimes = [...normalizedTimes].sort((a, b) => a - b);\\n    \\n    let gini = 0;\\n    for (let i = 0; i < n; i++) {\\n      gini += (2 * (i + 1) - n - 1) * sortedTimes[i];\\n    }\\n    gini = gini / (n * sortedTimes.reduce((sum, time) => sum + time, 0));\\n\\n    // Convert Gini to balance score (0 = perfect inequality, 1 = perfect equality)\\n    return Math.max(0, 1 - Math.abs(gini));\\n  };\\n\\n  // Calculate interaction frequency\\n  const calculateInteractionFrequency = () => {\\n    const turns = state.metrics.interactions.turnTaking;\\n    if (turns.length < 2) return 0;\\n\\n    const conversationDuration = state.metrics.duration;\\n    if (conversationDuration === 0) return 0;\\n\\n    // Calculate turns per minute\\n    const turnsPerMinute = (turns.length / conversationDuration) * 60000;\\n    \\n    // Normalize to 0-1 scale (assuming 10 turns/minute is high interaction)\\n    return Math.min(1, turnsPerMinute / 10);\\n  };\\n\\n  // Calculate response promptness\\n  const calculateResponsePromptness = () => {\\n    const {responseTimes} = state.metrics.interactions;\\n    if (responseTimes.length === 0) return 1;\\n\\n    // Calculate average response time\\n    const avgResponseTime = responseTimes.reduce((sum, time) => sum + time, 0) / responseTimes.length;\\n    \\n    // Good response time is under 2 seconds, excellent is under 1 second\\n    if (avgResponseTime <= 1000) return 1;\\n    if (avgResponseTime <= 2000) return 0.8;\\n    if (avgResponseTime <= 3000) return 0.6;\\n    if (avgResponseTime <= 5000) return 0.4;\\n    return 0.2;\\n  };\\n\\n  // Get interaction summary\\n  const getInteractionSummary = () => {\\n    const {interactions} = state.metrics;\\n    \\n    const avgResponseTime = interactions.responseTimes.length > 0\\n      ? interactions.responseTimes.reduce((sum, time) => sum + time, 0) / interactions.responseTimes.length\\n      : 0;\\n\\n    const turnFrequency = state.metrics.duration > 0\\n      ? (interactions.turnTaking.length / state.metrics.duration) * 60000 // turns per minute\\n      : 0;\\n\\n    return {\\n      totalTurns: interactions.turnTaking.length,\\n      interruptions: interactions.interruptions,\\n      averageResponseTime: Math.round(avgResponseTime),\\n      turnFrequency: Math.round(turnFrequency * 10) / 10, // 1 decimal place\\n      engagement: interactions.engagement,\\n      interactionHealth: calculateInteractionHealth()\\n    };\\n  };\\n\\n  // Calculate overall interaction health\\n  const calculateInteractionHealth = () => {\\n    const summary = getInteractionSummary();\\n    \\n    let healthScore = 0;\\n    \\n    // Low interruptions are good\\n    const interruptionRate = summary.totalTurns > 0 \\n      ? summary.interruptions / summary.totalTurns \\n      : 0;\\n    \\n    if (interruptionRate < 0.1) healthScore += 2;\\n    else if (interruptionRate < 0.2) healthScore += 1;\\n    \\n    // Good response times are good\\n    if (summary.averageResponseTime < 2000) healthScore += 2;\\n    else if (summary.averageResponseTime < 4000) healthScore += 1;\\n    \\n    // Good turn frequency is good\\n    if (summary.turnFrequency >= 3 && summary.turnFrequency <= 8) healthScore += 2;\\n    else if (summary.turnFrequency >= 1) healthScore += 1;\\n    \\n    if (healthScore >= 5) return 'excellent';\\n    if (healthScore >= 3) return 'good';\\n    if (healthScore >= 1) return 'fair';\\n    return 'poor';\\n  };\\n\\n  return {\\n    analyzeTurnTaking,\\n    calculateEngagement,\\n    getInteractionSummary\\n  };\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/features/speech-analysis/analytics/metrics-calculator.js\",\"messages\":[{\"ruleId\":\"max-lines-per-function\",\"severity\":1,\"message\":\"Arrow function has too many lines (152). Maximum allowed is 150.\",\"line\":6,\"column\":40,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"exceed\",\"endLine\":218,\"endColumn\":2}],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":1,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Conversation Metrics Calculator Module\\n * Handles speaking time, word count, and participant statistics\\n */\\n\\nexport const createMetricsCalculator = (state) => {\\n  // Calculate speaking time metrics\\n  const calculateSpeakingTimeMetrics = () => {\\n    const metrics = state.metrics.speakingTime;\\n    let totalTime = 0;\\n\\n    // Calculate total speaking time\\n    for (const chunks of state.rawData.participants.values()) {\\n      for (const chunk of chunks) {\\n        if (chunk.duration) {\\n          totalTime += chunk.duration;\\n        }\\n      }\\n    }\\n\\n    metrics.total = totalTime;\\n\\n    // Calculate speaking time by participant\\n    metrics.byParticipant.clear();\\n    for (const [participantId, chunks] of state.rawData.participants.entries()) {\\n      let participantTime = 0;\\n      for (const chunk of chunks) {\\n        if (chunk.duration) {\\n          participantTime += chunk.duration;\\n        }\\n      }\\n      metrics.byParticipant.set(participantId, participantTime);\\n    }\\n\\n    // Calculate distribution\\n    if (totalTime > 0) {\\n      metrics.distribution = {};\\n      for (const [participantId, time] of metrics.byParticipant.entries()) {\\n        metrics.distribution[participantId] = time / totalTime;\\n      }\\n    }\\n\\n    return metrics;\\n  };\\n\\n  // Calculate word count metrics\\n  const calculateWordCountMetrics = () => {\\n    const metrics = state.metrics.wordCount;\\n    let totalWords = 0;\\n    const vocabulary = new Set();\\n    const wordFrequency = new Map();\\n\\n    // Reset metrics\\n    metrics.byParticipant.clear();\\n\\n    // Process all chunks\\n    for (const [participantId, chunks] of state.rawData.participants.entries()) {\\n      let participantWords = 0;\\n      \\n      for (const chunk of chunks) {\\n        if (chunk.text) {\\n          const words = chunk.text.toLowerCase()\\n            .split(/\\\\s+/)\\n            .filter(word => word.length > 2); // Filter short words\\n          \\n          participantWords += words.length;\\n          totalWords += words.length;\\n\\n          // Track vocabulary\\n          words.forEach(word => {\\n            vocabulary.add(word);\\n            wordFrequency.set(word, (wordFrequency.get(word) || 0) + 1);\\n          });\\n        }\\n      }\\n      \\n      metrics.byParticipant.set(participantId, participantWords);\\n    }\\n\\n    // Update metrics\\n    metrics.total = totalWords;\\n    metrics.vocabulary.unique = vocabulary;\\n    \\n    // Find repeated words (frequency > 1)\\n    metrics.vocabulary.repeated.clear();\\n    for (const [word, freq] of wordFrequency.entries()) {\\n      if (freq > 1) {\\n        metrics.vocabulary.repeated.set(word, freq);\\n      }\\n    }\\n\\n    // Calculate words per minute\\n    const durationMinutes = state.metrics.duration / (1000 * 60);\\n    metrics.averageWordsPerMinute = durationMinutes > 0 ? totalWords / durationMinutes : 0;\\n\\n    return metrics;\\n  };\\n\\n  // Calculate sentiment trends\\n  const calculateSentimentTrends = () => {\\n    const metrics = state.metrics.sentimentTrends;\\n    const {sentimentWindow} = state.config;\\n    \\n    metrics.byParticipant.clear();\\n    metrics.timeline = [];\\n    let totalSentiment = 0;\\n    let sentimentCount = 0;\\n\\n    // Process by participant\\n    for (const [participantId, chunks] of state.rawData.participants.entries()) {\\n      const participantSentiments = [];\\n      \\n      for (const chunk of chunks) {\\n        if (chunk.sentiment !== undefined) {\\n          participantSentiments.push({\\n            value: chunk.sentiment,\\n            timestamp: chunk.timestamp\\n          });\\n          \\n          // Add to timeline\\n          metrics.timeline.push({\\n            participant: participantId,\\n            sentiment: chunk.sentiment,\\n            timestamp: chunk.timestamp\\n          });\\n          \\n          totalSentiment += chunk.sentiment;\\n          sentimentCount++;\\n        }\\n      }\\n      \\n      // Calculate rolling average for participant\\n      const recentSentiments = participantSentiments\\n        .slice(-sentimentWindow)\\n        .map(s => s.value);\\n      \\n      const avgSentiment = recentSentiments.length > 0 \\n        ? recentSentiments.reduce((a, b) => a + b, 0) / recentSentiments.length\\n        : 0;\\n      \\n      metrics.byParticipant.set(participantId, {\\n        current: avgSentiment,\\n        history: participantSentiments,\\n        trend: calculateSentimentTrend(participantSentiments)\\n      });\\n    }\\n\\n    // Calculate overall sentiment\\n    metrics.averageSentiment = sentimentCount > 0 ? totalSentiment / sentimentCount : 0;\\n    \\n    // Sort timeline by timestamp\\n    metrics.timeline.sort((a, b) => a.timestamp - b.timestamp);\\n\\n    return metrics;\\n  };\\n\\n  // Calculate sentiment trend direction\\n  const calculateSentimentTrend = (sentiments) => {\\n    if (sentiments.length < 2) return 'neutral';\\n    \\n    const recent = sentiments.slice(-3);\\n    if (recent.length < 2) return 'neutral';\\n    \\n    const firstHalf = recent.slice(0, Math.ceil(recent.length / 2));\\n    const secondHalf = recent.slice(Math.ceil(recent.length / 2));\\n    \\n    const firstAvg = firstHalf.reduce((a, b) => a + b.value, 0) / firstHalf.length;\\n    const secondAvg = secondHalf.reduce((a, b) => a + b.value, 0) / secondHalf.length;\\n    \\n    const diff = secondAvg - firstAvg;\\n    \\n    if (diff > 0.1) return 'improving';\\n    if (diff < -0.1) return 'declining';\\n    return 'stable';\\n  };\\n\\n  // Update participant data\\n  const updateParticipantMetrics = (participantId, chunk) => {\\n    if (!state.rawData.participants.has(participantId)) {\\n      state.rawData.participants.set(participantId, []);\\n    }\\n    \\n    const participantChunks = state.rawData.participants.get(participantId);\\n    participantChunks.push(chunk);\\n    \\n    // Keep only recent chunks (memory management)\\n    const maxChunks = 1000;\\n    if (participantChunks.length > maxChunks) {\\n      participantChunks.splice(0, participantChunks.length - maxChunks);\\n    }\\n  };\\n\\n  // Get participant statistics\\n  const getParticipantStats = (participantId) => {\\n    const chunks = state.rawData.participants.get(participantId) || [];\\n    const speakingTime = state.metrics.speakingTime.byParticipant.get(participantId) || 0;\\n    const wordCount = state.metrics.wordCount.byParticipant.get(participantId) || 0;\\n    const sentiment = state.metrics.sentimentTrends.byParticipant.get(participantId);\\n    \\n    return {\\n      participantId,\\n      chunkCount: chunks.length,\\n      speakingTime,\\n      wordCount,\\n      sentiment: sentiment || { current: 0, trend: 'neutral' },\\n      wordsPerMinute: speakingTime > 0 ? (wordCount / (speakingTime / 60000)) : 0,\\n      averageChunkLength: chunks.length > 0 ? speakingTime / chunks.length : 0\\n    };\\n  };\\n\\n  return {\\n    calculateSpeakingTimeMetrics,\\n    calculateWordCountMetrics,\\n    calculateSentimentTrends,\\n    updateParticipantMetrics,\\n    getParticipantStats\\n  };\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/features/speech-analysis/analytics/quality-assessor.js\",\"messages\":[{\"ruleId\":\"max-lines-per-function\",\"severity\":1,\"message\":\"Arrow function has too many lines (157). Maximum allowed is 150.\",\"line\":6,\"column\":38,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"exceed\",\"endLine\":222,\"endColumn\":2},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'participantId' is assigned a value but never used. Allowed unused vars must match /^_/u.\",\"line\":84,\"column\":17,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":84,\"endColumn\":30,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"participantId\"},\"fix\":{\"range\":[3287,3300],\"text\":\"\"},\"desc\":\"Remove unused variable 'participantId'.\"}]},{\"ruleId\":\"no-nested-ternary\",\"severity\":1,\"message\":\"Do not nest ternary expressions.\",\"line\":198,\"column\":17,\"nodeType\":\"ConditionalExpression\",\"messageId\":\"noNestedTernary\",\"endLine\":198,\"endColumn\":69},{\"ruleId\":\"no-nested-ternary\",\"severity\":1,\"message\":\"Do not nest ternary expressions.\",\"line\":202,\"column\":17,\"nodeType\":\"ConditionalExpression\",\"messageId\":\"noNestedTernary\",\"endLine\":202,\"endColumn\":79},{\"ruleId\":\"no-nested-ternary\",\"severity\":1,\"message\":\"Do not nest ternary expressions.\",\"line\":206,\"column\":17,\"nodeType\":\"ConditionalExpression\",\"messageId\":\"noNestedTernary\",\"endLine\":206,\"endColumn\":87}],\"suppressedMessages\":[],\"errorCount\":1,\"fatalErrorCount\":0,\"warningCount\":4,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Conversation Quality Assessment Module\\n * Evaluates conversation flow, coherence, and overall quality\\n */\\n\\nexport const createQualityAssessor = (state) => {\\n  // Calculate conversation flow\\n  const calculateConversationFlow = () => {\\n    const turns = state.metrics.interactions.turnTaking;\\n    const {responseTimes} = state.metrics.interactions;\\n    \\n    if (turns.length < 2) return 0;\\n\\n    let flowScore = 0;\\n    let factors = 0;\\n\\n    // Factor 1: Turn distribution consistency\\n    const turnDurations = turns.map(turn => turn.duration);\\n    const avgTurnDuration = turnDurations.reduce((sum, dur) => sum + dur, 0) / turnDurations.length;\\n    \\n    // Calculate coefficient of variation for turn durations\\n    const variance = turnDurations.reduce((sum, dur) => sum + Math.pow(dur - avgTurnDuration, 2), 0) / turnDurations.length;\\n    const stdDev = Math.sqrt(variance);\\n    const cv = avgTurnDuration > 0 ? stdDev / avgTurnDuration : 1;\\n    \\n    // Lower variation = better flow (normalize to 0-1)\\n    const turnConsistency = Math.max(0, 1 - (cv / 2)); // Assuming CV of 2 is maximum\\n    flowScore += turnConsistency;\\n    factors++;\\n\\n    // Factor 2: Response time consistency\\n    if (responseTimes.length > 0) {\\n      const avgResponseTime = responseTimes.reduce((sum, time) => sum + time, 0) / responseTimes.length;\\n      const responseVariance = responseTimes.reduce((sum, time) => sum + Math.pow(time - avgResponseTime, 2), 0) / responseTimes.length;\\n      const responseStdDev = Math.sqrt(responseVariance);\\n      const responseCv = avgResponseTime > 0 ? responseStdDev / avgResponseTime : 1;\\n      \\n      const responseConsistency = Math.max(0, 1 - (responseCv / 2));\\n      flowScore += responseConsistency;\\n      factors++;\\n    }\\n\\n    // Factor 3: Interruption impact\\n    const interruptionRate = turns.length > 0 ? state.metrics.interactions.interruptions / turns.length : 0;\\n    const interruptionPenalty = Math.max(0, 1 - (interruptionRate * 3)); // 33% interruptions = 0 score\\n    flowScore += interruptionPenalty;\\n    factors++;\\n\\n    return factors > 0 ? flowScore / factors : 0;\\n  };\\n\\n  // Calculate conversation coherence\\n  const calculateConversationCoherence = () => {\\n    const {topics} = state.metrics;\\n    const {participants} = state.rawData;\\n    \\n    if (topics.discovered.length === 0) return 0;\\n\\n    let coherenceScore = 0;\\n    let factors = 0;\\n\\n    // Factor 1: Topic focus (fewer dominant topics = more coherent)\\n    const dominantTopicRatio = topics.dominantTopics.length > 0 \\n      ? topics.dominantTopics[0].frequency / topics.discovered.reduce((sum, t) => sum + t.frequency, 0)\\n      : 0;\\n    \\n    coherenceScore += Math.min(1, dominantTopicRatio * 2); // 50% concentration = full score\\n    factors++;\\n\\n    // Factor 2: Topic transition smoothness\\n    const {transitions} = topics;\\n    if (transitions.length > 0) {\\n      // Count abrupt transitions (many new topics at once)\\n      const abruptTransitions = transitions.filter(t => t.newTopics.length > 2).length;\\n      const smoothnessScore = Math.max(0, 1 - (abruptTransitions / transitions.length));\\n      coherenceScore += smoothnessScore;\\n      factors++;\\n    }\\n\\n    // Factor 3: Participant topic consistency\\n    let participantConsistency = 0;\\n    let consistencyCount = 0;\\n\\n    for (const [participantId, chunks] of participants.entries()) {\\n      const participantTopics = new Map();\\n      \\n      chunks.forEach(chunk => {\\n        if (chunk.text) {\\n          // Simple keyword extraction for participant topics\\n          const words = chunk.text.toLowerCase().split(/\\\\s+/);\\n          words.forEach(word => {\\n            if (word.length > 4) {\\n              participantTopics.set(word, (participantTopics.get(word) || 0) + 1);\\n            }\\n          });\\n        }\\n      });\\n\\n      // Calculate topic concentration for this participant\\n      if (participantTopics.size > 0) {\\n        const topicFreqs = Array.from(participantTopics.values());\\n        const total = topicFreqs.reduce((sum, freq) => sum + freq, 0);\\n        const maxFreq = Math.max(...topicFreqs);\\n        const concentration = total > 0 ? maxFreq / total : 0;\\n        \\n        participantConsistency += concentration;\\n        consistencyCount++;\\n      }\\n    }\\n\\n    if (consistencyCount > 0) {\\n      coherenceScore += participantConsistency / consistencyCount;\\n      factors++;\\n    }\\n\\n    return factors > 0 ? coherenceScore / factors : 0;\\n  };\\n\\n  // Calculate participation quality\\n  const calculateParticipationQuality = () => {\\n    const speakingTimes = Array.from(state.metrics.speakingTime.byParticipant.values());\\n    const wordCounts = Array.from(state.metrics.wordCount.byParticipant.values());\\n    const participantCount = state.rawData.participants.size;\\n    \\n    if (participantCount <= 1) return 1;\\n\\n    let participationScore = 0;\\n    let factors = 0;\\n\\n    // Factor 1: Speaking time balance\\n    const totalSpeakingTime = speakingTimes.reduce((sum, time) => sum + time, 0);\\n    if (totalSpeakingTime > 0) {\\n      const expectedTimePerParticipant = totalSpeakingTime / participantCount;\\n      const timeDeviations = speakingTimes.map(time => \\n        Math.abs(time - expectedTimePerParticipant) / expectedTimePerParticipant\\n      );\\n      const avgDeviation = timeDeviations.reduce((sum, dev) => sum + dev, 0) / timeDeviations.length;\\n      const timeBalance = Math.max(0, 1 - avgDeviation); // Lower deviation = better balance\\n      \\n      participationScore += timeBalance;\\n      factors++;\\n    }\\n\\n    // Factor 2: Word count balance\\n    const totalWords = wordCounts.reduce((sum, words) => sum + words, 0);\\n    if (totalWords > 0) {\\n      const expectedWordsPerParticipant = totalWords / participantCount;\\n      const wordDeviations = wordCounts.map(words => \\n        Math.abs(words - expectedWordsPerParticipant) / expectedWordsPerParticipant\\n      );\\n      const avgWordDeviation = wordDeviations.reduce((sum, dev) => sum + dev, 0) / wordDeviations.length;\\n      const wordBalance = Math.max(0, 1 - avgWordDeviation);\\n      \\n      participationScore += wordBalance;\\n      factors++;\\n    }\\n\\n    // Factor 3: Minimum participation threshold\\n    const minSpeakingTime = Math.min(...speakingTimes);\\n    const avgSpeakingTime = totalSpeakingTime / participantCount;\\n    const minParticipationRatio = avgSpeakingTime > 0 ? minSpeakingTime / avgSpeakingTime : 0;\\n    \\n    // Penalize if any participant speaks less than 20% of average\\n    const minParticipationScore = minParticipationRatio >= 0.2 ? 1 : minParticipationRatio / 0.2;\\n    participationScore += minParticipationScore;\\n    factors++;\\n\\n    return factors > 0 ? participationScore / factors : 0;\\n  };\\n\\n  // Calculate overall conversation quality\\n  const calculateOverallQuality = () => {\\n    const flow = calculateConversationFlow();\\n    const coherence = calculateConversationCoherence();\\n    const participation = calculateParticipationQuality();\\n    \\n    // Weighted average of quality factors\\n    const overallScore = (flow * 0.3) + (coherence * 0.4) + (participation * 0.3);\\n    \\n    // Convert to qualitative rating\\n    if (overallScore >= 0.8) return 'excellent';\\n    if (overallScore >= 0.6) return 'good';\\n    if (overallScore >= 0.4) return 'fair';\\n    if (overallScore >= 0.2) return 'poor';\\n    return 'very poor';\\n  };\\n\\n  // Get detailed quality assessment\\n  const getQualityAssessment = () => {\\n    const flow = calculateConversationFlow();\\n    const coherence = calculateConversationCoherence();\\n    const participation = calculateParticipationQuality();\\n    const overall = calculateOverallQuality();\\n    \\n    return {\\n      flow: {\\n        score: Math.round(flow * 100),\\n        rating: flow >= 0.7 ? 'good' : flow >= 0.4 ? 'fair' : 'poor'\\n      },\\n      coherence: {\\n        score: Math.round(coherence * 100),\\n        rating: coherence >= 0.7 ? 'good' : coherence >= 0.4 ? 'fair' : 'poor'\\n      },\\n      participation: {\\n        score: Math.round(participation * 100),\\n        rating: participation >= 0.7 ? 'good' : participation >= 0.4 ? 'fair' : 'poor'\\n      },\\n      overall: {\\n        rating: overall,\\n        score: Math.round(((flow * 0.3) + (coherence * 0.4) + (participation * 0.3)) * 100)\\n      }\\n    };\\n  };\\n\\n  return {\\n    calculateConversationFlow,\\n    calculateConversationCoherence,\\n    calculateParticipationQuality,\\n    calculateOverallQuality,\\n    getQualityAssessment\\n  };\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/features/speech-analysis/analytics/topic-analyzer.js\",\"messages\":[{\"ruleId\":\"max-lines-per-function\",\"severity\":1,\"message\":\"Arrow function has too many lines (177). Maximum allowed is 150.\",\"line\":6,\"column\":36,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"exceed\",\"endLine\":251,\"endColumn\":2},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'keyword' is defined but never used. Allowed unused args must match /^_/u.\",\"line\":56,\"column\":17,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":56,\"endColumn\":24,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"keyword\"},\"fix\":{\"range\":[1991,1998],\"text\":\"\"},\"desc\":\"Remove unused variable 'keyword'.\"}]},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'keyword' is defined but never used. Allowed unused args must match /^_/u.\",\"line\":132,\"column\":17,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":132,\"endColumn\":24,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"keyword\"},\"fix\":{\"range\":[4418,4425],\"text\":\"\"},\"desc\":\"Remove unused variable 'keyword'.\"}]}],\"suppressedMessages\":[],\"errorCount\":2,\"fatalErrorCount\":0,\"warningCount\":1,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Topic Analysis Module\\n * Handles topic discovery, transitions, and timeline analysis\\n */\\n\\nexport const createTopicAnalyzer = (state) => {\\n  // Extract keywords from text\\n  const extractKeywords = (text) => {\\n    // Simple keyword extraction (in production, use more sophisticated NLP)\\n    const stopWords = new Set(['the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', \\n                              'to', 'for', 'of', 'with', 'by', 'is', 'are', 'was', 'were']);\\n    \\n    return text.toLowerCase()\\n      .split(/\\\\s+/)\\n      .filter(word => word.length > 3 && !stopWords.has(word))\\n      .map(word => word.replace(/[^a-zA-Z]/g, ''))\\n      .filter(word => word.length > 2);\\n  };\\n\\n  // Analyze topics from conversation chunks\\n  const analyzeTopics = () => {\\n    const {topics} = state.metrics;\\n    const keywordFreq = new Map();\\n    const topicClusters = new Map();\\n    \\n    // Extract keywords from all chunks\\n    for (const chunks of state.rawData.participants.values()) {\\n      for (const chunk of chunks) {\\n        if (chunk.text) {\\n          const keywords = extractKeywords(chunk.text);\\n          \\n          keywords.forEach(keyword => {\\n            keywordFreq.set(keyword, (keywordFreq.get(keyword) || 0) + 1);\\n            \\n            // Add to timeline\\n            if (!topicClusters.has(keyword)) {\\n              topicClusters.set(keyword, []);\\n            }\\n            topicClusters.get(keyword).push({\\n              timestamp: chunk.timestamp,\\n              participant: chunk.participantId || 'unknown',\\n              context: chunk.text.substring(0, 100)\\n            });\\n          });\\n        }\\n      }\\n    }\\n\\n    // Find significant topics (above threshold)\\n    const totalChunks = Array.from(state.rawData.participants.values())\\n      .reduce((total, chunks) => total + chunks.length, 0);\\n    \\n    const minFrequency = Math.max(2, Math.floor(totalChunks * state.config.topicThreshold));\\n    \\n    topics.discovered = Array.from(keywordFreq.entries())\\n      .filter(([keyword, freq]) => freq >= minFrequency)\\n      .map(([keyword, freq]) => ({\\n        keyword,\\n        frequency: freq,\\n        relevance: freq / totalChunks,\\n        timeline: topicClusters.get(keyword) || []\\n      }))\\n      .sort((a, b) => b.frequency - a.frequency);\\n\\n    // Update dominant topics (top 5)\\n    topics.dominantTopics = topics.discovered.slice(0, 5);\\n\\n    // Calculate topic transitions\\n    topics.transitions = calculateTopicTransitions();\\n    \\n    // Build topic timeline\\n    topics.timeline = buildTopicTimeline();\\n\\n    return topics;\\n  };\\n\\n  // Calculate topic transitions\\n  const calculateTopicTransitions = () => {\\n    const transitions = [];\\n    const windowSize = 3; // Number of chunks to consider for context\\n\\n    // Sort all chunks by timestamp\\n    const allChunks = [];\\n    for (const [participantId, chunks] of state.rawData.participants.entries()) {\\n      chunks.forEach(chunk => {\\n        allChunks.push({ ...chunk, participantId });\\n      });\\n    }\\n    allChunks.sort((a, b) => a.timestamp - b.timestamp);\\n\\n    // Analyze transitions using sliding window\\n    for (let i = windowSize; i < allChunks.length - windowSize; i++) {\\n      const before = allChunks.slice(i - windowSize, i);\\n      const after = allChunks.slice(i, i + windowSize);\\n\\n      const beforeTopics = getChunkTopics(before);\\n      const afterTopics = getChunkTopics(after);\\n\\n      // Find topic changes\\n      const newTopics = afterTopics.filter(topic => !beforeTopics.includes(topic));\\n      const lostTopics = beforeTopics.filter(topic => !afterTopics.includes(topic));\\n\\n      if (newTopics.length > 0 || lostTopics.length > 0) {\\n        transitions.push({\\n          timestamp: allChunks[i].timestamp,\\n          participant: allChunks[i].participantId,\\n          newTopics,\\n          lostTopics,\\n          context: allChunks[i].text?.substring(0, 150)\\n        });\\n      }\\n    }\\n\\n    return transitions.slice(-20); // Keep recent transitions\\n  };\\n\\n  // Get topics from a group of chunks\\n  const getChunkTopics = (chunks) => {\\n    const keywordCount = new Map();\\n    \\n    chunks.forEach(chunk => {\\n      if (chunk.text) {\\n        const keywords = extractKeywords(chunk.text);\\n        keywords.forEach(keyword => {\\n          keywordCount.set(keyword, (keywordCount.get(keyword) || 0) + 1);\\n        });\\n      }\\n    });\\n\\n    // Return keywords that appear more than once\\n    return Array.from(keywordCount.entries())\\n      .filter(([keyword, count]) => count > 1)\\n      .map(([keyword]) => keyword);\\n  };\\n\\n  // Build topic timeline\\n  const buildTopicTimeline = () => {\\n    const timeline = [];\\n    const timeWindow = 30000; // 30 seconds\\n\\n    // Group chunks by time windows\\n    const allChunks = [];\\n    for (const [participantId, chunks] of state.rawData.participants.entries()) {\\n      chunks.forEach(chunk => {\\n        allChunks.push({ ...chunk, participantId });\\n      });\\n    }\\n    allChunks.sort((a, b) => a.timestamp - b.timestamp);\\n\\n    if (allChunks.length === 0) return timeline;\\n\\n    const startTime = allChunks[0].timestamp;\\n    const endTime = allChunks[allChunks.length - 1].timestamp;\\n\\n    // Create time buckets\\n    for (let time = startTime; time <= endTime; time += timeWindow) {\\n      const windowChunks = allChunks.filter(chunk => \\n        chunk.timestamp >= time && chunk.timestamp < time + timeWindow\\n      );\\n\\n      if (windowChunks.length > 0) {\\n        const windowTopics = getChunkTopics(windowChunks);\\n        \\n        timeline.push({\\n          startTime: time,\\n          endTime: time + timeWindow,\\n          topics: windowTopics,\\n          participants: [...new Set(windowChunks.map(c => c.participantId))],\\n          activityLevel: windowChunks.length\\n        });\\n      }\\n    }\\n\\n    return timeline;\\n  };\\n\\n  // Get topic summary\\n  const getTopicSummary = () => {\\n    const {topics} = state.metrics;\\n    \\n    return {\\n      totalTopics: topics.discovered.length,\\n      dominantTopics: topics.dominantTopics.map(t => t.keyword),\\n      topicDiversity: calculateTopicDiversity(),\\n      recentTransitions: topics.transitions.slice(-5),\\n      topicCoverage: calculateTopicCoverage()\\n    };\\n  };\\n\\n  // Calculate topic diversity (how varied the conversation topics are)\\n  const calculateTopicDiversity = () => {\\n    const topics = state.metrics.topics.discovered;\\n    if (topics.length === 0) return 0;\\n\\n    // Calculate entropy-like measure\\n    const totalFreq = topics.reduce((sum, topic) => sum + topic.frequency, 0);\\n    let diversity = 0;\\n\\n    topics.forEach(topic => {\\n      const p = topic.frequency / totalFreq;\\n      if (p > 0) {\\n        diversity -= p * Math.log2(p);\\n      }\\n    });\\n\\n    // Normalize to 0-1 scale\\n    const maxDiversity = Math.log2(topics.length);\\n    return maxDiversity > 0 ? diversity / maxDiversity : 0;\\n  };\\n\\n  // Calculate topic coverage (how well topics are distributed across participants)\\n  const calculateTopicCoverage = () => {\\n    const participantCount = state.rawData.participants.size;\\n    if (participantCount <= 1) return 1;\\n\\n    const topicParticipation = new Map();\\n\\n    // Track which participants contribute to each topic\\n    for (const [participantId, chunks] of state.rawData.participants.entries()) {\\n      const participantKeywords = new Set();\\n      \\n      chunks.forEach(chunk => {\\n        if (chunk.text) {\\n          const keywords = extractKeywords(chunk.text);\\n          keywords.forEach(keyword => participantKeywords.add(keyword));\\n        }\\n      });\\n\\n      participantKeywords.forEach(keyword => {\\n        if (!topicParticipation.has(keyword)) {\\n          topicParticipation.set(keyword, new Set());\\n        }\\n        topicParticipation.get(keyword).add(participantId);\\n      });\\n    }\\n\\n    // Calculate average participation per topic\\n    const participationRates = Array.from(topicParticipation.values())\\n      .map(participants => participants.size / participantCount);\\n\\n    return participationRates.length > 0 \\n      ? participationRates.reduce((sum, rate) => sum + rate, 0) / participationRates.length\\n      : 0;\\n  };\\n\\n  return {\\n    analyzeTopics,\\n    getTopicSummary,\\n    extractKeywords\\n  };\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/features/speech-analysis/audio-quality.js\",\"messages\":[{\"ruleId\":\"max-lines-per-function\",\"severity\":1,\"message\":\"Arrow function has too many lines (303). Maximum allowed is 150.\",\"line\":22,\"column\":43,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"exceed\",\"endLine\":455,\"endColumn\":2},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'timeData' is defined but never used. Allowed unused args must match /^_/u.\",\"line\":228,\"column\":40,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":228,\"endColumn\":48,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"timeData\"},\"fix\":{\"range\":[6885,6895],\"text\":\"\"},\"desc\":\"Remove unused variable 'timeData'.\"}]},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":281,\"column\":38,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":281,\"endColumn\":39},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":281,\"column\":42,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":281,\"endColumn\":43},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '/'. Use parentheses to clarify the intended order of operations.\",\"line\":281,\"column\":42,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":281,\"endColumn\":43},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '/'. Use parentheses to clarify the intended order of operations.\",\"line\":281,\"column\":57,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":281,\"endColumn\":58},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'clarity' is assigned a value but never used. Allowed unused vars must match /^_/u.\",\"line\":286,\"column\":48,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":286,\"endColumn\":55,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"clarity\"},\"fix\":{\"range\":[9189,9198],\"text\":\"\"},\"desc\":\"Remove unused variable 'clarity'.\"}]}],\"suppressedMessages\":[],\"errorCount\":2,\"fatalErrorCount\":0,\"warningCount\":5,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Audio Quality Analysis\\n * Real-time audio quality monitoring and enhancement\\n * Following functional programming patterns with factory functions\\n */\\n\\nimport { checkFeatures, detectRuntime } from '../../shared/utils/runtime-detector.js';\\nimport { createSpeechEvent } from '../../core/configuration/types.ts';\\n\\n// Audio quality metrics factory\\nexport const createAudioQualityMetrics = (config = {}) => ({\\n  signalToNoise: config.signalToNoise || 0,\\n  volumeLevel: config.volumeLevel || 0,\\n  backgroundNoise: config.backgroundNoise || 0,\\n  clarity: config.clarity || 0,\\n  distortion: config.distortion || 0,\\n  timestamp: config.timestamp || Date.now(),\\n  quality: config.quality || 'unknown' // 'excellent', 'good', 'fair', 'poor'\\n});\\n\\n// Audio quality analyzer factory\\nexport const createAudioQualityAnalyzer = (config = {}) => {\\n  const state = {\\n    runtime: detectRuntime(),\\n    features: checkFeatures(),\\n    audioContext: null,\\n    analyser: null,\\n    microphone: null,\\n    isInitialized: false,\\n    isAnalyzing: false,\\n    \\n    // Configuration\\n    config: {\\n      fftSize: config.fftSize || 2048,\\n      smoothingTimeConstant: config.smoothingTimeConstant || 0.8,\\n      minDecibels: config.minDecibels || -90,\\n      maxDecibels: config.maxDecibels || -10,\\n      sampleRate: config.sampleRate || 44100,\\n      ...config\\n    },\\n    \\n    // Analysis buffers\\n    frequencyData: null,\\n    timeData: null,\\n    \\n    // Quality history for trend analysis\\n    qualityHistory: [],\\n    maxHistoryLength: config.maxHistoryLength || 100,\\n    \\n    // Thresholds for quality assessment\\n    thresholds: {\\n      excellent: { snr: 20, volume: 0.3, noise: 0.1 },\\n      good: { snr: 15, volume: 0.2, noise: 0.2 },\\n      fair: { snr: 10, volume: 0.1, noise: 0.3 },\\n      poor: { snr: 5, volume: 0.05, noise: 0.5 }\\n    },\\n    \\n    // Callbacks\\n    callbacks: {\\n      onQualityUpdate: [],\\n      onQualityChange: [],\\n      onError: []\\n    }\\n  };\\n\\n  // Initialize audio quality analyzer\\n  const initialize = async () => {\\n    if (!state.runtime.isBrowser) {\\n      console.log('⚠️ Audio quality analysis requires browser environment');\\n      return false;\\n    }\\n\\n    if (!state.features.webAudio) {\\n      console.log('⚠️ Web Audio API not supported');\\n      return false;\\n    }\\n\\n    try {\\n      // Request microphone access\\n      const stream = await navigator.mediaDevices.getUserMedia({\\n        audio: {\\n          echoCancellation: true,\\n          noiseSuppression: true,\\n          autoGainControl: true,\\n          sampleRate: state.config.sampleRate\\n        }\\n      });\\n\\n      // Create audio context\\n      state.audioContext = new (window.AudioContext || window.webkitAudioContext)({\\n        sampleRate: state.config.sampleRate\\n      });\\n\\n      // Create analyser node\\n      state.analyser = state.audioContext.createAnalyser();\\n      state.analyser.fftSize = state.config.fftSize;\\n      state.analyser.smoothingTimeConstant = state.config.smoothingTimeConstant;\\n      state.analyser.minDecibels = state.config.minDecibels;\\n      state.analyser.maxDecibels = state.config.maxDecibels;\\n\\n      // Connect microphone to analyser\\n      state.microphone = state.audioContext.createMediaStreamSource(stream);\\n      state.microphone.connect(state.analyser);\\n\\n      // Initialize data arrays\\n      state.frequencyData = new Uint8Array(state.analyser.frequencyBinCount);\\n      state.timeData = new Uint8Array(state.analyser.frequencyBinCount);\\n\\n      state.isInitialized = true;\\n      console.log('✅ Audio quality analyzer initialized');\\n      \\n      return true;\\n\\n    } catch (error) {\\n      console.error('❌ Audio quality analyzer initialization failed:', error);\\n      notifyError(new Error(`Audio quality initialization failed: ${error.message}`));\\n      return false;\\n    }\\n  };\\n\\n  // Start quality analysis\\n  const startAnalysis = () => {\\n    if (!state.isInitialized) {\\n      throw new Error('Audio quality analyzer not initialized');\\n    }\\n\\n    state.isAnalyzing = true;\\n    analyzeLoop();\\n    console.log('🎤 Audio quality analysis started');\\n  };\\n\\n  // Stop quality analysis\\n  const stopAnalysis = () => {\\n    state.isAnalyzing = false;\\n    console.log('🔇 Audio quality analysis stopped');\\n  };\\n\\n  // Main analysis loop\\n  const analyzeLoop = () => {\\n    if (!state.isAnalyzing) return;\\n\\n    try {\\n      // Get frequency and time domain data\\n      state.analyser.getByteFrequencyData(state.frequencyData);\\n      state.analyser.getByteTimeDomainData(state.timeData);\\n\\n      // Calculate quality metrics\\n      const metrics = calculateQualityMetrics();\\n      \\n      // Add to history\\n      state.qualityHistory.push(metrics);\\n      if (state.qualityHistory.length > state.maxHistoryLength) {\\n        state.qualityHistory.shift();\\n      }\\n\\n      // Notify callbacks\\n      notifyCallbacks('onQualityUpdate', metrics);\\n\\n      // Check for quality changes\\n      const previousQuality = state.qualityHistory.length > 1 \\n        ? state.qualityHistory[state.qualityHistory.length - 2].quality\\n        : null;\\n      \\n      if (previousQuality && previousQuality !== metrics.quality) {\\n        notifyCallbacks('onQualityChange', {\\n          from: previousQuality,\\n          to: metrics.quality,\\n          metrics\\n        });\\n      }\\n\\n    } catch (error) {\\n      console.warn('Audio quality analysis error:', error);\\n      notifyError(error);\\n    }\\n\\n    // Schedule next analysis\\n    requestAnimationFrame(analyzeLoop);\\n  };\\n\\n  // Calculate comprehensive quality metrics\\n  const calculateQualityMetrics = () => {\\n    // Volume level (RMS)\\n    const volumeLevel = calculateRMS(state.timeData);\\n    \\n    // Signal-to-noise ratio estimation\\n    const snr = calculateSNR(state.frequencyData, state.timeData);\\n    \\n    // Background noise level\\n    const backgroundNoise = calculateBackgroundNoise(state.frequencyData);\\n    \\n    // Audio clarity (high frequency content)\\n    const clarity = calculateClarity(state.frequencyData);\\n    \\n    // Distortion estimation\\n    const distortion = calculateDistortion(state.timeData);\\n    \\n    // Overall quality assessment\\n    const quality = assessOverallQuality({\\n      snr,\\n      volumeLevel,\\n      backgroundNoise,\\n      clarity,\\n      distortion\\n    });\\n\\n    return createAudioQualityMetrics({\\n      signalToNoise: Math.round(snr * 100) / 100,\\n      volumeLevel: Math.round(volumeLevel * 100) / 100,\\n      backgroundNoise: Math.round(backgroundNoise * 100) / 100,\\n      clarity: Math.round(clarity * 100) / 100,\\n      distortion: Math.round(distortion * 100) / 100,\\n      quality\\n    });\\n  };\\n\\n  // Calculate RMS (Root Mean Square) for volume\\n  const calculateRMS = (timeData) => {\\n    let sum = 0;\\n    for (let i = 0; i < timeData.length; i++) {\\n      const normalized = (timeData[i] - 128) / 128;\\n      sum += normalized * normalized;\\n    }\\n    return Math.sqrt(sum / timeData.length);\\n  };\\n\\n  // Estimate signal-to-noise ratio\\n  const calculateSNR = (frequencyData, timeData) => {\\n    // Get signal level (average of frequency bins)\\n    const signalLevel = frequencyData.reduce((sum, value) => sum + value, 0) / frequencyData.length;\\n    \\n    // Estimate noise floor (lowest 10% of frequency bins)\\n    const sortedFreqs = [...frequencyData].sort((a, b) => a - b);\\n    const noiseFloor = sortedFreqs.slice(0, Math.floor(sortedFreqs.length * 0.1))\\n      .reduce((sum, value) => sum + value, 0) / (sortedFreqs.length * 0.1);\\n    \\n    // Calculate SNR in dB\\n    const snr = 20 * Math.log10(signalLevel / (noiseFloor + 1e-10));\\n    return Math.max(0, snr); // Ensure non-negative\\n  };\\n\\n  // Calculate background noise level\\n  const calculateBackgroundNoise = (frequencyData) => {\\n    // Focus on lower frequencies for background noise\\n    const lowFreqBins = frequencyData.slice(0, Math.floor(frequencyData.length * 0.3));\\n    const avgLowFreq = lowFreqBins.reduce((sum, value) => sum + value, 0) / lowFreqBins.length;\\n    return avgLowFreq / 255; // Normalize to 0-1\\n  };\\n\\n  // Calculate audio clarity (high frequency content)\\n  const calculateClarity = (frequencyData) => {\\n    // Focus on higher frequencies for clarity\\n    const highFreqStart = Math.floor(frequencyData.length * 0.6);\\n    const highFreqBins = frequencyData.slice(highFreqStart);\\n    const avgHighFreq = highFreqBins.reduce((sum, value) => sum + value, 0) / highFreqBins.length;\\n    return avgHighFreq / 255; // Normalize to 0-1\\n  };\\n\\n  // Estimate distortion\\n  const calculateDistortion = (timeData) => {\\n    // Look for clipping and non-linearities\\n    let clippingCount = 0;\\n    let totalVariation = 0;\\n    \\n    for (let i = 0; i < timeData.length; i++) {\\n      // Check for clipping\\n      if (timeData[i] === 0 || timeData[i] === 255) {\\n        clippingCount++;\\n      }\\n      \\n      // Calculate total variation\\n      if (i > 0) {\\n        totalVariation += Math.abs(timeData[i] - timeData[i - 1]);\\n      }\\n    }\\n    \\n    const clippingRatio = clippingCount / timeData.length;\\n    const avgVariation = totalVariation / (timeData.length - 1);\\n    \\n    // Combine metrics for distortion estimate\\n    return Math.min(1, clippingRatio * 2 + avgVariation / 255);\\n  };\\n\\n  // Assess overall quality based on metrics\\n  const assessOverallQuality = (metrics) => {\\n    const { snr, volumeLevel, backgroundNoise, clarity } = metrics;\\n    \\n    // Check against thresholds\\n    const {thresholds} = state;\\n    \\n    if (snr >= thresholds.excellent.snr && \\n        volumeLevel >= thresholds.excellent.volume && \\n        backgroundNoise <= thresholds.excellent.noise) {\\n      return 'excellent';\\n    } else if (snr >= thresholds.good.snr && \\n               volumeLevel >= thresholds.good.volume && \\n               backgroundNoise <= thresholds.good.noise) {\\n      return 'good';\\n    } else if (snr >= thresholds.fair.snr && \\n               volumeLevel >= thresholds.fair.volume && \\n               backgroundNoise <= thresholds.fair.noise) {\\n      return 'fair';\\n    } else {\\n      return 'poor';\\n    }\\n  };\\n\\n  // Get quality statistics\\n  const getQualityStats = () => {\\n    if (state.qualityHistory.length === 0) {\\n      return null;\\n    }\\n\\n    const recentHistory = state.qualityHistory.slice(-20); // Last 20 measurements\\n    \\n    return {\\n      current: state.qualityHistory[state.qualityHistory.length - 1],\\n      average: {\\n        signalToNoise: recentHistory.reduce((sum, m) => sum + m.signalToNoise, 0) / recentHistory.length,\\n        volumeLevel: recentHistory.reduce((sum, m) => sum + m.volumeLevel, 0) / recentHistory.length,\\n        backgroundNoise: recentHistory.reduce((sum, m) => sum + m.backgroundNoise, 0) / recentHistory.length,\\n        clarity: recentHistory.reduce((sum, m) => sum + m.clarity, 0) / recentHistory.length\\n      },\\n      trend: calculateQualityTrend(),\\n      recommendations: generateRecommendations()\\n    };\\n  };\\n\\n  // Calculate quality trend\\n  const calculateQualityTrend = () => {\\n    if (state.qualityHistory.length < 10) {\\n      return 'insufficient_data';\\n    }\\n\\n    const recent = state.qualityHistory.slice(-10);\\n    const older = state.qualityHistory.slice(-20, -10);\\n\\n    if (older.length === 0) return 'stable';\\n\\n    const recentAvgSNR = recent.reduce((sum, m) => sum + m.signalToNoise, 0) / recent.length;\\n    const olderAvgSNR = older.reduce((sum, m) => sum + m.signalToNoise, 0) / older.length;\\n\\n    const improvement = recentAvgSNR - olderAvgSNR;\\n\\n    if (improvement > 2) return 'improving';\\n    if (improvement < -2) return 'degrading';\\n    return 'stable';\\n  };\\n\\n  // Generate quality improvement recommendations\\n  const generateRecommendations = () => {\\n    const current = state.qualityHistory[state.qualityHistory.length - 1];\\n    if (!current) return [];\\n\\n    const recommendations = [];\\n\\n    if (current.volumeLevel < 0.1) {\\n      recommendations.push('Speak closer to the microphone or increase input volume');\\n    } else if (current.volumeLevel > 0.8) {\\n      recommendations.push('Reduce input volume to avoid distortion');\\n    }\\n\\n    if (current.backgroundNoise > 0.3) {\\n      recommendations.push('Find a quieter environment or use noise cancellation');\\n    }\\n\\n    if (current.signalToNoise < 10) {\\n      recommendations.push('Improve microphone quality or reduce background noise');\\n    }\\n\\n    if (current.clarity < 0.2) {\\n      recommendations.push('Check microphone frequency response or speak more clearly');\\n    }\\n\\n    return recommendations;\\n  };\\n\\n  // Cleanup resources\\n  const cleanup = async () => {\\n    stopAnalysis();\\n    \\n    if (state.microphone) {\\n      state.microphone.disconnect();\\n      state.microphone = null;\\n    }\\n    \\n    if (state.audioContext) {\\n      await state.audioContext.close();\\n      state.audioContext = null;\\n    }\\n    \\n    state.isInitialized = false;\\n    console.log('🧹 Audio quality analyzer cleaned up');\\n  };\\n\\n  // Event subscription methods\\n  const onQualityUpdate = (callback) => subscribeCallback('onQualityUpdate', callback);\\n  const onQualityChange = (callback) => subscribeCallback('onQualityChange', callback);\\n  const onError = (callback) => subscribeCallback('onError', callback);\\n\\n  // Helper functions\\n  const subscribeCallback = (eventType, callback) => {\\n    state.callbacks[eventType].push(callback);\\n    return () => {\\n      const index = state.callbacks[eventType].indexOf(callback);\\n      if (index !== -1) state.callbacks[eventType].splice(index, 1);\\n    };\\n  };\\n\\n  const notifyCallbacks = (eventType, data) => {\\n    state.callbacks[eventType].forEach(callback => {\\n      try {\\n        callback(createSpeechEvent({\\n          type: eventType,\\n          data,\\n          timestamp: Date.now()\\n        }));\\n      } catch (error) {\\n        console.warn(`Audio quality ${eventType} callback error:`, error);\\n      }\\n    });\\n  };\\n\\n  const notifyError = (error) => {\\n    notifyCallbacks('onError', { error: error.message });\\n  };\\n\\n  return {\\n    // Core functionality\\n    initialize,\\n    startAnalysis,\\n    stopAnalysis,\\n    cleanup,\\n\\n    // Status\\n    isInitialized: () => state.isInitialized,\\n    isAnalyzing: () => state.isAnalyzing,\\n\\n    // Quality metrics\\n    getQualityStats,\\n    getHistory: () => [...state.qualityHistory],\\n    getCurrentQuality: () => state.qualityHistory[state.qualityHistory.length - 1] || null,\\n\\n    // Event handlers\\n    onQualityUpdate,\\n    onQualityChange,\\n    onError,\\n\\n    // Configuration\\n    updateThresholds: (newThresholds) => {\\n      Object.assign(state.thresholds, newThresholds);\\n    },\\n    getThresholds: () => ({ ...state.thresholds })\\n  };\\n};\\n\\n// Export quality metrics factory for external use (already exported above as const)\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/features/speech-analysis/audio/agc-config.js\",\"messages\":[],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/features/speech-analysis/audio/agc-processor.js\",\"messages\":[{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":38,\"column\":42,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":38,\"endColumn\":43},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":38,\"column\":59,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":38,\"endColumn\":60},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":38,\"column\":59,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":38,\"endColumn\":60},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":38,\"column\":85,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":38,\"endColumn\":86},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":40,\"column\":43,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":40,\"endColumn\":44},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":40,\"column\":60,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":40,\"endColumn\":61},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":40,\"column\":60,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":40,\"endColumn\":61},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":40,\"column\":87,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":40,\"endColumn\":88},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":72,\"column\":58,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":72,\"endColumn\":59},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":72,\"column\":90,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":72,\"endColumn\":91},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":73,\"column\":56,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":73,\"endColumn\":57},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":73,\"column\":88,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":73,\"endColumn\":89}],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":12,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * AGC Processing Core\\n * Core automatic gain control processing logic\\n */\\n\\nexport const createAGCProcessor = (state) => {\\n  // Convert linear to dB\\n  const linearToDb = (linear) => 20 * Math.log10(Math.max(linear, 1e-10));\\n\\n  // Convert dB to linear\\n  const dbToLinear = (db) => Math.pow(10, db / 20);\\n\\n  // Initialize AGC\\n  const initialize = () => {\\n    // Calculate time constants\\n    state.attackCoeff = Math.exp(-1 / (state.config.attackTime * state.config.sampleRate));\\n    state.releaseCoeff = Math.exp(-1 / (state.config.releaseTime * state.config.sampleRate));\\n    \\n    // Initialize look-ahead buffer\\n    const lookAheadSamples = Math.floor(state.config.lookAheadTime * state.config.sampleRate);\\n    state.lookAheadBuffer = new Float32Array(lookAheadSamples);\\n  };\\n\\n  // Process single sample with envelope following\\n  const processSample = (inputSample, lookAheadSize) => {\\n    // Store current sample in look-ahead buffer\\n    state.lookAheadBuffer[state.lookAheadIndex] = inputSample;\\n    \\n    // Get delayed sample for processing\\n    const delayedIndex = (state.lookAheadIndex + 1) % lookAheadSize;\\n    const delayedSample = state.lookAheadBuffer[delayedIndex];\\n    \\n    // Calculate envelope of current sample\\n    const inputLevel = Math.abs(inputSample);\\n    \\n    // Envelope follower\\n    if (inputLevel > state.envelope) {\\n      state.envelope = state.attackCoeff * state.envelope + (1 - state.attackCoeff) * inputLevel;\\n    } else {\\n      state.envelope = state.releaseCoeff * state.envelope + (1 - state.releaseCoeff) * inputLevel;\\n    }\\n    \\n    // Calculate required gain\\n    const inputLevelDb = linearToDb(state.envelope);\\n    const gainNeededDb = state.config.targetLevel - inputLevelDb;\\n    \\n    // Limit gain\\n    const limitedGainDb = Math.max(state.config.minGain, \\n                                 Math.min(state.config.maxGain, gainNeededDb));\\n    \\n    // Smooth gain changes\\n    const targetGain = dbToLinear(limitedGainDb);\\n    const gainDiff = targetGain - state.currentGain;\\n    state.currentGain += gainDiff * 0.01; // Smooth gain adjustment\\n    \\n    // Apply gain to delayed sample\\n    const outputSample = delayedSample * state.currentGain;\\n    \\n    // Update buffer index\\n    state.lookAheadIndex = (state.lookAheadIndex + 1) % lookAheadSize;\\n    \\n    return outputSample;\\n  };\\n\\n  // Update statistics\\n  const updateStats = (audioBuffer) => {\\n    state.stats.totalFrames++;\\n    const avgInputLevel = audioBuffer.reduce((sum, s) => sum + Math.abs(s), 0) / audioBuffer.length;\\n    const inputLevelDb = linearToDb(avgInputLevel);\\n    \\n    state.stats.peakLevel = Math.max(state.stats.peakLevel, inputLevelDb);\\n    state.stats.averageLevel = (state.stats.averageLevel * (state.stats.totalFrames - 1) + inputLevelDb) / state.stats.totalFrames;\\n    state.stats.averageGain = (state.stats.averageGain * (state.stats.totalFrames - 1) + linearToDb(state.currentGain)) / state.stats.totalFrames;\\n    \\n    if (Math.abs(linearToDb(state.currentGain)) > 1) {\\n      state.stats.gainAdjustments++;\\n    }\\n  };\\n\\n  return {\\n    initialize,\\n    processSample,\\n    updateStats\\n  };\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/features/speech-analysis/audio/analysis-processor.js\",\"messages\":[{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'event' is defined but never used. Allowed unused args must match /^_/u.\",\"line\":8,\"column\":30,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":8,\"endColumn\":35,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"event\"},\"fix\":{\"range\":[240,245],\"text\":\"\"},\"desc\":\"Remove unused variable 'event'.\"}]}],\"suppressedMessages\":[],\"errorCount\":1,\"fatalErrorCount\":0,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Audio Analysis Processor Module\\n * Real-time frame processing and callback management\\n */\\n\\nexport const createAnalysisProcessor = (state, featureExtractor, callbackNotifier) => {\\n  // Process audio frame\\n  const processAudioFrame = (event) => {\\n    const startTime = performance.now();\\n    \\n    // Get time domain data\\n    state.analyser.getFloatTimeDomainData(state.buffers.time);\\n    \\n    // Get frequency domain data\\n    state.analyser.getFloatFrequencyData(state.buffers.frequency);\\n    \\n    // Extract features\\n    const features = featureExtractor.extractFeatures(\\n      state.buffers.time,\\n      state.buffers.frequency,\\n      state.audioContext.sampleRate\\n    );\\n    \\n    // Update state\\n    Object.assign(state.features, features);\\n    \\n    // Notify callbacks\\n    callbackNotifier.notifyCallbacks('onFeatures', features);\\n    \\n    if (features.pitch > 0) {\\n      callbackNotifier.notifyCallbacks('onPitch', features.pitch);\\n    }\\n    \\n    callbackNotifier.notifyCallbacks('onEnergy', features.energy);\\n    callbackNotifier.notifyCallbacks('onSpectrum', state.buffers.frequency);\\n    \\n    // Update metrics\\n    updateMetrics(startTime);\\n  };\\n\\n  // Update performance metrics\\n  const updateMetrics = (startTime) => {\\n    state.metrics.framesProcessed++;\\n    const processingTime = performance.now() - startTime;\\n    state.metrics.lastProcessTime = processingTime;\\n    state.metrics.averageLatency = \\n      (state.metrics.averageLatency * 0.9) + (processingTime * 0.1);\\n  };\\n\\n  // Get processing statistics\\n  const getProcessingStats = () => ({\\n    framesProcessed: state.metrics.framesProcessed,\\n    lastProcessTime: state.metrics.lastProcessTime,\\n    averageLatency: state.metrics.averageLatency,\\n    currentFeatures: { ...state.features }\\n  });\\n\\n  // Reset metrics\\n  const resetMetrics = () => {\\n    state.metrics.framesProcessed = 0;\\n    state.metrics.lastProcessTime = 0;\\n    state.metrics.averageLatency = 0;\\n  };\\n\\n  return {\\n    processAudioFrame,\\n    getProcessingStats,\\n    resetMetrics\\n  };\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/features/speech-analysis/audio/audio-preprocessing-pipeline.js\",\"messages\":[{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":187,\"column\":27,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":187,\"endColumn\":28},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":187,\"column\":32,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":187,\"endColumn\":33},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":187,\"column\":32,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":187,\"endColumn\":33},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":187,\"column\":43,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":187,\"endColumn\":44},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":187,\"column\":54,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":187,\"endColumn\":55},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":187,\"column\":65,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":187,\"endColumn\":66},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":187,\"column\":76,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":187,\"endColumn\":77},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":188,\"column\":27,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":188,\"endColumn\":28},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":188,\"column\":38,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":188,\"endColumn\":39},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":188,\"column\":49,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":188,\"endColumn\":50},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":202,\"column\":50,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":202,\"endColumn\":51},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":202,\"column\":57,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":202,\"endColumn\":58},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":202,\"column\":57,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":202,\"endColumn\":58},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":202,\"column\":65,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":202,\"endColumn\":66}],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":14,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Audio Preprocessing Pipeline\\n * Advanced audio preprocessing and enhancement\\n * Following functional programming patterns with factory functions\\n */\\n\\nimport { createEnhancedMemoryPool } from '../../shared/utils/enhanced-memory-pool.js';\\nimport { createNoiseReductionConfig, createNoiseReductionState } from './noise-reduction-config.js';\\nimport { createFFTProcessor } from './noise-reduction-fft.js';\\nimport { createWindowProcessor } from './noise-reduction-window.js';\\nimport { createSpectralProcessor } from './noise-reduction-spectral.js';\\nimport { createAGCConfig, createAGCState } from './agc-config.js';\\nimport { createAGCProcessor } from './agc-processor.js';\\nimport { createPreprocessingConfig, createPreprocessingState } from './preprocessing-config.js';\\nimport { createModulesManager } from './preprocessing-modules.js';\\nimport { createQualityCalculator } from './preprocessing-quality.js';\\n\\n// Noise reduction using spectral subtraction\\nexport const createNoiseReduction = (config = {}) => {\\n  const noiseConfig = createNoiseReductionConfig(config);\\n  const state = createNoiseReductionState(noiseConfig);\\n  \\n  // Create modular processors\\n  const fftProcessor = createFFTProcessor();\\n  const windowProcessor = createWindowProcessor(state);\\n  const spectralProcessor = createSpectralProcessor(state);\\n\\n  // Apply spectral subtraction\\n  const processFrame = (audioBuffer, isQuiet = false) => {\\n    if (!state.window) {\\n      windowProcessor.initializeWindow();\\n    }\\n    \\n    // Apply window\\n    const windowed = windowProcessor.applyWindow(audioBuffer);\\n    \\n    // Forward FFT\\n    const fftResult = fftProcessor.fft(windowed);\\n    \\n    // Calculate magnitudes and phases\\n    const { magnitudes, phases } = fftProcessor.extractMagnitudesAndPhases(fftResult);\\n    \\n    // Update noise profile if in quiet segment\\n    if (isQuiet || state.adaptationFrames < state.targetAdaptationFrames) {\\n      spectralProcessor.updateNoiseProfile(magnitudes);\\n    }\\n    \\n    // Apply spectral subtraction\\n    const enhancedMagnitudes = spectralProcessor.applySpectralSubtraction(magnitudes);\\n    \\n    // Reconstruct complex spectrum\\n    const enhancedSpectrum = fftProcessor.reconstructSpectrum(enhancedMagnitudes, phases);\\n    \\n    // Inverse FFT\\n    const enhanced = fftProcessor.ifft(enhancedSpectrum);\\n    \\n    // Process overlap-add\\n    const output = windowProcessor.processOverlapAdd(enhanced);\\n    \\n    // Update statistics\\n    spectralProcessor.updateStats();\\n    \\n    return output;\\n  };\\n\\n  return {\\n    processFrame,\\n    getStats: () => ({ ...state.stats }),\\n    updateConfig: (newConfig) => Object.assign(state.config, newConfig),\\n    reset: () => {\\n      state.noiseProfile = null;\\n      state.noiseProfileInitialized = false;\\n      state.adaptationFrames = 0;\\n      if (state.overlapBuffer) {\\n        state.overlapBuffer.fill(0);\\n      }\\n    }\\n  };\\n};\\n\\n// Automatic Gain Control (AGC)\\nexport const createAutomaticGainControl = (config = {}) => {\\n  const agcConfig = createAGCConfig(config);\\n  const state = createAGCState(agcConfig);\\n  const processor = createAGCProcessor(state);\\n\\n  // Process audio frame with AGC\\n  const processFrame = (audioBuffer) => {\\n    if (!state.lookAheadBuffer) {\\n      processor.initialize();\\n    }\\n    \\n    const output = new Float32Array(audioBuffer.length);\\n    const lookAheadSize = state.lookAheadBuffer.length;\\n    \\n    for (let i = 0; i < audioBuffer.length; i++) {\\n      output[i] = processor.processSample(audioBuffer[i], lookAheadSize);\\n    }\\n    \\n    // Update statistics\\n    processor.updateStats(audioBuffer);\\n    \\n    return output;\\n  };\\n\\n  return {\\n    processFrame,\\n    getStats: () => ({ ...state.stats }),\\n    updateConfig: (newConfig) => {\\n      Object.assign(state.config, newConfig);\\n      processor.initialize(); // Reinitialize with new config\\n    },\\n    reset: () => {\\n      state.currentGain = 1.0;\\n      state.envelope = 0.0;\\n      if (state.lookAheadBuffer) {\\n        state.lookAheadBuffer.fill(0);\\n      }\\n      state.lookAheadIndex = 0;\\n    }\\n  };\\n};\\n\\n// High-pass filter for DC removal and low-frequency noise\\nexport const createHighPassFilter = (config = {}) => {\\n  const state = {\\n    config: {\\n      cutoffFrequency: config.cutoffFrequency || 80, // Hz\\n      sampleRate: config.sampleRate || 44100,\\n      order: config.order || 2 // Filter order\\n    },\\n    \\n    // Filter history (for biquad implementation)\\n    x1: 0, x2: 0, // Input history\\n    y1: 0, y2: 0, // Output history\\n    \\n    // Biquad coefficients\\n    b0: 0, b1: 0, b2: 0,\\n    a1: 0, a2: 0,\\n    \\n    stats: {\\n      totalSamples: 0,\\n      dcOffset: 0\\n    }\\n  };\\n\\n  // Calculate biquad coefficients for high-pass filter\\n  const calculateCoefficients = () => {\\n    const nyquist = state.config.sampleRate / 2;\\n    const normalizedFreq = state.config.cutoffFrequency / nyquist;\\n    const omega = 2 * Math.PI * normalizedFreq;\\n    \\n    const sin = Math.sin(omega);\\n    const cos = Math.cos(omega);\\n    const alpha = sin / (2 * 0.707); // Q = 0.707 for Butterworth response\\n    \\n    // High-pass biquad coefficients\\n    const b0 = (1 + cos) / 2;\\n    const b1 = -(1 + cos);\\n    const b2 = (1 + cos) / 2;\\n    const a0 = 1 + alpha;\\n    const a1 = -2 * cos;\\n    const a2 = 1 - alpha;\\n    \\n    // Normalize coefficients\\n    state.b0 = b0 / a0;\\n    state.b1 = b1 / a0;\\n    state.b2 = b2 / a0;\\n    state.a1 = a1 / a0;\\n    state.a2 = a2 / a0;\\n  };\\n\\n  // Process audio buffer\\n  const processFrame = (audioBuffer) => {\\n    if (state.b0 === 0) {\\n      calculateCoefficients();\\n    }\\n    \\n    const output = new Float32Array(audioBuffer.length);\\n    let dcSum = 0;\\n    \\n    for (let i = 0; i < audioBuffer.length; i++) {\\n      const x0 = audioBuffer[i];\\n      dcSum += x0;\\n      \\n      // Biquad filter equation\\n      const y0 = state.b0 * x0 + state.b1 * state.x1 + state.b2 * state.x2 - \\n                 state.a1 * state.y1 - state.a2 * state.y2;\\n      \\n      // Update history\\n      state.x2 = state.x1;\\n      state.x1 = x0;\\n      state.y2 = state.y1;\\n      state.y1 = y0;\\n      \\n      output[i] = y0;\\n    }\\n    \\n    // Update statistics\\n    state.stats.totalSamples += audioBuffer.length;\\n    const avgDC = dcSum / audioBuffer.length;\\n    state.stats.dcOffset = (state.stats.dcOffset * 0.99 + avgDC * 0.01);\\n    \\n    return output;\\n  };\\n\\n  return {\\n    processFrame,\\n    getStats: () => ({ ...state.stats }),\\n    updateConfig: (newConfig) => {\\n      Object.assign(state.config, newConfig);\\n      calculateCoefficients();\\n    },\\n    reset: () => {\\n      state.x1 = state.x2 = 0;\\n      state.y1 = state.y2 = 0;\\n    }\\n  };\\n};\\n\\n// Comprehensive audio preprocessing pipeline\\nexport const createAudioPreprocessingPipeline = (config = {}) => {\\n  const preprocessingConfig = createPreprocessingConfig(config);\\n  const state = createPreprocessingState(preprocessingConfig);\\n  \\n  const memoryPool = createEnhancedMemoryPool({\\n    maxPoolSize: state.config.maxPoolSize,\\n    enableMetrics: true\\n  });\\n  memoryPool.initialize();\\n  \\n  // Create modular components\\n  const modulesManager = createModulesManager(\\n    state, \\n    createNoiseReduction, \\n    createAutomaticGainControl, \\n    createHighPassFilter\\n  );\\n  const qualityCalculator = createQualityCalculator(state);\\n\\n  // Register result type\\n  memoryPool.registerFactory('PreprocessingResult', () => ({\\n    _pooled: true,\\n    processedAudio: null,\\n    processingTime: 0,\\n    modulesApplied: [],\\n    qualityMetrics: {\\n      signalLevel: 0,\\n      noiseLevel: 0,\\n      dcOffset: 0\\n    },\\n    timestamp: 0\\n  }));\\n\\n  // Process audio frame through pipeline\\n  const processFrame = (audioBuffer, isQuiet = false, timestamp = Date.now()) => {\\n    if (!state.isInitialized) {\\n      modulesManager.initialize();\\n    }\\n    \\n    const startTime = performance.now();\\n    \\n    // Process through modules\\n    const { processedAudio, modulesApplied } = modulesManager.processAudio(audioBuffer, isQuiet);\\n    \\n    const processingTime = performance.now() - startTime;\\n    \\n    // Calculate quality metrics and update statistics\\n    const qualityMetrics = qualityCalculator.calculateQualityMetrics(processedAudio, audioBuffer);\\n    qualityCalculator.updateStats(processingTime);\\n    \\n    // Create result\\n    const result = memoryPool.acquire('PreprocessingResult');\\n    result.processedAudio = processedAudio;\\n    result.processingTime = processingTime;\\n    result.modulesApplied = modulesApplied;\\n    result.qualityMetrics = qualityMetrics;\\n    result.timestamp = timestamp;\\n    \\n    return result;\\n  };\\n\\n  // Release result\\n  const releaseResult = (result) => {\\n    memoryPool.release(result);\\n  };\\n\\n  // Get comprehensive statistics\\n  const getStats = () => ({\\n    ...state.stats,\\n    modules: modulesManager.getModuleStats(),\\n    memoryPool: memoryPool.getStats(),\\n    processingEfficiency: qualityCalculator.getProcessingEfficiency()\\n  });\\n\\n  // Update configuration\\n  const updateConfig = (newConfig) => {\\n    Object.assign(state.config, newConfig);\\n    modulesManager.updateConfig(newConfig);\\n  };\\n\\n  // Reset all modules\\n  const reset = () => {\\n    modulesManager.reset();\\n    qualityCalculator.resetStats();\\n  };\\n\\n  // Cleanup\\n  const cleanup = () => {\\n    memoryPool.cleanup();\\n  };\\n\\n  return {\\n    processFrame,\\n    releaseResult,\\n    getStats,\\n    updateConfig,\\n    reset,\\n    cleanup,\\n    isInitialized: () => state.isInitialized\\n  };\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/features/speech-analysis/audio/audio-quality-metrics.js\",\"messages\":[{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":44,\"column\":29,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":44,\"endColumn\":30},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":44,\"column\":36,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":44,\"endColumn\":37},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":45,\"column\":38,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":45,\"endColumn\":39},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":45,\"column\":46,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":45,\"endColumn\":47},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":45,\"column\":61,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":45,\"endColumn\":62},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":45,\"column\":69,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":45,\"endColumn\":70},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":46,\"column\":28,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":46,\"endColumn\":29},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":46,\"column\":36,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":46,\"endColumn\":37},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":49,\"column\":15,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":49,\"endColumn\":16},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":49,\"column\":40,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":49,\"endColumn\":41},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":56,\"column\":29,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":56,\"endColumn\":30},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":56,\"column\":36,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":56,\"endColumn\":37},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":56,\"column\":50,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":56,\"endColumn\":51},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":56,\"column\":58,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":56,\"endColumn\":59},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":97,\"column\":64,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":97,\"endColumn\":65},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":97,\"column\":88,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":97,\"endColumn\":89},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":97,\"column\":88,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":97,\"endColumn\":89},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":98,\"column\":69,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":98,\"endColumn\":70},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":135,\"column\":67,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":135,\"endColumn\":68},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":135,\"column\":94,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":135,\"endColumn\":95},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":135,\"column\":94,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":135,\"endColumn\":95},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":136,\"column\":72,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":136,\"endColumn\":73},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":148,\"column\":54,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":148,\"endColumn\":55},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":148,\"column\":86,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":148,\"endColumn\":87},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":266,\"column\":54,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":266,\"endColumn\":55},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":266,\"column\":86,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":266,\"endColumn\":87},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":270,\"column\":37,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":270,\"endColumn\":38},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":270,\"column\":50,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":270,\"endColumn\":51},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":342,\"column\":37,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":342,\"endColumn\":38},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":342,\"column\":58,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":342,\"endColumn\":59}],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":30,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Audio Quality Metrics Module\\n * Advanced audio quality assessment and scoring\\n * Following functional programming patterns with factory functions\\n */\\n\\nimport { createEnhancedMemoryPool } from '../../shared/utils/enhanced-memory-pool.js';\\nimport { createQualityAnalyzerConfig, createQualityAnalyzerState } from './quality-analyzer-config.js';\\nimport { createQualityAnalysisCore } from './quality-analyzer-core.js';\\nimport { createQualityStatsManager } from './quality-analyzer-stats.js';\\n\\n// Signal-to-Noise Ratio (SNR) calculator with frequency weighting\\nexport const createSNRCalculator = (config = {}) => {\\n  const state = {\\n    config: {\\n      frameSize: config.frameSize || 1024,\\n      sampleRate: config.sampleRate || 44100,\\n      noiseFloor: config.noiseFloor || -60, // dB\\n      frequencyWeighting: config.frequencyWeighting || 'A', // 'A', 'C', or 'none'\\n      smoothingFactor: config.smoothingFactor || 0.9\\n    },\\n    \\n    // Adaptive noise estimation\\n    noiseProfile: null,\\n    signalProfile: null,\\n    adaptiveNoiseLevel: null,\\n    \\n    // Statistics\\n    stats: {\\n      totalFrames: 0,\\n      averageSNR: 0,\\n      peakSNR: -Infinity,\\n      minSNR: Infinity,\\n      noiseFloorEstimate: 0\\n    }\\n  };\\n\\n  // A-weighting filter coefficients (simplified approximation)\\n  const getAWeightingGain = (frequency) => {\\n    const f2 = frequency * frequency;\\n    const f4 = f2 * f2;\\n    \\n    const numerator = 12194 * 12194 * f4;\\n    const denominator = (f2 + 20.6 * 20.6) * \\n                       Math.sqrt((f2 + 107.7 * 107.7) * (f2 + 737.9 * 737.9)) * \\n                       (f2 + 12194 * 12194);\\n    \\n    const linearGain = numerator / denominator;\\n    return 20 * Math.log10(linearGain) + 2.0; // +2.0 dB normalization\\n  };\\n\\n  // C-weighting filter (simplified)\\n  const getCWeightingGain = (frequency) => {\\n    const f2 = frequency * frequency;\\n    const numerator = 12194 * 12194 * f2;\\n    const denominator = (f2 + 20.6 * 20.6) * (f2 + 12194 * 12194);\\n    \\n    const linearGain = numerator / denominator;\\n    return 20 * Math.log10(linearGain);\\n  };\\n\\n  // Apply frequency weighting to FFT magnitudes\\n  const applyFrequencyWeighting = (fftMagnitudes, sampleRate) => {\\n    if (state.config.frequencyWeighting === 'none') {\\n      return fftMagnitudes;\\n    }\\n    \\n    const weighted = new Float32Array(fftMagnitudes.length);\\n    const binWidth = sampleRate / (fftMagnitudes.length * 2);\\n    \\n    for (let i = 0; i < fftMagnitudes.length; i++) {\\n      const frequency = i * binWidth;\\n      let gain = 0;\\n      \\n      if (state.config.frequencyWeighting === 'A') {\\n        gain = getAWeightingGain(frequency);\\n      } else if (state.config.frequencyWeighting === 'C') {\\n        gain = getCWeightingGain(frequency);\\n      }\\n      \\n      // Convert dB gain to linear multiplier\\n      const linearGain = Math.pow(10, gain / 20);\\n      weighted[i] = fftMagnitudes[i] * linearGain;\\n    }\\n    \\n    return weighted;\\n  };\\n\\n  // Estimate noise floor from quiet segments\\n  const updateNoiseProfile = (fftMagnitudes, isQuiet) => {\\n    if (isQuiet) {\\n      if (state.noiseProfile === null) {\\n        state.noiseProfile = new Float32Array(fftMagnitudes);\\n      } else {\\n        // Exponential moving average\\n        for (let i = 0; i < fftMagnitudes.length; i++) {\\n          state.noiseProfile[i] = state.config.smoothingFactor * state.noiseProfile[i] + \\n                                 (1 - state.config.smoothingFactor) * fftMagnitudes[i];\\n        }\\n      }\\n    }\\n  };\\n\\n  // Calculate SNR from audio frame\\n  const calculateSNR = (audioBuffer, fftMagnitudes = null, isQuiet = false) => {\\n    let signalPower = 0;\\n    let noisePower = 0;\\n    \\n    if (fftMagnitudes) {\\n      // Frequency domain calculation (more accurate)\\n      const weighted = applyFrequencyWeighting(fftMagnitudes, state.config.sampleRate);\\n      \\n      // Update noise profile during quiet segments\\n      updateNoiseProfile(weighted, isQuiet);\\n      \\n      // Calculate signal and noise power\\n      for (let i = 0; i < weighted.length; i++) {\\n        const signalMag = weighted[i];\\n        const noiseMag = state.noiseProfile ? state.noiseProfile[i] : 0;\\n        \\n        signalPower += signalMag * signalMag;\\n        noisePower += noiseMag * noiseMag;\\n      }\\n    } else {\\n      // Time domain calculation (fallback)\\n      for (let i = 0; i < audioBuffer.length; i++) {\\n        signalPower += audioBuffer[i] * audioBuffer[i];\\n      }\\n      \\n      // Estimate noise power from signal during quiet segments\\n      if (isQuiet) {\\n        if (state.adaptiveNoiseLevel === null) {\\n          state.adaptiveNoiseLevel = signalPower;\\n        } else {\\n          state.adaptiveNoiseLevel = state.config.smoothingFactor * state.adaptiveNoiseLevel + \\n                                    (1 - state.config.smoothingFactor) * signalPower;\\n        }\\n      }\\n      \\n      noisePower = state.adaptiveNoiseLevel || Math.pow(10, state.config.noiseFloor / 10);\\n    }\\n    \\n    // Calculate SNR in dB\\n    const snr = noisePower > 0 ? 10 * Math.log10(signalPower / noisePower) : 60; // Max SNR when no noise\\n    \\n    // Update statistics\\n    state.stats.totalFrames++;\\n    state.stats.averageSNR = (state.stats.averageSNR * (state.stats.totalFrames - 1) + snr) / state.stats.totalFrames;\\n    state.stats.peakSNR = Math.max(state.stats.peakSNR, snr);\\n    state.stats.minSNR = Math.min(state.stats.minSNR, snr);\\n    state.stats.noiseFloorEstimate = noisePower > 0 ? 10 * Math.log10(noisePower) : state.config.noiseFloor;\\n    \\n    return {\\n      snr,\\n      signalPower: 10 * Math.log10(signalPower),\\n      noisePower: 10 * Math.log10(noisePower),\\n      quality: Math.max(0, Math.min(100, (snr + 10) * 2)) // 0-100 scale\\n    };\\n  };\\n\\n  return {\\n    calculateSNR,\\n    getStats: () => ({ ...state.stats }),\\n    updateConfig: (newConfig) => Object.assign(state.config, newConfig),\\n    reset: () => {\\n      state.noiseProfile = null;\\n      state.adaptiveNoiseLevel = null;\\n      state.stats = {\\n        totalFrames: 0,\\n        averageSNR: 0,\\n        peakSNR: -Infinity,\\n        minSNR: Infinity,\\n        noiseFloorEstimate: 0\\n      };\\n    }\\n  };\\n};\\n\\n// Total Harmonic Distortion (THD) calculator\\nexport const createTHDCalculator = (config = {}) => {\\n  const state = {\\n    config: {\\n      frameSize: config.frameSize || 1024,\\n      sampleRate: config.sampleRate || 44100,\\n      fundamentalRange: config.fundamentalRange || [80, 800], // Hz\\n      maxHarmonics: config.maxHarmonics || 10\\n    },\\n    \\n    stats: {\\n      totalFrames: 0,\\n      averageTHD: 0,\\n      peakTHD: 0\\n    }\\n  };\\n\\n  // Find fundamental frequency and harmonics\\n  const findFundamentalAndHarmonics = (fftMagnitudes, sampleRate) => {\\n    const binWidth = sampleRate / (fftMagnitudes.length * 2);\\n    const minBin = Math.floor(state.config.fundamentalRange[0] / binWidth);\\n    const maxBin = Math.floor(state.config.fundamentalRange[1] / binWidth);\\n    \\n    // Find peak in fundamental range\\n    let peakBin = minBin;\\n    let peakMagnitude = fftMagnitudes[minBin];\\n    \\n    for (let i = minBin; i <= maxBin && i < fftMagnitudes.length; i++) {\\n      if (fftMagnitudes[i] > peakMagnitude) {\\n        peakMagnitude = fftMagnitudes[i];\\n        peakBin = i;\\n      }\\n    }\\n    \\n    const fundamentalFreq = peakBin * binWidth;\\n    const fundamentalMag = peakMagnitude;\\n    \\n    // Find harmonics\\n    const harmonics = [];\\n    for (let h = 2; h <= state.config.maxHarmonics; h++) {\\n      const harmonicFreq = fundamentalFreq * h;\\n      const harmonicBin = Math.round(harmonicFreq / binWidth);\\n      \\n      if (harmonicBin < fftMagnitudes.length) {\\n        harmonics.push({\\n          frequency: harmonicFreq,\\n          magnitude: fftMagnitudes[harmonicBin],\\n          order: h\\n        });\\n      }\\n    }\\n    \\n    return {\\n      fundamental: {\\n        frequency: fundamentalFreq,\\n        magnitude: fundamentalMag\\n      },\\n      harmonics\\n    };\\n  };\\n\\n  // Calculate THD\\n  const calculateTHD = (fftMagnitudes) => {\\n    const analysis = findFundamentalAndHarmonics(fftMagnitudes, state.config.sampleRate);\\n    \\n    if (analysis.fundamental.magnitude === 0 || analysis.harmonics.length === 0) {\\n      return {\\n        thd: 0,\\n        thdPercent: 0,\\n        fundamental: analysis.fundamental,\\n        harmonics: analysis.harmonics,\\n        quality: 100\\n      };\\n    }\\n    \\n    // Calculate THD as ratio of harmonic power to fundamental power\\n    let harmonicPowerSum = 0;\\n    for (const harmonic of analysis.harmonics) {\\n      harmonicPowerSum += harmonic.magnitude * harmonic.magnitude;\\n    }\\n    \\n    const fundamentalPower = analysis.fundamental.magnitude * analysis.fundamental.magnitude;\\n    const thd = Math.sqrt(harmonicPowerSum / fundamentalPower);\\n    const thdPercent = thd * 100;\\n    \\n    // Update statistics\\n    state.stats.totalFrames++;\\n    state.stats.averageTHD = (state.stats.averageTHD * (state.stats.totalFrames - 1) + thdPercent) / state.stats.totalFrames;\\n    state.stats.peakTHD = Math.max(state.stats.peakTHD, thdPercent);\\n    \\n    // Quality score (lower THD = higher quality)\\n    const quality = Math.max(0, 100 - thdPercent * 10);\\n    \\n    return {\\n      thd,\\n      thdPercent,\\n      fundamental: analysis.fundamental,\\n      harmonics: analysis.harmonics,\\n      quality\\n    };\\n  };\\n\\n  return {\\n    calculateTHD,\\n    getStats: () => ({ ...state.stats }),\\n    updateConfig: (newConfig) => Object.assign(state.config, newConfig)\\n  };\\n};\\n\\n// Audio clipping detector\\nexport const createClippingDetector = (config = {}) => {\\n  const state = {\\n    config: {\\n      clippingThreshold: config.clippingThreshold || 0.98, // Fraction of full scale\\n      consecutiveThreshold: config.consecutiveThreshold || 5, // Consecutive samples\\n      frameSize: config.frameSize || 1024\\n    },\\n    \\n    stats: {\\n      totalFrames: 0,\\n      clippedFrames: 0,\\n      clippingRatio: 0,\\n      maxClippingDuration: 0,\\n      totalClippingSamples: 0\\n    }\\n  };\\n\\n  // Detect clipping in audio buffer\\n  const detectClipping = (audioBuffer) => {\\n    let clippingSamples = 0;\\n    let consecutiveClips = 0;\\n    let maxConsecutiveClips = 0;\\n    let isFrameClipped = false;\\n    \\n    for (let i = 0; i < audioBuffer.length; i++) {\\n      const sample = Math.abs(audioBuffer[i]);\\n      \\n      if (sample >= state.config.clippingThreshold) {\\n        consecutiveClips++;\\n        clippingSamples++;\\n        \\n        if (consecutiveClips >= state.config.consecutiveThreshold) {\\n          isFrameClipped = true;\\n        }\\n      } else {\\n        maxConsecutiveClips = Math.max(maxConsecutiveClips, consecutiveClips);\\n        consecutiveClips = 0;\\n      }\\n    }\\n    \\n    maxConsecutiveClips = Math.max(maxConsecutiveClips, consecutiveClips);\\n    \\n    // Update statistics\\n    state.stats.totalFrames++;\\n    if (isFrameClipped) {\\n      state.stats.clippedFrames++;\\n    }\\n    state.stats.clippingRatio = state.stats.clippedFrames / state.stats.totalFrames;\\n    state.stats.maxClippingDuration = Math.max(state.stats.maxClippingDuration, maxConsecutiveClips);\\n    state.stats.totalClippingSamples += clippingSamples;\\n    \\n    // Quality score\\n    const clippingPercentage = (clippingSamples / audioBuffer.length) * 100;\\n    const quality = Math.max(0, 100 - clippingPercentage * 20);\\n    \\n    return {\\n      isClipped: isFrameClipped,\\n      clippingSamples,\\n      clippingPercentage,\\n      maxConsecutiveClips,\\n      quality\\n    };\\n  };\\n\\n  return {\\n    detectClipping,\\n    getStats: () => ({ ...state.stats }),\\n    updateConfig: (newConfig) => Object.assign(state.config, newConfig)\\n  };\\n};\\n\\n// Comprehensive audio quality analyzer\\nexport const createAudioQualityAnalyzer = (config = {}) => {\\n  const analyzerConfig = createQualityAnalyzerConfig(config);\\n  const memoryPool = createEnhancedMemoryPool({\\n    maxPoolSize: analyzerConfig.maxPoolSize,\\n    enableMetrics: true\\n  });\\n  memoryPool.initialize();\\n\\n  const state = createQualityAnalyzerState(\\n    analyzerConfig,\\n    createSNRCalculator(config.snr),\\n    createTHDCalculator(config.thd),\\n    createClippingDetector(config.clipping)\\n  );\\n  \\n  // Create modular processors\\n  const analysisCore = createQualityAnalysisCore(state);\\n  const statsManager = createQualityStatsManager(state);\\n\\n  // Register quality result type\\n  memoryPool.registerFactory('QualityResult', () => ({\\n    _pooled: true,\\n    timestamp: 0,\\n    overallQuality: 0,\\n    qualityLevel: 'unknown',\\n    snr: null,\\n    thd: null,\\n    clipping: null,\\n    metrics: {\\n      signalStrength: 0,\\n      noiseLevel: 0,\\n      distortion: 0,\\n      clarity: 0\\n    },\\n    recommendations: []\\n  }));\\n\\n  // Analyze audio quality comprehensively\\n  const analyzeQuality = (audioBuffer, fftMagnitudes = null, isQuiet = false, timestamp = Date.now()) => {\\n    // Run individual analyses\\n    const { snrResult, thdResult, clippingResult } = analysisCore.runAnalyses(audioBuffer, fftMagnitudes, isQuiet);\\n    \\n    // Calculate overall quality and level\\n    const overallQuality = analysisCore.calculateOverallQuality(snrResult, thdResult, clippingResult);\\n    const qualityLevel = analysisCore.determineQualityLevel(overallQuality);\\n    \\n    // Generate recommendations and metrics\\n    const recommendations = analysisCore.generateRecommendations(snrResult, thdResult, clippingResult);\\n    const detailedMetrics = analysisCore.calculateDetailedMetrics(snrResult, thdResult, clippingResult, audioBuffer);\\n    \\n    // Update statistics\\n    statsManager.updateStats(overallQuality, qualityLevel);\\n    \\n    // Create pooled result\\n    const result = memoryPool.acquire('QualityResult');\\n    Object.assign(result, {\\n      timestamp,\\n      overallQuality,\\n      qualityLevel,\\n      snr: snrResult,\\n      thd: thdResult,\\n      clipping: clippingResult,\\n      metrics: detailedMetrics,\\n      recommendations: [...recommendations]\\n    });\\n    \\n    return result;\\n  };\\n\\n  // Release quality result\\n  const releaseResult = (result) => {\\n    memoryPool.release(result);\\n  };\\n\\n  // Get comprehensive statistics\\n  const getStats = () => ({\\n    ...statsManager.getComprehensiveStats(),\\n    individual: {\\n      snr: state.snrCalculator.getStats(),\\n      thd: state.thdCalculator.getStats(),\\n      clipping: state.clippingDetector.getStats()\\n    },\\n    memoryPool: memoryPool.getStats()\\n  });\\n\\n  // Reset all analyzers\\n  const reset = () => {\\n    state.snrCalculator.reset();\\n    state.stats = {\\n      totalFrames: 0,\\n      overallQuality: 0,\\n      qualityDistribution: {\\n        excellent: 0,\\n        good: 0,\\n        fair: 0,\\n        poor: 0\\n      },\\n      qualityTrend: []\\n    };\\n  };\\n\\n  // Update configuration\\n  const updateConfig = (newConfig) => {\\n    Object.assign(state.config, newConfig);\\n    \\n    if (newConfig.snr) {\\n      state.snrCalculator.updateConfig(newConfig.snr);\\n    }\\n    if (newConfig.thd) {\\n      state.thdCalculator.updateConfig(newConfig.thd);\\n    }\\n    if (newConfig.clipping) {\\n      state.clippingDetector.updateConfig(newConfig.clipping);\\n    }\\n  };\\n\\n  // Cleanup\\n  const cleanup = () => {\\n    memoryPool.cleanup();\\n  };\\n\\n  return {\\n    analyzeQuality,\\n    releaseResult,\\n    getStats,\\n    reset,\\n    updateConfig,\\n    cleanup\\n  };\\n};\\n\\n// Real-time quality monitoring integration\\nexport const createRealTimeQualityMonitor = (config = {}) => {\\n  const state = {\\n    analyzer: createAudioQualityAnalyzer(config.analyzer),\\n    isMonitoring: false,\\n    \\n    config: {\\n      updateInterval: config.updateInterval || 100, // ms\\n      alertThresholds: {\\n        quality: config.qualityAlertThreshold || 30,\\n        snr: config.snrAlertThreshold || 5\\n      }\\n    },\\n    \\n    callbacks: {\\n      onQualityUpdate: config.onQualityUpdate || (() => {}),\\n      onQualityAlert: config.onQualityAlert || (() => {}),\\n      onQualityImprovement: config.onQualityImprovement || (() => {})\\n    },\\n    \\n    lastQuality: null,\\n    alertState: false\\n  };\\n\\n  // Process audio frame with monitoring\\n  const processFrame = (audioBuffer, fftMagnitudes = null, isQuiet = false) => {\\n    if (!state.isMonitoring) return null;\\n    \\n    const result = state.analyzer.analyzeQuality(audioBuffer, fftMagnitudes, isQuiet);\\n    \\n    // Check for quality alerts\\n    const isLowQuality = result.overallQuality < state.config.alertThresholds.quality ||\\n                        result.snr.snr < state.config.alertThresholds.snr;\\n    \\n    if (isLowQuality && !state.alertState) {\\n      state.alertState = true;\\n      state.callbacks.onQualityAlert(result);\\n    } else if (!isLowQuality && state.alertState) {\\n      state.alertState = false;\\n      state.callbacks.onQualityImprovement(result);\\n    }\\n    \\n    // Regular quality updates\\n    state.callbacks.onQualityUpdate(result);\\n    state.lastQuality = result.overallQuality;\\n    \\n    return result;\\n  };\\n\\n  // Start monitoring\\n  const startMonitoring = () => {\\n    state.isMonitoring = true;\\n  };\\n\\n  // Stop monitoring\\n  const stopMonitoring = () => {\\n    state.isMonitoring = false;\\n    state.alertState = false;\\n  };\\n\\n  return {\\n    processFrame,\\n    startMonitoring,\\n    stopMonitoring,\\n    getStats: () => state.analyzer.getStats(),\\n    updateConfig: (newConfig) => {\\n      Object.assign(state.config, newConfig);\\n      if (newConfig.analyzer) {\\n        state.analyzer.updateConfig(newConfig.analyzer);\\n      }\\n    },\\n    cleanup: () => state.analyzer.cleanup(),\\n    isMonitoring: () => state.isMonitoring\\n  };\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/features/speech-analysis/audio/callback-notifier.js\",\"messages\":[],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/features/speech-analysis/audio/conversation-analytics.js\",\"messages\":[{\"ruleId\":\"max-lines-per-function\",\"severity\":1,\"message\":\"Arrow function has too many lines (291). Maximum allowed is 150.\",\"line\":11,\"column\":44,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"exceed\",\"endLine\":401,\"endColumn\":2},{\"ruleId\":\"max-statements\",\"severity\":1,\"message\":\"Arrow function has too many statements (45). Maximum allowed is 40.\",\"line\":68,\"column\":29,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"exceed\",\"endLine\":143,\"endColumn\":4},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'previousSpeakers' is assigned a value but never used. Allowed unused vars must match /^_/u.\",\"line\":70,\"column\":11,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":70,\"endColumn\":27,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"previousSpeakers\"},\"fix\":{\"range\":[2228,2324],\"text\":\"\"},\"desc\":\"Remove unused variable 'previousSpeakers'.\"}]},{\"ruleId\":\"prefer-destructuring\",\"severity\":1,\"message\":\"Use array destructuring.\",\"line\":74,\"column\":13,\"nodeType\":\"VariableDeclarator\",\"messageId\":\"preferDestructuring\",\"endLine\":74,\"endColumn\":47},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":366,\"column\":49,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":366,\"endColumn\":50},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":366,\"column\":79,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":366,\"endColumn\":80},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":367,\"column\":45,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":367,\"endColumn\":46},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":367,\"column\":88,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":367,\"endColumn\":89}],\"suppressedMessages\":[],\"errorCount\":1,\"fatalErrorCount\":0,\"warningCount\":7,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Conversation Flow Analysis\\n * Analyzes conversation patterns including turn-taking, interruptions, silence patterns, and interaction quality\\n */\\n\\nimport { createObjectPool } from '../../../shared/utils/object-pool.js';\\n\\n/**\\n * Creates conversation analytics analyzer for dialog flow analysis\\n */\\nexport const createConversationAnalytics = (config = {}) => {\\n  const {\\n    minSilenceDuration = 0.5,      // Minimum silence for turn boundary (seconds)\\n    maxSilenceDuration = 3.0,      // Maximum natural pause (seconds)\\n    interruptionThreshold = 0.2,   // Overlap threshold for interruption detection\\n    turnLengthWindow = 5.0,        // Window for turn length analysis\\n    flowAnalysisWindow = 30.0,     // Window for flow pattern analysis\\n    memoryPoolSize = 100           // Object pooling for performance\\n  } = config;\\n\\n  // Enhanced memory pooling system\\n  const pools = {\\n    turnData: createObjectPool(memoryPoolSize, () => ({\\n      speakerId: null,\\n      startTime: 0,\\n      endTime: 0,\\n      duration: 0,\\n      type: 'speech', // 'speech', 'silence', 'overlap'\\n      confidence: 0,\\n      reset() {\\n        this.speakerId = null;\\n        this.startTime = 0;\\n        this.endTime = 0;\\n        this.duration = 0;\\n        this.type = 'speech';\\n        this.confidence = 0;\\n      }\\n    })),\\n    flowMetrics: createObjectPool(memoryPoolSize / 2, () => ({\\n      turnsPerMinute: 0,\\n      averageTurnLength: 0,\\n      silenceRatio: 0,\\n      interruptionRate: 0,\\n      participationBalance: 0,\\n      conversationRhythm: 0,\\n      reset() {\\n        this.turnsPerMinute = 0;\\n        this.averageTurnLength = 0;\\n        this.silenceRatio = 0;\\n        this.interruptionRate = 0;\\n        this.participationBalance = 0;\\n        this.conversationRhythm = 0;\\n      }\\n    }))\\n  };\\n\\n  // State management\\n  let conversationHistory = [];\\n  let currentTurn = null;\\n  let silenceStartTime = null;\\n  let lastAnalysisTime = 0;\\n  const speakingStates = new Map(); // speakerId -> boolean\\n  let turnMetrics = [];\\n\\n  /**\\n   * Analyzes turn-taking patterns and conversation flow\\n   */\\n  const analyzeTurnTaking = (speakerData, timestamp) => {\\n    const activeSpeakers = Object.keys(speakerData).filter(id => speakerData[id].isActive);\\n    const previousSpeakers = Array.from(speakingStates.keys()).filter(id => speakingStates.get(id));\\n\\n    // Detect turn changes\\n    if (activeSpeakers.length === 1) {\\n      const currentSpeaker = activeSpeakers[0];\\n      \\n      // Start new turn\\n      if (!currentTurn || currentTurn.speakerId !== currentSpeaker) {\\n        // End previous turn\\n        if (currentTurn) {\\n          currentTurn.endTime = timestamp;\\n          currentTurn.duration = currentTurn.endTime - currentTurn.startTime;\\n          turnMetrics.push({ ...currentTurn });\\n        }\\n\\n        // Start new turn\\n        currentTurn = pools.turnData.acquire();\\n        currentTurn.speakerId = currentSpeaker;\\n        currentTurn.startTime = timestamp;\\n        currentTurn.type = 'speech';\\n        currentTurn.confidence = speakerData[currentSpeaker].confidence || 0.8;\\n      }\\n      \\n      silenceStartTime = null;\\n    } else if (activeSpeakers.length === 0) {\\n      // Handle silence\\n      if (currentTurn && !silenceStartTime) {\\n        silenceStartTime = timestamp;\\n      }\\n      \\n      // Check for turn boundary silence\\n      if (silenceStartTime && (timestamp - silenceStartTime) >= minSilenceDuration) {\\n        if (currentTurn) {\\n          currentTurn.endTime = silenceStartTime;\\n          currentTurn.duration = currentTurn.endTime - currentTurn.startTime;\\n          turnMetrics.push({ ...currentTurn });\\n          pools.turnData.release(currentTurn);\\n          currentTurn = null;\\n        }\\n\\n        // Create silence turn\\n        const silenceTurn = pools.turnData.acquire();\\n        silenceTurn.speakerId = 'silence';\\n        silenceTurn.startTime = silenceStartTime;\\n        silenceTurn.endTime = timestamp;\\n        silenceTurn.duration = timestamp - silenceStartTime;\\n        silenceTurn.type = 'silence';\\n        silenceTurn.confidence = 1.0;\\n        turnMetrics.push({ ...silenceTurn });\\n        pools.turnData.release(silenceTurn);\\n      }\\n    } else if (activeSpeakers.length > 1) {\\n      // Handle overlapping speech (interruptions)\\n      const overlapTurn = pools.turnData.acquire();\\n      overlapTurn.speakerId = activeSpeakers.join('+');\\n      overlapTurn.startTime = timestamp - 0.1; // Approximate overlap start\\n      overlapTurn.endTime = timestamp;\\n      overlapTurn.duration = 0.1;\\n      overlapTurn.type = 'overlap';\\n      overlapTurn.confidence = 0.6;\\n      turnMetrics.push({ ...overlapTurn });\\n      pools.turnData.release(overlapTurn);\\n    }\\n\\n    // Update speaker states\\n    speakingStates.clear();\\n    activeSpeakers.forEach(id => speakingStates.set(id, true));\\n\\n    return {\\n      currentSpeaker: activeSpeakers.length === 1 ? activeSpeakers[0] : null,\\n      activeSpeakers: activeSpeakers.length,\\n      turnBoundary: currentTurn !== null\\n    };\\n  };\\n\\n  /**\\n   * Calculates conversation flow metrics\\n   */\\n  const calculateFlowMetrics = (windowStart, windowEnd) => {\\n    const windowTurns = turnMetrics.filter(turn => \\n      turn.startTime >= windowStart && turn.endTime <= windowEnd\\n    );\\n    \\n    if (windowTurns.length === 0) {\\n      return null;\\n    }\\n\\n    const metrics = pools.flowMetrics.acquire();\\n    const windowDuration = windowEnd - windowStart;\\n\\n    // Calculate basic metrics\\n    const speechTurns = windowTurns.filter(t => t.type === 'speech');\\n    const silenceTurns = windowTurns.filter(t => t.type === 'silence');\\n    const overlapTurns = windowTurns.filter(t => t.type === 'overlap');\\n\\n    // Turns per minute\\n    metrics.turnsPerMinute = (speechTurns.length / windowDuration) * 60;\\n\\n    // Average turn length\\n    const totalSpeechDuration = speechTurns.reduce((sum, t) => sum + t.duration, 0);\\n    metrics.averageTurnLength = speechTurns.length > 0 ? totalSpeechDuration / speechTurns.length : 0;\\n\\n    // Silence ratio\\n    const totalSilenceDuration = silenceTurns.reduce((sum, t) => sum + t.duration, 0);\\n    metrics.silenceRatio = totalSilenceDuration / windowDuration;\\n\\n    // Interruption rate\\n    metrics.interruptionRate = overlapTurns.length / Math.max(speechTurns.length, 1);\\n\\n    // Participation balance (entropy-based)\\n    const speakerDurations = new Map();\\n    speechTurns.forEach(turn => {\\n      const duration = speakerDurations.get(turn.speakerId) || 0;\\n      speakerDurations.set(turn.speakerId, duration + turn.duration);\\n    });\\n\\n    if (speakerDurations.size > 1) {\\n      const totalDuration = Array.from(speakerDurations.values()).reduce((sum, d) => sum + d, 0);\\n      const proportions = Array.from(speakerDurations.values()).map(d => d / totalDuration);\\n      const entropy = proportions.reduce((sum, p) => sum - (p * Math.log2(p)), 0);\\n      const maxEntropy = Math.log2(speakerDurations.size);\\n      metrics.participationBalance = entropy / maxEntropy;\\n    } else {\\n      metrics.participationBalance = 0;\\n    }\\n\\n    // Conversation rhythm (regularity of turn-taking)\\n    const turnIntervals = [];\\n    for (let i = 1; i < speechTurns.length; i++) {\\n      turnIntervals.push(speechTurns[i].startTime - speechTurns[i-1].endTime);\\n    }\\n\\n    if (turnIntervals.length > 1) {\\n      const meanInterval = turnIntervals.reduce((sum, interval) => sum + interval, 0) / turnIntervals.length;\\n      const variance = turnIntervals.reduce((sum, interval) => \\n        sum + Math.pow(interval - meanInterval, 2), 0) / turnIntervals.length;\\n      const stdDev = Math.sqrt(variance);\\n      metrics.conversationRhythm = meanInterval > 0 ? 1 / (1 + (stdDev / meanInterval)) : 0;\\n    } else {\\n      metrics.conversationRhythm = 0;\\n    }\\n\\n    return metrics;\\n  };\\n\\n  /**\\n   * Detects conversation patterns and anomalies\\n   */\\n  const detectConversationPatterns = (metrics) => {\\n    const patterns = [];\\n\\n    // Detect dominant speaker\\n    if (metrics.participationBalance < 0.3) {\\n      patterns.push({\\n        type: 'dominant_speaker',\\n        severity: 1 - metrics.participationBalance,\\n        description: 'One speaker dominates the conversation'\\n      });\\n    }\\n\\n    // Detect high interruption rate\\n    if (metrics.interruptionRate > 0.3) {\\n      patterns.push({\\n        type: 'high_interruptions',\\n        severity: Math.min(metrics.interruptionRate, 1),\\n        description: 'Frequent interruptions detected'\\n      });\\n    }\\n\\n    // Detect awkward silences\\n    if (metrics.silenceRatio > 0.4) {\\n      patterns.push({\\n        type: 'excessive_silence',\\n        severity: Math.min(metrics.silenceRatio, 1),\\n        description: 'Unusually long periods of silence'\\n      });\\n    }\\n\\n    // Detect rapid fire conversation\\n    if (metrics.turnsPerMinute > 30) {\\n      patterns.push({\\n        type: 'rapid_fire',\\n        severity: Math.min(metrics.turnsPerMinute / 40, 1),\\n        description: 'Very rapid turn-taking detected'\\n      });\\n    }\\n\\n    // Detect poor conversation rhythm\\n    if (metrics.conversationRhythm < 0.3) {\\n      patterns.push({\\n        type: 'irregular_rhythm',\\n        severity: 1 - metrics.conversationRhythm,\\n        description: 'Irregular conversation rhythm'\\n      });\\n    }\\n\\n    return patterns;\\n  };\\n\\n  /**\\n   * Main analysis function\\n   */\\n  const analyze = (speakerData, audioFeatures, timestamp) => {\\n    // Analyze turn-taking\\n    const turnInfo = analyzeTurnTaking(speakerData, timestamp);\\n\\n    // Periodic flow analysis\\n    if (timestamp - lastAnalysisTime >= flowAnalysisWindow) {\\n      const windowStart = timestamp - flowAnalysisWindow;\\n      const metrics = calculateFlowMetrics(windowStart, timestamp);\\n      \\n      if (metrics) {\\n        const patterns = detectConversationPatterns(metrics);\\n        \\n        // Store in conversation history\\n        conversationHistory.push({\\n          timestamp,\\n          windowStart,\\n          windowEnd: timestamp,\\n          metrics: { ...metrics },\\n          patterns,\\n          turnCount: turnMetrics.length\\n        });\\n\\n        pools.flowMetrics.release(metrics);\\n\\n        // Cleanup old turn metrics\\n        turnMetrics = turnMetrics.filter(turn => turn.startTime > windowStart - flowAnalysisWindow);\\n      }\\n\\n      lastAnalysisTime = timestamp;\\n    }\\n\\n    return {\\n      turnInfo,\\n      currentMetrics: conversationHistory.length > 0 ? \\n        conversationHistory[conversationHistory.length - 1] : null,\\n      totalTurns: turnMetrics.length,\\n      poolStats: {\\n        turnDataUsage: pools.turnData.getStats(),\\n        flowMetricsUsage: pools.flowMetrics.getStats()\\n      }\\n    };\\n  };\\n\\n  /**\\n   * Gets conversation summary statistics\\n   */\\n  const getConversationSummary = () => {\\n    if (conversationHistory.length === 0) {\\n      return null;\\n    }\\n\\n    const latestAnalysis = conversationHistory[conversationHistory.length - 1];\\n    const allPatterns = conversationHistory.flatMap(h => h.patterns);\\n    \\n    return {\\n      totalDuration: conversationHistory.length * flowAnalysisWindow,\\n      analysisWindows: conversationHistory.length,\\n      currentMetrics: latestAnalysis.metrics,\\n      detectedPatterns: allPatterns,\\n      patternSummary: {\\n        dominantSpeaker: allPatterns.filter(p => p.type === 'dominant_speaker').length,\\n        highInterruptions: allPatterns.filter(p => p.type === 'high_interruptions').length,\\n        excessiveSilence: allPatterns.filter(p => p.type === 'excessive_silence').length,\\n        rapidFire: allPatterns.filter(p => p.type === 'rapid_fire').length,\\n        irregularRhythm: allPatterns.filter(p => p.type === 'irregular_rhythm').length\\n      },\\n      overallQuality: calculateOverallConversationQuality()\\n    };\\n  };\\n\\n  /**\\n   * Calculates overall conversation quality score\\n   */\\n  const calculateOverallConversationQuality = () => {\\n    if (conversationHistory.length === 0) return 0;\\n\\n    const recent = conversationHistory.slice(-3); // Last 3 windows\\n    const avgMetrics = recent.reduce((acc, h) => {\\n      acc.participationBalance += h.metrics.participationBalance;\\n      acc.conversationRhythm += h.metrics.conversationRhythm;\\n      acc.interruptionRate += h.metrics.interruptionRate;\\n      acc.silenceRatio += h.metrics.silenceRatio;\\n      return acc;\\n    }, { participationBalance: 0, conversationRhythm: 0, interruptionRate: 0, silenceRatio: 0 });\\n\\n    const count = recent.length;\\n    avgMetrics.participationBalance /= count;\\n    avgMetrics.conversationRhythm /= count;\\n    avgMetrics.interruptionRate /= count;\\n    avgMetrics.silenceRatio /= count;\\n\\n    // Weighted quality score (0-1)\\n    const balanceScore = avgMetrics.participationBalance * 0.3;\\n    const rhythmScore = avgMetrics.conversationRhythm * 0.25;\\n    const interruptionPenalty = Math.max(0, 0.2 - avgMetrics.interruptionRate * 0.2);\\n    const silencePenalty = Math.max(0, 0.25 - Math.abs(avgMetrics.silenceRatio - 0.15) * 0.25);\\n\\n    return Math.min(1, balanceScore + rhythmScore + interruptionPenalty + silencePenalty);\\n  };\\n\\n  /**\\n   * Resets analysis state\\n   */\\n  const reset = () => {\\n    conversationHistory = [];\\n    turnMetrics = [];\\n    currentTurn = null;\\n    silenceStartTime = null;\\n    lastAnalysisTime = 0;\\n    speakingStates.clear();\\n    pools.turnData.reset();\\n    pools.flowMetrics.reset();\\n  };\\n\\n  return {\\n    analyze,\\n    getConversationSummary,\\n    reset,\\n    \\n    // Configuration access\\n    getConfig: () => ({\\n      minSilenceDuration,\\n      maxSilenceDuration,\\n      interruptionThreshold,\\n      turnLengthWindow,\\n      flowAnalysisWindow,\\n      memoryPoolSize\\n    })\\n  };\\n};\\n\\n// Export factory function following functional programming patterns\\n\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/features/speech-analysis/audio/diarization/diarization-manager.js\",\"messages\":[{\"ruleId\":\"max-lines-per-function\",\"severity\":1,\"message\":\"Arrow function has too many lines (238). Maximum allowed is 150.\",\"line\":10,\"column\":41,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"exceed\",\"endLine\":317,\"endColumn\":2},{\"ruleId\":\"max-statements\",\"severity\":1,\"message\":\"Arrow function has too many statements (52). Maximum allowed is 40.\",\"line\":79,\"column\":24,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"exceed\",\"endLine\":203,\"endColumn\":4},{\"ruleId\":\"complexity\",\"severity\":1,\"message\":\"Arrow function has a complexity of 25. Maximum allowed is 20.\",\"line\":79,\"column\":24,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"complex\",\"endLine\":203,\"endColumn\":4},{\"ruleId\":\"prefer-destructuring\",\"severity\":1,\"message\":\"Use object destructuring.\",\"line\":100,\"column\":7,\"nodeType\":\"AssignmentExpression\",\"messageId\":\"preferDestructuring\",\"endLine\":100,\"endColumn\":46},{\"ruleId\":\"prefer-destructuring\",\"severity\":1,\"message\":\"Use object destructuring.\",\"line\":101,\"column\":7,\"nodeType\":\"AssignmentExpression\",\"messageId\":\"preferDestructuring\",\"endLine\":101,\"endColumn\":48},{\"ruleId\":\"prefer-destructuring\",\"severity\":1,\"message\":\"Use object destructuring.\",\"line\":171,\"column\":7,\"nodeType\":\"AssignmentExpression\",\"messageId\":\"preferDestructuring\",\"endLine\":171,\"endColumn\":49},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":176,\"column\":43,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":176,\"endColumn\":44},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":176,\"column\":49,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":176,\"endColumn\":50},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":176,\"column\":49,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":176,\"endColumn\":50},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":176,\"column\":62,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":176,\"endColumn\":63},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":185,\"column\":56,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":185,\"endColumn\":57},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":185,\"column\":88,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":185,\"endColumn\":89},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":249,\"column\":62,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":249,\"endColumn\":63},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":249,\"column\":91,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":249,\"endColumn\":92}],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":14,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Speaker Diarization Manager\\n * Orchestrates speaker change detection and voice fingerprinting for comprehensive diarization\\n */\\n\\nimport { createEnhancedMemoryPool } from '../../../shared/utils/enhanced-memory-pool.js';\\nimport { createVoiceFingerprinting } from './voice-fingerprinting.js';\\nimport { createSpeakerChangeDetection } from './speaker-change-detection.js';\\n\\nexport const createDiarizationManager = (config = {}) => {\\n  const memoryPool = createEnhancedMemoryPool({\\n    maxPoolSize: config.maxPoolSize || 100,\\n    enableMetrics: true\\n  });\\n  memoryPool.initialize();\\n\\n  const state = {\\n    config: {\\n      frameSize: config.frameSize || 1024,\\n      hopSize: config.hopSize || 512,\\n      sampleRate: config.sampleRate || 44100,\\n      \\n      // Processing parameters\\n      enableChangeDetection: config.enableChangeDetection !== false,\\n      enableVoiceFingerprinting: config.enableVoiceFingerprinting !== false,\\n      minSpeakerDuration: config.minSpeakerDuration || 2000, // ms\\n      \\n      ...config\\n    },\\n    \\n    // Components\\n    voiceFingerprinting: null,\\n    changeDetection: null,\\n    \\n    // Current processing state\\n    currentSpeaker: null,\\n    speakerSegments: [],\\n    isInitialized: false,\\n    \\n    // Statistics\\n    stats: {\\n      totalFrames: 0,\\n      totalSpeakers: 0,\\n      totalSpeakerSwitches: 0,\\n      averageSegmentDuration: 0,\\n      confidence: 0\\n    }\\n  };\\n\\n  // Initialize components\\n  const initialize = () => {\\n    if (state.config.enableVoiceFingerprinting) {\\n      state.voiceFingerprinting = createVoiceFingerprinting(state.config);\\n    }\\n    \\n    if (state.config.enableChangeDetection) {\\n      state.changeDetection = createSpeakerChangeDetection(state.config);\\n    }\\n    \\n    state.isInitialized = true;\\n  };\\n\\n  // Register diarization result type\\n  memoryPool.registerFactory('DiarizationResult', () => ({\\n    _pooled: true,\\n    timestamp: 0,\\n    speakerId: null,\\n    confidence: 0,\\n    speakerChanged: false,\\n    segmentInfo: null,\\n    processing: {\\n      changeDetected: false,\\n      fingerprinted: false,\\n      processingTime: 0\\n    }\\n  }));\\n\\n  // Process audio frame for diarization\\n  const processFrame = (audioBuffer, timestamp = Date.now()) => {\\n    if (!state.isInitialized) {\\n      initialize();\\n    }\\n    \\n    const startTime = performance.now();\\n    let speakerId = null;\\n    let confidence = 0;\\n    let speakerChanged = false;\\n    let segmentInfo = null;\\n    \\n    // Run change detection\\n    let changeResult = null;\\n    if (state.changeDetection) {\\n      changeResult = state.changeDetection.processFrame(audioBuffer, timestamp);\\n    }\\n    \\n    // Run voice fingerprinting\\n    let fingerprintResult = null;\\n    if (state.voiceFingerprinting) {\\n      fingerprintResult = state.voiceFingerprinting.processAudioSegment(audioBuffer, timestamp);\\n      speakerId = fingerprintResult.speakerId;\\n      confidence = fingerprintResult.confidence;\\n    }\\n    \\n    // Combine results\\n    if (changeResult && changeResult.changeDetected) {\\n      // Speaker change detected, trust the change detection\\n      if (state.currentSpeaker) {\\n        // End current segment\\n        const segment = {\\n          speakerId: state.currentSpeaker.speakerId,\\n          startTime: state.currentSpeaker.startTime,\\n          endTime: timestamp,\\n          duration: timestamp - state.currentSpeaker.startTime,\\n          confidence: state.currentSpeaker.confidence\\n        };\\n        \\n        if (segment.duration >= state.config.minSpeakerDuration) {\\n          state.speakerSegments.push(segment);\\n          state.stats.totalSpeakerSwitches++;\\n        }\\n      }\\n      \\n      // Start new segment\\n      if (speakerId) {\\n        state.currentSpeaker = {\\n          speakerId,\\n          startTime: timestamp,\\n          confidence\\n        };\\n        speakerChanged = true;\\n        \\n        if (fingerprintResult && fingerprintResult.newSpeaker) {\\n          state.stats.totalSpeakers++;\\n        }\\n      }\\n      \\n      segmentInfo = changeResult.segment;\\n    } else if (speakerId && speakerId !== (state.currentSpeaker?.speakerId)) {\\n      // Voice fingerprinting detected different speaker\\n      if (confidence > 0.7) { // High confidence threshold\\n        if (state.currentSpeaker) {\\n          // End current segment\\n          const segment = {\\n            speakerId: state.currentSpeaker.speakerId,\\n            startTime: state.currentSpeaker.startTime,\\n            endTime: timestamp,\\n            duration: timestamp - state.currentSpeaker.startTime,\\n            confidence: state.currentSpeaker.confidence\\n          };\\n          \\n          if (segment.duration >= state.config.minSpeakerDuration) {\\n            state.speakerSegments.push(segment);\\n            state.stats.totalSpeakerSwitches++;\\n          }\\n        }\\n        \\n        // Start new segment\\n        state.currentSpeaker = {\\n          speakerId,\\n          startTime: timestamp,\\n          confidence\\n        };\\n        speakerChanged = true;\\n        \\n        if (fingerprintResult && fingerprintResult.newSpeaker) {\\n          state.stats.totalSpeakers++;\\n        }\\n      }\\n    } else if (state.currentSpeaker) {\\n      // Continue with current speaker\\n      speakerId = state.currentSpeaker.speakerId;\\n      \\n      // Update confidence with moving average\\n      if (confidence > 0) {\\n        state.currentSpeaker.confidence = \\n          state.currentSpeaker.confidence * 0.9 + confidence * 0.1;\\n      }\\n    }\\n    \\n    const processingTime = performance.now() - startTime;\\n    \\n    // Update statistics\\n    state.stats.totalFrames++;\\n    if (confidence > 0) {\\n      state.stats.confidence = (state.stats.confidence * (state.stats.totalFrames - 1) + \\n                               confidence) / state.stats.totalFrames;\\n    }\\n    \\n    // Create result\\n    const result = memoryPool.acquire('DiarizationResult');\\n    result.timestamp = timestamp;\\n    result.speakerId = speakerId;\\n    result.confidence = confidence;\\n    result.speakerChanged = speakerChanged;\\n    result.segmentInfo = segmentInfo;\\n    result.processing = {\\n      changeDetected: changeResult?.changeDetected || false,\\n      fingerprinted: fingerprintResult !== null,\\n      processingTime\\n    };\\n    \\n    return result;\\n  };\\n\\n  // Release diarization result\\n  const releaseResult = (result) => {\\n    memoryPool.release(result);\\n  };\\n\\n  // Get all speaker segments\\n  const getSegments = () => {\\n    const allSegments = [...state.speakerSegments];\\n    \\n    // Add current segment if it exists\\n    if (state.currentSpeaker) {\\n      const current = {\\n        speakerId: state.currentSpeaker.speakerId,\\n        startTime: state.currentSpeaker.startTime,\\n        endTime: Date.now(),\\n        duration: Date.now() - state.currentSpeaker.startTime,\\n        confidence: state.currentSpeaker.confidence,\\n        active: true\\n      };\\n      allSegments.push(current);\\n    }\\n    \\n    return allSegments;\\n  };\\n\\n  // Get speaker information\\n  const getSpeakerInfo = () => {\\n    const speakers = new Map();\\n    \\n    for (const segment of state.speakerSegments) {\\n      if (!speakers.has(segment.speakerId)) {\\n        speakers.set(segment.speakerId, {\\n          speakerId: segment.speakerId,\\n          totalDuration: 0,\\n          segmentCount: 0,\\n          averageConfidence: 0,\\n          firstAppearance: segment.startTime,\\n          lastAppearance: segment.endTime\\n        });\\n      }\\n      \\n      const speaker = speakers.get(segment.speakerId);\\n      speaker.totalDuration += segment.duration;\\n      speaker.segmentCount++;\\n      speaker.averageConfidence = (speaker.averageConfidence * (speaker.segmentCount - 1) + \\n                                  segment.confidence) / speaker.segmentCount;\\n      speaker.lastAppearance = Math.max(speaker.lastAppearance, segment.endTime);\\n    }\\n    \\n    return Array.from(speakers.values());\\n  };\\n\\n  // Get comprehensive statistics\\n  const getStats = () => ({\\n    ...state.stats,\\n    components: {\\n      voiceFingerprinting: state.voiceFingerprinting ? state.voiceFingerprinting.getStats() : null,\\n      changeDetection: state.changeDetection ? state.changeDetection.getStats() : null\\n    },\\n    memoryPool: memoryPool.getStats(),\\n    currentSegments: state.speakerSegments.length,\\n    activeSpeaker: state.currentSpeaker?.speakerId || null\\n  });\\n\\n  // Update configuration\\n  const updateConfig = (newConfig) => {\\n    Object.assign(state.config, newConfig);\\n    \\n    if (newConfig.voiceFingerprinting && state.voiceFingerprinting) {\\n      state.voiceFingerprinting.updateConfig(newConfig.voiceFingerprinting);\\n    }\\n    if (newConfig.changeDetection && state.changeDetection) {\\n      state.changeDetection.updateConfig(newConfig.changeDetection);\\n    }\\n  };\\n\\n  // Reset system\\n  const reset = () => {\\n    state.currentSpeaker = null;\\n    state.speakerSegments = [];\\n    state.stats = {\\n      totalFrames: 0,\\n      totalSpeakers: 0,\\n      totalSpeakerSwitches: 0,\\n      averageSegmentDuration: 0,\\n      confidence: 0\\n    };\\n    \\n    if (state.voiceFingerprinting) {\\n      state.voiceFingerprinting.resetSpeakers();\\n    }\\n    if (state.changeDetection) {\\n      state.changeDetection.reset();\\n    }\\n  };\\n\\n  // Cleanup\\n  const cleanup = () => {\\n    memoryPool.cleanup();\\n  };\\n\\n  return {\\n    processFrame,\\n    releaseResult,\\n    getSegments,\\n    getSpeakerInfo,\\n    getStats,\\n    updateConfig,\\n    reset,\\n    cleanup,\\n    isInitialized: () => state.isInitialized\\n  };\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/features/speech-analysis/audio/diarization/speaker-change-detection.js\",\"messages\":[{\"ruleId\":\"max-lines-per-function\",\"severity\":1,\"message\":\"Arrow function has too many lines (207). Maximum allowed is 150.\",\"line\":7,\"column\":45,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"exceed\",\"endLine\":285,\"endColumn\":2},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":40,\"column\":60,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":40,\"endColumn\":61},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":40,\"column\":71,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":40,\"endColumn\":72},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":40,\"column\":71,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":40,\"endColumn\":72},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":40,\"column\":82,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":40,\"endColumn\":83},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":51,\"column\":63,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":51,\"endColumn\":64},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":51,\"column\":69,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":51,\"endColumn\":70},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":198,\"column\":49,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":198,\"endColumn\":50},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":198,\"column\":83,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":198,\"endColumn\":84}],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":9,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Speaker Change Detection Module\\n * Detects speaker transitions using audio features and change point detection\\n */\\n\\n// Speaker change detection using audio features\\nexport const createSpeakerChangeDetection = (config = {}) => {\\n  const state = {\\n    config: {\\n      windowSize: config.windowSize || 2000, // ms\\n      stepSize: config.stepSize || 500, // ms\\n      changeThreshold: config.changeThreshold || 0.3,\\n      minSegmentDuration: config.minSegmentDuration || 1000, // ms\\n      \\n      // Feature parameters\\n      spectralFeatures: config.spectralFeatures !== false,\\n      pitchFeatures: config.pitchFeatures !== false,\\n      energyFeatures: config.energyFeatures !== false\\n    },\\n    \\n    // Sliding window for change detection\\n    featureHistory: [],\\n    currentSegment: null,\\n    segments: [],\\n    \\n    stats: {\\n      totalSegments: 0,\\n      averageSegmentDuration: 0,\\n      changePointsDetected: 0\\n    }\\n  };\\n\\n  // Extract features for change detection\\n  const extractFeatures = (audioBuffer) => {\\n    const features = {};\\n    \\n    if (state.config.spectralFeatures) {\\n      // Spectral centroid and rolloff\\n      const fft = performSimpleFFT(audioBuffer);\\n      const magnitudes = fft.map(bin => Math.sqrt(bin.real * bin.real + bin.imag * bin.imag));\\n      \\n      let weightedSum = 0, totalMagnitude = 0;\\n      for (let i = 0; i < magnitudes.length; i++) {\\n        weightedSum += i * magnitudes[i];\\n        totalMagnitude += magnitudes[i];\\n      }\\n      features.spectralCentroid = totalMagnitude > 0 ? weightedSum / totalMagnitude : 0;\\n      \\n      // Spectral rolloff (95% of energy)\\n      let cumulativeEnergy = 0;\\n      const totalEnergy = magnitudes.reduce((sum, mag) => sum + mag * mag, 0);\\n      const rolloffThreshold = totalEnergy * 0.95;\\n      \\n      for (let i = 0; i < magnitudes.length; i++) {\\n        cumulativeEnergy += magnitudes[i] * magnitudes[i];\\n        if (cumulativeEnergy >= rolloffThreshold) {\\n          features.spectralRolloff = i;\\n          break;\\n        }\\n      }\\n    }\\n    \\n    if (state.config.pitchFeatures) {\\n      // Simple pitch estimation using autocorrelation\\n      const pitch = estimatePitch(audioBuffer);\\n      features.pitch = pitch;\\n    }\\n    \\n    if (state.config.energyFeatures) {\\n      // RMS energy and zero crossing rate\\n      let rms = 0, zcr = 0;\\n      for (let i = 0; i < audioBuffer.length; i++) {\\n        rms += audioBuffer[i] * audioBuffer[i];\\n        if (i > 0 && Math.sign(audioBuffer[i]) !== Math.sign(audioBuffer[i - 1])) {\\n          zcr++;\\n        }\\n      }\\n      features.rms = Math.sqrt(rms / audioBuffer.length);\\n      features.zcr = zcr / (audioBuffer.length - 1);\\n    }\\n    \\n    return features;\\n  };\\n\\n  // Simple pitch estimation\\n  const estimatePitch = (audioBuffer) => {\\n    const sampleRate = 44100; // Assume standard rate\\n    const minPitch = 80, maxPitch = 400;\\n    const minPeriod = Math.floor(sampleRate / maxPitch);\\n    const maxPeriod = Math.floor(sampleRate / minPitch);\\n    \\n    let bestCorrelation = 0;\\n    let bestPeriod = minPeriod;\\n    \\n    for (let period = minPeriod; period <= maxPeriod && period < audioBuffer.length / 2; period++) {\\n      let correlation = 0;\\n      const samples = audioBuffer.length - period;\\n      \\n      for (let i = 0; i < samples; i++) {\\n        correlation += audioBuffer[i] * audioBuffer[i + period];\\n      }\\n      \\n      correlation /= samples;\\n      \\n      if (correlation > bestCorrelation) {\\n        bestCorrelation = correlation;\\n        bestPeriod = period;\\n      }\\n    }\\n    \\n    return bestCorrelation > 0.3 ? sampleRate / bestPeriod : 0;\\n  };\\n\\n  // Simple FFT for spectral analysis\\n  const performSimpleFFT = (audioBuffer) => {\\n    const N = Math.min(audioBuffer.length, 1024); // Limit size for performance\\n    const output = new Array(N / 2);\\n    \\n    for (let k = 0; k < N / 2; k++) {\\n      let sumReal = 0;\\n      let sumImag = 0;\\n      \\n      for (let n = 0; n < N; n++) {\\n        const angle = -2 * Math.PI * k * n / N;\\n        sumReal += audioBuffer[n] * Math.cos(angle);\\n        sumImag += audioBuffer[n] * Math.sin(angle);\\n      }\\n      \\n      output[k] = { real: sumReal, imag: sumImag };\\n    }\\n    \\n    return output;\\n  };\\n\\n  // Calculate feature distance\\n  const calculateFeatureDistance = (features1, features2) => {\\n    const keys = Object.keys(features1);\\n    let totalDistance = 0;\\n    let count = 0;\\n    \\n    for (const key of keys) {\\n      if (features2.hasOwnProperty(key)) {\\n        const val1 = features1[key];\\n        const val2 = features2[key];\\n        \\n        // Normalize based on feature type\\n        let distance;\\n        if (key === 'pitch') {\\n          distance = Math.abs(val1 - val2) / Math.max(val1, val2, 100); // Normalize by frequency\\n        } else if (key === 'spectralCentroid' || key === 'spectralRolloff') {\\n          distance = Math.abs(val1 - val2) / Math.max(val1, val2, 1);\\n        } else {\\n          distance = Math.abs(val1 - val2) / (Math.abs(val1) + Math.abs(val2) + 1e-10);\\n        }\\n        \\n        totalDistance += distance;\\n        count++;\\n      }\\n    }\\n    \\n    return count > 0 ? totalDistance / count : 1;\\n  };\\n\\n  // Process audio frame for change detection\\n  const processFrame = (audioBuffer, timestamp = Date.now()) => {\\n    const features = extractFeatures(audioBuffer);\\n    \\n    // Add to history\\n    state.featureHistory.push({ features, timestamp });\\n    \\n    // Remove old entries outside window\\n    const windowStart = timestamp - state.config.windowSize;\\n    state.featureHistory = state.featureHistory.filter(entry => entry.timestamp >= windowStart);\\n    \\n    // Detect change if we have enough history\\n    if (state.featureHistory.length >= 4) { // Need at least 4 points\\n      const recent = state.featureHistory.slice(-2);\\n      const older = state.featureHistory.slice(0, -2);\\n      \\n      // Calculate average features for each group\\n      const recentAvg = averageFeatures(recent);\\n      const olderAvg = averageFeatures(older);\\n      \\n      const distance = calculateFeatureDistance(recentAvg, olderAvg);\\n      \\n      // Check for speaker change\\n      if (distance > state.config.changeThreshold) {\\n        // End current segment if it exists and is long enough\\n        if (state.currentSegment && \\n            (timestamp - state.currentSegment.startTime) >= state.config.minSegmentDuration) {\\n          \\n          state.currentSegment.endTime = timestamp;\\n          state.currentSegment.duration = state.currentSegment.endTime - state.currentSegment.startTime;\\n          state.segments.push({ ...state.currentSegment });\\n          \\n          state.stats.totalSegments++;\\n          state.stats.averageSegmentDuration = \\n            (state.stats.averageSegmentDuration * (state.stats.totalSegments - 1) + \\n             state.currentSegment.duration) / state.stats.totalSegments;\\n          state.stats.changePointsDetected++;\\n        }\\n        \\n        // Start new segment\\n        state.currentSegment = {\\n          startTime: timestamp,\\n          endTime: null,\\n          duration: null,\\n          features: recentAvg,\\n          changeDistance: distance\\n        };\\n        \\n        return {\\n          changeDetected: true,\\n          timestamp,\\n          distance,\\n          segment: { ...state.currentSegment }\\n        };\\n      }\\n    }\\n    \\n    // Initialize first segment\\n    if (!state.currentSegment) {\\n      state.currentSegment = {\\n        startTime: timestamp,\\n        endTime: null,\\n        duration: null,\\n        features,\\n        changeDistance: 0\\n      };\\n    }\\n    \\n    return {\\n      changeDetected: false,\\n      timestamp,\\n      distance: 0,\\n      segment: state.currentSegment\\n    };\\n  };\\n\\n  // Calculate average features\\n  const averageFeatures = (entries) => {\\n    if (entries.length === 0) return {};\\n    \\n    const keys = Object.keys(entries[0].features);\\n    const avg = {};\\n    \\n    for (const key of keys) {\\n      avg[key] = entries.reduce((sum, entry) => sum + entry.features[key], 0) / entries.length;\\n    }\\n    \\n    return avg;\\n  };\\n\\n  // Get detected segments\\n  const getSegments = () => {\\n    const allSegments = [...state.segments];\\n    \\n    // Add current segment if it exists\\n    if (state.currentSegment) {\\n      const current = { ...state.currentSegment };\\n      current.endTime = Date.now();\\n      current.duration = current.endTime - current.startTime;\\n      allSegments.push(current);\\n    }\\n    \\n    return allSegments;\\n  };\\n\\n  return {\\n    processFrame,\\n    getSegments,\\n    getStats: () => ({ ...state.stats }),\\n    updateConfig: (newConfig) => Object.assign(state.config, newConfig),\\n    reset: () => {\\n      state.featureHistory = [];\\n      state.currentSegment = null;\\n      state.segments = [];\\n      state.stats = {\\n        totalSegments: 0,\\n        averageSegmentDuration: 0,\\n        changePointsDetected: 0\\n      };\\n    }\\n  };\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/features/speech-analysis/audio/diarization/voice-fingerprinting.js\",\"messages\":[{\"ruleId\":\"max-lines-per-function\",\"severity\":1,\"message\":\"Arrow function has too many lines (230). Maximum allowed is 150.\",\"line\":7,\"column\":42,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"exceed\",\"endLine\":314,\"endColumn\":2},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '/' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":43,\"column\":44,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":43,\"endColumn\":45},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '/' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":43,\"column\":48,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":43,\"endColumn\":49},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '/'. Use parentheses to clarify the intended order of operations.\",\"line\":49,\"column\":26,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":49,\"endColumn\":27},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '/'. Use parentheses to clarify the intended order of operations.\",\"line\":49,\"column\":51,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":49,\"endColumn\":52},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '/'. Use parentheses to clarify the intended order of operations.\",\"line\":83,\"column\":50,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":83,\"endColumn\":51},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '/'. Use parentheses to clarify the intended order of operations.\",\"line\":83,\"column\":57,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":83,\"endColumn\":58},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":89,\"column\":51,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":89,\"endColumn\":52},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":89,\"column\":62,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":89,\"endColumn\":63},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":89,\"column\":62,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":89,\"endColumn\":63},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":89,\"column\":73,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":89,\"endColumn\":74},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":199,\"column\":52,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":199,\"endColumn\":53},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":199,\"column\":71,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":199,\"endColumn\":72},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":260,\"column\":38,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":260,\"endColumn\":39},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":260,\"column\":55,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":260,\"endColumn\":56},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":260,\"column\":55,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":260,\"endColumn\":56},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":260,\"column\":63,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":260,\"endColumn\":64},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":261,\"column\":42,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":261,\"endColumn\":43},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":261,\"column\":63,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":261,\"endColumn\":64},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":261,\"column\":63,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":261,\"endColumn\":64},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":261,\"column\":71,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":261,\"endColumn\":72},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":273,\"column\":68,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":273,\"endColumn\":69},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":273,\"column\":113,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":273,\"endColumn\":114}],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":23,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Voice Fingerprinting Module\\n * Advanced speaker identification using MFCC features and acoustic fingerprinting\\n */\\n\\n// Voice fingerprinting using MFCC features\\nexport const createVoiceFingerprinting = (config = {}) => {\\n  const state = {\\n    config: {\\n      frameSize: config.frameSize || 1024,\\n      hopSize: config.hopSize || 512,\\n      sampleRate: config.sampleRate || 44100,\\n      mfccCoefficients: config.mfccCoefficients || 13,\\n      melFilters: config.melFilters || 26,\\n      minFreq: config.minFreq || 80,\\n      maxFreq: config.maxFreq || 8000,\\n      \\n      // Fingerprint parameters\\n      fingerprintLength: config.fingerprintLength || 50, // Number of MFCC frames\\n      updateThreshold: config.updateThreshold || 0.8, // Similarity threshold for updates\\n      minSpeechDuration: config.minSpeechDuration || 1000 // ms\\n    },\\n    \\n    // Speaker fingerprints database\\n    fingerprints: new Map(),\\n    speakerCounter: 0,\\n    \\n    // Mel filter bank\\n    melFilterBank: null,\\n    \\n    // Statistics\\n    stats: {\\n      totalSpeakers: 0,\\n      totalFingerprints: 0,\\n      averageSimilarity: 0,\\n      identificationsPerformed: 0\\n    }\\n  };\\n\\n  // Initialize mel filter bank\\n  const initializeMelFilterBank = () => {\\n    const nyquist = state.config.sampleRate / 2;\\n    const fftSize = state.config.frameSize / 2 + 1;\\n    const melLow = melScale(state.config.minFreq);\\n    const melHigh = melScale(state.config.maxFreq);\\n    \\n    const melPoints = [];\\n    for (let i = 0; i <= state.config.melFilters + 1; i++) {\\n      const mel = melLow + (melHigh - melLow) * i / (state.config.melFilters + 1);\\n      melPoints.push(invMelScale(mel));\\n    }\\n    \\n    // Convert to FFT bin indices\\n    const binPoints = melPoints.map(freq => Math.floor(freq * fftSize / nyquist));\\n    \\n    // Create triangular filters\\n    state.melFilterBank = [];\\n    for (let i = 1; i <= state.config.melFilters; i++) {\\n      const filter = new Float32Array(fftSize);\\n      const left = binPoints[i - 1];\\n      const center = binPoints[i];\\n      const right = binPoints[i + 1];\\n      \\n      // Left slope\\n      for (let j = left; j <= center; j++) {\\n        if (center > left) {\\n          filter[j] = (j - left) / (center - left);\\n        }\\n      }\\n      \\n      // Right slope\\n      for (let j = center; j <= right; j++) {\\n        if (right > center) {\\n          filter[j] = (right - j) / (right - center);\\n        }\\n      }\\n      \\n      state.melFilterBank.push(filter);\\n    }\\n  };\\n\\n  // Mel scale conversion\\n  const melScale = (freq) => 2595 * Math.log10(1 + freq / 700);\\n  const invMelScale = (mel) => 700 * (Math.pow(10, mel / 2595) - 1);\\n\\n  // Calculate MFCC features from audio\\n  const calculateMFCC = (audioBuffer) => {\\n    const fft = performFFT(audioBuffer);\\n    const powerSpectrum = fft.map(bin => bin.real * bin.real + bin.imag * bin.imag);\\n    \\n    // Apply mel filter bank\\n    const melEnergies = new Array(state.config.melFilters);\\n    for (let i = 0; i < state.config.melFilters; i++) {\\n      let energy = 0;\\n      for (let j = 0; j < powerSpectrum.length; j++) {\\n        energy += powerSpectrum[j] * state.melFilterBank[i][j];\\n      }\\n      melEnergies[i] = Math.log(energy + 1e-10); // Add small epsilon\\n    }\\n    \\n    // Discrete Cosine Transform\\n    const mfccCoeffs = new Array(state.config.mfccCoefficients);\\n    for (let i = 0; i < state.config.mfccCoefficients; i++) {\\n      let coeff = 0;\\n      for (let j = 0; j < state.config.melFilters; j++) {\\n        coeff += melEnergies[j] * Math.cos(i * (j + 0.5) * Math.PI / state.config.melFilters);\\n      }\\n      mfccCoeffs[i] = coeff;\\n    }\\n    \\n    return mfccCoeffs;\\n  };\\n\\n  // Simple FFT implementation\\n  const performFFT = (audioBuffer) => {\\n    const N = audioBuffer.length;\\n    const output = new Array(N);\\n    \\n    for (let k = 0; k < N; k++) {\\n      let sumReal = 0;\\n      let sumImag = 0;\\n      \\n      for (let n = 0; n < N; n++) {\\n        const angle = -2 * Math.PI * k * n / N;\\n        sumReal += audioBuffer[n] * Math.cos(angle);\\n        sumImag += audioBuffer[n] * Math.sin(angle);\\n      }\\n      \\n      output[k] = { real: sumReal, imag: sumImag };\\n    }\\n    \\n    return output;\\n  };\\n\\n  // Create voice fingerprint from MFCC sequence\\n  const createFingerprint = (mfccSequence) => {\\n    if (mfccSequence.length < state.config.fingerprintLength) {\\n      return null;\\n    }\\n    \\n    // Use statistical measures across the sequence\\n    const fingerprint = {\\n      mean: new Array(state.config.mfccCoefficients).fill(0),\\n      variance: new Array(state.config.mfccCoefficients).fill(0),\\n      delta: new Array(state.config.mfccCoefficients).fill(0),\\n      deltaDelta: new Array(state.config.mfccCoefficients).fill(0)\\n    };\\n    \\n    // Calculate means\\n    for (const frame of mfccSequence) {\\n      for (let i = 0; i < state.config.mfccCoefficients; i++) {\\n        fingerprint.mean[i] += frame[i];\\n      }\\n    }\\n    for (let i = 0; i < state.config.mfccCoefficients; i++) {\\n      fingerprint.mean[i] /= mfccSequence.length;\\n    }\\n    \\n    // Calculate variances\\n    for (const frame of mfccSequence) {\\n      for (let i = 0; i < state.config.mfccCoefficients; i++) {\\n        const diff = frame[i] - fingerprint.mean[i];\\n        fingerprint.variance[i] += diff * diff;\\n      }\\n    }\\n    for (let i = 0; i < state.config.mfccCoefficients; i++) {\\n      fingerprint.variance[i] /= mfccSequence.length;\\n    }\\n    \\n    // Calculate delta coefficients (derivatives)\\n    if (mfccSequence.length >= 3) {\\n      for (let t = 1; t < mfccSequence.length - 1; t++) {\\n        for (let i = 0; i < state.config.mfccCoefficients; i++) {\\n          fingerprint.delta[i] += (mfccSequence[t + 1][i] - mfccSequence[t - 1][i]) / 2;\\n        }\\n      }\\n      for (let i = 0; i < state.config.mfccCoefficients; i++) {\\n        fingerprint.delta[i] /= (mfccSequence.length - 2);\\n      }\\n    }\\n    \\n    return fingerprint;\\n  };\\n\\n  // Calculate similarity between fingerprints\\n  const calculateSimilarity = (fp1, fp2) => {\\n    if (!fp1 || !fp2) return 0;\\n    \\n    let totalDistance = 0;\\n    let components = 0;\\n    \\n    // Mean similarity (using cosine similarity)\\n    let dot = 0, norm1 = 0, norm2 = 0;\\n    for (let i = 0; i < state.config.mfccCoefficients; i++) {\\n      dot += fp1.mean[i] * fp2.mean[i];\\n      norm1 += fp1.mean[i] * fp1.mean[i];\\n      norm2 += fp2.mean[i] * fp2.mean[i];\\n    }\\n    const meanSimilarity = dot / (Math.sqrt(norm1) * Math.sqrt(norm2) + 1e-10);\\n    totalDistance += meanSimilarity;\\n    components++;\\n    \\n    // Variance similarity (using negative normalized difference)\\n    let varianceDiff = 0;\\n    for (let i = 0; i < state.config.mfccCoefficients; i++) {\\n      varianceDiff += Math.abs(fp1.variance[i] - fp2.variance[i]) / \\n                      (Math.max(fp1.variance[i], fp2.variance[i]) + 1e-10);\\n    }\\n    const varianceSimilarity = 1 - (varianceDiff / state.config.mfccCoefficients);\\n    totalDistance += varianceSimilarity;\\n    components++;\\n    \\n    return totalDistance / components;\\n  };\\n\\n  // Process audio segment and return speaker identification\\n  const processAudioSegment = (audioBuffer, timestamp = Date.now()) => {\\n    if (!state.melFilterBank) {\\n      initializeMelFilterBank();\\n    }\\n    \\n    const mfccFeatures = calculateMFCC(audioBuffer);\\n    \\n    // For longer segments, collect multiple MFCC frames\\n    const mfccSequence = [mfccFeatures]; // In real implementation, collect over time\\n    const fingerprint = createFingerprint(mfccSequence);\\n    \\n    if (!fingerprint) {\\n      return {\\n        speakerId: null,\\n        confidence: 0,\\n        newSpeaker: false,\\n        timestamp\\n      };\\n    }\\n    \\n    // Find best matching speaker\\n    let bestMatch = null;\\n    let bestSimilarity = 0;\\n    \\n    for (const [speakerId, storedFingerprint] of state.fingerprints.entries()) {\\n      const similarity = calculateSimilarity(fingerprint, storedFingerprint);\\n      if (similarity > bestSimilarity) {\\n        bestSimilarity = similarity;\\n        bestMatch = speakerId;\\n      }\\n    }\\n    \\n    let speakerId;\\n    let newSpeaker = false;\\n    \\n    if (bestSimilarity > state.config.updateThreshold) {\\n      // Existing speaker\\n      speakerId = bestMatch;\\n      \\n      // Update fingerprint (adaptive learning)\\n      const stored = state.fingerprints.get(speakerId);\\n      const alpha = 0.1; // Learning rate\\n      for (let i = 0; i < state.config.mfccCoefficients; i++) {\\n        stored.mean[i] = (1 - alpha) * stored.mean[i] + alpha * fingerprint.mean[i];\\n        stored.variance[i] = (1 - alpha) * stored.variance[i] + alpha * fingerprint.variance[i];\\n      }\\n    } else {\\n      // New speaker\\n      speakerId = `speaker_${++state.speakerCounter}`;\\n      state.fingerprints.set(speakerId, fingerprint);\\n      newSpeaker = true;\\n      state.stats.totalSpeakers++;\\n    }\\n    \\n    // Update statistics\\n    state.stats.identificationsPerformed++;\\n    state.stats.averageSimilarity = (state.stats.averageSimilarity * (state.stats.identificationsPerformed - 1) + \\n                                   bestSimilarity) / state.stats.identificationsPerformed;\\n    \\n    return {\\n      speakerId,\\n      confidence: bestSimilarity,\\n      newSpeaker,\\n      fingerprint,\\n      timestamp\\n    };\\n  };\\n\\n  // Get speaker information\\n  const getSpeakerInfo = (speakerId) => {\\n    const fingerprint = state.fingerprints.get(speakerId);\\n    if (!fingerprint) return null;\\n    \\n    return {\\n      speakerId,\\n      fingerprintExists: true,\\n      mfccDimensions: state.config.mfccCoefficients,\\n      lastUpdated: Date.now()\\n    };\\n  };\\n\\n  // Reset speaker database\\n  const resetSpeakers = () => {\\n    state.fingerprints.clear();\\n    state.speakerCounter = 0;\\n    state.stats.totalSpeakers = 0;\\n  };\\n\\n  return {\\n    processAudioSegment,\\n    getSpeakerInfo,\\n    resetSpeakers,\\n    getStats: () => ({ ...state.stats }),\\n    updateConfig: (newConfig) => Object.assign(state.config, newConfig),\\n    getSpeakerCount: () => state.fingerprints.size,\\n    getAllSpeakers: () => Array.from(state.fingerprints.keys())\\n  };\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/features/speech-analysis/audio/emotion-classifier.js\",\"messages\":[{\"ruleId\":\"max-lines-per-function\",\"severity\":1,\"message\":\"Arrow function has too many lines (189). Maximum allowed is 150.\",\"line\":7,\"column\":40,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"exceed\",\"endLine\":266,\"endColumn\":2},{\"ruleId\":\"complexity\",\"severity\":1,\"message\":\"Arrow function has a complexity of 39. Maximum allowed is 20.\",\"line\":43,\"column\":27,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"complex\",\"endLine\":171,\"endColumn\":4},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":151,\"column\":40,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":151,\"endColumn\":41},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":151,\"column\":44,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":151,\"endColumn\":45},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '/'. Use parentheses to clarify the intended order of operations.\",\"line\":151,\"column\":69,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":151,\"endColumn\":70},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '/'. Use parentheses to clarify the intended order of operations.\",\"line\":151,\"column\":80,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":151,\"endColumn\":81},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":198,\"column\":46,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":198,\"endColumn\":47},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":198,\"column\":77,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":198,\"endColumn\":78},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":198,\"column\":77,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":198,\"endColumn\":78},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":199,\"column\":44,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":199,\"endColumn\":45},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":233,\"column\":68,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":233,\"endColumn\":69},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":233,\"column\":109,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":233,\"endColumn\":110}],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":12,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Emotion Classification Module\\n * Classifies emotions based on prosodic features using rule-based and ML approaches\\n */\\n\\n// Emotion classification using prosodic features\\nexport const createEmotionClassifier = (config = {}) => {\\n  const state = {\\n    config: {\\n      // Classification parameters\\n      windowSize: config.windowSize || 5, // frames to analyze\\n      confidenceThreshold: config.confidenceThreshold || 0.6,\\n      smoothingFactor: config.smoothingFactor || 0.3,\\n      \\n      // Emotion model parameters\\n      emotions: config.emotions || ['neutral', 'happy', 'sad', 'angry', 'fearful', 'surprised'],\\n      useArousalValence: config.useArousalValence !== false\\n    },\\n    \\n    // Feature buffer for classification\\n    featureBuffer: [],\\n    \\n    // Emotion history for smoothing\\n    emotionHistory: [],\\n    currentEmotion: 'neutral',\\n    currentConfidence: 0,\\n    \\n    // Statistics\\n    stats: {\\n      totalClassifications: 0,\\n      emotionCounts: {},\\n      averageConfidence: 0,\\n      transitionCount: 0\\n    }\\n  };\\n\\n  // Initialize emotion counts\\n  state.config.emotions.forEach(emotion => {\\n    state.stats.emotionCounts[emotion] = 0;\\n  });\\n\\n  // Simple emotion classification using prosodic features\\n  const classifyEmotion = (features) => {\\n    if (features.length < state.config.windowSize) {\\n      return {\\n        emotion: 'neutral',\\n        confidence: 0.5,\\n        scores: {},\\n        arousal: 0,\\n        valence: 0\\n      };\\n    }\\n    \\n    // Calculate aggregate features over window\\n    const validFeatures = features.filter(f => f.pitch > 0);\\n    if (validFeatures.length === 0) {\\n      return {\\n        emotion: 'neutral',\\n        confidence: 0.3,\\n        scores: {},\\n        arousal: 0,\\n        valence: 0\\n      };\\n    }\\n    \\n    // Aggregate prosodic features\\n    const avgPitch = validFeatures.reduce((sum, f) => sum + f.pitch, 0) / validFeatures.length;\\n    const avgEnergy = features.reduce((sum, f) => sum + f.energy.rms, 0) / features.length;\\n    const avgTempo = features.reduce((sum, f) => sum + f.timing.tempo, 0) / features.length;\\n    \\n    const pitchVar = Math.sqrt(\\n      validFeatures.reduce((sum, f) => sum + Math.pow(f.pitch - avgPitch, 2), 0) / validFeatures.length\\n    );\\n    const energyVar = Math.sqrt(\\n      features.reduce((sum, f) => sum + Math.pow(f.energy.rms - avgEnergy, 2), 0) / features.length\\n    );\\n    \\n    // Simple rule-based classification (can be replaced with ML model)\\n    const scores = {};\\n    \\n    // Happy: Higher pitch, higher energy, more variability\\n    scores.happy = \\n      (avgPitch > 180 ? 0.3 : 0) + \\n      (avgEnergy > 0.15 ? 0.3 : 0) + \\n      (pitchVar > 30 ? 0.2 : 0) + \\n      (avgTempo > 1.1 ? 0.2 : 0);\\n    \\n    // Sad: Lower pitch, lower energy, less variability\\n    scores.sad = \\n      (avgPitch < 120 ? 0.4 : 0) + \\n      (avgEnergy < 0.08 ? 0.3 : 0) + \\n      (pitchVar < 20 ? 0.2 : 0) + \\n      (avgTempo < 0.9 ? 0.1 : 0);\\n    \\n    // Angry: Higher pitch, much higher energy, high variability\\n    scores.angry = \\n      (avgPitch > 200 ? 0.2 : 0) + \\n      (avgEnergy > 0.25 ? 0.4 : 0) + \\n      (pitchVar > 50 ? 0.2 : 0) + \\n      (energyVar > 0.1 ? 0.2 : 0);\\n    \\n    // Fearful: Higher pitch, moderate energy, high variability\\n    scores.fearful = \\n      (avgPitch > 220 ? 0.3 : 0) + \\n      (avgEnergy > 0.12 && avgEnergy < 0.2 ? 0.2 : 0) + \\n      (pitchVar > 40 ? 0.3 : 0) + \\n      (avgTempo > 1.2 ? 0.2 : 0);\\n    \\n    // Surprised: Sudden pitch/energy changes\\n    const recentChanges = features.slice(-3);\\n    const pitchChange = recentChanges.length >= 2 ? \\n      Math.abs(recentChanges[recentChanges.length - 1].pitch - recentChanges[0].pitch) : 0;\\n    const energyChange = recentChanges.length >= 2 ? \\n      Math.abs(recentChanges[recentChanges.length - 1].energy.rms - recentChanges[0].energy.rms) : 0;\\n    \\n    scores.surprised = \\n      (pitchChange > 50 ? 0.4 : 0) + \\n      (energyChange > 0.1 ? 0.3 : 0) + \\n      (avgEnergy > 0.15 ? 0.2 : 0) + \\n      (avgTempo > 1.3 ? 0.1 : 0);\\n    \\n    // Neutral: Moderate values, low variability\\n    scores.neutral = \\n      (avgPitch > 130 && avgPitch < 180 ? 0.3 : 0) + \\n      (avgEnergy > 0.08 && avgEnergy < 0.2 ? 0.3 : 0) + \\n      (pitchVar < 25 ? 0.2 : 0) + \\n      (avgTempo > 0.9 && avgTempo < 1.1 ? 0.2 : 0);\\n    \\n    // Find dominant emotion\\n    let maxScore = 0;\\n    let dominantEmotion = 'neutral';\\n    \\n    for (const [emotion, score] of Object.entries(scores)) {\\n      if (score > maxScore) {\\n        maxScore = score;\\n        dominantEmotion = emotion;\\n      }\\n    }\\n    \\n    // Calculate confidence based on score separation\\n    const sortedScores = Object.values(scores).sort((a, b) => b - a);\\n    const confidence = sortedScores.length > 1 ? \\n      (sortedScores[0] - sortedScores[1]) / sortedScores[0] : 0.5;\\n    \\n    // Calculate arousal and valence if enabled\\n    let arousal = 0;\\n    let valence = 0;\\n    \\n    if (state.config.useArousalValence) {\\n      // Arousal: Energy + Tempo + Pitch Variability\\n      arousal = Math.min(1, (avgEnergy * 2 + Math.abs(avgTempo - 1) + pitchVar / 100));\\n      \\n      // Valence: Happy/Surprised positive, Sad/Angry/Fearful negative\\n      const positiveEmotions = ['happy', 'surprised'];\\n      const negativeEmotions = ['sad', 'angry', 'fearful'];\\n      \\n      if (positiveEmotions.includes(dominantEmotion)) {\\n        valence = maxScore;\\n      } else if (negativeEmotions.includes(dominantEmotion)) {\\n        valence = -maxScore;\\n      }\\n    }\\n    \\n    return {\\n      emotion: dominantEmotion,\\n      confidence: Math.max(0, Math.min(1, confidence)),\\n      scores,\\n      arousal,\\n      valence\\n    };\\n  };\\n\\n  // Apply temporal smoothing to emotion classification\\n  const smoothEmotion = (emotionResult) => {\\n    state.emotionHistory.push(emotionResult);\\n    \\n    // Maintain history size\\n    if (state.emotionHistory.length > 10) {\\n      state.emotionHistory.shift();\\n    }\\n    \\n    if (state.emotionHistory.length < 3) {\\n      return emotionResult;\\n    }\\n    \\n    // Simple temporal smoothing - require consistency for emotion changes\\n    const recentEmotions = state.emotionHistory.slice(-3);\\n    const currentEmotionCount = recentEmotions.filter(e => e.emotion === emotionResult.emotion).length;\\n    \\n    if (currentEmotionCount >= 2 || emotionResult.confidence > 0.8) {\\n      // High confidence or consistent emotion\\n      return emotionResult;\\n    } else {\\n      // Low confidence, maintain previous emotion but update confidence\\n      return {\\n        ...emotionResult,\\n        emotion: state.currentEmotion,\\n        confidence: emotionResult.confidence * state.config.smoothingFactor + \\n                   state.currentConfidence * (1 - state.config.smoothingFactor)\\n      };\\n    }\\n  };\\n\\n  // Process features and return emotion classification\\n  const processFeatures = (features) => {\\n    // Add features to buffer\\n    if (Array.isArray(features)) {\\n      state.featureBuffer = features.slice(-state.config.windowSize);\\n    } else {\\n      state.featureBuffer.push(features);\\n      if (state.featureBuffer.length > state.config.windowSize) {\\n        state.featureBuffer.shift();\\n      }\\n    }\\n    \\n    // Classify emotion\\n    const emotionResult = classifyEmotion(state.featureBuffer);\\n    \\n    // Apply temporal smoothing\\n    const smoothedResult = smoothEmotion(emotionResult);\\n    \\n    // Update state\\n    if (state.currentEmotion !== smoothedResult.emotion) {\\n      state.stats.transitionCount++;\\n    }\\n    \\n    state.currentEmotion = smoothedResult.emotion;\\n    state.currentConfidence = smoothedResult.confidence;\\n    \\n    // Update statistics\\n    state.stats.totalClassifications++;\\n    state.stats.emotionCounts[smoothedResult.emotion]++;\\n    state.stats.averageConfidence = (state.stats.averageConfidence * (state.stats.totalClassifications - 1) + \\n                                   smoothedResult.confidence) / state.stats.totalClassifications;\\n    \\n    return {\\n      ...smoothedResult,\\n      timestamp: Date.now()\\n    };\\n  };\\n\\n  return {\\n    processFeatures,\\n    getCurrentEmotion: () => state.currentEmotion,\\n    getCurrentConfidence: () => state.currentConfidence,\\n    getStats: () => ({ ...state.stats }),\\n    getEmotionHistory: () => [...state.emotionHistory],\\n    updateConfig: (newConfig) => Object.assign(state.config, newConfig),\\n    reset: () => {\\n      state.featureBuffer = [];\\n      state.emotionHistory = [];\\n      state.currentEmotion = 'neutral';\\n      state.currentConfidence = 0;\\n      state.stats = {\\n        totalClassifications: 0,\\n        emotionCounts: {},\\n        averageConfidence: 0,\\n        transitionCount: 0\\n      };\\n      // Reinitialize emotion counts\\n      state.config.emotions.forEach(emotion => {\\n        state.stats.emotionCounts[emotion] = 0;\\n      });\\n    }\\n  };\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/features/speech-analysis/audio/emotion-config.js\",\"messages\":[],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/features/speech-analysis/audio/emotion-detection.js\",\"messages\":[{\"ruleId\":\"max-lines-per-function\",\"severity\":1,\"message\":\"Arrow function has too many lines (186). Maximum allowed is 150.\",\"line\":13,\"column\":39,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"exceed\",\"endLine\":269,\"endColumn\":2},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":103,\"column\":36,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":103,\"endColumn\":37},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":103,\"column\":42,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":103,\"endColumn\":43},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":103,\"column\":42,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":103,\"endColumn\":43},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":103,\"column\":79,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":103,\"endColumn\":80},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":178,\"column\":23,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":178,\"endColumn\":24},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":178,\"column\":61,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":178,\"endColumn\":62},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":178,\"column\":61,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":178,\"endColumn\":62},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":178,\"column\":69,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":178,\"endColumn\":70},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":191,\"column\":21,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":191,\"endColumn\":22},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":191,\"column\":60,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":191,\"endColumn\":61},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":191,\"column\":60,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":191,\"endColumn\":61},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":191,\"column\":68,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":191,\"endColumn\":69},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":228,\"column\":60,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":228,\"endColumn\":61},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":228,\"column\":92,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":228,\"endColumn\":93},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":240,\"column\":60,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":240,\"endColumn\":61},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":240,\"column\":92,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":240,\"endColumn\":93},{\"ruleId\":\"max-lines-per-function\",\"severity\":1,\"message\":\"Arrow function has too many lines (202). Maximum allowed is 150.\",\"line\":272,\"column\":40,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"exceed\",\"endLine\":543,\"endColumn\":2},{\"ruleId\":\"complexity\",\"severity\":1,\"message\":\"Arrow function has a complexity of 42. Maximum allowed is 20.\",\"line\":308,\"column\":27,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"complex\",\"endLine\":441,\"endColumn\":4},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '/' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":411,\"column\":40,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":411,\"endColumn\":41},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '/' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":411,\"column\":46,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":411,\"endColumn\":47},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '/'. Use parentheses to clarify the intended order of operations.\",\"line\":411,\"column\":46,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":411,\"endColumn\":47},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '/'. Use parentheses to clarify the intended order of operations.\",\"line\":411,\"column\":57,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":411,\"endColumn\":58},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '/'. Use parentheses to clarify the intended order of operations.\",\"line\":411,\"column\":62,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":411,\"endColumn\":63},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '/'. Use parentheses to clarify the intended order of operations.\",\"line\":411,\"column\":73,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":411,\"endColumn\":74},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":467,\"column\":30,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":467,\"endColumn\":31},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":467,\"column\":54,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":467,\"endColumn\":55},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":467,\"column\":54,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":467,\"endColumn\":55},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":467,\"column\":82,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":467,\"endColumn\":83},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":473,\"column\":67,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":473,\"endColumn\":68},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":473,\"column\":85,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":473,\"endColumn\":86},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":473,\"column\":85,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":473,\"endColumn\":86},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":473,\"column\":102,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":473,\"endColumn\":103},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":501,\"column\":40,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":501,\"endColumn\":41},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":501,\"column\":81,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":501,\"endColumn\":82}],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":35,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Emotion Detection from Voice Module\\n * Advanced emotional state analysis from speech audio features\\n * Following functional programming patterns with factory functions\\n */\\n\\nimport { createEnhancedMemoryPool } from '../../../shared/utils/enhanced-memory-pool.js';\\nimport { createEmotionConfig, updateEmotionConfig } from './emotion-config.js';\\nimport { createEmotionProcessor } from './emotion-processor.js';\\nimport { createEmotionStats } from './emotion-stats.js';\\n\\n// Prosodic feature extraction for emotion detection\\nexport const createProsodicAnalyzer = (config = {}) => {\\n  const state = {\\n    config: {\\n      frameSize: config.frameSize || 1024,\\n      hopSize: config.hopSize || 512,\\n      sampleRate: config.sampleRate || 44100,\\n      \\n      // Prosodic parameters\\n      pitchRange: config.pitchRange || [80, 400], // Hz\\n      energySmoothing: config.energySmoothing || 0.3,\\n      timingWindowSize: config.timingWindowSize || 10, // frames\\n      \\n      // Feature normalization\\n      normalizeFeatures: config.normalizeFeatures !== false,\\n      adaptiveNormalization: config.adaptiveNormalization !== false\\n    },\\n    \\n    // Feature history for temporal analysis\\n    featureHistory: [],\\n    normalizationStats: {\\n      pitch: { mean: 150, std: 50 },\\n      energy: { mean: 0.1, std: 0.05 },\\n      tempo: { mean: 1.0, std: 0.3 }\\n    },\\n    \\n    // Statistics\\n    stats: {\\n      totalFrames: 0,\\n      averagePitch: 0,\\n      averageEnergy: 0,\\n      pitchVariability: 0,\\n      energyVariability: 0\\n    }\\n  };\\n\\n  // Extract pitch using autocorrelation\\n  const extractPitch = (audioBuffer) => {\\n    const [minPeriod, maxPeriod] = [\\n      Math.floor(state.config.sampleRate / state.config.pitchRange[1]),\\n      Math.floor(state.config.sampleRate / state.config.pitchRange[0])\\n    ];\\n    \\n    let bestCorrelation = 0;\\n    let bestPeriod = minPeriod;\\n    \\n    for (let period = minPeriod; period <= maxPeriod && period < audioBuffer.length / 2; period++) {\\n      let correlation = 0;\\n      const samples = audioBuffer.length - period;\\n      \\n      for (let i = 0; i < samples; i++) {\\n        correlation += audioBuffer[i] * audioBuffer[i + period];\\n      }\\n      \\n      correlation /= samples;\\n      \\n      // Normalize by energy\\n      let energy = 0;\\n      for (let i = 0; i < samples; i++) {\\n        energy += audioBuffer[i] * audioBuffer[i];\\n      }\\n      energy = Math.sqrt(energy / samples);\\n      \\n      if (energy > 0.001) { // Only consider frames with significant energy\\n        correlation /= (energy * energy);\\n        \\n        if (correlation > bestCorrelation) {\\n          bestCorrelation = correlation;\\n          bestPeriod = period;\\n        }\\n      }\\n    }\\n    \\n    // Convert to frequency\\n    const pitch = bestCorrelation > 0.3 ? state.config.sampleRate / bestPeriod : 0;\\n    \\n    // Apply smoothing and bounds checking\\n    return pitch > state.config.pitchRange[0] && pitch < state.config.pitchRange[1] ? pitch : 0;\\n  };\\n\\n  // Extract energy features\\n  const extractEnergy = (audioBuffer) => {\\n    // RMS energy\\n    let rms = 0;\\n    for (let i = 0; i < audioBuffer.length; i++) {\\n      rms += audioBuffer[i] * audioBuffer[i];\\n    }\\n    rms = Math.sqrt(rms / audioBuffer.length);\\n    \\n    // Short-time energy (with smoothing)\\n    const smoothed = state.stats.totalFrames > 0 ? \\n      state.config.energySmoothing * rms + (1 - state.config.energySmoothing) * state.stats.averageEnergy : \\n      rms;\\n    \\n    // Energy dynamics (difference from recent average)\\n    const recentFrames = state.featureHistory.slice(-5);\\n    const recentAvgEnergy = recentFrames.length > 0 ? \\n      recentFrames.reduce((sum, f) => sum + f.energy, 0) / recentFrames.length : rms;\\n    \\n    const energyDelta = rms - recentAvgEnergy;\\n    \\n    return {\\n      rms,\\n      smoothed,\\n      delta: energyDelta,\\n      relative: recentAvgEnergy > 0 ? rms / recentAvgEnergy : 1\\n    };\\n  };\\n\\n  // Extract timing features\\n  const extractTiming = (audioBuffer, timestamp) => {\\n    // Speaking rate estimation (simplified)\\n    let zeroCrossingRate = 0;\\n    for (let i = 1; i < audioBuffer.length; i++) {\\n      if ((audioBuffer[i] >= 0) !== (audioBuffer[i-1] >= 0)) {\\n        zeroCrossingRate++;\\n      }\\n    }\\n    zeroCrossingRate /= (audioBuffer.length - 1);\\n    \\n    // Tempo estimation from recent timing\\n    let tempo = 1.0;\\n    if (state.featureHistory.length >= 2) {\\n      const recent = state.featureHistory.slice(-state.config.timingWindowSize);\\n      const timeDiffs = [];\\n      for (let i = 1; i < recent.length; i++) {\\n        timeDiffs.push(recent[i].timestamp - recent[i-1].timestamp);\\n      }\\n      \\n      if (timeDiffs.length > 0) {\\n        const avgInterval = timeDiffs.reduce((sum, diff) => sum + diff, 0) / timeDiffs.length;\\n        tempo = avgInterval > 0 ? 1000 / avgInterval : 1.0; // Convert to relative rate\\n      }\\n    }\\n    \\n    // Rhythm variability\\n    const recentZCRs = state.featureHistory.slice(-5).map(f => f.timing.zcr);\\n    const zcrVariability = recentZCRs.length > 1 ? \\n      Math.sqrt(recentZCRs.reduce((sum, zcr) => sum + Math.pow(zcr - zeroCrossingRate, 2), 0) / recentZCRs.length) :\\n      0;\\n    \\n    return {\\n      zcr: zeroCrossingRate,\\n      tempo,\\n      rhythmVariability: zcrVariability,\\n      timestamp\\n    };\\n  };\\n\\n  // Normalize features adaptively\\n  const normalizeFeatures = (features) => {\\n    if (!state.config.normalizeFeatures) {\\n      return features;\\n    }\\n    \\n    const normalized = { ...features };\\n    \\n    // Normalize pitch\\n    if (features.pitch > 0) {\\n      normalized.pitchNorm = (features.pitch - state.normalizationStats.pitch.mean) / \\n                            state.normalizationStats.pitch.std;\\n      \\n      if (state.config.adaptiveNormalization && state.stats.totalFrames > 10) {\\n        // Update normalization stats\\n        const alpha = 0.01; // Learning rate\\n        state.normalizationStats.pitch.mean = \\n          (1 - alpha) * state.normalizationStats.pitch.mean + alpha * features.pitch;\\n      }\\n    } else {\\n      normalized.pitchNorm = 0;\\n    }\\n    \\n    // Normalize energy\\n    normalized.energyNorm = (features.energy.rms - state.normalizationStats.energy.mean) / \\n                           state.normalizationStats.energy.std;\\n    \\n    if (state.config.adaptiveNormalization && state.stats.totalFrames > 10) {\\n      const alpha = 0.01;\\n      state.normalizationStats.energy.mean = \\n        (1 - alpha) * state.normalizationStats.energy.mean + alpha * features.energy.rms;\\n    }\\n    \\n    // Normalize tempo\\n    normalized.tempoNorm = (features.timing.tempo - state.normalizationStats.tempo.mean) / \\n                          state.normalizationStats.tempo.std;\\n    \\n    return normalized;\\n  };\\n\\n  // Process audio frame and extract prosodic features\\n  const processFrame = (audioBuffer, timestamp = Date.now()) => {\\n    const pitch = extractPitch(audioBuffer);\\n    const energy = extractEnergy(audioBuffer);\\n    const timing = extractTiming(audioBuffer, timestamp);\\n    \\n    const features = {\\n      pitch,\\n      energy,\\n      timing,\\n      timestamp\\n    };\\n    \\n    // Normalize features\\n    const normalizedFeatures = normalizeFeatures(features);\\n    \\n    // Add to history\\n    state.featureHistory.push(normalizedFeatures);\\n    \\n    // Maintain history size\\n    if (state.featureHistory.length > 100) {\\n      state.featureHistory.shift();\\n    }\\n    \\n    // Update statistics\\n    state.stats.totalFrames++;\\n    if (pitch > 0) {\\n      state.stats.averagePitch = (state.stats.averagePitch * (state.stats.totalFrames - 1) + pitch) / state.stats.totalFrames;\\n      \\n      // Calculate pitch variability\\n      const recentPitches = state.featureHistory.slice(-10).map(f => f.pitch).filter(p => p > 0);\\n      if (recentPitches.length > 1) {\\n        const pitchMean = recentPitches.reduce((sum, p) => sum + p, 0) / recentPitches.length;\\n        state.stats.pitchVariability = Math.sqrt(\\n          recentPitches.reduce((sum, p) => sum + Math.pow(p - pitchMean, 2), 0) / recentPitches.length\\n        );\\n      }\\n    }\\n    \\n    state.stats.averageEnergy = (state.stats.averageEnergy * (state.stats.totalFrames - 1) + energy.rms) / state.stats.totalFrames;\\n    \\n    // Calculate energy variability\\n    const recentEnergies = state.featureHistory.slice(-10).map(f => f.energy.rms);\\n    if (recentEnergies.length > 1) {\\n      const energyMean = recentEnergies.reduce((sum, e) => sum + e, 0) / recentEnergies.length;\\n      state.stats.energyVariability = Math.sqrt(\\n        recentEnergies.reduce((sum, e) => sum + Math.pow(e - energyMean, 2), 0) / recentEnergies.length\\n      );\\n    }\\n    \\n    return normalizedFeatures;\\n  };\\n\\n  return {\\n    processFrame,\\n    getStats: () => ({ ...state.stats }),\\n    updateConfig: (newConfig) => Object.assign(state.config, newConfig),\\n    reset: () => {\\n      state.featureHistory = [];\\n      state.stats = {\\n        totalFrames: 0,\\n        averagePitch: 0,\\n        averageEnergy: 0,\\n        pitchVariability: 0,\\n        energyVariability: 0\\n      };\\n    }\\n  };\\n};\\n\\n// Emotion classification using prosodic features\\nexport const createEmotionClassifier = (config = {}) => {\\n  const state = {\\n    config: {\\n      // Classification parameters\\n      windowSize: config.windowSize || 5, // frames to analyze\\n      confidenceThreshold: config.confidenceThreshold || 0.6,\\n      smoothingFactor: config.smoothingFactor || 0.3,\\n      \\n      // Emotion model parameters\\n      emotions: config.emotions || ['neutral', 'happy', 'sad', 'angry', 'fearful', 'surprised'],\\n      useArousalValence: config.useArousalValence !== false\\n    },\\n    \\n    // Feature buffer for classification\\n    featureBuffer: [],\\n    \\n    // Emotion history for smoothing\\n    emotionHistory: [],\\n    currentEmotion: 'neutral',\\n    currentConfidence: 0,\\n    \\n    // Statistics\\n    stats: {\\n      totalClassifications: 0,\\n      emotionCounts: {},\\n      averageConfidence: 0,\\n      transitionCount: 0\\n    }\\n  };\\n\\n  // Initialize emotion counts\\n  state.config.emotions.forEach(emotion => {\\n    state.stats.emotionCounts[emotion] = 0;\\n  });\\n\\n  // Simple emotion classification using prosodic features\\n  const classifyEmotion = (features) => {\\n    if (features.length < state.config.windowSize) {\\n      return {\\n        emotion: 'neutral',\\n        confidence: 0.5,\\n        scores: {},\\n        arousal: 0,\\n        valence: 0\\n      };\\n    }\\n    \\n    // Calculate aggregate features over window\\n    const validFeatures = features.filter(f => f.pitch > 0);\\n    if (validFeatures.length === 0) {\\n      return {\\n        emotion: 'neutral',\\n        confidence: 0.3,\\n        scores: {},\\n        arousal: 0,\\n        valence: 0\\n      };\\n    }\\n    \\n    // Aggregate prosodic features\\n    const avgPitch = validFeatures.reduce((sum, f) => sum + f.pitch, 0) / validFeatures.length;\\n    const avgEnergy = features.reduce((sum, f) => sum + f.energy.rms, 0) / features.length;\\n    const avgTempo = features.reduce((sum, f) => sum + f.timing.tempo, 0) / features.length;\\n    \\n    const pitchVar = Math.sqrt(\\n      validFeatures.reduce((sum, f) => sum + Math.pow(f.pitch - avgPitch, 2), 0) / validFeatures.length\\n    );\\n    const energyVar = Math.sqrt(\\n      features.reduce((sum, f) => sum + Math.pow(f.energy.rms - avgEnergy, 2), 0) / features.length\\n    );\\n    \\n    // Simple rule-based classification (can be replaced with ML model)\\n    const scores = {};\\n    \\n    // Happy: Higher pitch, higher energy, more variability\\n    scores.happy = \\n      (avgPitch > 180 ? 0.3 : 0) + \\n      (avgEnergy > 0.15 ? 0.3 : 0) + \\n      (pitchVar > 30 ? 0.2 : 0) + \\n      (avgTempo > 1.1 ? 0.2 : 0);\\n    \\n    // Sad: Lower pitch, lower energy, less variability\\n    scores.sad = \\n      (avgPitch < 120 ? 0.4 : 0) + \\n      (avgEnergy < 0.08 ? 0.3 : 0) + \\n      (pitchVar < 20 ? 0.2 : 0) + \\n      (avgTempo < 0.9 ? 0.1 : 0);\\n    \\n    // Angry: Higher pitch, much higher energy, high variability\\n    scores.angry = \\n      (avgPitch > 200 ? 0.2 : 0) + \\n      (avgEnergy > 0.25 ? 0.4 : 0) + \\n      (pitchVar > 50 ? 0.2 : 0) + \\n      (energyVar > 0.1 ? 0.2 : 0);\\n    \\n    // Fearful: Higher pitch, moderate energy, high variability\\n    scores.fearful = \\n      (avgPitch > 220 ? 0.3 : 0) + \\n      (avgEnergy > 0.12 && avgEnergy < 0.2 ? 0.2 : 0) + \\n      (pitchVar > 40 ? 0.3 : 0) + \\n      (avgTempo > 1.2 ? 0.2 : 0);\\n    \\n    // Surprised: Sudden pitch/energy changes\\n    const recentChanges = features.slice(-3);\\n    const pitchChange = recentChanges.length >= 2 ? \\n      Math.abs(recentChanges[recentChanges.length - 1].pitch - recentChanges[0].pitch) : 0;\\n    const energyChange = recentChanges.length >= 2 ? \\n      Math.abs(recentChanges[recentChanges.length - 1].energy.rms - recentChanges[0].energy.rms) : 0;\\n    \\n    scores.surprised = \\n      (pitchChange > 50 ? 0.4 : 0) + \\n      (energyChange > 0.1 ? 0.3 : 0) + \\n      (avgEnergy > 0.15 ? 0.2 : 0) + \\n      (avgTempo > 1.3 ? 0.1 : 0);\\n    \\n    // Neutral: Moderate values, low variability\\n    scores.neutral = \\n      (avgPitch > 130 && avgPitch < 180 ? 0.3 : 0) + \\n      (avgEnergy > 0.08 && avgEnergy < 0.2 ? 0.3 : 0) + \\n      (pitchVar < 25 ? 0.2 : 0) + \\n      (avgTempo > 0.9 && avgTempo < 1.1 ? 0.2 : 0);\\n    \\n    // Find dominant emotion\\n    let maxScore = 0;\\n    let dominantEmotion = 'neutral';\\n    \\n    for (const [emotion, score] of Object.entries(scores)) {\\n      if (score > maxScore) {\\n        maxScore = score;\\n        dominantEmotion = emotion;\\n      }\\n    }\\n    \\n    // Calculate arousal and valence for dimensional model\\n    let arousal = 0; // Energy/activation level\\n    let valence = 0; // Positive/negative sentiment\\n    \\n    if (state.config.useArousalValence) {\\n      // Arousal: based on energy and pitch variability\\n      arousal = Math.min(1, (avgEnergy / 0.3 + pitchVar / 60 + avgTempo / 1.5) / 3);\\n      \\n      // Valence: based on pitch and energy patterns\\n      if (dominantEmotion === 'happy') valence = 0.8;\\n      else if (dominantEmotion === 'sad') valence = -0.7;\\n      else if (dominantEmotion === 'angry') valence = -0.6;\\n      else if (dominantEmotion === 'fearful') valence = -0.5;\\n      else if (dominantEmotion === 'surprised') valence = 0.2;\\n      else valence = 0;\\n    }\\n    \\n    // Confidence based on score separation\\n    const sortedScores = Object.values(scores).sort((a, b) => b - a);\\n    const confidence = sortedScores.length >= 2 ? \\n      Math.min(1, maxScore / Math.max(sortedScores[1], 0.1)) : maxScore;\\n    \\n    return {\\n      emotion: dominantEmotion,\\n      confidence,\\n      scores,\\n      arousal,\\n      valence,\\n      features: {\\n        avgPitch,\\n        avgEnergy,\\n        avgTempo,\\n        pitchVariability: pitchVar,\\n        energyVariability: energyVar\\n      }\\n    };\\n  };\\n\\n  // Process prosodic features and classify emotion\\n  const classifyFromFeatures = (prosodicFeatures) => {\\n    // Add to feature buffer\\n    state.featureBuffer.push(prosodicFeatures);\\n    \\n    // Maintain buffer size\\n    if (state.featureBuffer.length > state.config.windowSize * 2) {\\n      state.featureBuffer.shift();\\n    }\\n    \\n    // Classify if we have enough features\\n    if (state.featureBuffer.length >= state.config.windowSize) {\\n      const classification = classifyEmotion(state.featureBuffer.slice(-state.config.windowSize));\\n      \\n      // Apply smoothing\\n      if (state.emotionHistory.length > 0) {\\n        const prevConfidence = state.currentConfidence;\\n        const {smoothingFactor} = state.config;\\n        \\n        // If new classification is confident enough, blend with previous\\n        if (classification.confidence > state.config.confidenceThreshold) {\\n          if (classification.emotion === state.currentEmotion) {\\n            // Same emotion, increase confidence\\n            state.currentConfidence = Math.min(1, \\n              prevConfidence * (1 - smoothingFactor) + classification.confidence * smoothingFactor\\n            );\\n          } else {\\n            // Different emotion, check if confident enough to switch\\n            if (classification.confidence > prevConfidence + 0.1) {\\n              state.currentEmotion = classification.emotion;\\n              state.currentConfidence = classification.confidence * smoothingFactor + prevConfidence * (1 - smoothingFactor);\\n              state.stats.transitionCount++;\\n            }\\n          }\\n        }\\n      } else {\\n        // First classification\\n        state.currentEmotion = classification.emotion;\\n        state.currentConfidence = classification.confidence;\\n      }\\n      \\n      // Add to history\\n      state.emotionHistory.push({\\n        emotion: state.currentEmotion,\\n        confidence: state.currentConfidence,\\n        timestamp: Date.now(),\\n        ...classification\\n      });\\n      \\n      // Maintain history size\\n      if (state.emotionHistory.length > 50) {\\n        state.emotionHistory.shift();\\n      }\\n      \\n      // Update statistics\\n      state.stats.totalClassifications++;\\n      state.stats.emotionCounts[state.currentEmotion]++;\\n      state.stats.averageConfidence = \\n        (state.stats.averageConfidence * (state.stats.totalClassifications - 1) + state.currentConfidence) / \\n        state.stats.totalClassifications;\\n      \\n      return {\\n        emotion: state.currentEmotion,\\n        confidence: state.currentConfidence,\\n        rawClassification: classification,\\n        timestamp: Date.now()\\n      };\\n    }\\n    \\n    return null;\\n  };\\n\\n  // Get emotion timeline\\n  const getEmotionTimeline = (timeWindow = 30000) => {\\n    const cutoff = Date.now() - timeWindow;\\n    return state.emotionHistory.filter(entry => entry.timestamp >= cutoff);\\n  };\\n\\n  return {\\n    classifyFromFeatures,\\n    getEmotionTimeline,\\n    getCurrentEmotion: () => ({ emotion: state.currentEmotion, confidence: state.currentConfidence }),\\n    getStats: () => ({ ...state.stats }),\\n    updateConfig: (newConfig) => Object.assign(state.config, newConfig),\\n    reset: () => {\\n      state.featureBuffer = [];\\n      state.emotionHistory = [];\\n      state.currentEmotion = 'neutral';\\n      state.currentConfidence = 0;\\n      state.stats = {\\n        totalClassifications: 0,\\n        emotionCounts: {},\\n        averageConfidence: 0,\\n        transitionCount: 0\\n      };\\n      state.config.emotions.forEach(emotion => {\\n        state.stats.emotionCounts[emotion] = 0;\\n      });\\n    }\\n  };\\n};\\n\\n// Complete emotion detection system\\nexport const createEmotionDetection = (config = {}) => {\\n  const emotionConfig = createEmotionConfig(config);\\n  \\n  const memoryPool = createEnhancedMemoryPool({\\n    maxPoolSize: emotionConfig.maxPoolSize,\\n    enableMetrics: true\\n  });\\n  memoryPool.initialize();\\n\\n  const processor = createEmotionProcessor(emotionConfig, memoryPool);\\n  const stats = createEmotionStats();\\n  \\n  const state = {\\n    config: emotionConfig,\\n    isInitialized: false\\n  };\\n\\n  // Initialize components\\n  const initialize = () => {\\n    processor.registerResultFactory();\\n    processor.initialize(createProsodicAnalyzer, createEmotionClassifier);\\n    state.isInitialized = true;\\n  };\\n\\n  // Process audio frame for emotion detection\\n  const processFrame = (audioBuffer, timestamp = Date.now()) => {\\n    if (!state.isInitialized) {\\n      initialize();\\n    }\\n    \\n    const startTime = performance.now();\\n    const result = processor.processFrame(audioBuffer, timestamp);\\n    const processingTime = performance.now() - startTime;\\n    \\n    // Record statistics\\n    stats.recordFrame(result, processingTime);\\n    \\n    return result;\\n  };\\n\\n  // Release emotion result\\n  const releaseResult = (result) => {\\n    processor.releaseResult(result);\\n  };\\n\\n  // Get current emotion state\\n  const getCurrentEmotion = () => {\\n    return processor.getCurrentEmotion();\\n  };\\n\\n  // Get emotion timeline\\n  const getEmotionTimeline = (timeWindow = 30000) => {\\n    return processor.getEmotionTimeline(timeWindow);\\n  };\\n\\n  // Get comprehensive statistics\\n  const getStats = () => {\\n    const componentStats = processor.getComponentStats();\\n    return {\\n      ...stats.getStats(componentStats),\\n      memoryPool: memoryPool.getStats(),\\n      processor: processor.getState()\\n    };\\n  };\\n\\n  // Update configuration\\n  const updateConfig = (newConfig) => {\\n    try {\\n      state.config = updateEmotionConfig(state.config, newConfig);\\n      processor.updateConfig(state.config);\\n    } catch (error) {\\n      console.warn('Emotion detection configuration update failed:', error.message);\\n      throw error;\\n    }\\n  };\\n\\n  // Reset system\\n  const reset = () => {\\n    processor.reset();\\n    stats.reset();\\n  };\\n\\n  // Cleanup\\n  const cleanup = () => {\\n    memoryPool.cleanup();\\n  };\\n\\n  return {\\n    processFrame,\\n    releaseResult,\\n    getCurrentEmotion,\\n    getEmotionTimeline,\\n    getStats,\\n    updateConfig,\\n    reset,\\n    cleanup,\\n    isInitialized: () => state.isInitialized\\n  };\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/features/speech-analysis/audio/emotion-processor.js\",\"messages\":[],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/features/speech-analysis/audio/emotion-stats.js\",\"messages\":[{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '/'. Use parentheses to clarify the intended order of operations.\",\"line\":108,\"column\":20,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":108,\"endColumn\":21},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '/'. Use parentheses to clarify the intended order of operations.\",\"line\":108,\"column\":74,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":108,\"endColumn\":75}],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":2,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Emotion detection statistics tracking and analysis\\n */\\n\\nexport const createEmotionStats = () => {\\n  const stats = {\\n    totalFrames: 0,\\n    emotionUpdates: 0,\\n    processingTime: 0,\\n    \\n    // Emotion frequency tracking\\n    emotionCounts: {\\n      neutral: 0,\\n      happy: 0,\\n      sad: 0,\\n      angry: 0,\\n      fear: 0,\\n      surprise: 0,\\n      disgust: 0\\n    },\\n    \\n    // Processing performance\\n    averageProcessingTime: 0,\\n    minProcessingTime: Infinity,\\n    maxProcessingTime: 0,\\n    \\n    // Feature extraction stats\\n    prosodicExtractions: 0,\\n    classificationAttempts: 0,\\n    confidenceSum: 0\\n  };\\n\\n  // Record a processed frame\\n  const recordFrame = (result, processingTime = 0) => {\\n    stats.totalFrames++;\\n    stats.processingTime += processingTime;\\n    \\n    // Update processing time statistics\\n    stats.averageProcessingTime = stats.processingTime / stats.totalFrames;\\n    stats.minProcessingTime = Math.min(stats.minProcessingTime, processingTime);\\n    stats.maxProcessingTime = Math.max(stats.maxProcessingTime, processingTime);\\n    \\n    if (result) {\\n      // Track emotion classifications\\n      if (result.emotion && stats.emotionCounts.hasOwnProperty(result.emotion)) {\\n        stats.emotionCounts[result.emotion]++;\\n      }\\n      \\n      // Track confidence\\n      if (typeof result.confidence === 'number') {\\n        stats.confidenceSum += result.confidence;\\n      }\\n      \\n      // Track processing stages\\n      if (result.processing?.prosodicExtracted) {\\n        stats.prosodicExtractions++;\\n      }\\n      \\n      if (result.processing?.emotionClassified) {\\n        stats.emotionUpdates++;\\n        stats.classificationAttempts++;\\n      }\\n    }\\n  };\\n\\n  // Get comprehensive statistics\\n  const getStats = (componentStats = {}) => {\\n    const totalEmotions = Object.values(stats.emotionCounts).reduce((sum, count) => sum + count, 0);\\n    \\n    const emotionDistribution = {};\\n    for (const [emotion, count] of Object.entries(stats.emotionCounts)) {\\n      emotionDistribution[emotion] = totalEmotions > 0 ? count / totalEmotions : 0;\\n    }\\n    \\n    const averageConfidence = stats.emotionUpdates > 0 ? \\n      stats.confidenceSum / stats.emotionUpdates : 0;\\n    \\n    return {\\n      ...stats,\\n      \\n      // Derived statistics\\n      emotionDistribution,\\n      averageConfidence,\\n      emotionUpdateRate: stats.totalFrames > 0 ? stats.emotionUpdates / stats.totalFrames : 0,\\n      prosodicExtractionRate: stats.totalFrames > 0 ? stats.prosodicExtractions / stats.totalFrames : 0,\\n      classificationSuccessRate: stats.classificationAttempts > 0 ? stats.emotionUpdates / stats.classificationAttempts : 0,\\n      \\n      // Performance metrics\\n      performance: {\\n        averageProcessingTime: stats.averageProcessingTime,\\n        minProcessingTime: stats.minProcessingTime === Infinity ? 0 : stats.minProcessingTime,\\n        maxProcessingTime: stats.maxProcessingTime,\\n        framesPerSecond: stats.averageProcessingTime > 0 ? 1000 / stats.averageProcessingTime : 0\\n      },\\n      \\n      // Component statistics\\n      components: componentStats\\n    };\\n  };\\n\\n  // Get real-time metrics\\n  const getRealTimeMetrics = () => {\\n    \\n    return {\\n      efficiency: stats.prosodicExtractions / Math.max(stats.totalFrames, 1),\\n      accuracy: stats.emotionUpdates / Math.max(stats.classificationAttempts, 1),\\n      responsiveness: stats.emotionUpdateRate,\\n      stability: 1 - (stats.maxProcessingTime - stats.minProcessingTime) / Math.max(stats.maxProcessingTime, 1)\\n    };\\n  };\\n\\n  // Get emotion summary\\n  const getEmotionSummary = () => {\\n    const totalEmotions = Object.values(stats.emotionCounts).reduce((sum, count) => sum + count, 0);\\n    \\n    if (totalEmotions === 0) {\\n      return {\\n        dominant: 'neutral',\\n        diversity: 0,\\n        activity: 0\\n      };\\n    }\\n    \\n    // Find dominant emotion\\n    const [dominant] = Object.entries(stats.emotionCounts)\\n      .reduce((a, b) => a[1] > b[1] ? a : b);\\n    \\n    // Calculate emotional diversity (entropy-like measure)\\n    let diversity = 0;\\n    for (const count of Object.values(stats.emotionCounts)) {\\n      if (count > 0) {\\n        const p = count / totalEmotions;\\n        diversity -= p * Math.log2(p);\\n      }\\n    }\\n    diversity /= Math.log2(Object.keys(stats.emotionCounts).length); // Normalize\\n    \\n    // Calculate emotional activity (non-neutral emotions)\\n    const activity = (totalEmotions - stats.emotionCounts.neutral) / totalEmotions;\\n    \\n    return {\\n      dominant,\\n      diversity,\\n      activity\\n    };\\n  };\\n\\n  // Reset all statistics\\n  const reset = () => {\\n    stats.totalFrames = 0;\\n    stats.emotionUpdates = 0;\\n    stats.processingTime = 0;\\n    stats.averageProcessingTime = 0;\\n    stats.minProcessingTime = Infinity;\\n    stats.maxProcessingTime = 0;\\n    stats.prosodicExtractions = 0;\\n    stats.classificationAttempts = 0;\\n    stats.confidenceSum = 0;\\n    \\n    // Reset emotion counts\\n    for (const emotion of Object.keys(stats.emotionCounts)) {\\n      stats.emotionCounts[emotion] = 0;\\n    }\\n  };\\n\\n  // Export statistics for analysis\\n  const exportStats = () => ({\\n    timestamp: Date.now(),\\n    rawStats: { ...stats },\\n    summary: getStats(),\\n    realTimeMetrics: getRealTimeMetrics(),\\n    emotionSummary: getEmotionSummary()\\n  });\\n\\n  // Update emotion count manually (for testing)\\n  const recordEmotion = (emotion, confidence = 1) => {\\n    if (stats.emotionCounts.hasOwnProperty(emotion)) {\\n      stats.emotionCounts[emotion]++;\\n      stats.emotionUpdates++;\\n      stats.confidenceSum += confidence;\\n    }\\n  };\\n\\n  return {\\n    recordFrame,\\n    getStats,\\n    getRealTimeMetrics,\\n    getEmotionSummary,\\n    reset,\\n    exportStats,\\n    recordEmotion,\\n    \\n    // Direct access to raw stats for testing\\n    getRawStats: () => ({ ...stats })\\n  };\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/features/speech-analysis/audio/feature-extractor.js\",\"messages\":[{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '/'. Use parentheses to clarify the intended order of operations.\",\"line\":157,\"column\":40,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":157,\"endColumn\":41},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '/'. Use parentheses to clarify the intended order of operations.\",\"line\":157,\"column\":59,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":157,\"endColumn\":60},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '/'. Use parentheses to clarify the intended order of operations.\",\"line\":169,\"column\":35,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":169,\"endColumn\":36},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '/'. Use parentheses to clarify the intended order of operations.\",\"line\":169,\"column\":46,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":169,\"endColumn\":47}],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":4,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Audio Feature Extraction Module\\n * Advanced audio analysis and feature computation\\n */\\n\\nexport const createFeatureExtractor = (config) => {\\n  // Extract audio features\\n  const extractFeatures = (timeData, freqData, sampleRate) => {\\n    const features = {\\n      pitch: 0,\\n      energy: 0,\\n      spectralCentroid: 0,\\n      spectralRolloff: 0,\\n      zeroCrossingRate: 0,\\n      spectralSpread: 0,\\n      spectralFlux: 0,\\n      harmonicRatio: 0\\n    };\\n    \\n    // Energy (RMS)\\n    features.energy = calculateRMS(timeData);\\n    \\n    // Zero Crossing Rate\\n    features.zeroCrossingRate = calculateZCR(timeData);\\n    \\n    // Pitch detection using autocorrelation\\n    features.pitch = detectPitch(timeData, sampleRate);\\n    \\n    // Spectral features\\n    const spectralFeatures = calculateSpectralFeatures(freqData, sampleRate);\\n    Object.assign(features, spectralFeatures);\\n    \\n    // MFCC calculation (simplified)\\n    features.mfcc = calculateMFCC(freqData, sampleRate);\\n    \\n    // Formant detection\\n    features.formants = detectFormants(freqData, sampleRate);\\n    \\n    return features;\\n  };\\n\\n  // Calculate RMS energy\\n  const calculateRMS = (buffer) => {\\n    let sum = 0;\\n    for (let i = 0; i < buffer.length; i++) {\\n      sum += buffer[i] * buffer[i];\\n    }\\n    return Math.sqrt(sum / buffer.length);\\n  };\\n\\n  // Calculate Zero Crossing Rate\\n  const calculateZCR = (buffer) => {\\n    let crossings = 0;\\n    for (let i = 1; i < buffer.length; i++) {\\n      if ((buffer[i] >= 0) !== (buffer[i - 1] >= 0)) {\\n        crossings++;\\n      }\\n    }\\n    return crossings / buffer.length;\\n  };\\n\\n  // Detect pitch using autocorrelation\\n  const detectPitch = (buffer, sampleRate) => {\\n    const minPeriod = Math.floor(sampleRate / (config.maxPitch || 400));\\n    const maxPeriod = Math.floor(sampleRate / (config.minPitch || 50));\\n    \\n    let maxCorrelation = 0;\\n    let bestPeriod = 0;\\n    \\n    // Autocorrelation\\n    for (let period = minPeriod; period < maxPeriod && period < buffer.length / 2; period++) {\\n      let correlation = 0;\\n      for (let i = 0; i < buffer.length - period; i++) {\\n        correlation += buffer[i] * buffer[i + period];\\n      }\\n      \\n      if (correlation > maxCorrelation) {\\n        maxCorrelation = correlation;\\n        bestPeriod = period;\\n      }\\n    }\\n    \\n    // Convert period to frequency\\n    return bestPeriod > 0 ? sampleRate / bestPeriod : 0;\\n  };\\n\\n  // Calculate spectral features\\n  const calculateSpectralFeatures = (freqData, sampleRate) => {\\n    const features = {};\\n    const nyquist = sampleRate / 2;\\n    const binWidth = nyquist / freqData.length;\\n    \\n    let weightedSum = 0;\\n    let totalMagnitude = 0;\\n    let rolloffSum = 0;\\n    let rolloffThreshold = 0;\\n    \\n    // Convert dB to linear magnitude\\n    const magnitudes = freqData.map(db => Math.pow(10, db / 20));\\n    \\n    // Calculate total magnitude\\n    for (let i = 0; i < magnitudes.length; i++) {\\n      totalMagnitude += magnitudes[i];\\n    }\\n    \\n    rolloffThreshold = totalMagnitude * 0.85; // 85% rolloff point\\n    \\n    // Spectral centroid and rolloff\\n    for (let i = 0; i < magnitudes.length; i++) {\\n      const frequency = i * binWidth;\\n      weightedSum += frequency * magnitudes[i];\\n      rolloffSum += magnitudes[i];\\n      \\n      if (rolloffSum >= rolloffThreshold && features.spectralRolloff === undefined) {\\n        features.spectralRolloff = frequency;\\n      }\\n    }\\n    \\n    features.spectralCentroid = totalMagnitude > 0 ? weightedSum / totalMagnitude : 0;\\n    features.spectralRolloff = features.spectralRolloff || nyquist;\\n    \\n    // Spectral spread (bandwidth around centroid)\\n    let spreadSum = 0;\\n    for (let i = 0; i < magnitudes.length; i++) {\\n      const frequency = i * binWidth;\\n      const diff = frequency - features.spectralCentroid;\\n      spreadSum += diff * diff * magnitudes[i];\\n    }\\n    features.spectralSpread = totalMagnitude > 0 ? Math.sqrt(spreadSum / totalMagnitude) : 0;\\n    \\n    return features;\\n  };\\n\\n  // Calculate MFCC (simplified version)\\n  const calculateMFCC = (freqData, sampleRate, numCoeffs = 13) => {\\n    const melFilters = createMelFilterBank(freqData.length, sampleRate);\\n    const mfcc = [];\\n    \\n    // Apply mel filter bank\\n    for (let i = 0; i < melFilters.length && i < numCoeffs; i++) {\\n      let sum = 0;\\n      for (let j = 0; j < freqData.length; j++) {\\n        const magnitude = Math.pow(10, freqData[j] / 20);\\n        sum += magnitude * melFilters[i][j];\\n      }\\n      \\n      // Log and DCT (simplified)\\n      mfcc.push(Math.log(sum + 1e-10));\\n    }\\n    \\n    return mfcc;\\n  };\\n\\n  // Create simplified mel filter bank\\n  const createMelFilterBank = (fftSize, sampleRate, numFilters = 13) => {\\n    const filters = [];\\n    const melMax = 2595 * Math.log10(1 + (sampleRate / 2) / 700);\\n    \\n    for (let i = 0; i < numFilters; i++) {\\n      const filter = new Array(fftSize).fill(0);\\n      const melCenter = (i + 1) * melMax / (numFilters + 1);\\n      const freqCenter = 700 * (Math.pow(10, melCenter / 2595) - 1);\\n      const binCenter = Math.floor(freqCenter * fftSize / sampleRate);\\n      \\n      // Triangular filter\\n      const width = Math.max(1, Math.floor(fftSize / numFilters));\\n      for (let j = Math.max(0, binCenter - width); j < Math.min(fftSize, binCenter + width); j++) {\\n        const distance = Math.abs(j - binCenter);\\n        filter[j] = Math.max(0, 1 - distance / width);\\n      }\\n      \\n      filters.push(filter);\\n    }\\n    \\n    return filters;\\n  };\\n\\n  // Detect formants (simplified)\\n  const detectFormants = (freqData, sampleRate, maxFormants = 4) => {\\n    const formants = [];\\n    const nyquist = sampleRate / 2;\\n    const binWidth = nyquist / freqData.length;\\n    \\n    // Convert to linear magnitude\\n    const magnitudes = freqData.map(db => Math.pow(10, db / 20));\\n    \\n    // Simple peak finding for formants\\n    for (let i = 1; i < magnitudes.length - 1 && formants.length < maxFormants; i++) {\\n      const freq = i * binWidth;\\n      \\n      // Look for peaks in speech frequency range (200-3000 Hz)\\n      if (freq > 200 && freq < 3000) {\\n        if (magnitudes[i] > magnitudes[i - 1] && magnitudes[i] > magnitudes[i + 1]) {\\n          // Check if it's a significant peak\\n          const localMax = Math.max(...magnitudes.slice(Math.max(0, i - 5), i + 6));\\n          if (magnitudes[i] > localMax * 0.7) {\\n            formants.push({\\n              frequency: freq,\\n              amplitude: magnitudes[i]\\n            });\\n          }\\n        }\\n      }\\n    }\\n    \\n    return formants.sort((a, b) => a.frequency - b.frequency);\\n  };\\n\\n  return {\\n    extractFeatures,\\n    calculateRMS,\\n    calculateZCR,\\n    detectPitch,\\n    calculateSpectralFeatures,\\n    calculateMFCC,\\n    detectFormants\\n  };\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/features/speech-analysis/audio/noise-reduction-config.js\",\"messages\":[],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/features/speech-analysis/audio/noise-reduction-fft.js\",\"messages\":[{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '-'. Use parentheses to clarify the intended order of operations.\",\"line\":38,\"column\":38,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":38,\"endColumn\":39},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '-'. Use parentheses to clarify the intended order of operations.\",\"line\":38,\"column\":56,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":38,\"endColumn\":57},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":38,\"column\":56,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":38,\"endColumn\":57},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":38,\"column\":80,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":38,\"endColumn\":81},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":53,\"column\":51,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":53,\"endColumn\":52},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":53,\"column\":71,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":53,\"endColumn\":72},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":53,\"column\":71,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":53,\"endColumn\":72},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":53,\"column\":91,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":53,\"endColumn\":92}],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":8,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * FFT Operations for Noise Reduction\\n * Fast Fourier Transform and signal processing utilities\\n */\\n\\nexport const createFFTProcessor = () => {\\n  // FFT implementation (simplified)\\n  const fft = (inputBuffer) => {\\n    const N = inputBuffer.length;\\n    const output = new Array(N);\\n    \\n    for (let k = 0; k < N; k++) {\\n      let sumReal = 0;\\n      let sumImag = 0;\\n      \\n      for (let n = 0; n < N; n++) {\\n        const angle = -2 * Math.PI * k * n / N;\\n        sumReal += inputBuffer[n] * Math.cos(angle);\\n        sumImag += inputBuffer[n] * Math.sin(angle);\\n      }\\n      \\n      output[k] = { real: sumReal, imag: sumImag };\\n    }\\n    \\n    return output;\\n  };\\n\\n  // Inverse FFT\\n  const ifft = (complexBuffer) => {\\n    const N = complexBuffer.length;\\n    const output = new Float32Array(N);\\n    \\n    for (let n = 0; n < N; n++) {\\n      let sum = 0;\\n      \\n      for (let k = 0; k < N; k++) {\\n        const angle = 2 * Math.PI * k * n / N;\\n        sum += complexBuffer[k].real * Math.cos(angle) - complexBuffer[k].imag * Math.sin(angle);\\n      }\\n      \\n      output[n] = sum / N;\\n    }\\n    \\n    return output;\\n  };\\n\\n  // Calculate magnitudes and phases from FFT result\\n  const extractMagnitudesAndPhases = (fftResult) => {\\n    const magnitudes = new Float32Array(fftResult.length);\\n    const phases = new Float32Array(fftResult.length);\\n    \\n    for (let i = 0; i < fftResult.length; i++) {\\n      magnitudes[i] = Math.sqrt(fftResult[i].real * fftResult[i].real + fftResult[i].imag * fftResult[i].imag);\\n      phases[i] = Math.atan2(fftResult[i].imag, fftResult[i].real);\\n    }\\n    \\n    return { magnitudes, phases };\\n  };\\n\\n  // Reconstruct complex spectrum from magnitudes and phases\\n  const reconstructSpectrum = (magnitudes, phases) => {\\n    const spectrum = new Array(magnitudes.length);\\n    for (let i = 0; i < magnitudes.length; i++) {\\n      spectrum[i] = {\\n        real: magnitudes[i] * Math.cos(phases[i]),\\n        imag: magnitudes[i] * Math.sin(phases[i])\\n      };\\n    }\\n    return spectrum;\\n  };\\n\\n  return {\\n    fft,\\n    ifft,\\n    extractMagnitudesAndPhases,\\n    reconstructSpectrum\\n  };\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/features/speech-analysis/audio/noise-reduction-spectral.js\",\"messages\":[{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":19,\"column\":38,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":19,\"endColumn\":39},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":19,\"column\":62,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":19,\"endColumn\":63},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":19,\"column\":62,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":19,\"endColumn\":63},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":19,\"column\":75,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":19,\"endColumn\":76},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":39,\"column\":39,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":39,\"endColumn\":40},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":39,\"column\":60,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":39,\"endColumn\":61}],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":6,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Spectral Processing for Noise Reduction\\n * Handles noise profile management and spectral subtraction\\n */\\n\\nexport const createSpectralProcessor = (state) => {\\n  // Update noise profile during quiet segments\\n  const updateNoiseProfile = (magnitudes) => {\\n    if (!state.noiseProfileInitialized) {\\n      state.noiseProfile = new Float32Array(magnitudes.length);\\n      for (let i = 0; i < magnitudes.length; i++) {\\n        state.noiseProfile[i] = magnitudes[i];\\n      }\\n      state.noiseProfileInitialized = true;\\n    } else {\\n      // Exponential moving average\\n      const rate = state.config.learningRate;\\n      for (let i = 0; i < magnitudes.length; i++) {\\n        state.noiseProfile[i] = rate * state.noiseProfile[i] + (1 - rate) * magnitudes[i];\\n      }\\n    }\\n    \\n    state.adaptationFrames++;\\n  };\\n\\n  // Apply spectral subtraction\\n  const applySpectralSubtraction = (magnitudes) => {\\n    if (!state.noiseProfile) {\\n      return magnitudes;\\n    }\\n\\n    const enhancedMagnitudes = new Float32Array(magnitudes.length);\\n    \\n    for (let i = 0; i < magnitudes.length; i++) {\\n      const signalMag = magnitudes[i];\\n      const noiseMag = state.noiseProfile[i];\\n      \\n      // Spectral subtraction\\n      const subtractedMag = signalMag - state.config.alpha * noiseMag;\\n      const flooredMag = Math.max(subtractedMag, state.config.beta * signalMag);\\n      \\n      // Apply gain limits\\n      const gain = signalMag > 0 ? flooredMag / signalMag : 1;\\n      const limitedGain = Math.max(state.config.minGain, Math.min(state.config.maxGain, gain));\\n      \\n      enhancedMagnitudes[i] = signalMag * limitedGain;\\n    }\\n    \\n    return enhancedMagnitudes;\\n  };\\n\\n  // Update statistics\\n  const updateStats = () => {\\n    state.stats.totalFrames++;\\n    if (state.noiseProfile) {\\n      state.stats.noiseReductionApplied++;\\n      const avgNoise = state.noiseProfile.reduce((sum, n) => sum + n, 0) / state.noiseProfile.length;\\n      state.stats.averageNoiseLevel = avgNoise;\\n    }\\n  };\\n\\n  return {\\n    updateNoiseProfile,\\n    applySpectralSubtraction,\\n    updateStats\\n  };\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/features/speech-analysis/audio/noise-reduction-window.js\",\"messages\":[],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/features/speech-analysis/audio/pace/fluency-analyzer.js\",\"messages\":[{\"ruleId\":\"max-lines-per-function\",\"severity\":1,\"message\":\"Arrow function has too many lines (209). Maximum allowed is 150.\",\"line\":6,\"column\":38,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"exceed\",\"endLine\":298,\"endColumn\":2},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":216,\"column\":41,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":216,\"endColumn\":42},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":216,\"column\":93,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":216,\"endColumn\":94},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":219,\"column\":40,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":219,\"endColumn\":41},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":219,\"column\":88,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":219,\"endColumn\":89},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":221,\"column\":45,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":221,\"endColumn\":46},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":221,\"column\":72,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":221,\"endColumn\":73}],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":7,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Fluency Analyzer Module\\n * Analyzes speech fluency through filler words, hesitations, repetitions, and speech flow\\n */\\n\\nexport const createFluencyAnalyzer = (config = {}) => {\\n  const state = {\\n    config: {\\n      // Filler word patterns\\n      fillerWords: config.fillerWords || [\\n        'um', 'uh', 'er', 'ah', 'like', 'you know', 'so', 'well',\\n        'actually', 'basically', 'literally', 'sort of', 'kind of'\\n      ],\\n      \\n      // Pause detection\\n      minPauseLength: config.minPauseLength || 200, // ms\\n      hesitationPauseLength: config.hesitationPauseLength || 500, // ms\\n      \\n      // Repetition detection\\n      repetitionWindow: config.repetitionWindow || 3, // words\\n      \\n      // Fluency scoring\\n      fluencyWeights: config.fluencyWeights || {\\n        fillers: 0.3,\\n        pauses: 0.3,\\n        repetitions: 0.2,\\n        flow: 0.2\\n      }\\n    },\\n    \\n    // Tracking arrays\\n    fillerEvents: [],\\n    pauseEvents: [],\\n    repetitionEvents: [],\\n    speechFlow: [],\\n    \\n    // Current state\\n    lastWordTime: null,\\n    recentWords: [],\\n    \\n    // Statistics\\n    stats: {\\n      totalFillers: 0,\\n      totalPauses: 0,\\n      totalRepetitions: 0,\\n      averagePauseLength: 0,\\n      fillerRate: 0, // fillers per minute\\n      fluencyScore: 100, // 0-100 scale\\n      speechFlowIndex: 0\\n    }\\n  };\\n\\n  // Detect filler words in text\\n  const detectFillers = (text, timestamp) => {\\n    if (!text || typeof text !== 'string') return [];\\n    \\n    const words = text.toLowerCase().split(/\\\\s+/);\\n    const fillers = [];\\n    \\n    for (let i = 0; i < words.length; i++) {\\n      const word = words[i].replace(/[.!?;:]*/g, ''); // Remove punctuation\\n      \\n      // Check single word fillers\\n      if (state.config.fillerWords.includes(word)) {\\n        fillers.push({\\n          type: 'single',\\n          text: word,\\n          position: i,\\n          timestamp: timestamp + (i * 100) // Approximate timing\\n        });\\n      }\\n      \\n      // Check multi-word fillers\\n      if (i < words.length - 1) {\\n        const twoWordPhrase = `${word} ${words[i + 1].replace(/[.!?;:]*/g, '')}`;\\n        if (state.config.fillerWords.includes(twoWordPhrase)) {\\n          fillers.push({\\n            type: 'phrase',\\n            text: twoWordPhrase,\\n            position: i,\\n            timestamp: timestamp + (i * 100)\\n          });\\n          i++; // Skip next word\\n        }\\n      }\\n    }\\n    \\n    // Add to tracking\\n    state.fillerEvents.push(...fillers);\\n    state.stats.totalFillers += fillers.length;\\n    \\n    return fillers;\\n  };\\n\\n  // Detect repetitions in recent speech\\n  const detectRepetitions = (text, timestamp) => {\\n    if (!text || typeof text !== 'string') return [];\\n    \\n    const words = text.toLowerCase().split(/\\\\s+/)\\n      .map(word => word.replace(/[.!?;:]*/g, ''))\\n      .filter(word => word.length > 0);\\n    \\n    const repetitions = [];\\n    \\n    // Add new words to recent words buffer\\n    words.forEach(word => {\\n      state.recentWords.push({ word, time: timestamp });\\n    });\\n    \\n    // Maintain buffer size\\n    while (state.recentWords.length > state.config.repetitionWindow * 3) {\\n      state.recentWords.shift();\\n    }\\n    \\n    // Look for repetitions in recent window\\n    const recentWordTexts = state.recentWords.map(w => w.word);\\n    const wordCounts = {};\\n    \\n    recentWordTexts.forEach(word => {\\n      wordCounts[word] = (wordCounts[word] || 0) + 1;\\n    });\\n    \\n    // Find words that appear more than once\\n    for (const [word, count] of Object.entries(wordCounts)) {\\n      if (count > 1 && word.length > 2) { // Ignore short words\\n        repetitions.push({\\n          word,\\n          count,\\n          timestamp,\\n          severity: count > 2 ? 'high' : 'moderate'\\n        });\\n      }\\n    }\\n    \\n    // Add to tracking\\n    state.repetitionEvents.push(...repetitions);\\n    state.stats.totalRepetitions += repetitions.length;\\n    \\n    return repetitions;\\n  };\\n\\n  // Add pause information\\n  const addPause = (startTime, endTime, type = 'normal') => {\\n    const duration = endTime - startTime;\\n    \\n    if (duration >= state.config.minPauseLength) {\\n      const pause = {\\n        startTime,\\n        endTime,\\n        duration,\\n        type: duration >= state.config.hesitationPauseLength ? 'hesitation' : type,\\n        timestamp: Date.now()\\n      };\\n      \\n      state.pauseEvents.push(pause);\\n      state.stats.totalPauses++;\\n      \\n      // Update average pause length\\n      const totalPauseDuration = state.pauseEvents.reduce((sum, p) => sum + p.duration, 0);\\n      state.stats.averagePauseLength = totalPauseDuration / state.pauseEvents.length;\\n      \\n      return pause;\\n    }\\n    \\n    return null;\\n  };\\n\\n  // Calculate speech flow index\\n  const calculateSpeechFlow = (speechSegments, timeWindow = 30000) => {\\n    const cutoffTime = Date.now() - timeWindow;\\n    const recentSegments = speechSegments.filter(seg => seg.timestamp >= cutoffTime);\\n    \\n    if (recentSegments.length === 0) return 0;\\n    \\n    // Calculate flow based on segment continuity and duration\\n    let flowScore = 0;\\n    let totalDuration = 0;\\n    \\n    for (let i = 0; i < recentSegments.length; i++) {\\n      const segment = recentSegments[i];\\n      totalDuration += segment.duration;\\n      \\n      // Base score from segment length (longer = better flow)\\n      const lengthScore = Math.min(1, segment.duration / 3000); // 3 seconds max\\n      \\n      // Penalty for very short segments (indicates choppy speech)\\n      const choppyPenalty = segment.duration < 1000 ? 0.5 : 1;\\n      \\n      // Bonus for consistent rate within segment\\n      const rateConsistency = segment.wordCount > 0 ? \\n        Math.min(1, segment.wordRate / 150) : 0; // 150 WPM as reference\\n      \\n      flowScore += lengthScore * choppyPenalty * rateConsistency * segment.duration;\\n    }\\n    \\n    // Normalize by total duration\\n    const averageFlow = totalDuration > 0 ? flowScore / totalDuration : 0;\\n    state.stats.speechFlowIndex = Math.max(0, Math.min(1, averageFlow));\\n    \\n    return state.stats.speechFlowIndex;\\n  };\\n\\n  // Calculate overall fluency score\\n  const calculateFluencyScore = (speechDuration = 0, timeWindow = 30000) => {\\n    if (speechDuration === 0) return state.stats.fluencyScore;\\n    \\n    const weights = state.config.fluencyWeights;\\n    const cutoffTime = Date.now() - timeWindow;\\n    \\n    // Filter events to time window\\n    const recentFillers = state.fillerEvents.filter(f => f.timestamp >= cutoffTime);\\n    const recentPauses = state.pauseEvents.filter(p => p.timestamp >= cutoffTime);\\n    const recentRepetitions = state.repetitionEvents.filter(r => r.timestamp >= cutoffTime);\\n    \\n    // Calculate component scores (0-100)\\n    const fillerScore = Math.max(0, 100 - (recentFillers.length / (speechDuration / 60000)) * 10);\\n    \\n    const hesitationPauses = recentPauses.filter(p => p.type === 'hesitation').length;\\n    const pauseScore = Math.max(0, 100 - (hesitationPauses / (speechDuration / 60000)) * 15);\\n    \\n    const repetitionScore = Math.max(0, 100 - recentRepetitions.length * 5);\\n    \\n    const flowScore = state.stats.speechFlowIndex * 100;\\n    \\n    // Weighted combination\\n    const fluencyScore = \\n      (fillerScore * weights.fillers) +\\n      (pauseScore * weights.pauses) +\\n      (repetitionScore * weights.repetitions) +\\n      (flowScore * weights.flow);\\n    \\n    state.stats.fluencyScore = Math.max(0, Math.min(100, fluencyScore));\\n    \\n    // Update filler rate\\n    state.stats.fillerRate = speechDuration > 0 ? \\n      (recentFillers.length / (speechDuration / 60000)) : 0;\\n    \\n    return {\\n      overall: state.stats.fluencyScore,\\n      components: {\\n        fillers: fillerScore,\\n        pauses: pauseScore,\\n        repetitions: repetitionScore,\\n        flow: flowScore\\n      },\\n      details: {\\n        fillerCount: recentFillers.length,\\n        hesitationPauses,\\n        repetitionCount: recentRepetitions.length,\\n        flowIndex: state.stats.speechFlowIndex\\n      }\\n    };\\n  };\\n\\n  // Process speech segment for fluency analysis\\n  const processSegment = (text, startTime, endTime, speechSegments = []) => {\\n    const fillers = detectFillers(text, startTime);\\n    const repetitions = detectRepetitions(text, startTime);\\n    const speechFlow = calculateSpeechFlow(speechSegments);\\n    const fluency = calculateFluencyScore(endTime - startTime);\\n    \\n    return {\\n      fillers,\\n      repetitions,\\n      speechFlow,\\n      fluency,\\n      timestamp: Date.now()\\n    };\\n  };\\n\\n  return {\\n    detectFillers,\\n    detectRepetitions,\\n    addPause,\\n    calculateSpeechFlow,\\n    calculateFluencyScore,\\n    processSegment,\\n    getStats: () => ({ ...state.stats }),\\n    updateConfig: (newConfig) => Object.assign(state.config, newConfig),\\n    reset: () => {\\n      state.fillerEvents = [];\\n      state.pauseEvents = [];\\n      state.repetitionEvents = [];\\n      state.speechFlow = [];\\n      state.lastWordTime = null;\\n      state.recentWords = [];\\n      state.stats = {\\n        totalFillers: 0,\\n        totalPauses: 0,\\n        totalRepetitions: 0,\\n        averagePauseLength: 0,\\n        fillerRate: 0,\\n        fluencyScore: 100,\\n        speechFlowIndex: 0\\n      };\\n    }\\n  };\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/features/speech-analysis/audio/pace/pace-analysis-manager.js\",\"messages\":[{\"ruleId\":\"max-lines-per-function\",\"severity\":1,\"message\":\"Arrow function has too many lines (249). Maximum allowed is 150.\",\"line\":10,\"column\":42,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"exceed\",\"endLine\":334,\"endColumn\":2}],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":1,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Pace Analysis Manager\\n * Orchestrates speaking rate analysis and fluency analysis for comprehensive pace metrics\\n */\\n\\nimport { createEnhancedMemoryPool } from '../../../shared/utils/enhanced-memory-pool.js';\\nimport { createSpeakingRateAnalyzer } from './speaking-rate-analyzer.js';\\nimport { createFluencyAnalyzer } from './fluency-analyzer.js';\\n\\nexport const createPaceAnalysisManager = (config = {}) => {\\n  const memoryPool = createEnhancedMemoryPool({\\n    maxPoolSize: config.maxPoolSize || 100,\\n    enableMetrics: true\\n  });\\n  memoryPool.initialize();\\n\\n  const state = {\\n    config: {\\n      // Processing parameters\\n      enableRateAnalysis: config.enableRateAnalysis !== false,\\n      enableFluencyAnalysis: config.enableFluencyAnalysis !== false,\\n      \\n      // Update intervals\\n      analysisInterval: config.analysisInterval || 1000, // ms\\n      reportingWindow: config.reportingWindow || 30000, // ms\\n      \\n      ...config\\n    },\\n    \\n    // Components\\n    rateAnalyzer: null,\\n    fluencyAnalyzer: null,\\n    \\n    // Processing state\\n    lastAnalysisTime: 0,\\n    isInitialized: false,\\n    \\n    // Statistics\\n    stats: {\\n      totalSegments: 0,\\n      totalAnalyses: 0,\\n      processingTime: 0\\n    }\\n  };\\n\\n  // Initialize components\\n  const initialize = () => {\\n    if (state.config.enableRateAnalysis) {\\n      state.rateAnalyzer = createSpeakingRateAnalyzer(state.config.rate);\\n    }\\n    \\n    if (state.config.enableFluencyAnalysis) {\\n      state.fluencyAnalyzer = createFluencyAnalyzer(state.config.fluency);\\n    }\\n    \\n    state.isInitialized = true;\\n  };\\n\\n  // Register pace analysis result type\\n  memoryPool.registerFactory('PaceAnalysisResult', () => ({\\n    _pooled: true,\\n    timestamp: 0,\\n    speakingRate: {\\n      current: 0,\\n      smoothed: 0,\\n      category: 'normal',\\n      variability: 0\\n    },\\n    fluency: {\\n      score: 100,\\n      fillerCount: 0,\\n      pauseCount: 0,\\n      repetitionCount: 0,\\n      flowIndex: 0\\n    },\\n    segment: null,\\n    processing: {\\n      rateAnalyzed: false,\\n      fluencyAnalyzed: false,\\n      processingTime: 0\\n    }\\n  }));\\n\\n  // Process speech segment for pace analysis\\n  const processSegment = (text, startTime, endTime, speakerId = null) => {\\n    if (!state.isInitialized) {\\n      initialize();\\n    }\\n    \\n    const processingStart = performance.now();\\n    const timestamp = Date.now();\\n    \\n    // Skip too frequent updates\\n    if (timestamp - state.lastAnalysisTime < state.config.analysisInterval) {\\n      return null;\\n    }\\n    \\n    let rateResult = null;\\n    let fluencyResult = null;\\n    \\n    // Analyze speaking rate\\n    if (state.rateAnalyzer) {\\n      const segment = state.rateAnalyzer.addSpeechSegment(text, startTime, endTime, speakerId);\\n      if (segment) {\\n        rateResult = {\\n          current: segment.wordRate,\\n          smoothed: state.rateAnalyzer.getSmoothedRate(),\\n          category: state.rateAnalyzer.categorizeRate(segment.wordRate),\\n          variability: state.rateAnalyzer.calculateRateVariability()\\n        };\\n      }\\n    }\\n    \\n    // Analyze fluency\\n    if (state.fluencyAnalyzer) {\\n      const speechSegments = state.rateAnalyzer ? state.rateAnalyzer.getStats() : [];\\n      fluencyResult = state.fluencyAnalyzer.processSegment(text, startTime, endTime, speechSegments);\\n    }\\n    \\n    const processingTime = performance.now() - processingStart;\\n    \\n    // Update statistics\\n    state.stats.totalSegments++;\\n    state.stats.totalAnalyses++;\\n    state.stats.processingTime += processingTime;\\n    state.lastAnalysisTime = timestamp;\\n    \\n    // Create result if we have analysis data\\n    if (rateResult || fluencyResult) {\\n      const result = memoryPool.acquire('PaceAnalysisResult');\\n      \\n      result.timestamp = timestamp;\\n      \\n      if (rateResult) {\\n        result.speakingRate = rateResult;\\n      }\\n      \\n      if (fluencyResult) {\\n        result.fluency = {\\n          score: fluencyResult.fluency.overall,\\n          fillerCount: fluencyResult.fillers.length,\\n          pauseCount: fluencyResult.fluency.details.hesitationPauses || 0,\\n          repetitionCount: fluencyResult.repetitions.length,\\n          flowIndex: fluencyResult.speechFlow\\n        };\\n      }\\n      \\n      result.segment = {\\n        text,\\n        startTime,\\n        endTime,\\n        duration: endTime - startTime,\\n        speakerId\\n      };\\n      \\n      result.processing = {\\n        rateAnalyzed: rateResult !== null,\\n        fluencyAnalyzed: fluencyResult !== null,\\n        processingTime\\n      };\\n      \\n      return result;\\n    }\\n    \\n    return null;\\n  };\\n\\n  // Add pause information (for fluency analysis)\\n  const addPause = (startTime, endTime, type = 'normal') => {\\n    if (!state.isInitialized) {\\n      initialize();\\n    }\\n    \\n    if (state.fluencyAnalyzer) {\\n      return state.fluencyAnalyzer.addPause(startTime, endTime, type);\\n    }\\n    \\n    return null;\\n  };\\n\\n  // Release pace analysis result\\n  const releaseResult = (result) => {\\n    memoryPool.release(result);\\n  };\\n\\n  // Get current pace metrics\\n  const getCurrentPaceMetrics = () => {\\n    const metrics = {};\\n    \\n    if (state.rateAnalyzer) {\\n      metrics.speakingRate = {\\n        current: state.rateAnalyzer.getCurrentRate(),\\n        smoothed: state.rateAnalyzer.getSmoothedRate(),\\n        stats: state.rateAnalyzer.getRateStats()\\n      };\\n    }\\n    \\n    if (state.fluencyAnalyzer) {\\n      metrics.fluency = {\\n        score: state.fluencyAnalyzer.getStats().fluencyScore,\\n        fillerRate: state.fluencyAnalyzer.getStats().fillerRate,\\n        flowIndex: state.fluencyAnalyzer.getStats().speechFlowIndex\\n      };\\n    }\\n    \\n    return metrics;\\n  };\\n\\n  // Get comprehensive analysis report\\n  const getAnalysisReport = (timeWindow = state.config.reportingWindow) => {\\n    const report = {\\n      timeWindow,\\n      timestamp: Date.now(),\\n      speakingRate: null,\\n      fluency: null,\\n      summary: null\\n    };\\n    \\n    if (state.rateAnalyzer) {\\n      const rateStats = state.rateAnalyzer.getRateStats(timeWindow);\\n      report.speakingRate = {\\n        ...rateStats,\\n        overall: state.rateAnalyzer.getStats()\\n      };\\n    }\\n    \\n    if (state.fluencyAnalyzer) {\\n      const fluencyStats = state.fluencyAnalyzer.getStats();\\n      report.fluency = {\\n        score: fluencyStats.fluencyScore,\\n        components: {\\n          fillers: fluencyStats.totalFillers,\\n          pauses: fluencyStats.totalPauses,\\n          repetitions: fluencyStats.totalRepetitions,\\n          flow: fluencyStats.speechFlowIndex\\n        },\\n        rates: {\\n          filler: fluencyStats.fillerRate,\\n          averagePause: fluencyStats.averagePauseLength\\n        }\\n      };\\n    }\\n    \\n    // Generate summary\\n    report.summary = generateSummary(report);\\n    \\n    return report;\\n  };\\n\\n  // Generate human-readable summary\\n  const generateSummary = (report) => {\\n    const insights = [];\\n    \\n    if (report.speakingRate) {\\n      const rate = report.speakingRate.averageRate;\\n      const {category} = report.speakingRate;\\n      insights.push(`Speaking rate: ${Math.round(rate)} WPM (${category})`);\\n      \\n      if (report.speakingRate.variability > 30) {\\n        insights.push('High rate variability detected');\\n      }\\n    }\\n    \\n    if (report.fluency) {\\n      const score = Math.round(report.fluency.score);\\n      insights.push(`Fluency score: ${score}/100`);\\n      \\n      if (report.fluency.rates.filler > 5) {\\n        insights.push('High filler word usage');\\n      }\\n      \\n      if (report.fluency.components.flow < 0.7) {\\n        insights.push('Choppy speech flow detected');\\n      }\\n    }\\n    \\n    return insights;\\n  };\\n\\n  // Get comprehensive statistics\\n  const getStats = () => ({\\n    ...state.stats,\\n    averageProcessingTime: state.stats.totalSegments > 0 ? \\n      state.stats.processingTime / state.stats.totalSegments : 0,\\n    components: {\\n      rate: state.rateAnalyzer ? state.rateAnalyzer.getStats() : null,\\n      fluency: state.fluencyAnalyzer ? state.fluencyAnalyzer.getStats() : null\\n    },\\n    memoryPool: memoryPool.getStats()\\n  });\\n\\n  // Update configuration\\n  const updateConfig = (newConfig) => {\\n    Object.assign(state.config, newConfig);\\n    \\n    if (newConfig.rate && state.rateAnalyzer) {\\n      state.rateAnalyzer.updateConfig(newConfig.rate);\\n    }\\n    if (newConfig.fluency && state.fluencyAnalyzer) {\\n      state.fluencyAnalyzer.updateConfig(newConfig.fluency);\\n    }\\n  };\\n\\n  // Reset analysis system\\n  const reset = () => {\\n    if (state.rateAnalyzer) state.rateAnalyzer.reset();\\n    if (state.fluencyAnalyzer) state.fluencyAnalyzer.reset();\\n    \\n    state.lastAnalysisTime = 0;\\n    state.stats = {\\n      totalSegments: 0,\\n      totalAnalyses: 0,\\n      processingTime: 0\\n    };\\n  };\\n\\n  // Cleanup\\n  const cleanup = () => {\\n    memoryPool.cleanup();\\n  };\\n\\n  return {\\n    processSegment,\\n    addPause,\\n    releaseResult,\\n    getCurrentPaceMetrics,\\n    getAnalysisReport,\\n    getStats,\\n    updateConfig,\\n    reset,\\n    cleanup,\\n    isInitialized: () => state.isInitialized\\n  };\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/features/speech-analysis/audio/pace/speaking-rate-analyzer.js\",\"messages\":[{\"ruleId\":\"max-lines-per-function\",\"severity\":1,\"message\":\"Arrow function has too many lines (176). Maximum allowed is 150.\",\"line\":6,\"column\":43,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"exceed\",\"endLine\":239,\"endColumn\":2},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":134,\"column\":36,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":134,\"endColumn\":37},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":134,\"column\":47,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":134,\"endColumn\":48},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":134,\"column\":47,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":134,\"endColumn\":48},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":134,\"column\":84,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":134,\"endColumn\":85},{\"ruleId\":\"consistent-return\",\"severity\":1,\"message\":\"Arrow function expected no return value.\",\"line\":151,\"column\":5,\"nodeType\":\"ReturnStatement\",\"messageId\":\"unexpectedReturnValue\",\"endLine\":151,\"endColumn\":20}],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":6,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Speaking Rate Analyzer Module\\n * Calculates words per minute, syllable rates, and speaking speed categorization\\n */\\n\\nexport const createSpeakingRateAnalyzer = (config = {}) => {\\n  const state = {\\n    config: {\\n      // Rate calculation parameters\\n      windowSize: config.windowSize || 10000, // ms\\n      minWordLength: config.minWordLength || 2,\\n      syllablePattern: config.syllablePattern || /[aeiouyAEIOUY]+/g,\\n      \\n      // Smoothing and adaptation\\n      smoothingFactor: config.smoothingFactor || 0.3,\\n      adaptiveWindow: config.adaptiveWindow !== false,\\n      \\n      // Rate categories (WPM ranges)\\n      rateCategories: config.rateCategories || {\\n        verySlow: [0, 80],\\n        slow: [80, 120],\\n        normal: [120, 160],\\n        fast: [160, 200],\\n        veryFast: [200, 300]\\n      }\\n    },\\n    \\n    // Speech tracking\\n    speechSegments: [],\\n    wordEvents: [],\\n    syllableEvents: [],\\n    \\n    // Current metrics\\n    currentRate: 0,\\n    smoothedRate: 0,\\n    \\n    // Statistics\\n    stats: {\\n      totalWords: 0,\\n      totalSyllables: 0,\\n      totalSpeechTime: 0,\\n      averageRate: 0,\\n      peakRate: 0,\\n      rateVariability: 0,\\n      rateDistribution: {}\\n    }\\n  };\\n\\n  // Initialize rate distribution\\n  Object.keys(state.config.rateCategories).forEach(category => {\\n    state.stats.rateDistribution[category] = 0;\\n  });\\n\\n  // Estimate syllable count from text\\n  const estimateSyllables = (word) => {\\n    if (!word || word.length < state.config.minWordLength) return 0;\\n    \\n    // Remove non-alphabetic characters\\n    const cleanWord = word.toLowerCase().replace(/[^a-z]/g, '');\\n    if (cleanWord.length === 0) return 0;\\n    \\n    // Count vowel groups\\n    const syllables = cleanWord.match(state.config.syllablePattern) || [];\\n    let count = syllables.length;\\n    \\n    // Adjust for silent 'e'\\n    if (cleanWord.endsWith('e') && count > 1) {\\n      count--;\\n    }\\n    \\n    // Ensure at least one syllable\\n    return Math.max(1, count);\\n  };\\n\\n  // Add speech segment with timing information\\n  const addSpeechSegment = (text, startTime, endTime, speakerId = null) => {\\n    if (!text || typeof text !== 'string') return;\\n    \\n    const words = text.trim().split(/\\\\s+/).filter(word => \\n      word.length >= state.config.minWordLength && /[a-zA-Z]/.test(word)\\n    );\\n    \\n    if (words.length === 0) return;\\n    \\n    const duration = endTime - startTime;\\n    const wordRate = words.length / (duration / 60000); // WPM\\n    \\n    // Calculate syllables\\n    const syllables = words.reduce((sum, word) => sum + estimateSyllables(word), 0);\\n    const syllableRate = syllables / (duration / 60000); // Syllables per minute\\n    \\n    const segment = {\\n      text,\\n      startTime,\\n      endTime,\\n      duration,\\n      wordCount: words.length,\\n      syllableCount: syllables,\\n      wordRate,\\n      syllableRate,\\n      speakerId,\\n      timestamp: Date.now()\\n    };\\n    \\n    // Add to tracking\\n    state.speechSegments.push(segment);\\n    \\n    // Add individual word events\\n    const wordDuration = duration / words.length;\\n    words.forEach((word, index) => {\\n      const wordTime = startTime + (index * wordDuration);\\n      state.wordEvents.push({\\n        word,\\n        time: wordTime,\\n        syllables: estimateSyllables(word),\\n        segmentIndex: state.speechSegments.length - 1\\n      });\\n      \\n      // Add syllable events\\n      const syllableCount = estimateSyllables(word);\\n      const syllableDuration = wordDuration / syllableCount;\\n      for (let s = 0; s < syllableCount; s++) {\\n        state.syllableEvents.push({\\n          time: wordTime + (s * syllableDuration),\\n          wordIndex: state.wordEvents.length - 1,\\n          syllableIndex: s\\n        });\\n      }\\n    });\\n    \\n    // Update current rates\\n    state.currentRate = wordRate;\\n    state.smoothedRate = state.smoothedRate === 0 ? wordRate :\\n      state.config.smoothingFactor * wordRate + (1 - state.config.smoothingFactor) * state.smoothedRate;\\n    \\n    // Update statistics\\n    state.stats.totalWords += words.length;\\n    state.stats.totalSyllables += syllables;\\n    state.stats.totalSpeechTime += duration;\\n    \\n    const overallRate = state.stats.totalWords / (state.stats.totalSpeechTime / 60000);\\n    state.stats.averageRate = overallRate;\\n    state.stats.peakRate = Math.max(state.stats.peakRate, wordRate);\\n    \\n    // Update rate distribution\\n    const category = categorizeRate(wordRate);\\n    if (category) {\\n      state.stats.rateDistribution[category]++;\\n    }\\n    \\n    return segment;\\n  };\\n\\n  // Categorize speaking rate\\n  const categorizeRate = (rate) => {\\n    for (const [category, [min, max]] of Object.entries(state.config.rateCategories)) {\\n      if (rate >= min && rate < max) {\\n        return category;\\n      }\\n    }\\n    return null;\\n  };\\n\\n  // Calculate rate variability over recent segments\\n  const calculateRateVariability = (timeWindow = state.config.windowSize) => {\\n    const cutoffTime = Date.now() - timeWindow;\\n    const recentSegments = state.speechSegments.filter(seg => seg.timestamp >= cutoffTime);\\n    \\n    if (recentSegments.length < 2) return 0;\\n    \\n    const rates = recentSegments.map(seg => seg.wordRate);\\n    const meanRate = rates.reduce((sum, rate) => sum + rate, 0) / rates.length;\\n    const variance = rates.reduce((sum, rate) => sum + Math.pow(rate - meanRate, 2), 0) / rates.length;\\n    \\n    state.stats.rateVariability = Math.sqrt(variance);\\n    return state.stats.rateVariability;\\n  };\\n\\n  // Get rate statistics over time window\\n  const getRateStats = (timeWindow = state.config.windowSize) => {\\n    const cutoffTime = Date.now() - timeWindow;\\n    const recentSegments = state.speechSegments.filter(seg => seg.timestamp >= cutoffTime);\\n    \\n    if (recentSegments.length === 0) {\\n      return {\\n        averageRate: 0,\\n        medianRate: 0,\\n        minRate: 0,\\n        maxRate: 0,\\n        variability: 0,\\n        segmentCount: 0\\n      };\\n    }\\n    \\n    const rates = recentSegments.map(seg => seg.wordRate).sort((a, b) => a - b);\\n    const averageRate = rates.reduce((sum, rate) => sum + rate, 0) / rates.length;\\n    const medianRate = rates[Math.floor(rates.length / 2)];\\n    \\n    return {\\n      averageRate,\\n      medianRate,\\n      minRate: rates[0],\\n      maxRate: rates[rates.length - 1],\\n      variability: calculateRateVariability(timeWindow),\\n      segmentCount: recentSegments.length,\\n      category: categorizeRate(averageRate)\\n    };\\n  };\\n\\n  return {\\n    addSpeechSegment,\\n    getCurrentRate: () => state.currentRate,\\n    getSmoothedRate: () => state.smoothedRate,\\n    getRateStats,\\n    calculateRateVariability,\\n    categorizeRate,\\n    getStats: () => ({ ...state.stats }),\\n    updateConfig: (newConfig) => Object.assign(state.config, newConfig),\\n    reset: () => {\\n      state.speechSegments = [];\\n      state.wordEvents = [];\\n      state.syllableEvents = [];\\n      state.currentRate = 0;\\n      state.smoothedRate = 0;\\n      state.stats = {\\n        totalWords: 0,\\n        totalSyllables: 0,\\n        totalSpeechTime: 0,\\n        averageRate: 0,\\n        peakRate: 0,\\n        rateVariability: 0,\\n        rateDistribution: {}\\n      };\\n      Object.keys(state.config.rateCategories).forEach(category => {\\n        state.stats.rateDistribution[category] = 0;\\n      });\\n    }\\n  };\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/features/speech-analysis/audio/preprocessing-config.js\",\"messages\":[],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/features/speech-analysis/audio/preprocessing-modules.js\",\"messages\":[],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/features/speech-analysis/audio/preprocessing-quality.js\",\"messages\":[],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/features/speech-analysis/audio/processing-chain.js\",\"messages\":[{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'config' is defined but never used. Allowed unused args must match /^_/u.\",\"line\":6,\"column\":58,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":6,\"endColumn\":64,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"config\"},\"fix\":{\"range\":[158,166],\"text\":\"\"},\"desc\":\"Remove unused variable 'config'.\"}]},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'e' is defined but never used.\",\"line\":94,\"column\":18,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":94,\"endColumn\":19}],\"suppressedMessages\":[],\"errorCount\":2,\"fatalErrorCount\":0,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Audio Processing Chain Module\\n * Handles audio preprocessing filters and graph connections\\n */\\n\\nexport const createAudioProcessingChain = (audioContext, config) => {\\n  const nodes = {\\n    gain: null,\\n    compressor: null,\\n    highpass: null,\\n    lowpass: null,\\n    notch: null\\n  };\\n\\n  // Create audio preprocessing chain\\n  const createPreprocessingChain = () => {\\n    // Gain control\\n    nodes.gain = audioContext.createGain();\\n    nodes.gain.gain.value = 1.0;\\n    \\n    // Dynamic range compression\\n    nodes.compressor = audioContext.createDynamicsCompressor();\\n    nodes.compressor.threshold.value = -24;\\n    nodes.compressor.knee.value = 30;\\n    nodes.compressor.ratio.value = 12;\\n    nodes.compressor.attack.value = 0.003;\\n    nodes.compressor.release.value = 0.25;\\n    \\n    // High-pass filter (remove DC offset and rumble)\\n    nodes.highpass = audioContext.createBiquadFilter();\\n    nodes.highpass.type = 'highpass';\\n    nodes.highpass.frequency.value = 80; // Hz\\n    nodes.highpass.Q.value = 0.7;\\n    \\n    // Low-pass filter (anti-aliasing)\\n    nodes.lowpass = audioContext.createBiquadFilter();\\n    nodes.lowpass.type = 'lowpass';\\n    nodes.lowpass.frequency.value = 8000; // Hz\\n    nodes.lowpass.Q.value = 0.7;\\n    \\n    // Notch filter for 50/60Hz hum removal\\n    nodes.notch = audioContext.createBiquadFilter();\\n    nodes.notch.type = 'notch';\\n    nodes.notch.frequency.value = 60; // Hz (adjust for your region)\\n    nodes.notch.Q.value = 30;\\n\\n    return nodes;\\n  };\\n\\n  // Connect preprocessing chain\\n  const connectPreprocessingChain = (microphone, analyser, scriptProcessor) => {\\n    microphone\\n      .connect(nodes.gain)\\n      .connect(nodes.highpass)\\n      .connect(nodes.lowpass)\\n      .connect(nodes.notch)\\n      .connect(nodes.compressor)\\n      .connect(analyser);\\n    \\n    nodes.compressor.connect(scriptProcessor);\\n  };\\n\\n  // Connect simple chain without preprocessing\\n  const connectSimpleChain = (microphone, analyser, scriptProcessor) => {\\n    microphone.connect(analyser);\\n    microphone.connect(scriptProcessor);\\n  };\\n\\n  // Update preprocessing parameters\\n  const updateParameters = (params) => {\\n    if (params.gain && nodes.gain) {\\n      nodes.gain.gain.value = params.gain;\\n    }\\n    if (params.threshold && nodes.compressor) {\\n      nodes.compressor.threshold.value = params.threshold;\\n    }\\n    if (params.highpassFreq && nodes.highpass) {\\n      nodes.highpass.frequency.value = params.highpassFreq;\\n    }\\n    if (params.lowpassFreq && nodes.lowpass) {\\n      nodes.lowpass.frequency.value = params.lowpassFreq;\\n    }\\n    if (params.notchFreq && nodes.notch) {\\n      nodes.notch.frequency.value = params.notchFreq;\\n    }\\n  };\\n\\n  // Cleanup processing nodes\\n  const cleanup = () => {\\n    Object.values(nodes).forEach(node => {\\n      if (node) {\\n        try {\\n          node.disconnect();\\n        } catch (e) {\\n          // Node may already be disconnected\\n        }\\n      }\\n    });\\n  };\\n\\n  return {\\n    createPreprocessingChain,\\n    connectPreprocessingChain,\\n    connectSimpleChain,\\n    updateParameters,\\n    cleanup,\\n    getNodes: () => nodes\\n  };\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/features/speech-analysis/audio/prosodic-analyzer.js\",\"messages\":[{\"ruleId\":\"max-lines-per-function\",\"severity\":1,\"message\":\"Arrow function has too many lines (215). Maximum allowed is 150.\",\"line\":7,\"column\":39,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"exceed\",\"endLine\":295,\"endColumn\":2},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":112,\"column\":16,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":112,\"endColumn\":17},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":112,\"column\":53,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":112,\"endColumn\":54},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":112,\"column\":53,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":112,\"endColumn\":54},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":114,\"column\":89,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":114,\"endColumn\":90},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'audioBuffer' is defined but never used. Allowed unused args must match /^_/u.\",\"line\":122,\"column\":26,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":122,\"endColumn\":37,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"audioBuffer\"},\"fix\":{\"range\":[3607,3619],\"text\":\"\"},\"desc\":\"Remove unused variable 'audioBuffer'.\"}]},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'timestamp' is defined but never used. Allowed unused args must match /^_/u.\",\"line\":122,\"column\":39,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":122,\"endColumn\":48,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"timestamp\"},\"fix\":{\"range\":[3618,3629],\"text\":\"\"},\"desc\":\"Remove unused variable 'timestamp'.\"}]},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":253,\"column\":60,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":253,\"endColumn\":61},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":253,\"column\":92,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":253,\"endColumn\":93},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":265,\"column\":60,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":265,\"endColumn\":61},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":265,\"column\":92,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":265,\"endColumn\":93}],\"suppressedMessages\":[],\"errorCount\":2,\"fatalErrorCount\":0,\"warningCount\":9,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Prosodic Analysis Module\\n * Extracts pitch, energy, and timing features from speech audio\\n */\\n\\n// Prosodic feature extraction for emotion detection\\nexport const createProsodicAnalyzer = (config = {}) => {\\n  const state = {\\n    config: {\\n      frameSize: config.frameSize || 1024,\\n      hopSize: config.hopSize || 512,\\n      sampleRate: config.sampleRate || 44100,\\n      \\n      // Prosodic parameters\\n      pitchRange: config.pitchRange || [80, 400], // Hz\\n      energySmoothing: config.energySmoothing || 0.3,\\n      timingWindowSize: config.timingWindowSize || 10, // frames\\n      \\n      // Feature normalization\\n      normalizeFeatures: config.normalizeFeatures !== false,\\n      adaptiveNormalization: config.adaptiveNormalization !== false\\n    },\\n    \\n    // Feature history for temporal analysis\\n    featureHistory: [],\\n    normalizationStats: {\\n      pitch: { mean: 150, std: 50 },\\n      energy: { mean: 0.1, std: 0.05 },\\n      tempo: { mean: 1.0, std: 0.3 }\\n    },\\n    \\n    // Statistics\\n    stats: {\\n      totalFrames: 0,\\n      averagePitch: 0,\\n      averageEnergy: 0,\\n      pitchVariability: 0,\\n      energyVariability: 0\\n    }\\n  };\\n\\n  // Extract pitch using autocorrelation\\n  const extractPitch = (audioBuffer) => {\\n    const [minPeriod, maxPeriod] = [\\n      Math.floor(state.config.sampleRate / state.config.pitchRange[1]),\\n      Math.floor(state.config.sampleRate / state.config.pitchRange[0])\\n    ];\\n    \\n    let bestCorrelation = 0;\\n    let bestPeriod = minPeriod;\\n    \\n    for (let period = minPeriod; period <= maxPeriod && period < audioBuffer.length / 2; period++) {\\n      let correlation = 0;\\n      const samples = audioBuffer.length - period;\\n      \\n      for (let i = 0; i < samples; i++) {\\n        correlation += audioBuffer[i] * audioBuffer[i + period];\\n      }\\n      \\n      correlation /= samples;\\n      \\n      // Normalize by energy\\n      let energy = 0;\\n      for (let i = 0; i < samples; i++) {\\n        energy += audioBuffer[i] * audioBuffer[i];\\n      }\\n      energy = Math.sqrt(energy / samples);\\n      \\n      if (energy > 0.001) { // Only consider frames with significant energy\\n        correlation /= (energy * energy);\\n        \\n        if (correlation > bestCorrelation) {\\n          bestCorrelation = correlation;\\n          bestPeriod = period;\\n        }\\n      }\\n    }\\n    \\n    // Convert to frequency\\n    const pitch = bestCorrelation > 0.3 ? state.config.sampleRate / bestPeriod : 0;\\n    \\n    // Apply smoothing and bounds checking\\n    return pitch > state.config.pitchRange[0] && pitch < state.config.pitchRange[1] ? pitch : 0;\\n  };\\n\\n  // Extract energy features\\n  const extractEnergy = (audioBuffer) => {\\n    // RMS energy\\n    let rms = 0;\\n    for (let i = 0; i < audioBuffer.length; i++) {\\n      rms += audioBuffer[i] * audioBuffer[i];\\n    }\\n    rms = Math.sqrt(rms / audioBuffer.length);\\n    \\n    // Peak energy\\n    let peak = 0;\\n    for (let i = 0; i < audioBuffer.length; i++) {\\n      const abs = Math.abs(audioBuffer[i]);\\n      if (abs > peak) peak = abs;\\n    }\\n    \\n    // Zero crossing rate (for voicing detection)\\n    let zcr = 0;\\n    for (let i = 1; i < audioBuffer.length; i++) {\\n      if ((audioBuffer[i] >= 0) !== (audioBuffer[i - 1] >= 0)) {\\n        zcr++;\\n      }\\n    }\\n    zcr /= audioBuffer.length;\\n    \\n    return {\\n      rms: rms * (1 - state.config.energySmoothing) + \\n           (state.featureHistory.length > 0 ? \\n            state.featureHistory[state.featureHistory.length - 1].energy?.rms || 0 : 0) * \\n           state.config.energySmoothing,\\n      peak,\\n      zcr\\n    };\\n  };\\n\\n  // Extract timing and rhythm features\\n  const extractTiming = (audioBuffer, timestamp) => {\\n    // Simple tempo estimation based on energy peaks\\n    const windowSize = state.config.timingWindowSize;\\n    \\n    if (state.featureHistory.length < windowSize) {\\n      return {\\n        tempo: 1.0,\\n        rhythm: 0.5,\\n        pauses: 0\\n      };\\n    }\\n    \\n    // Calculate inter-peak intervals\\n    const recent = state.featureHistory.slice(-windowSize);\\n    const energyThreshold = recent.reduce((sum, f) => sum + f.energy.rms, 0) / recent.length * 1.5;\\n    \\n    const peaks = [];\\n    for (let i = 1; i < recent.length - 1; i++) {\\n      if (recent[i].energy.rms > energyThreshold &&\\n          recent[i].energy.rms > recent[i-1].energy.rms &&\\n          recent[i].energy.rms > recent[i+1].energy.rms) {\\n        peaks.push(i);\\n      }\\n    }\\n    \\n    // Estimate tempo from peak intervals\\n    let tempo = 1.0;\\n    if (peaks.length > 1) {\\n      const intervals = [];\\n      for (let i = 1; i < peaks.length; i++) {\\n        intervals.push(peaks[i] - peaks[i-1]);\\n      }\\n      \\n      const avgInterval = intervals.reduce((sum, interval) => sum + interval, 0) / intervals.length;\\n      tempo = 60 / (avgInterval * state.config.hopSize / state.config.sampleRate); // BPM converted to relative\\n      tempo = Math.max(0.5, Math.min(2.0, tempo / 120)); // Normalize around 120 BPM\\n    }\\n    \\n    // Simple pause detection\\n    const silenceThreshold = 0.01;\\n    const silentFrames = recent.filter(f => f.energy.rms < silenceThreshold).length;\\n    const pauseRatio = silentFrames / recent.length;\\n    \\n    return {\\n      tempo,\\n      rhythm: 1 - pauseRatio, // Inverse of pause ratio\\n      pauses: pauseRatio\\n    };\\n  };\\n\\n  // Normalize features using adaptive or fixed normalization\\n  const normalizeFeatures = (features) => {\\n    if (!state.config.normalizeFeatures) {\\n      return features;\\n    }\\n    \\n    const normalizedFeatures = { ...features };\\n    \\n    if (state.config.adaptiveNormalization && state.featureHistory.length > 10) {\\n      // Update normalization statistics\\n      const recentFeatures = state.featureHistory.slice(-50);\\n      const validPitches = recentFeatures.map(f => f.pitch).filter(p => p > 0);\\n      const energies = recentFeatures.map(f => f.energy.rms);\\n      const tempos = recentFeatures.map(f => f.timing.tempo);\\n      \\n      if (validPitches.length > 0) {\\n        state.normalizationStats.pitch.mean = validPitches.reduce((sum, p) => sum + p, 0) / validPitches.length;\\n        state.normalizationStats.pitch.std = Math.sqrt(\\n          validPitches.reduce((sum, p) => sum + Math.pow(p - state.normalizationStats.pitch.mean, 2), 0) / validPitches.length\\n        );\\n      }\\n      \\n      state.normalizationStats.energy.mean = energies.reduce((sum, e) => sum + e, 0) / energies.length;\\n      state.normalizationStats.energy.std = Math.sqrt(\\n        energies.reduce((sum, e) => sum + Math.pow(e - state.normalizationStats.energy.mean, 2), 0) / energies.length\\n      );\\n      \\n      state.normalizationStats.tempo.mean = tempos.reduce((sum, t) => sum + t, 0) / tempos.length;\\n      state.normalizationStats.tempo.std = Math.sqrt(\\n        tempos.reduce((sum, t) => sum + Math.pow(t - state.normalizationStats.tempo.mean, 2), 0) / tempos.length\\n      );\\n    }\\n    \\n    // Apply normalization\\n    if (features.pitch > 0) {\\n      normalizedFeatures.pitch = (features.pitch - state.normalizationStats.pitch.mean) / \\n                                (state.normalizationStats.pitch.std || 1);\\n    }\\n    \\n    normalizedFeatures.energy = {\\n      ...features.energy,\\n      rms: (features.energy.rms - state.normalizationStats.energy.mean) / \\n           (state.normalizationStats.energy.std || 1)\\n    };\\n    \\n    normalizedFeatures.timing = {\\n      ...features.timing,\\n      tempo: (features.timing.tempo - state.normalizationStats.tempo.mean) / \\n             (state.normalizationStats.tempo.std || 1)\\n    };\\n    \\n    return normalizedFeatures;\\n  };\\n\\n  // Process audio frame and extract prosodic features\\n  const processFrame = (audioBuffer, timestamp = Date.now()) => {\\n    const pitch = extractPitch(audioBuffer);\\n    const energy = extractEnergy(audioBuffer);\\n    const timing = extractTiming(audioBuffer, timestamp);\\n    \\n    const features = {\\n      pitch,\\n      energy,\\n      timing,\\n      timestamp\\n    };\\n    \\n    // Normalize features\\n    const normalizedFeatures = normalizeFeatures(features);\\n    \\n    // Add to history\\n    state.featureHistory.push(normalizedFeatures);\\n    \\n    // Maintain history size\\n    if (state.featureHistory.length > 100) {\\n      state.featureHistory.shift();\\n    }\\n    \\n    // Update statistics\\n    state.stats.totalFrames++;\\n    if (pitch > 0) {\\n      state.stats.averagePitch = (state.stats.averagePitch * (state.stats.totalFrames - 1) + pitch) / state.stats.totalFrames;\\n      \\n      // Calculate pitch variability\\n      const recentPitches = state.featureHistory.slice(-10).map(f => f.pitch).filter(p => p > 0);\\n      if (recentPitches.length > 1) {\\n        const pitchMean = recentPitches.reduce((sum, p) => sum + p, 0) / recentPitches.length;\\n        state.stats.pitchVariability = Math.sqrt(\\n          recentPitches.reduce((sum, p) => sum + Math.pow(p - pitchMean, 2), 0) / recentPitches.length\\n        );\\n      }\\n    }\\n    \\n    state.stats.averageEnergy = (state.stats.averageEnergy * (state.stats.totalFrames - 1) + energy.rms) / state.stats.totalFrames;\\n    \\n    // Calculate energy variability\\n    const recentEnergies = state.featureHistory.slice(-10).map(f => f.energy.rms);\\n    if (recentEnergies.length > 1) {\\n      const energyMean = recentEnergies.reduce((sum, e) => sum + e, 0) / recentEnergies.length;\\n      state.stats.energyVariability = Math.sqrt(\\n        recentEnergies.reduce((sum, e) => sum + Math.pow(e - energyMean, 2), 0) / recentEnergies.length\\n      );\\n    }\\n    \\n    return normalizedFeatures;\\n  };\\n\\n  return {\\n    processFrame,\\n    getStats: () => ({ ...state.stats }),\\n    getFeatureHistory: () => [...state.featureHistory],\\n    updateConfig: (newConfig) => Object.assign(state.config, newConfig),\\n    reset: () => {\\n      state.featureHistory = [];\\n      state.stats = {\\n        totalFrames: 0,\\n        averagePitch: 0,\\n        averageEnergy: 0,\\n        pitchVariability: 0,\\n        energyVariability: 0\\n      };\\n    }\\n  };\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/features/speech-analysis/audio/quality-analyzer-config.js\",\"messages\":[],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/features/speech-analysis/audio/quality-analyzer-core.js\",\"messages\":[{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":67,\"column\":67,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":67,\"endColumn\":68},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":67,\"column\":71,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":67,\"endColumn\":72}],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":2,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Audio Quality Analysis Core\\n * Core quality analysis and scoring logic\\n */\\n\\nexport const createQualityAnalysisCore = (state) => {\\n  // Run individual quality analyses\\n  const runAnalyses = (audioBuffer, fftMagnitudes, isQuiet) => {\\n    const snrResult = state.snrCalculator.calculateSNR(audioBuffer, fftMagnitudes, isQuiet);\\n    let thdResult = { thd: 0, quality: 100 };\\n    if (fftMagnitudes) {\\n      thdResult = state.thdCalculator.calculateTHD(fftMagnitudes);\\n    }\\n    const clippingResult = state.clippingDetector.detectClipping(audioBuffer);\\n    \\n    return { snrResult, thdResult, clippingResult };\\n  };\\n\\n  // Calculate weighted overall quality score\\n  const calculateOverallQuality = (snrResult, thdResult, clippingResult) => {\\n    const snrWeight = 0.4;\\n    const thdWeight = 0.3;\\n    const clippingWeight = 0.3;\\n    \\n    return (snrResult.quality * snrWeight) +\\n           (thdResult.quality * thdWeight) +\\n           (clippingResult.quality * clippingWeight);\\n  };\\n\\n  // Determine quality level from score\\n  const determineQualityLevel = (overallQuality) => {\\n    if (overallQuality >= state.config.qualityThresholds.excellent) {\\n      return 'excellent';\\n    } else if (overallQuality >= state.config.qualityThresholds.good) {\\n      return 'good';\\n    } else if (overallQuality >= state.config.qualityThresholds.fair) {\\n      return 'fair';\\n    } else {\\n      return 'poor';\\n    }\\n  };\\n\\n  // Generate quality recommendations\\n  const generateRecommendations = (snrResult, thdResult, clippingResult) => {\\n    const recommendations = [];\\n    \\n    if (snrResult.snr < 10) {\\n      recommendations.push('Reduce background noise or increase microphone gain');\\n    }\\n    if (thdResult.thdPercent > 10) {\\n      recommendations.push('Check for audio hardware distortion or overdriving');\\n    }\\n    if (clippingResult.isClipped) {\\n      recommendations.push('Reduce input level to prevent audio clipping');\\n    }\\n    if (snrResult.snr > 40 && thdResult.thdPercent < 1 && !clippingResult.isClipped) {\\n      recommendations.push('Excellent audio quality - maintain current settings');\\n    } else if (snrResult.signalStrength < -20) {\\n      recommendations.push('Increase microphone sensitivity or move closer to source');\\n    }\\n    \\n    return recommendations;\\n  };\\n\\n  // Calculate detailed metrics\\n  const calculateDetailedMetrics = (snrResult, thdResult, clippingResult, audioBuffer) => {\\n    const rmsLevel = Math.sqrt(audioBuffer.reduce((sum, s) => sum + s * s, 0) / audioBuffer.length);\\n    const peakLevel = Math.max(...audioBuffer.map(Math.abs));\\n    \\n    return {\\n      signalStrength: 20 * Math.log10(rmsLevel + 1e-10),\\n      noiseLevel: snrResult.noiseLevel || -60,\\n      distortion: thdResult.thdPercent || 0,\\n      clarity: Math.max(0, 100 - (thdResult.thdPercent || 0) - Math.max(0, (clippingResult.clippingPercent || 0) * 10)),\\n      dynamicRange: 20 * Math.log10((peakLevel + 1e-10) / (rmsLevel + 1e-10)),\\n      peakLevel: 20 * Math.log10(peakLevel + 1e-10)\\n    };\\n  };\\n\\n  return {\\n    runAnalyses,\\n    calculateOverallQuality,\\n    determineQualityLevel,\\n    generateRecommendations,\\n    calculateDetailedMetrics\\n  };\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/features/speech-analysis/audio/quality-analyzer-stats.js\",\"messages\":[{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":16,\"column\":42,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":16,\"endColumn\":43},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":16,\"column\":59,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":16,\"endColumn\":60},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":16,\"column\":59,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":16,\"endColumn\":60},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":16,\"column\":73,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":16,\"endColumn\":74}],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":4,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Quality Analysis Statistics Manager\\n * Manages quality statistics and trends\\n */\\n\\nexport const createQualityStatsManager = (state) => {\\n  // Update quality statistics\\n  const updateStats = (overallQuality, qualityLevel) => {\\n    state.stats.totalFrames++;\\n    \\n    // Update running average\\n    const alpha = 0.1; // Smoothing factor\\n    if (state.stats.totalFrames === 1) {\\n      state.stats.overallQuality = overallQuality;\\n    } else {\\n      state.stats.overallQuality = alpha * overallQuality + (1 - alpha) * state.stats.overallQuality;\\n    }\\n    \\n    // Update quality distribution\\n    state.stats.qualityDistribution[qualityLevel]++;\\n    \\n    // Add to quality trend (keep last 100 samples)\\n    state.stats.qualityTrend.push({\\n      quality: overallQuality,\\n      level: qualityLevel,\\n      timestamp: Date.now()\\n    });\\n    \\n    if (state.stats.qualityTrend.length > 100) {\\n      state.stats.qualityTrend.shift();\\n    }\\n  };\\n\\n  // Get quality trend analysis\\n  const getTrendAnalysis = () => {\\n    if (state.stats.qualityTrend.length < 5) {\\n      return { trend: 'insufficient_data', confidence: 0 };\\n    }\\n    \\n    const recent = state.stats.qualityTrend.slice(-10);\\n    const older = state.stats.qualityTrend.slice(-20, -10);\\n    \\n    if (older.length === 0) {\\n      return { trend: 'stable', confidence: 0.5 };\\n    }\\n    \\n    const recentAvg = recent.reduce((sum, s) => sum + s.quality, 0) / recent.length;\\n    const olderAvg = older.reduce((sum, s) => sum + s.quality, 0) / older.length;\\n    \\n    const change = recentAvg - olderAvg;\\n    const confidence = Math.min(1.0, Math.abs(change) / 10);\\n    \\n    let trend;\\n    if (Math.abs(change) < 2) {\\n      trend = 'stable';\\n    } else if (change > 0) {\\n      trend = change > 5 ? 'improving_significantly' : 'improving';\\n    } else {\\n      trend = change < -5 ? 'degrading_significantly' : 'degrading';\\n    }\\n    \\n    return { trend, confidence, change };\\n  };\\n\\n  // Get comprehensive statistics\\n  const getComprehensiveStats = () => ({\\n    ...state.stats,\\n    qualityTrendAnalysis: getTrendAnalysis(),\\n    averageQualityByLevel: {\\n      excellent: state.stats.qualityDistribution.excellent / Math.max(1, state.stats.totalFrames) * 100,\\n      good: state.stats.qualityDistribution.good / Math.max(1, state.stats.totalFrames) * 100,\\n      fair: state.stats.qualityDistribution.fair / Math.max(1, state.stats.totalFrames) * 100,\\n      poor: state.stats.qualityDistribution.poor / Math.max(1, state.stats.totalFrames) * 100\\n    }\\n  });\\n\\n  return {\\n    updateStats,\\n    getTrendAnalysis,\\n    getComprehensiveStats\\n  };\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/features/speech-analysis/audio/realtime-audio-analyzer.js\",\"messages\":[{\"ruleId\":\"max-lines-per-function\",\"severity\":1,\"message\":\"Arrow function has too many lines (184). Maximum allowed is 150.\",\"line\":14,\"column\":44,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"exceed\",\"endLine\":273,\"endColumn\":2}],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":1,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Real-time Audio Analysis Pipeline\\n * Advanced audio processing and feature extraction for speech analysis\\n * Following functional programming patterns with factory functions\\n */\\n\\n// Import modular components\\nimport { createAudioProcessingChain } from './processing-chain.js';\\nimport { createFeatureExtractor } from './feature-extractor.js';\\nimport { createAnalysisProcessor } from './analysis-processor.js';\\nimport { createCallbackNotifier } from './callback-notifier.js';\\n\\n// Create real-time audio analyzer factory\\nexport const createRealtimeAudioAnalyzer = (config = {}) => {\\n  const state = {\\n    audioContext: null,\\n    analyser: null,\\n    microphone: null,\\n    scriptProcessor: null,\\n    \\n    // Analysis buffers\\n    buffers: {\\n      time: null,\\n      frequency: null,\\n      fftSize: config.fftSize || 2048,\\n      smoothing: config.smoothingTimeConstant || 0.8\\n    },\\n    \\n    // Feature extraction\\n    features: {\\n      pitch: 0,\\n      energy: 0,\\n      spectralCentroid: 0,\\n      spectralRolloff: 0,\\n      zeroCrossingRate: 0,\\n      mfcc: [],\\n      formants: []\\n    },\\n    \\n    // Configuration\\n    config: {\\n      sampleRate: config.sampleRate || 48000,\\n      fftSize: config.fftSize || 2048,\\n      smoothingTimeConstant: config.smoothingTimeConstant || 0.8,\\n      minPitch: config.minPitch || 50, // Hz\\n      maxPitch: config.maxPitch || 400, // Hz\\n      frameSize: config.frameSize || 512,\\n      hopSize: config.hopSize || 256,\\n      enablePreprocessing: config.enablePreprocessing !== false,\\n      enableNoiseSuppression: config.enableNoiseSuppression !== false,\\n      ...config\\n    },\\n    \\n    // State tracking\\n    isInitialized: false,\\n    isAnalyzing: false,\\n    \\n    // Callbacks\\n    callbacks: {\\n      onFeatures: [],\\n      onPitch: [],\\n      onEnergy: [],\\n      onSpectrum: [],\\n      onError: []\\n    },\\n    \\n    // Performance metrics\\n    metrics: {\\n      framesProcessed: 0,\\n      lastProcessTime: 0,\\n      averageLatency: 0\\n    }\\n  };\\n\\n  // Create modular components\\n  const callbackNotifier = createCallbackNotifier(state);\\n  const featureExtractor = createFeatureExtractor(state.config);\\n  const analysisProcessor = createAnalysisProcessor(state, featureExtractor, callbackNotifier);\\n  let processingChain = null;\\n\\n  // Initialize audio context and analyzer\\n  const initialize = async () => {\\n    try {\\n      // Create audio context\\n      const AudioContext = window.AudioContext || window.webkitAudioContext;\\n      state.audioContext = new AudioContext({\\n        sampleRate: state.config.sampleRate,\\n        latencyHint: 'interactive'\\n      });\\n      \\n      // Create analyser node\\n      state.analyser = state.audioContext.createAnalyser();\\n      state.analyser.fftSize = state.config.fftSize;\\n      state.analyser.smoothingTimeConstant = state.config.smoothingTimeConstant;\\n      \\n      // Initialize buffers\\n      state.buffers.time = new Float32Array(state.analyser.fftSize);\\n      state.buffers.frequency = new Float32Array(state.analyser.frequencyBinCount);\\n      \\n      // Create processing chain\\n      processingChain = createAudioProcessingChain(state.audioContext, state.config);\\n      \\n      // Create preprocessing chain if enabled\\n      if (state.config.enablePreprocessing) {\\n        processingChain.createPreprocessingChain();\\n      }\\n      \\n      state.isInitialized = true;\\n      console.log('✅ Real-time audio analyzer initialized');\\n      console.log(`📊 Sample rate: ${state.audioContext.sampleRate}Hz`);\\n      console.log(`📊 FFT size: ${state.analyser.fftSize}`);\\n      \\n      return true;\\n    } catch (error) {\\n      console.error('Failed to initialize audio analyzer:', error);\\n      callbackNotifier.notifyError(error);\\n      throw error;\\n    }\\n  };\\n\\n  // Start audio analysis\\n  const startAnalysis = async (stream) => {\\n    if (!state.isInitialized) {\\n      await initialize();\\n    }\\n    \\n    if (state.isAnalyzing) {\\n      console.warn('Already analyzing audio');\\n      return;\\n    }\\n    \\n    try {\\n      // Create microphone source\\n      state.microphone = state.audioContext.createMediaStreamSource(stream);\\n      \\n      // Create script processor for real-time processing\\n      state.scriptProcessor = state.audioContext.createScriptProcessor(\\n        state.config.frameSize,\\n        1, // mono input\\n        1  // mono output\\n      );\\n      \\n      // Setup audio processing callback\\n      state.scriptProcessor.onaudioprocess = analysisProcessor.processAudioFrame;\\n      \\n      // Connect audio graph\\n      if (state.config.enablePreprocessing) {\\n        processingChain.connectPreprocessingChain(state.microphone, state.analyser, state.scriptProcessor);\\n      } else {\\n        processingChain.connectSimpleChain(state.microphone, state.analyser, state.scriptProcessor);\\n      }\\n      \\n      state.scriptProcessor.connect(state.audioContext.destination);\\n      \\n      state.isAnalyzing = true;\\n      console.log('🎤 Started real-time audio analysis');\\n      \\n    } catch (error) {\\n      console.error('Failed to start audio analysis:', error);\\n      callbackNotifier.notifyError(error);\\n      throw error;\\n    }\\n  };\\n\\n  // Stop audio analysis\\n  const stopAnalysis = () => {\\n    if (!state.isAnalyzing) return;\\n    \\n    try {\\n      if (state.scriptProcessor) {\\n        state.scriptProcessor.disconnect();\\n        state.scriptProcessor.onaudioprocess = null;\\n        state.scriptProcessor = null;\\n      }\\n      \\n      if (state.microphone) {\\n        state.microphone.disconnect();\\n        state.microphone = null;\\n      }\\n      \\n      // Cleanup processing chain\\n      if (processingChain) {\\n        processingChain.cleanup();\\n      }\\n      \\n      state.isAnalyzing = false;\\n      console.log('🛑 Stopped real-time audio analysis');\\n      \\n    } catch (error) {\\n      console.error('Error stopping audio analysis:', error);\\n      callbackNotifier.notifyError(error);\\n    }\\n  };\\n\\n  // Data access methods\\n  const getFeatures = () => ({ ...state.features });\\n  \\n  const getSpectrum = () => new Float32Array(state.buffers.frequency);\\n  \\n  const getWaveform = () => new Float32Array(state.buffers.time);\\n  \\n  const getMetrics = () => analysisProcessor.getProcessingStats();\\n\\n  // Configuration methods\\n  const updateConfig = (newConfig) => {\\n    Object.assign(state.config, newConfig);\\n    \\n    if (state.analyser) {\\n      if (newConfig.fftSize) {\\n        state.analyser.fftSize = newConfig.fftSize;\\n        state.buffers.time = new Float32Array(state.analyser.fftSize);\\n        state.buffers.frequency = new Float32Array(state.analyser.frequencyBinCount);\\n      }\\n      \\n      if (newConfig.smoothingTimeConstant !== undefined) {\\n        state.analyser.smoothingTimeConstant = newConfig.smoothingTimeConstant;\\n      }\\n    }\\n\\n    // Update processing chain parameters if needed\\n    if (processingChain && newConfig.gain !== undefined) {\\n      processingChain.updateParameters({ gain: newConfig.gain });\\n    }\\n  };\\n\\n  // Cleanup\\n  const cleanup = () => {\\n    stopAnalysis();\\n    \\n    if (state.audioContext) {\\n      state.audioContext.close();\\n      state.audioContext = null;\\n    }\\n    \\n    if (processingChain) {\\n      processingChain.cleanup();\\n    }\\n\\n    callbackNotifier.clearAllCallbacks();\\n    \\n    state.isInitialized = false;\\n    console.log('🧹 Audio analyzer cleaned up');\\n  };\\n\\n  return {\\n    // Core functionality\\n    initialize,\\n    startAnalysis,\\n    stopAnalysis,\\n    cleanup,\\n    \\n    // Data access\\n    getFeatures,\\n    getSpectrum,\\n    getWaveform,\\n    getMetrics,\\n    \\n    // Configuration\\n    updateConfig,\\n    getConfig: () => ({ ...state.config }),\\n    \\n    // Status\\n    isInitialized: () => state.isInitialized,\\n    isAnalyzing: () => state.isAnalyzing,\\n    \\n    // Event handlers - delegated to callbackNotifier\\n    onFeatures: callbackNotifier.onFeatures,\\n    onPitch: callbackNotifier.onPitch,\\n    onEnergy: callbackNotifier.onEnergy,\\n    onSpectrum: callbackNotifier.onSpectrum,\\n    onError: callbackNotifier.onError\\n  };\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/features/speech-analysis/audio/speaker-diarization.js\",\"messages\":[{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'createVoiceFingerprinting' is defined but never used. Allowed unused vars must match /^_/u.\",\"line\":13,\"column\":10,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":13,\"endColumn\":35,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"createVoiceFingerprinting\"},\"fix\":{\"range\":[500,582],\"text\":\"\"},\"desc\":\"Remove unused variable 'createVoiceFingerprinting'.\"}]},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'createSpeakerChangeDetection' is defined but never used. Allowed unused vars must match /^_/u.\",\"line\":14,\"column\":10,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":14,\"endColumn\":38,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"createSpeakerChangeDetection\"},\"fix\":{\"range\":[583,672],\"text\":\"\"},\"desc\":\"Remove unused variable 'createSpeakerChangeDetection'.\"}]}],\"suppressedMessages\":[],\"errorCount\":2,\"fatalErrorCount\":0,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Speaker Diarization Module\\n * Advanced speaker identification and segmentation for multi-speaker conversations\\n * Following functional programming patterns with factory functions\\n * \\n * Refactored into modular components for maintainability:\\n * - Voice Fingerprinting: MFCC-based speaker identification\\n * - Speaker Change Detection: Audio feature-based change point detection  \\n * - Diarization Manager: Orchestrates both components for complete diarization\\n */\\n\\n// Import modular components\\nimport { createVoiceFingerprinting } from './diarization/voice-fingerprinting.js';\\nimport { createSpeakerChangeDetection } from './diarization/speaker-change-detection.js';\\nimport { createDiarizationManager } from './diarization/diarization-manager.js';\\n\\n// Re-export individual components for advanced usage\\nexport { createVoiceFingerprinting } from './diarization/voice-fingerprinting.js';\\nexport { createSpeakerChangeDetection } from './diarization/speaker-change-detection.js';\\n\\n// Main speaker diarization system using the diarization manager\\nexport const createSpeakerDiarization = (config = {}) => {\\n  console.log('🎙️ Initializing comprehensive speaker diarization system...');\\n  \\n  // Create diarization manager with all modular components\\n  const diarizationManager = createDiarizationManager(config);\\n  \\n  console.log('✅ Speaker diarization system initialized with modular components');\\n  \\n  // Return the complete API with enhanced logging\\n  return {\\n    ...diarizationManager,\\n    \\n    // Enhanced processing with logging\\n    processFrame: (audioBuffer, timestamp = Date.now()) => {\\n      const result = diarizationManager.processFrame(audioBuffer, timestamp);\\n      \\n      if (result.speakerChanged) {\\n        console.log(`🔄 Speaker change detected: ${result.speakerId} (confidence: ${result.confidence.toFixed(3)})`);\\n      }\\n      \\n      return result;\\n    },\\n    \\n    // Enhanced stats with component breakdown\\n    getStats: () => {\\n      const stats = diarizationManager.getStats();\\n      \\n      console.log('📊 Diarization Stats:', {\\n        totalFrames: stats.totalFrames,\\n        totalSpeakers: stats.totalSpeakers,\\n        totalSpeakerSwitches: stats.totalSpeakerSwitches,\\n        averageConfidence: stats.confidence?.toFixed(3) || 'N/A',\\n        activeSpeaker: stats.activeSpeaker\\n      });\\n      \\n      return stats;\\n    },\\n    \\n    // Enhanced reset with logging\\n    reset: () => {\\n      console.log('🔄 Resetting speaker diarization system...');\\n      diarizationManager.reset();\\n      console.log('✅ Speaker diarization system reset');\\n    },\\n    \\n    // Enhanced cleanup with logging  \\n    cleanup: () => {\\n      console.log('🧹 Cleaning up speaker diarization system...');\\n      diarizationManager.cleanup();\\n      console.log('✅ Speaker diarization system cleaned up');\\n    }\\n  };\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/features/speech-analysis/audio/speaking-pace-analysis.js\",\"messages\":[{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'createSpeakingRateAnalyzer' is defined but never used. Allowed unused vars must match /^_/u.\",\"line\":13,\"column\":10,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":13,\"endColumn\":36,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"createSpeakingRateAnalyzer\"},\"fix\":{\"range\":[535,613],\"text\":\"\"},\"desc\":\"Remove unused variable 'createSpeakingRateAnalyzer'.\"}]},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'createFluencyAnalyzer' is defined but never used. Allowed unused vars must match /^_/u.\",\"line\":14,\"column\":10,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":14,\"endColumn\":31,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"createFluencyAnalyzer\"},\"fix\":{\"range\":[614,681],\"text\":\"\"},\"desc\":\"Remove unused variable 'createFluencyAnalyzer'.\"}]}],\"suppressedMessages\":[],\"errorCount\":2,\"fatalErrorCount\":0,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Speaking Pace Analysis Module\\n * Advanced speech rate, fluency, and articulation pattern analysis\\n * Following functional programming patterns with factory functions\\n * \\n * Refactored into modular components for maintainability:\\n * - Speaking Rate Analyzer: Words per minute, syllable rates, and speed categorization\\n * - Fluency Analyzer: Filler words, hesitations, repetitions, and speech flow analysis\\n * - Pace Analysis Manager: Orchestrates both components for comprehensive pace analysis\\n */\\n\\n// Import modular components\\nimport { createSpeakingRateAnalyzer } from './pace/speaking-rate-analyzer.js';\\nimport { createFluencyAnalyzer } from './pace/fluency-analyzer.js';\\nimport { createPaceAnalysisManager } from './pace/pace-analysis-manager.js';\\n\\n// Re-export individual components for advanced usage\\nexport { createSpeakingRateAnalyzer } from './pace/speaking-rate-analyzer.js';\\nexport { createFluencyAnalyzer } from './pace/fluency-analyzer.js';\\n\\n// Main speaking pace analysis system using the pace analysis manager\\nexport const createSpeakingPaceAnalysis = (config = {}) => {\\n  console.log('⏱️ Initializing comprehensive speaking pace analysis system...');\\n  \\n  // Create pace analysis manager with all modular components\\n  const paceManager = createPaceAnalysisManager(config);\\n  \\n  console.log('✅ Speaking pace analysis system initialized with modular components');\\n  \\n  // Return the complete API with enhanced logging and reporting\\n  return {\\n    ...paceManager,\\n    \\n    // Enhanced processing with logging\\n    processSegment: (text, startTime, endTime, speakerId = null) => {\\n      const result = paceManager.processSegment(text, startTime, endTime, speakerId);\\n      \\n      if (result) {\\n        const duration = endTime - startTime;\\n        const wordCount = text.trim().split(/\\\\s+/).length;\\n        const wpm = Math.round((wordCount / duration) * 60000);\\n        \\n        console.log(`📈 Pace analysis: ${wpm} WPM (${result.speakingRate.category}), Fluency: ${Math.round(result.fluency.score)}/100`);\\n      }\\n      \\n      return result;\\n    },\\n    \\n    // Enhanced analysis report with detailed insights\\n    getAnalysisReport: (timeWindow) => {\\n      const report = paceManager.getAnalysisReport(timeWindow);\\n      \\n      console.log('📊 Pace Analysis Report:', {\\n        timeWindow: `${timeWindow || 30000}ms`,\\n        speakingRate: report.speakingRate?.averageRate ? `${Math.round(report.speakingRate.averageRate)} WPM` : 'N/A',\\n        fluencyScore: report.fluency?.score ? `${Math.round(report.fluency.score)}/100` : 'N/A',\\n        insights: report.summary || []\\n      });\\n      \\n      return report;\\n    },\\n    \\n    // Enhanced metrics with component breakdown\\n    getCurrentPaceMetrics: () => {\\n      const metrics = paceManager.getCurrentPaceMetrics();\\n      \\n      console.log('🎯 Current Pace Metrics:', {\\n        currentRate: metrics.speakingRate?.current ? `${Math.round(metrics.speakingRate.current)} WPM` : 'N/A',\\n        smoothedRate: metrics.speakingRate?.smoothed ? `${Math.round(metrics.speakingRate.smoothed)} WPM` : 'N/A',\\n        fluencyScore: metrics.fluency?.score ? `${Math.round(metrics.fluency.score)}/100` : 'N/A',\\n        fillerRate: metrics.fluency?.fillerRate ? `${metrics.fluency.fillerRate.toFixed(1)} per min` : 'N/A'\\n      });\\n      \\n      return metrics;\\n    },\\n    \\n    // Enhanced stats with component details\\n    getStats: () => {\\n      const stats = paceManager.getStats();\\n      \\n      console.log('📈 Pace Analysis Statistics:', {\\n        totalSegments: stats.totalSegments,\\n        totalAnalyses: stats.totalAnalyses,\\n        avgProcessingTime: stats.averageProcessingTime ? `${stats.averageProcessingTime.toFixed(2)}ms` : 'N/A',\\n        rateAnalyzer: stats.components.rate ? 'Active' : 'Inactive',\\n        fluencyAnalyzer: stats.components.fluency ? 'Active' : 'Inactive'\\n      });\\n      \\n      return stats;\\n    },\\n    \\n    // Enhanced reset with logging\\n    reset: () => {\\n      console.log('🔄 Resetting speaking pace analysis system...');\\n      paceManager.reset();\\n      console.log('✅ Speaking pace analysis system reset');\\n    },\\n    \\n    // Enhanced cleanup with logging\\n    cleanup: () => {\\n      console.log('🧹 Cleaning up speaking pace analysis system...');\\n      paceManager.cleanup();\\n      console.log('✅ Speaking pace analysis system cleaned up');\\n    }\\n  };\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/features/speech-analysis/audio/vad-config.js\",\"messages\":[],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/features/speech-analysis/audio/vad-consensus.js\",\"messages\":[],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/features/speech-analysis/audio/vad-smoothing.js\",\"messages\":[],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/features/speech-analysis/audio/vad-stats.js\",\"messages\":[],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/features/speech-analysis/audio/voice-activity-detection.js\",\"messages\":[{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":85,\"column\":65,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":85,\"endColumn\":66},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":85,\"column\":95,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":85,\"endColumn\":96},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":85,\"column\":95,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":85,\"endColumn\":96},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":86,\"column\":43,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":86,\"endColumn\":44},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":240,\"column\":54,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":240,\"endColumn\":55},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":240,\"column\":86,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":240,\"endColumn\":87},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":295,\"column\":62,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":295,\"endColumn\":63},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":295,\"column\":94,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":295,\"endColumn\":95}],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":8,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Voice Activity Detection (VAD) Module\\n * Advanced speech detection using multiple algorithms\\n * Following functional programming patterns with factory functions\\n */\\n\\nimport { createEnhancedMemoryPool } from '../../../shared/utils/enhanced-memory-pool.js';\\nimport { createVADConfig, updateVADConfig } from './vad-config.js';\\nimport { createVADConsensus } from './vad-consensus.js';\\nimport { createVADStats } from './vad-stats.js';\\n\\n// Energy-based VAD using RMS and spectral energy\\nexport const createEnergyBasedVAD = (config = {}) => {\\n  const state = {\\n    config: {\\n      // Energy thresholds\\n      energyThreshold: config.energyThreshold || 0.01,\\n      minSpeechDuration: config.minSpeechDuration || 100, // ms\\n      minSilenceDuration: config.minSilenceDuration || 200, // ms\\n      \\n      // Adaptive thresholds\\n      adaptiveThreshold: config.adaptiveThreshold || true,\\n      adaptationRate: config.adaptationRate || 0.95,\\n      \\n      // Frame parameters\\n      frameSize: config.frameSize || 1024,\\n      hopSize: config.hopSize || 512,\\n      sampleRate: config.sampleRate || 44100,\\n      \\n      // Frequency analysis\\n      speechFreqMin: config.speechFreqMin || 80, // Hz\\n      speechFreqMax: config.speechFreqMax || 8000, // Hz\\n    },\\n    \\n    // Adaptive state\\n    backgroundEnergyLevel: 0.001,\\n    dynamicThreshold: 0.01,\\n    energyBuffer: [],\\n    bufferSize: 50,\\n    \\n    // Speech state tracking\\n    currentState: 'silence', // 'silence' | 'speech' | 'transition'\\n    speechStartTime: null,\\n    silenceStartTime: null,\\n    consecutiveSpeechFrames: 0,\\n    consecutiveSilenceFrames: 0,\\n    \\n    // Statistics\\n    stats: {\\n      totalFrames: 0,\\n      speechFrames: 0,\\n      silenceFrames: 0,\\n      voiceActivityRatio: 0,\\n      averageEnergy: 0,\\n      backgroundNoise: 0\\n    }\\n  };\\n\\n  // Calculate RMS energy of audio buffer\\n  const calculateRMSEnergy = (audioBuffer) => {\\n    let sumSquares = 0;\\n    for (let i = 0; i < audioBuffer.length; i++) {\\n      sumSquares += audioBuffer[i] * audioBuffer[i];\\n    }\\n    return Math.sqrt(sumSquares / audioBuffer.length);\\n  };\\n\\n  // Calculate spectral energy in speech frequency range\\n  const calculateSpectralEnergy = (fftData, sampleRate) => {\\n    const binWidth = sampleRate / fftData.length;\\n    const minBin = Math.floor(state.config.speechFreqMin / binWidth);\\n    const maxBin = Math.floor(state.config.speechFreqMax / binWidth);\\n    \\n    let spectralEnergy = 0;\\n    for (let i = minBin; i <= maxBin && i < fftData.length; i++) {\\n      spectralEnergy += fftData[i] * fftData[i];\\n    }\\n    \\n    return Math.sqrt(spectralEnergy / (maxBin - minBin + 1));\\n  };\\n\\n  // Update background energy level adaptively\\n  const updateBackgroundLevel = (energy) => {\\n    if (state.currentState === 'silence') {\\n      state.backgroundEnergyLevel = state.backgroundEnergyLevel * state.config.adaptationRate + \\n                                   energy * (1 - state.config.adaptationRate);\\n    }\\n    \\n    // Update energy buffer for statistics\\n    state.energyBuffer.push(energy);\\n    if (state.energyBuffer.length > state.bufferSize) {\\n      state.energyBuffer.shift();\\n    }\\n    \\n    // Calculate dynamic threshold\\n    if (state.config.adaptiveThreshold) {\\n      const avgEnergy = state.energyBuffer.reduce((sum, e) => sum + e, 0) / state.energyBuffer.length;\\n      state.dynamicThreshold = Math.max(\\n        state.backgroundEnergyLevel * 3,\\n        avgEnergy * 1.5,\\n        state.config.energyThreshold\\n      );\\n    }\\n  };\\n\\n  // Process audio frame and detect voice activity\\n  const processFrame = (audioBuffer, fftData = null, timestamp = Date.now()) => {\\n    const rmsEnergy = calculateRMSEnergy(audioBuffer);\\n    let spectralEnergy = 0;\\n    \\n    if (fftData) {\\n      spectralEnergy = calculateSpectralEnergy(fftData, state.config.sampleRate);\\n    }\\n    \\n    // Combined energy metric\\n    const combinedEnergy = rmsEnergy + (spectralEnergy * 0.3);\\n    \\n    // Update background level\\n    updateBackgroundLevel(combinedEnergy);\\n    \\n    // Determine voice activity\\n    const threshold = state.config.adaptiveThreshold ? state.dynamicThreshold : state.config.energyThreshold;\\n    const isVoiceActive = combinedEnergy > threshold;\\n    \\n    // State transition logic with hysteresis\\n    let newState = state.currentState;\\n    const frameDuration = (state.config.frameSize / state.config.sampleRate) * 1000; // ms\\n    \\n    if (isVoiceActive) {\\n      state.consecutiveSpeechFrames++;\\n      state.consecutiveSilenceFrames = 0;\\n      \\n      if (state.currentState === 'silence' && \\n          state.consecutiveSpeechFrames * frameDuration >= state.config.minSpeechDuration) {\\n        newState = 'speech';\\n        state.speechStartTime = timestamp;\\n      }\\n    } else {\\n      state.consecutiveSilenceFrames++;\\n      state.consecutiveSpeechFrames = 0;\\n      \\n      if (state.currentState === 'speech' && \\n          state.consecutiveSilenceFrames * frameDuration >= state.config.minSilenceDuration) {\\n        newState = 'silence';\\n        state.silenceStartTime = timestamp;\\n      }\\n    }\\n    \\n    state.currentState = newState;\\n    \\n    // Update statistics\\n    state.stats.totalFrames++;\\n    if (newState === 'speech') {\\n      state.stats.speechFrames++;\\n    } else {\\n      state.stats.silenceFrames++;\\n    }\\n    \\n    state.stats.voiceActivityRatio = state.stats.speechFrames / state.stats.totalFrames;\\n    state.stats.averageEnergy = state.energyBuffer.reduce((sum, e) => sum + e, 0) / state.energyBuffer.length;\\n    state.stats.backgroundNoise = state.backgroundEnergyLevel;\\n    \\n    return {\\n      isVoiceActive: newState === 'speech',\\n      energy: combinedEnergy,\\n      threshold,\\n      state: newState,\\n      timestamp,\\n      confidence: Math.min(combinedEnergy / threshold, 2.0) / 2.0\\n    };\\n  };\\n\\n  // Reset VAD state\\n  const reset = () => {\\n    state.currentState = 'silence';\\n    state.speechStartTime = null;\\n    state.silenceStartTime = null;\\n    state.consecutiveSpeechFrames = 0;\\n    state.consecutiveSilenceFrames = 0;\\n    state.energyBuffer.length = 0;\\n    state.stats = {\\n      totalFrames: 0,\\n      speechFrames: 0,\\n      silenceFrames: 0,\\n      voiceActivityRatio: 0,\\n      averageEnergy: 0,\\n      backgroundNoise: 0\\n    };\\n  };\\n\\n  // Get current statistics\\n  const getStats = () => ({ ...state.stats });\\n\\n  // Update configuration\\n  const updateConfig = (newConfig) => {\\n    Object.assign(state.config, newConfig);\\n  };\\n\\n  return {\\n    processFrame,\\n    reset,\\n    getStats,\\n    updateConfig,\\n    getCurrentState: () => state.currentState,\\n    getThreshold: () => state.config.adaptiveThreshold ? state.dynamicThreshold : state.config.energyThreshold\\n  };\\n};\\n\\n// Zero Crossing Rate (ZCR) based VAD\\nexport const createZCRBasedVAD = (config = {}) => {\\n  const state = {\\n    config: {\\n      zcrThreshold: config.zcrThreshold || 0.1,\\n      frameSize: config.frameSize || 1024,\\n      sampleRate: config.sampleRate || 44100\\n    },\\n    stats: {\\n      totalFrames: 0,\\n      averageZCR: 0\\n    }\\n  };\\n\\n  // Calculate zero crossing rate\\n  const calculateZCR = (audioBuffer) => {\\n    let crossings = 0;\\n    for (let i = 1; i < audioBuffer.length; i++) {\\n      if ((audioBuffer[i] >= 0) !== (audioBuffer[i-1] >= 0)) {\\n        crossings++;\\n      }\\n    }\\n    return crossings / (audioBuffer.length - 1);\\n  };\\n\\n  const processFrame = (audioBuffer, timestamp = Date.now()) => {\\n    const zcr = calculateZCR(audioBuffer);\\n    const isVoiceActive = zcr > state.config.zcrThreshold;\\n    \\n    // Update statistics\\n    state.stats.totalFrames++;\\n    state.stats.averageZCR = (state.stats.averageZCR * (state.stats.totalFrames - 1) + zcr) / state.stats.totalFrames;\\n    \\n    return {\\n      isVoiceActive,\\n      zcr,\\n      threshold: state.config.zcrThreshold,\\n      timestamp,\\n      confidence: Math.min(zcr / state.config.zcrThreshold, 2.0) / 2.0\\n    };\\n  };\\n\\n  return {\\n    processFrame,\\n    getStats: () => ({ ...state.stats }),\\n    updateConfig: (newConfig) => Object.assign(state.config, newConfig)\\n  };\\n};\\n\\n// Spectral entropy based VAD\\nexport const createSpectralEntropyVAD = (config = {}) => {\\n  const state = {\\n    config: {\\n      entropyThreshold: config.entropyThreshold || 0.7,\\n      frameSize: config.frameSize || 1024\\n    },\\n    stats: {\\n      totalFrames: 0,\\n      averageEntropy: 0\\n    }\\n  };\\n\\n  // Calculate spectral entropy\\n  const calculateSpectralEntropy = (fftMagnitudes) => {\\n    // Normalize magnitudes to probabilities\\n    const totalEnergy = fftMagnitudes.reduce((sum, mag) => sum + mag, 0);\\n    if (totalEnergy === 0) return 0;\\n    \\n    let entropy = 0;\\n    for (let i = 0; i < fftMagnitudes.length; i++) {\\n      const probability = fftMagnitudes[i] / totalEnergy;\\n      if (probability > 0) {\\n        entropy -= probability * Math.log2(probability);\\n      }\\n    }\\n    \\n    // Normalize entropy\\n    return entropy / Math.log2(fftMagnitudes.length);\\n  };\\n\\n  const processFrame = (fftMagnitudes, timestamp = Date.now()) => {\\n    const entropy = calculateSpectralEntropy(fftMagnitudes);\\n    const isVoiceActive = entropy > state.config.entropyThreshold;\\n    \\n    // Update statistics\\n    state.stats.totalFrames++;\\n    state.stats.averageEntropy = (state.stats.averageEntropy * (state.stats.totalFrames - 1) + entropy) / state.stats.totalFrames;\\n    \\n    return {\\n      isVoiceActive,\\n      entropy,\\n      threshold: state.config.entropyThreshold,\\n      timestamp,\\n      confidence: Math.min(entropy / state.config.entropyThreshold, 2.0) / 2.0\\n    };\\n  };\\n\\n  return {\\n    processFrame,\\n    getStats: () => ({ ...state.stats }),\\n    updateConfig: (newConfig) => Object.assign(state.config, newConfig)\\n  };\\n};\\n\\n// Combined multi-algorithm VAD\\nexport const createAdvancedVAD = (config = {}) => {\\n  const memoryPool = createEnhancedMemoryPool({\\n    maxPoolSize: config.maxPoolSize || 100,\\n    enableMetrics: true\\n  });\\n  memoryPool.initialize();\\n\\n  const vadConfig = createVADConfig(config);\\n  const consensus = createVADConsensus(vadConfig);\\n  const stats = createVADStats();\\n  \\n  const state = {\\n    config: vadConfig,\\n    \\n    // Individual VAD algorithms\\n    energyVAD: createEnergyBasedVAD(config.energy),\\n    zcrVAD: createZCRBasedVAD(config.zcr),\\n    entropyVAD: createSpectralEntropyVAD(config.entropy)\\n  };\\n\\n  // Process frame with all algorithms\\n  const processFrame = (audioBuffer, fftData = null, timestamp = Date.now()) => {\\n    // Get decisions from individual algorithms\\n    const energyResult = state.energyVAD.processFrame(audioBuffer, fftData, timestamp);\\n    const zcrResult = state.zcrVAD.processFrame(audioBuffer, timestamp);\\n    \\n    let entropyResult = { isVoiceActive: false, confidence: 0 };\\n    if (fftData) {\\n      entropyResult = state.entropyVAD.processFrame(fftData, timestamp);\\n    }\\n\\n    // Process consensus decision using modular components\\n    const consensusResult = consensus.processConsensus(energyResult, zcrResult, entropyResult, timestamp);\\n    \\n    // Record statistics\\n    stats.recordFrame(consensusResult);\\n\\n    // Create pooled result object\\n    const result = memoryPool.acquire('VADResult');\\n    Object.assign(result, consensusResult);\\n\\n    return result;\\n  };\\n\\n  // Register custom result type with memory pool\\n  memoryPool.registerFactory('VADResult', () => ({\\n    _pooled: true,\\n    isVoiceActive: false,\\n    confidence: 0,\\n    timestamp: 0,\\n    smoothedDecision: false,\\n    algorithms: null,\\n    consensus: null\\n  }));\\n\\n  // Release VAD result back to pool\\n  const releaseResult = (result) => {\\n    memoryPool.release(result);\\n  };\\n\\n  // Reset all VAD algorithms\\n  const reset = () => {\\n    state.energyVAD.reset();\\n    state.zcrVAD.reset();\\n    state.entropyVAD.reset();\\n    consensus.reset();\\n    stats.reset();\\n  };\\n\\n  // Get comprehensive statistics\\n  const getStats = () => {\\n    const individualStats = {\\n      energy: state.energyVAD.getStats(),\\n      zcr: state.zcrVAD.getStats(),\\n      entropy: state.entropyVAD.getStats()\\n    };\\n\\n    return {\\n      ...stats.getStats(individualStats),\\n      memoryPool: memoryPool.getStats(),\\n      consensus: consensus.getState()\\n    };\\n  };\\n\\n  // Update configuration\\n  const updateConfig = (newConfig) => {\\n    try {\\n      state.config = updateVADConfig(state.config, newConfig);\\n      consensus.updateConfig(state.config);\\n      \\n      if (newConfig.energy) {\\n        state.energyVAD.updateConfig(newConfig.energy);\\n      }\\n      if (newConfig.zcr) {\\n        state.zcrVAD.updateConfig(newConfig.zcr);\\n      }\\n      if (newConfig.entropy) {\\n        state.entropyVAD.updateConfig(newConfig.entropy);\\n      }\\n    } catch (error) {\\n      console.warn('VAD configuration update failed:', error.message);\\n      throw error;\\n    }\\n  };\\n\\n  // Cleanup\\n  const cleanup = () => {\\n    memoryPool.cleanup();\\n  };\\n\\n  return {\\n    processFrame,\\n    releaseResult,\\n    reset,\\n    getStats,\\n    updateConfig,\\n    cleanup,\\n    getCurrentState: () => state.energyVAD.getCurrentState(),\\n    getThreshold: () => state.config.consensusThreshold\\n  };\\n};\\n\\n// VAD integration with Web Audio API\\nexport const createWebAudioVAD = (config = {}) => {\\n  const state = {\\n    audioContext: null,\\n    analyserNode: null,\\n    scriptProcessor: null,\\n    vad: createAdvancedVAD(config.vad),\\n    isActive: false,\\n    \\n    config: {\\n      fftSize: config.fftSize || 1024,\\n      smoothingTimeConstant: config.smoothingTimeConstant || 0.8,\\n      minDecibels: config.minDecibels || -90,\\n      maxDecibels: config.maxDecibels || -10\\n    },\\n    \\n    callbacks: {\\n      onVoiceStart: config.onVoiceStart || (() => {}),\\n      onVoiceEnd: config.onVoiceEnd || (() => {}),\\n      onVoiceActivity: config.onVoiceActivity || (() => {})\\n    },\\n    \\n    lastState: 'silence'\\n  };\\n\\n  // Initialize Web Audio API components\\n  const initialize = async (audioStream) => {\\n    try {\\n      state.audioContext = new (window.AudioContext || window.webkitAudioContext)({\\n        sampleRate: config.sampleRate || 44100\\n      });\\n\\n      // Create analyser node\\n      state.analyserNode = state.audioContext.createAnalyser();\\n      state.analyserNode.fftSize = state.config.fftSize;\\n      state.analyserNode.smoothingTimeConstant = state.config.smoothingTimeConstant;\\n      state.analyserNode.minDecibels = state.config.minDecibels;\\n      state.analyserNode.maxDecibels = state.config.maxDecibels;\\n\\n      // Create script processor for real-time analysis\\n      state.scriptProcessor = state.audioContext.createScriptProcessor(\\n        state.config.fftSize, 1, 1\\n      );\\n\\n      // Connect audio stream\\n      const source = state.audioContext.createMediaStreamSource(audioStream);\\n      source.connect(state.analyserNode);\\n      state.analyserNode.connect(state.scriptProcessor);\\n      state.scriptProcessor.connect(state.audioContext.destination);\\n\\n      // Process audio frames\\n      state.scriptProcessor.onaudioprocess = (event) => {\\n        if (!state.isActive) return;\\n\\n        const audioBuffer = event.inputBuffer.getChannelData(0);\\n        const fftData = new Float32Array(state.analyserNode.frequencyBinCount);\\n        state.analyserNode.getFloatFrequencyData(fftData);\\n\\n        // Convert dB to linear magnitude\\n        const magnitudes = fftData.map(db => Math.pow(10, db / 20));\\n\\n        const result = state.vad.processFrame(audioBuffer, magnitudes);\\n        \\n        // Trigger callbacks\\n        state.callbacks.onVoiceActivity(result);\\n        \\n        if (result.isVoiceActive && state.lastState !== 'speech') {\\n          state.callbacks.onVoiceStart(result);\\n          state.lastState = 'speech';\\n        } else if (!result.isVoiceActive && state.lastState !== 'silence') {\\n          state.callbacks.onVoiceEnd(result);\\n          state.lastState = 'silence';\\n        }\\n\\n        // Release result back to pool\\n        state.vad.releaseResult(result);\\n      };\\n\\n      return true;\\n    } catch (error) {\\n      console.error('Failed to initialize Web Audio VAD:', error);\\n      return false;\\n    }\\n  };\\n\\n  // Start voice activity detection\\n  const start = () => {\\n    if (state.audioContext && state.audioContext.state === 'suspended') {\\n      state.audioContext.resume();\\n    }\\n    state.isActive = true;\\n  };\\n\\n  // Stop voice activity detection\\n  const stop = () => {\\n    state.isActive = false;\\n  };\\n\\n  // Cleanup resources\\n  const cleanup = () => {\\n    stop();\\n    \\n    if (state.scriptProcessor) {\\n      state.scriptProcessor.disconnect();\\n      state.scriptProcessor = null;\\n    }\\n    \\n    if (state.analyserNode) {\\n      state.analyserNode.disconnect();\\n      state.analyserNode = null;\\n    }\\n    \\n    if (state.audioContext) {\\n      state.audioContext.close();\\n      state.audioContext = null;\\n    }\\n    \\n    state.vad.cleanup();\\n  };\\n\\n  return {\\n    initialize,\\n    start,\\n    stop,\\n    cleanup,\\n    getStats: () => state.vad.getStats(),\\n    updateConfig: (newConfig) => {\\n      Object.assign(state.config, newConfig);\\n      if (newConfig.vad) {\\n        state.vad.updateConfig(newConfig.vad);\\n      }\\n    },\\n    isActive: () => state.isActive\\n  };\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/features/speech-analysis/context-manager.js\",\"messages\":[{\"ruleId\":null,\"nodeType\":null,\"fatal\":true,\"severity\":2,\"message\":\"Parsing error: Unexpected token ContextManagerConfiguration\",\"line\":10,\"column\":8}],\"suppressedMessages\":[],\"errorCount\":1,\"fatalErrorCount\":1,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Conversation Context Manager - Compatibility Layer\\n * Provides backward compatibility while using the new modular TypeScript implementation\\n */\\n\\nimport createContextManager, {\\n  analyzeContext,\\n  CONTEXT_STRATEGIES,\\n  ContextStrategy,\\n  type ContextManagerConfiguration,\\n  type ConversationContext,\\n  type ContextChunk,\\n  type SemanticSearchResult,\\n  type TopicExtractionResult,\\n  type TopicEvolutionResult\\n} from './context/index.ts';\\n\\n// Export the main factory function\\nexport { createContextManager };\\n\\n// Export utilities and constants\\nexport {\\n  analyzeContext,\\n  CONTEXT_STRATEGIES,\\n  ContextStrategy\\n};\\n\\n// Export types for TypeScript consumers\\nexport type {\\n  ContextManagerConfiguration,\\n  ConversationContext,\\n  ContextChunk,\\n  SemanticSearchResult,\\n  TopicExtractionResult,\\n  TopicEvolutionResult\\n};\\n\\n// Default export for backward compatibility\\n\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/features/speech-analysis/conversation-analytics.js\",\"messages\":[{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'createConversationContext' is defined but never used. Allowed unused vars must match /^_/u.\",\"line\":8,\"column\":3,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":8,\"endColumn\":28,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"createConversationContext\"},\"fix\":{\"range\":[161,187],\"text\":\"\"},\"desc\":\"Remove unused variable 'createConversationContext'.\"}]},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'createSpeechEvent' is defined but never used. Allowed unused vars must match /^_/u.\",\"line\":9,\"column\":3,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":9,\"endColumn\":20,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"createSpeechEvent\"},\"fix\":{\"range\":[186,207],\"text\":\"\"},\"desc\":\"Remove unused variable 'createSpeechEvent'.\"}]},{\"ruleId\":\"complexity\",\"severity\":1,\"message\":\"Arrow function has a complexity of 55. Maximum allowed is 20.\",\"line\":19,\"column\":42,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"complex\",\"endLine\":74,\"endColumn\":3},{\"ruleId\":\"max-lines-per-function\",\"severity\":1,\"message\":\"Arrow function has too many lines (230). Maximum allowed is 150.\",\"line\":77,\"column\":44,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"exceed\",\"endLine\":403,\"endColumn\":2}],\"suppressedMessages\":[],\"errorCount\":2,\"fatalErrorCount\":0,\"warningCount\":2,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Conversation Analytics\\n * Real-time conversation analysis and metrics\\n * Following functional programming patterns with factory functions\\n */\\n\\nimport {\\n  createConversationContext,\\n  createSpeechEvent\\n} from '../../core/configuration/types.ts';\\n\\n// Import modular analytics components\\nimport { createMetricsCalculator } from './analytics/metrics-calculator.js';\\nimport { createTopicAnalyzer } from './analytics/topic-analyzer.js';\\nimport { createInteractionAnalyzer } from './analytics/interaction-analyzer.js';\\nimport { createQualityAssessor } from './analytics/quality-assessor.js';\\n\\n// Conversation metrics factory\\nexport const createConversationMetrics = (config = {}) => ({\\n  // Speaking time metrics\\n  speakingTime: {\\n    total: config.speakingTime?.total || 0,\\n    byParticipant: config.speakingTime?.byParticipant || new Map(),\\n    distribution: config.speakingTime?.distribution || {}\\n  },\\n\\n  // Word count metrics\\n  wordCount: {\\n    total: config.wordCount?.total || 0,\\n    byParticipant: config.wordCount?.byParticipant || new Map(),\\n    averageWordsPerMinute: config.wordCount?.averageWordsPerMinute || 0,\\n    vocabulary: {\\n      unique: config.wordCount?.vocabulary?.unique || new Set(),\\n      repeated: config.wordCount?.vocabulary?.repeated || new Map()\\n    }\\n  },\\n\\n  // Sentiment trends\\n  sentimentTrends: {\\n    overall: config.sentimentTrends?.overall || [],\\n    byParticipant: config.sentimentTrends?.byParticipant || new Map(),\\n    timeline: config.sentimentTrends?.timeline || [],\\n    averageSentiment: config.sentimentTrends?.averageSentiment || 0\\n  },\\n\\n  // Topic analysis\\n  topics: {\\n    discovered: config.topics?.discovered || [],\\n    timeline: config.topics?.timeline || [],\\n    transitions: config.topics?.transitions || [],\\n    dominantTopics: config.topics?.dominantTopics || []\\n  },\\n\\n  // Interaction patterns\\n  interactions: {\\n    turnTaking: config.interactions?.turnTaking || [],\\n    interruptions: config.interactions?.interruptions || 0,\\n    responseTimes: config.interactions?.responseTimes || [],\\n    engagement: config.interactions?.engagement || 'unknown'\\n  },\\n\\n  // Conversation quality\\n  quality: {\\n    flow: config.quality?.flow || 0,\\n    coherence: config.quality?.coherence || 0,\\n    participation: config.quality?.participation || 0,\\n    overall: config.quality?.overall || 'unknown'\\n  },\\n\\n  // Timestamps\\n  startTime: config.startTime || Date.now(),\\n  lastUpdate: config.lastUpdate || Date.now(),\\n  duration: config.duration || 0\\n});\\n\\n// Conversation analytics engine factory\\nexport const createConversationAnalytics = (config = {}) => {\\n  const state = {\\n    isInitialized: false,\\n    isAnalyzing: false,\\n    \\n    // Configuration\\n    config: {\\n      updateInterval: config.updateInterval || 5000, // 5 seconds\\n      sentimentWindow: config.sentimentWindow || 10, // Last 10 chunks\\n      topicThreshold: config.topicThreshold || 0.3,\\n      minWordCount: config.minWordCount || 5,\\n      ...config\\n    },\\n\\n    // Analytics data\\n    metrics: createConversationMetrics(),\\n    rawData: {\\n      chunks: [],\\n      participants: new Map(),\\n      sessions: new Map()\\n    },\\n\\n    // Processing state\\n    processingQueue: [],\\n    lastProcessed: 0,\\n    \\n    // Update timer\\n    updateTimer: null,\\n\\n    // Callbacks\\n    callbacks: {\\n      onMetricsUpdate: [],\\n      onTopicDiscovered: [],\\n      onSentimentChange: [],\\n      onEngagementChange: [],\\n      onError: []\\n    }\\n  };\\n\\n  // Create modular analytics components\\n  const metricsCalculator = createMetricsCalculator(state);\\n  const topicAnalyzer = createTopicAnalyzer(state);\\n  const interactionAnalyzer = createInteractionAnalyzer(state);\\n  const qualityAssessor = createQualityAssessor(state);\\n\\n  // Initialize analytics engine\\n  const initialize = () => {\\n    if (state.isInitialized) {\\n      console.warn('Conversation analytics already initialized');\\n      return true;\\n    }\\n\\n    console.log('📊 Initializing conversation analytics...');\\n    \\n    state.isInitialized = true;\\n    state.metrics.startTime = Date.now();\\n    \\n    console.log('✅ Conversation analytics initialized');\\n    return true;\\n  };\\n\\n  // Start analytics processing\\n  const startAnalysis = () => {\\n    if (!state.isInitialized) {\\n      throw new Error('Analytics not initialized');\\n    }\\n\\n    if (state.isAnalyzing) {\\n      console.warn('Analytics already running');\\n      return;\\n    }\\n\\n    state.isAnalyzing = true;\\n    \\n    // Start periodic updates\\n    state.updateTimer = setInterval(() => {\\n      if (state.processingQueue.length > 0) {\\n        processQueue();\\n      }\\n      updateMetrics();\\n    }, state.config.updateInterval);\\n\\n    console.log('📊 Conversation analytics started');\\n  };\\n\\n  // Stop analytics processing\\n  const stopAnalysis = () => {\\n    if (!state.isAnalyzing) return;\\n\\n    state.isAnalyzing = false;\\n    \\n    if (state.updateTimer) {\\n      clearInterval(state.updateTimer);\\n      state.updateTimer = null;\\n    }\\n\\n    console.log('📊 Conversation analytics stopped');\\n  };\\n\\n  // Add speech chunk for analysis\\n  const addChunk = (chunk, participantId = 'default', analysisResults = []) => {\\n    if (!state.isInitialized) {\\n      throw new Error('Analytics not initialized');\\n    }\\n\\n    const enrichedChunk = {\\n      ...chunk,\\n      participantId,\\n      analysisResults,\\n      addedAt: Date.now()\\n    };\\n\\n    // Add to raw data\\n    state.rawData.chunks.push(enrichedChunk);\\n    \\n    // Initialize participant if new\\n    if (!state.rawData.participants.has(participantId)) {\\n      state.rawData.participants.set(participantId, {\\n        id: participantId,\\n        chunks: [],\\n        totalWords: 0,\\n        totalTime: 0,\\n        sentimentHistory: [],\\n        topics: new Set()\\n      });\\n    }\\n\\n    // Update participant data\\n    const participant = state.rawData.participants.get(participantId);\\n    participant.chunks.push(enrichedChunk);\\n    participant.totalWords += chunk.text.split(' ').length;\\n    \\n    // Add to processing queue\\n    state.processingQueue.push(enrichedChunk);\\n\\n    console.log(`📊 Added chunk for participant ${participantId}: \\\"${chunk.text.substring(0, 50)}...\\\"`);\\n  };\\n\\n  // Process queued chunks\\n  const processQueue = () => {\\n    const chunksToProcess = [...state.processingQueue];\\n    state.processingQueue = [];\\n\\n    chunksToProcess.forEach(chunk => {\\n      processChunk(chunk);\\n    });\\n\\n    state.lastProcessed = Date.now();\\n  };\\n\\n  // Process individual chunk\\n  const processChunk = (chunk) => {\\n    try {\\n      // Update participant metrics using modular calculator\\n      metricsCalculator.updateParticipantMetrics(chunk.participantId, chunk);\\n      \\n    } catch (error) {\\n      console.warn('Error processing chunk:', error);\\n      notifyCallbacks('onError', { error: error.message, chunk });\\n    }\\n  };\\n\\n  // Update all metrics\\n  const updateMetrics = () => {\\n    // Update duration\\n    state.metrics.duration = Date.now() - state.metrics.startTime;\\n    state.metrics.lastUpdate = Date.now();\\n\\n    // Recalculate all metrics using modular components\\n    metricsCalculator.calculateSpeakingTimeMetrics();\\n    metricsCalculator.calculateWordCountMetrics();\\n    metricsCalculator.calculateSentimentTrends();\\n    topicAnalyzer.analyzeTopics();\\n    interactionAnalyzer.analyzeTurnTaking();\\n    \\n    // Update interaction engagement\\n    state.metrics.interactions.engagement = interactionAnalyzer.calculateEngagement();\\n    \\n    // Update quality metrics using modular assessor\\n    const qualityAssessment = qualityAssessor.getQualityAssessment();\\n    state.metrics.quality = {\\n      flow: qualityAssessment.flow.score / 100,\\n      coherence: qualityAssessment.coherence.score / 100,\\n      participation: qualityAssessment.participation.score / 100,\\n      overall: qualityAssessment.overall.rating\\n    };\\n\\n    // Notify metrics update\\n    notifyCallbacks('onMetricsUpdate', state.metrics);\\n  };\\n\\n  // Get current analytics data\\n  const getMetrics = () => ({\\n    ...state.metrics,\\n    // Convert Maps to Objects for serialization\\n    speakingTime: {\\n      ...state.metrics.speakingTime,\\n      byParticipant: Object.fromEntries(state.metrics.speakingTime.byParticipant)\\n    },\\n    wordCount: {\\n      ...state.metrics.wordCount,\\n      byParticipant: Object.fromEntries(state.metrics.wordCount.byParticipant),\\n      vocabulary: {\\n        unique: Array.from(state.metrics.wordCount.vocabulary.unique),\\n        repeated: Object.fromEntries(state.metrics.wordCount.vocabulary.repeated)\\n      }\\n    },\\n    sentimentTrends: {\\n      ...state.metrics.sentimentTrends,\\n      byParticipant: Object.fromEntries(state.metrics.sentimentTrends.byParticipant)\\n    }\\n  });\\n\\n  // Get participant statistics using modular calculator\\n  const getParticipantStats = (participantId) => {\\n    return metricsCalculator.getParticipantStats(participantId);\\n  };\\n\\n  // Get topic summary using modular analyzer\\n  const getTopicSummary = () => {\\n    return topicAnalyzer.getTopicSummary();\\n  };\\n\\n  // Get interaction summary using modular analyzer\\n  const getInteractionSummary = () => {\\n    return interactionAnalyzer.getInteractionSummary();\\n  };\\n\\n  // Get quality assessment using modular assessor\\n  const getQualityAssessment = () => {\\n    return qualityAssessor.getQualityAssessment();\\n  };\\n\\n  // Helper functions\\n  const notifyCallbacks = (event, data) => {\\n    const callbacks = state.callbacks[event] || [];\\n    callbacks.forEach(callback => {\\n      try {\\n        callback(data);\\n      } catch (error) {\\n        console.warn(`Callback error for ${event}:`, error);\\n      }\\n    });\\n  };\\n\\n  // Event handlers\\n  const onMetricsUpdate = (callback) => {\\n    state.callbacks.onMetricsUpdate.push(callback);\\n    return () => removeCallback('onMetricsUpdate', callback);\\n  };\\n\\n  const onTopicDiscovered = (callback) => {\\n    state.callbacks.onTopicDiscovered.push(callback);\\n    return () => removeCallback('onTopicDiscovered', callback);\\n  };\\n\\n  const onSentimentChange = (callback) => {\\n    state.callbacks.onSentimentChange.push(callback);\\n    return () => removeCallback('onSentimentChange', callback);\\n  };\\n\\n  const onEngagementChange = (callback) => {\\n    state.callbacks.onEngagementChange.push(callback);\\n    return () => removeCallback('onEngagementChange', callback);\\n  };\\n\\n  const onError = (callback) => {\\n    state.callbacks.onError.push(callback);\\n    return () => removeCallback('onError', callback);\\n  };\\n\\n  const removeCallback = (event, callback) => {\\n    const callbacks = state.callbacks[event];\\n    if (callbacks) {\\n      const index = callbacks.indexOf(callback);\\n      if (index !== -1) callbacks.splice(index, 1);\\n    }\\n  };\\n\\n  // Cleanup\\n  const cleanup = () => {\\n    stopAnalysis();\\n    \\n    // Clear all data\\n    state.rawData.chunks = [];\\n    state.rawData.participants.clear();\\n    state.rawData.sessions.clear();\\n    state.processingQueue = [];\\n    \\n    // Clear callbacks\\n    Object.keys(state.callbacks).forEach(event => {\\n      state.callbacks[event] = [];\\n    });\\n    \\n    state.isInitialized = false;\\n    console.log('🧹 Conversation analytics cleaned up');\\n  };\\n\\n  return {\\n    // Core functionality\\n    initialize,\\n    startAnalysis,\\n    stopAnalysis,\\n    cleanup,\\n    \\n    // Data processing\\n    addChunk,\\n    \\n    // Data access - delegated to modular components\\n    getMetrics,\\n    getParticipantStats,\\n    getTopicSummary,\\n    getInteractionSummary,\\n    getQualityAssessment,\\n    \\n    // Event handlers\\n    onMetricsUpdate,\\n    onTopicDiscovered,\\n    onSentimentChange,\\n    onEngagementChange,\\n    onError,\\n    \\n    // Status\\n    isInitialized: () => state.isInitialized,\\n    isAnalyzing: () => state.isAnalyzing\\n  };\\n};\\n\\n\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/features/speech-analysis/index.js\",\"messages\":[],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/features/speech-analysis/llm-backends.js\",\"messages\":[{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":28,\"column\":70,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":28,\"endColumn\":71},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":28,\"column\":76,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":28,\"endColumn\":77}],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":2,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * LLM backend implementations and management\\n */\\n\\nimport { LLM_BACKENDS } from './llm-config.js';\\n\\n// Create mock backend for testing and fallback\\nexport const createMockBackend = () => {\\n  const responses = [\\n    \\\"This appears to be a neutral conversation with professional tone.\\\",\\n    \\\"The speaker seems engaged and focused on the topic.\\\",\\n    \\\"Key themes include technology, collaboration, and problem-solving.\\\",\\n    \\\"The emotional tone is positive and constructive.\\\"\\n  ];\\n  \\n  return {\\n    name: 'mock',\\n    \\n    checkAvailability: async () => true,\\n    \\n    initialize: async () => {\\n      console.log('🎭 Mock LLM backend initialized');\\n      return true;\\n    },\\n    \\n    generate: async (prompt) => {\\n      // Simulate processing delay\\n      await new Promise(resolve => setTimeout(resolve, Math.random() * 500 + 200));\\n      \\n      // Return a relevant mock response based on prompt content\\n      if (prompt.toLowerCase().includes('sentiment')) {\\n        return \\\"positive, optimistic, engaged, constructive, collaborative\\\";\\n      } else if (prompt.toLowerCase().includes('controversial')) {\\n        return \\\"No controversial statements detected. The conversation maintains a respectful tone.\\\";\\n      } else if (prompt.toLowerCase().includes('theme')) {\\n        return \\\"Main themes: technology discussion, problem-solving approach, team collaboration.\\\";\\n      } else if (prompt.toLowerCase().includes('emotion')) {\\n        return \\\"Emotional tone: Professional confidence with collaborative engagement.\\\";\\n      } else {\\n        return responses[Math.floor(Math.random() * responses.length)];\\n      }\\n    },\\n    \\n    cleanup: async () => {\\n      console.log('🧹 Mock backend cleaned up');\\n    }\\n  };\\n};\\n\\n// Create WebLLM backend (browser-only)\\nexport const createWebLLMBackend = () => {\\n  let webllm = null;\\n  \\n  return {\\n    name: 'webllm',\\n    \\n    checkAvailability: async () => {\\n      // Check if we're in a browser environment with WebAssembly support\\n      return typeof window !== 'undefined' && \\n             typeof WebAssembly !== 'undefined' &&\\n             navigator.gpu !== undefined;\\n    },\\n    \\n    initialize: async () => {\\n      try {\\n        // Dynamic import to avoid issues in Node.js\\n        if (typeof window !== 'undefined') {\\n          // This would be the actual WebLLM initialization\\n          // const { CreateWebWorkerMLCEngine } = await import('@mlc-ai/web-llm');\\n          // webllm = new CreateWebWorkerMLCEngine(...);\\n          console.log('🕸️ WebLLM backend would initialize here');\\n        }\\n        return true;\\n      } catch (error) {\\n        console.warn('WebLLM initialization failed:', error);\\n        return false;\\n      }\\n    },\\n    \\n    generate: async () => {\\n      if (!webllm) {\\n        throw new Error('WebLLM not initialized');\\n      }\\n      \\n      // This would be the actual WebLLM generation call\\n      // const response = await webllm.chat.completions.create({...});\\n      // return response.choices[0].message.content;\\n      \\n      // Fallback for demo\\n      console.log('🕸️ WebLLM would generate response here');\\n      return \\\"WebLLM response would appear here\\\";\\n    },\\n    \\n    cleanup: async () => {\\n      if (webllm) {\\n        // await webllm.dispose();\\n        webllm = null;\\n      }\\n      console.log('🧹 WebLLM backend cleaned up');\\n    }\\n  };\\n};\\n\\n// Create Transformers.js backend\\nexport const createTransformersJSBackend = () => {\\n  let pipeline = null;\\n  \\n  return {\\n    name: 'transformers_js',\\n    \\n    checkAvailability: async () => {\\n      try {\\n        // Check if Transformers.js is available\\n        return typeof window !== 'undefined' || typeof global !== 'undefined';\\n      } catch {\\n        return false;\\n      }\\n    },\\n    \\n    initialize: async () => {\\n      try {\\n        // Dynamic import to avoid issues if not available\\n        // const { pipeline: createPipeline } = await import('@xenova/transformers');\\n        // pipeline = await createPipeline('text-generation', config.model);\\n        console.log('🤗 Transformers.js backend would initialize here');\\n        return true;\\n      } catch (error) {\\n        console.warn('Transformers.js initialization failed:', error);\\n        return false;\\n      }\\n    },\\n    \\n    generate: async () => {\\n      if (!pipeline) {\\n        throw new Error('Transformers.js pipeline not initialized');\\n      }\\n      \\n      // This would be the actual Transformers.js generation call\\n      // const result = await pipeline(prompt, { max_length: config.maxTokens });\\n      // return result[0].generated_text;\\n      \\n      // Fallback for demo\\n      console.log('🤗 Transformers.js would generate response here');\\n      return \\\"Transformers.js response would appear here\\\";\\n    },\\n    \\n    cleanup: async () => {\\n      if (pipeline) {\\n        // Clean up pipeline resources\\n        pipeline = null;\\n      }\\n      console.log('🧹 Transformers.js backend cleaned up');\\n    }\\n  };\\n};\\n\\n// Create backend manager\\nexport const createBackendManager = () => {\\n  const backends = {\\n    webllm: createWebLLMBackend(),\\n    transformers_js: createTransformersJSBackend(),\\n    mock: createMockBackend()\\n  };\\n  \\n  // Get backend by name\\n  const getBackend = (name) => backends[name];\\n  \\n  // Get all available backends\\n  const getAllBackends = () => ({ ...backends });\\n  \\n  // Test backend availability\\n  const testBackendAvailability = async (backendName) => {\\n    const backend = backends[backendName];\\n    if (!backend) return false;\\n    \\n    try {\\n      return await backend.checkAvailability();\\n    } catch (error) {\\n      console.warn(`Backend availability test failed for ${backendName}:`, error);\\n      return false;\\n    }\\n  };\\n  \\n  // Find best available backend\\n  const findBestBackend = async (preferred, fallbacks = []) => {\\n    const backendOrder = [preferred, ...fallbacks].filter(Boolean);\\n    \\n    for (const backendName of backendOrder) {\\n      if (await testBackendAvailability(backendName)) {\\n        return backendName;\\n      }\\n    }\\n    \\n    return null;\\n  };\\n  \\n  // Get backend info\\n  const getBackendInfo = (backendName) => LLM_BACKENDS[backendName] || null;\\n  \\n  return {\\n    getBackend,\\n    getAllBackends,\\n    testBackendAvailability,\\n    findBestBackend,\\n    getBackendInfo,\\n    getAvailableBackends: () => Object.keys(backends)\\n  };\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/features/speech-analysis/llm-cache.js\",\"messages\":[],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/features/speech-analysis/llm-client.js\",\"messages\":[{\"ruleId\":\"max-lines-per-function\",\"severity\":1,\"message\":\"Arrow function has too many lines (235). Maximum allowed is 150.\",\"line\":38,\"column\":32,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"exceed\",\"endLine\":352,\"endColumn\":2},{\"ruleId\":\"max-len\",\"severity\":1,\"message\":\"This line has a length of 253. Maximum allowed is 150.\",\"line\":258,\"column\":1,\"nodeType\":\"Program\",\"messageId\":\"max\",\"endLine\":258,\"endColumn\":254}],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":2,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * LLM Client for Speech Analysis\\n * \\n * Provides a unified interface for various LLM backends with automatic fallback,\\n * intelligent caching, and comprehensive error handling for speech analysis tasks.\\n * \\n * Features:\\n * - Multiple backend support (WebLLM, Transformers.js, Mock)\\n * - Automatic backend detection and fallback\\n * - Intelligent response caching\\n * - Performance metrics and monitoring\\n * - Concurrent request management\\n * - Graceful error handling and retry logic\\n * \\n * @example\\n * ```javascript\\n * import { createLLMClient } from './llm-client.js';\\n * \\n * const llmClient = createLLMClient({\\n *   preferredBackend: 'webllm',\\n *   fallbackBackends: ['transformers_js', 'mock'],\\n *   enableCache: true\\n * });\\n * \\n * await llmClient.initialize();\\n * const result = await llmClient.generate('Analyze sentiment', 'Hello world');\\n * ```\\n */\\n\\nimport { checkFeatures, detectRuntime } from '../../shared/utils/runtime-detector.js';\\nimport { createAnalysisPromptResult } from '../../core/configuration/types.ts';\\nimport { createLLMConfig, createLLMState } from './llm-config.js';\\nimport { createBackendManager } from './llm-backends.js';\\nimport { createLLMCache } from './llm-cache.js';\\nimport { createMetricsTracker } from './llm-metrics.js';\\n\\n// Create LLM client factory\\nexport const createLLMClient = (config = {}) => {\\n  const llmConfig = createLLMConfig(config);\\n  const state = createLLMState(llmConfig);\\n  \\n  // Initialize runtime detection\\n  state.runtime = detectRuntime();\\n  state.features = checkFeatures();\\n  \\n  // Create components\\n  const backendManager = createBackendManager();\\n  const cache = createLLMCache(llmConfig.cacheSize, llmConfig.compressionEnabled);\\n  const metricsTracker = createMetricsTracker(state.callbacks);\\n  \\n  // Notify error callbacks\\n  const notifyError = (error) => {\\n    state.callbacks.onError.forEach(callback => {\\n      try {\\n        callback(error);\\n      } catch (callbackError) {\\n        console.warn('LLM error callback failed:', callbackError);\\n      }\\n    });\\n  };\\n  \\n  // Notify progress callbacks\\n  const notifyProgress = (progress) => {\\n    state.callbacks.onProgress.forEach(callback => {\\n      try {\\n        callback(progress);\\n      } catch (callbackError) {\\n        console.warn('LLM progress callback failed:', callbackError);\\n      }\\n    });\\n  };\\n\\n  // Initialize the best available backend\\n  const initialize = async () => {\\n    const bestBackend = await backendManager.findBestBackend(\\n      llmConfig.preferredBackend,\\n      llmConfig.fallbackBackends\\n    );\\n    \\n    if (!bestBackend) {\\n      throw new Error('No LLM backends available. All backends failed to initialize.');\\n    }\\n    \\n    try {\\n      const backend = backendManager.getBackend(bestBackend);\\n      const backendInfo = backendManager.getBackendInfo(bestBackend);\\n      \\n      console.log(`🔄 Initializing ${backendInfo?.name || bestBackend}...`);\\n      \\n      await backend.initialize(llmConfig);\\n      \\n      state.activeBackend = bestBackend;\\n      state.isReady = true;\\n      \\n      console.log(`✅ ${backendInfo?.name || bestBackend} initialized successfully`);\\n      \\n      // Notify ready callbacks\\n      state.callbacks.onReady.forEach(callback => {\\n        try {\\n          callback({ backend: bestBackend, model: llmConfig.model });\\n        } catch (error) {\\n          console.warn('LLM ready callback error:', error);\\n        }\\n      });\\n      \\n      return true;\\n    } catch (error) {\\n      console.error(`Failed to initialize ${bestBackend}:`, error);\\n      notifyError(new Error(`${bestBackend} initialization failed: ${error.message}`));\\n      throw error;\\n    }\\n  };\\n\\n  // Generate analysis using active backend\\n  const generate = async (prompt, text = '', systemPrompt = null) => {\\n    if (!state.isReady || !state.activeBackend) {\\n      throw new Error('LLM client not initialized');\\n    }\\n\\n    const startTime = performance.now();\\n    \\n    try {\\n      // Check cache first\\n      if (llmConfig.enableCache && cache.has(prompt, text, systemPrompt)) {\\n        metricsTracker.recordCacheHit();\\n        const cachedResult = cache.get(prompt, text, systemPrompt);\\n        console.log('💾 Using cached response');\\n        return cachedResult;\\n      }\\n\\n      // Get active backend\\n      const backend = backendManager.getBackend(state.activeBackend);\\n      if (!backend) {\\n        throw new Error(`Backend ${state.activeBackend} not available`);\\n      }\\n\\n      // Generate response\\n      const response = await backend.generate(prompt, systemPrompt);\\n      const processingTime = performance.now() - startTime;\\n      \\n      // Cache the response\\n      if (llmConfig.enableCache) {\\n        cache.set(prompt, text, systemPrompt, response);\\n      }\\n      \\n      // Record success metrics\\n      metricsTracker.recordSuccess(processingTime);\\n      \\n      return response;\\n    } catch (error) {\\n      const processingTime = performance.now() - startTime;\\n      metricsTracker.recordFailure(processingTime);\\n      \\n      console.warn('LLM generation failed:', error.message);\\n      notifyError(error);\\n      \\n      // Try fallback if graceful degradation is enabled\\n      if (llmConfig.gracefulDegradation) {\\n        return await attemptFallback(prompt, text, systemPrompt);\\n      }\\n      \\n      throw error;\\n    }\\n  };\\n\\n  // Attempt fallback to other backends\\n  const attemptFallback = async (prompt, text, systemPrompt) => {\\n    const fallbackBackends = llmConfig.fallbackBackends.filter(b => b !== state.activeBackend);\\n    \\n    for (const backendName of fallbackBackends) {\\n      try {\\n        const backend = backendManager.getBackend(backendName);\\n        if (!backend) continue;\\n        \\n        const isAvailable = await backend.checkAvailability();\\n        if (!isAvailable) continue;\\n        \\n        console.log(`🔄 Switching to fallback backend: ${backendName}`);\\n        \\n        await backend.initialize(llmConfig);\\n        const response = await backend.generate(prompt, systemPrompt);\\n        \\n        // Record backend switch\\n        metricsTracker.recordBackendSwitch(state.activeBackend, backendName, 'fallback');\\n        state.activeBackend = backendName;\\n        \\n        return response;\\n      } catch (error) {\\n        console.warn(`Fallback to ${backendName} failed:`, error.message);\\n        continue;\\n      }\\n    }\\n    \\n    throw new Error('All fallback backends failed');\\n  };\\n\\n  // Generate multiple analyses with concurrency control\\n  const generateMultipleAnalyses = async (prompts, text, systemPrompt = null) => {\\n    if (!Array.isArray(prompts) || prompts.length === 0) {\\n      return [];\\n    }\\n\\n    notifyProgress({ stage: 'starting', total: prompts.length, completed: 0 });\\n\\n    const results = [];\\n    const maxConcurrent = Math.min(prompts.length, llmConfig.maxConcurrentRequests);\\n    \\n    // Process prompts in batches to respect concurrency limits\\n    for (let i = 0; i < prompts.length; i += maxConcurrent) {\\n      const batch = prompts.slice(i, i + maxConcurrent);\\n      const batchPromises = batch.map(async (prompt, index) => {\\n        const globalIndex = i + index;\\n        try {\\n          const startTime = performance.now();\\n          const result = await generate(prompt, text, systemPrompt);\\n          const processingTime = performance.now() - startTime;\\n          \\n          notifyProgress({ \\n            stage: 'processing', \\n            total: prompts.length, \\n            completed: globalIndex + 1 \\n          });\\n          \\n          return createAnalysisPromptResult({\\n            prompt,\\n            result,\\n            confidence: 0.9, // Assume high confidence for successful generation\\n            processingTime\\n          });\\n        } catch (error) {\\n          console.warn(`Analysis ${globalIndex + 1} failed:`, error.message);\\n          return createAnalysisPromptResult({\\n            prompt,\\n            result: 'Analysis failed',\\n            confidence: 0,\\n            error: error.message\\n          });\\n        }\\n      });\\n\\n      const batchResults = await Promise.all(batchPromises);\\n      results.push(...batchResults);\\n    }\\n\\n    notifyProgress({ stage: 'completed', total: prompts.length, completed: results.length });\\n    console.log(`✅ Completed ${results.length} analyses`);\\n    return results;\\n  };\\n\\n  // Generate conversation summary\\n  const generateSummary = async (chunks, existingSummary = '') => {\\n    if (!chunks || chunks.length === 0) {\\n      return existingSummary || 'No conversation to summarize.';\\n    }\\n\\n    const chunksText = chunks.join('\\\\n\\\\n');\\n    const summaryPrompt = existingSummary \\n      ? `You have an existing conversation summary: \\\"${existingSummary}\\\"\\\\n\\\\nNew conversation chunks to integrate:\\\\n${chunksText}\\\\n\\\\nCreate an updated summary that incorporates both the existing summary and new chunks. Keep it concise but comprehensive.`\\n      : `Create a concise summary of the following conversation chunks:\\\\n${chunksText}\\\\n\\\\nSummary:`;\\n\\n    try {\\n      return await generate(summaryPrompt, '', 'You are a helpful assistant that creates conversation summaries. Keep summaries concise and informative.');\\n    } catch (error) {\\n      console.warn('Summary generation failed:', error.message);\\n      return existingSummary || 'Summary generation failed.';\\n    }\\n  };\\n\\n  // Get client status\\n  const getStatus = () => ({\\n    isReady: state.isReady,\\n    activeBackend: state.activeBackend,\\n    backendInfo: backendManager.getBackendInfo(state.activeBackend),\\n    model: llmConfig.model,\\n    metrics: metricsTracker.getMetrics(),\\n    performance: metricsTracker.getPerformanceStats(),\\n    cache: cache.getStats(),\\n    queueLength: state.requestQueue.length\\n  });\\n\\n  // Cleanup resources\\n  const cleanup = async () => {\\n    if (state.activeBackend) {\\n      const backend = backendManager.getBackend(state.activeBackend);\\n      if (backend) {\\n        try {\\n          await backend.cleanup();\\n        } catch (error) {\\n          console.warn('LLM backend cleanup error:', error);\\n        }\\n      }\\n    }\\n    \\n    cache.clear();\\n    state.requestQueue.length = 0;\\n    state.isReady = false;\\n    state.activeBackend = null;\\n  };\\n\\n  // Event handlers\\n  const onReady = (callback) => {\\n    state.callbacks.onReady.push(callback);\\n    return () => {\\n      const index = state.callbacks.onReady.indexOf(callback);\\n      if (index !== -1) state.callbacks.onReady.splice(index, 1);\\n    };\\n  };\\n\\n  const onError = (callback) => {\\n    state.callbacks.onError.push(callback);\\n    return () => {\\n      const index = state.callbacks.onError.indexOf(callback);\\n      if (index !== -1) state.callbacks.onError.splice(index, 1);\\n    };\\n  };\\n\\n  const onProgress = (callback) => {\\n    state.callbacks.onProgress.push(callback);\\n    return () => {\\n      const index = state.callbacks.onProgress.indexOf(callback);\\n      if (index !== -1) state.callbacks.onProgress.splice(index, 1);\\n    };\\n  };\\n\\n  return {\\n    // Core functionality\\n    initialize,\\n    generate,\\n    generateMultipleAnalyses,\\n    generateSummary,\\n    \\n    // Information and status\\n    getStatus,\\n    isReady: () => state.isReady,\\n    getAvailableBackends: backendManager.getAvailableBackends,\\n    \\n    // Event handling\\n    onReady,\\n    onError,\\n    onProgress,\\n    \\n    // Configuration and maintenance\\n    getConfiguration: () => ({ ...llmConfig }),\\n    updateConfiguration: (updates) => Object.assign(llmConfig, updates),\\n    clearCache: cache.clear,\\n    getMetrics: metricsTracker.getMetrics,\\n    getPerformanceStats: metricsTracker.getPerformanceStats,\\n    \\n    // Lifecycle\\n    cleanup\\n  };\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/features/speech-analysis/llm-config.js\",\"messages\":[],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/features/speech-analysis/llm-metrics.js\",\"messages\":[],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/features/speech-analysis/recognition/backend-manager.js\",\"messages\":[{\"ruleId\":\"consistent-return\",\"severity\":1,\"message\":\"Async arrow function expected no return value.\",\"line\":54,\"column\":5,\"nodeType\":\"ReturnStatement\",\"messageId\":\"unexpectedReturnValue\",\"endLine\":54,\"endColumn\":32},{\"ruleId\":\"consistent-return\",\"severity\":1,\"message\":\"Async arrow function expected no return value.\",\"line\":69,\"column\":5,\"nodeType\":\"ReturnStatement\",\"messageId\":\"unexpectedReturnValue\",\"endLine\":69,\"endColumn\":32},{\"ruleId\":\"consistent-return\",\"severity\":1,\"message\":\"Async arrow function expected no return value.\",\"line\":86,\"column\":5,\"nodeType\":\"ReturnStatement\",\"messageId\":\"unexpectedReturnValue\",\"endLine\":86,\"endColumn\":32}],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":3,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Speech Recognition Backend Manager\\n * Handles backend selection, initialization, and lifecycle management\\n */\\n\\nexport const createBackendManager = (backends, speechBackends) => {\\n  // Initialize the best available speech recognition backend\\n  const initializeBestBackend = async (state) => {\\n    const backendPriority = ['web_speech_api', 'speech_recognition_fallback'];\\n\\n    for (const backendName of backendPriority) {\\n      try {\\n        const backend = backends[backendName];\\n        const isAvailable = await backend.checkAvailability(state);\\n\\n        if (isAvailable) {\\n          state.activeBackend = backendName;\\n          await backend.initialize(state);\\n          state.isInitialized = true;\\n          \\n          console.log(`✅ Initialized backend: ${backendName}`);\\n          return true;\\n        }\\n      } catch (error) {\\n        console.warn(`Failed to initialize ${backendName}:`, error.message);\\n        continue;\\n      }\\n    }\\n\\n    throw new Error('No speech recognition backends available');\\n  };\\n\\n  // Start the active backend\\n  const startBackend = async (state) => {\\n    if (!state.isInitialized || !state.activeBackend) {\\n      throw new Error('Speech recognition not initialized');\\n    }\\n\\n    if (state.isListening) {\\n      console.warn('Speech recognition already listening');\\n      return;\\n    }\\n\\n    console.log('🎤 Starting speech recognition...');\\n    \\n    const backend = backends[state.activeBackend];\\n    await backend.start(state);\\n    \\n    state.isListening = true;\\n    state.metrics.totalSessions++;\\n    state.currentTranscript = '';\\n    state.finalTranscript = '';\\n\\n    return state.activeBackend;\\n  };\\n\\n  // Stop the active backend\\n  const stopBackend = async (state) => {\\n    if (!state.isListening || !state.activeBackend) {\\n      return;\\n    }\\n\\n    console.log('🔇 Stopping speech recognition...');\\n    \\n    const backend = backends[state.activeBackend];\\n    await backend.stop(state);\\n    \\n    state.isListening = false;\\n    return state.activeBackend;\\n  };\\n\\n  // Abort the active backend immediately\\n  const abortBackend = async (state) => {\\n    if (!state.isListening || !state.activeBackend) {\\n      return;\\n    }\\n\\n    const backend = backends[state.activeBackend];\\n    if (backend.abort) {\\n      await backend.abort(state);\\n    } else {\\n      await backend.stop(state);\\n    }\\n    \\n    state.isListening = false;\\n    return state.activeBackend;\\n  };\\n\\n  // Cleanup the active backend\\n  const cleanupBackend = async (state) => {\\n    if (state.activeBackend && backends[state.activeBackend]) {\\n      const backend = backends[state.activeBackend];\\n      if (backend.cleanup) {\\n        await backend.cleanup(state);\\n      }\\n    }\\n\\n    state.recognition = null;\\n    state.isInitialized = false;\\n    state.activeBackend = null;\\n  };\\n\\n  // Get backend information\\n  const getBackendInfo = (backendName) => {\\n    return speechBackends[backendName] || null;\\n  };\\n\\n  // Get all supported backends\\n  const getSupportedBackends = () => {\\n    return Object.keys(speechBackends);\\n  };\\n\\n  // Check if a specific backend is available\\n  const checkBackendAvailability = async (backendName, state) => {\\n    if (!backends[backendName]) {\\n      return false;\\n    }\\n\\n    try {\\n      return await backends[backendName].checkAvailability(state);\\n    } catch (error) {\\n      console.warn(`Backend ${backendName} availability check failed:`, error);\\n      return false;\\n    }\\n  };\\n\\n  return {\\n    initializeBestBackend,\\n    startBackend,\\n    stopBackend,\\n    abortBackend,\\n    cleanupBackend,\\n    getBackendInfo,\\n    getSupportedBackends,\\n    checkBackendAvailability\\n  };\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/features/speech-analysis/recognition/event-manager.js\",\"messages\":[{\"ruleId\":\"max-lines-per-function\",\"severity\":1,\"message\":\"Arrow function has too many lines (276). Maximum allowed is 150.\",\"line\":8,\"column\":35,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"exceed\",\"endLine\":359,\"endColumn\":2}],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":1,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Speech Recognition Event Manager\\n * Comprehensive event handling, callback management, and state transitions\\n */\\n\\nimport { createSpeechEvent } from '../../../core/configuration/types.ts';\\n\\nexport const createEventManager = () => {\\n  // Event queue for complex event sequencing\\n  let eventQueue = [];\\n  let isProcessingEvents = false;\\n\\n  const initializeCallbacks = (state) => {\\n    // Initialize all callback arrays if not already present\\n    const callbackTypes = [\\n      'onResult',\\n      'onInterimResult', \\n      'onError',\\n      'onStart',\\n      'onEnd',\\n      'onSpeechStart',\\n      'onSpeechEnd',\\n      'onAudioProcessing',\\n      'onStateChange'\\n    ];\\n\\n    if (!state.callbacks) {\\n      state.callbacks = {};\\n    }\\n\\n    callbackTypes.forEach(type => {\\n      if (!state.callbacks[type]) {\\n        state.callbacks[type] = [];\\n      }\\n    });\\n\\n    console.log('✅ Event manager callbacks initialized');\\n  };\\n\\n  const addCallback = (state, eventType, callback) => {\\n    if (!state.callbacks) {\\n      initializeCallbacks(state);\\n    }\\n\\n    if (!state.callbacks[eventType]) {\\n      state.callbacks[eventType] = [];\\n    }\\n\\n    if (typeof callback === 'function') {\\n      state.callbacks[eventType].push(callback);\\n      console.log(`📝 Added ${eventType} callback`);\\n      return true;\\n    }\\n\\n    console.warn(`⚠️ Invalid callback for ${eventType}: not a function`);\\n    return false;\\n  };\\n\\n  const removeCallback = (state, eventType, callback) => {\\n    if (!state.callbacks || !state.callbacks[eventType]) {\\n      return false;\\n    }\\n\\n    const index = state.callbacks[eventType].indexOf(callback);\\n    if (index > -1) {\\n      state.callbacks[eventType].splice(index, 1);\\n      console.log(`🗑️ Removed ${eventType} callback`);\\n      return true;\\n    }\\n\\n    return false;\\n  };\\n\\n  const clearCallbacks = (state, eventType = null) => {\\n    if (!state.callbacks) {\\n      return;\\n    }\\n\\n    if (eventType) {\\n      if (state.callbacks[eventType]) {\\n        state.callbacks[eventType] = [];\\n        console.log(`🧹 Cleared ${eventType} callbacks`);\\n      }\\n    } else {\\n      // Clear all callbacks\\n      Object.keys(state.callbacks).forEach(type => {\\n        state.callbacks[type] = [];\\n      });\\n      console.log('🧹 Cleared all callbacks');\\n    }\\n  };\\n\\n  const notifyCallbacks = (callbacks, data, eventType = 'unknown') => {\\n    if (!callbacks || !Array.isArray(callbacks) || callbacks.length === 0) {\\n      return;\\n    }\\n\\n    let successCount = 0;\\n    let errorCount = 0;\\n\\n    callbacks.forEach((callback, index) => {\\n      try {\\n        callback(data);\\n        successCount++;\\n      } catch (error) {\\n        errorCount++;\\n        console.error(`❌ Callback error for ${eventType}[${index}]:`, error);\\n        \\n        // Create error event for callback failures\\n        const errorEvent = createSpeechEvent({\\n          type: 'callback_error',\\n          data: {\\n            originalEventType: eventType,\\n            callbackIndex: index,\\n            error: error.message,\\n            stack: error.stack\\n          },\\n          severity: 'error'\\n        });\\n\\n        // Queue this error to avoid infinite recursion\\n        queueEvent(errorEvent, 'onError');\\n      }\\n    });\\n\\n    if (successCount > 0 || errorCount > 0) {\\n      console.log(`📤 ${eventType}: ${successCount} callbacks succeeded, ${errorCount} failed`);\\n    }\\n  };\\n\\n  const queueEvent = (eventData, eventType, priority = 'normal') => {\\n    const event = {\\n      data: eventData,\\n      type: eventType,\\n      priority,\\n      timestamp: Date.now(),\\n      id: generateEventId()\\n    };\\n\\n    // Insert based on priority\\n    if (priority === 'high') {\\n      eventQueue.unshift(event);\\n    } else {\\n      eventQueue.push(event);\\n    }\\n\\n    // Process queue if not already processing\\n    if (!isProcessingEvents) {\\n      processEventQueue();\\n    }\\n  };\\n\\n  const processEventQueue = async () => {\\n    if (isProcessingEvents || eventQueue.length === 0) {\\n      return;\\n    }\\n\\n    isProcessingEvents = true;\\n\\n    while (eventQueue.length > 0) {\\n      const event = eventQueue.shift();\\n      \\n      try {\\n        // Emit the event\\n        await emitEvent(event);\\n        \\n        // Small delay to prevent overwhelming the system\\n        if (eventQueue.length > 10) {\\n          await new Promise(resolve => setTimeout(resolve, 1));\\n        }\\n        \\n      } catch (error) {\\n        console.error('❌ Error processing queued event:', error);\\n      }\\n    }\\n\\n    isProcessingEvents = false;\\n  };\\n\\n  const emitEvent = async (event) => {\\n    // This would be implemented by the specific event system\\n    // For now, just log the event processing\\n    console.log(`🚀 Processing queued event: ${event.type} [${event.id}]`);\\n  };\\n\\n  const generateEventId = () => {\\n    return `evt_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;\\n  };\\n\\n  const createStateChangeEvent = (state, previousState, changedProperties) => {\\n    return createSpeechEvent({\\n      type: 'state_change',\\n      data: {\\n        current: {\\n          isListening: state.isListening,\\n          isInitialized: state.isInitialized,\\n          activeBackend: state.activeBackend,\\n          language: state.language,\\n          continuous: state.continuous\\n        },\\n        previous: previousState,\\n        changed: changedProperties,\\n        timestamp: Date.now()\\n      },\\n      severity: 'info'\\n    });\\n  };\\n\\n  const notifyStateChange = (state, previousState, changedProperties) => {\\n    if (!changedProperties || changedProperties.length === 0) {\\n      return;\\n    }\\n\\n    const stateChangeEvent = createStateChangeEvent(state, previousState, changedProperties);\\n    \\n    if (state.callbacks && state.callbacks.onStateChange) {\\n      notifyCallbacks(state.callbacks.onStateChange, stateChangeEvent, 'onStateChange');\\n    }\\n  };\\n\\n  const trackStateChanges = (state, callback) => {\\n    // Create a proxy to automatically track state changes\\n    const previousState = JSON.parse(JSON.stringify({\\n      isListening: state.isListening,\\n      isInitialized: state.isInitialized,\\n      activeBackend: state.activeBackend,\\n      language: state.language,\\n      continuous: state.continuous\\n    }));\\n\\n    return new Proxy(state, {\\n      set(target, property, value) {\\n        const oldValue = target[property];\\n        target[property] = value;\\n\\n        // Check if this is a tracked property that changed\\n        const trackedProperties = ['isListening', 'isInitialized', 'activeBackend', 'language', 'continuous'];\\n        \\n        if (trackedProperties.includes(property) && oldValue !== value) {\\n          const changedProperties = [property];\\n          \\n          if (callback) {\\n            callback(target, previousState, changedProperties);\\n          }\\n          \\n          // Update previous state\\n          previousState[property] = value;\\n        }\\n\\n        return true;\\n      }\\n    });\\n  };\\n\\n  const createErrorEvent = (error, context = {}) => {\\n    return createSpeechEvent({\\n      type: 'speech_recognition_error',\\n      data: {\\n        error: error.message || error,\\n        code: error.code || 'unknown',\\n        name: error.name || 'Error',\\n        stack: error.stack,\\n        context,\\n        timestamp: Date.now(),\\n        recoverable: isRecoverableError(error)\\n      },\\n      severity: 'error'\\n    });\\n  };\\n\\n  const isRecoverableError = (error) => {\\n    const recoverableErrors = [\\n      'no-speech',\\n      'aborted',\\n      'network'\\n    ];\\n\\n    return recoverableErrors.includes(error.code || error.error);\\n  };\\n\\n  const handleError = (state, error, context = {}) => {\\n    console.error('🚨 Speech recognition error:', error);\\n    \\n    // Update error metrics\\n    if (state.metrics) {\\n      state.metrics.errors = (state.metrics.errors || 0) + 1;\\n      state.metrics.lastError = {\\n        message: error.message || error,\\n        timestamp: Date.now(),\\n        context\\n      };\\n    }\\n\\n    // Create comprehensive error event\\n    const errorEvent = createErrorEvent(error, context);\\n    \\n    // Notify error callbacks\\n    if (state.callbacks && state.callbacks.onError) {\\n      notifyCallbacks(state.callbacks.onError, errorEvent, 'onError');\\n    }\\n\\n    // Queue for processing if needed\\n    if (context.async) {\\n      queueEvent(errorEvent, 'onError', 'high');\\n    }\\n\\n    return errorEvent;\\n  };\\n\\n  const validateCallbackRegistration = (eventType, callback) => {\\n    const validEvents = [\\n      'onResult', 'onInterimResult', 'onError', 'onStart', 'onEnd',\\n      'onSpeechStart', 'onSpeechEnd', 'onAudioProcessing', 'onStateChange'\\n    ];\\n\\n    if (!validEvents.includes(eventType)) {\\n      throw new Error(`Invalid event type: ${eventType}. Valid types: ${validEvents.join(', ')}`);\\n    }\\n\\n    if (typeof callback !== 'function') {\\n      throw new Error(`Callback must be a function, got ${typeof callback}`);\\n    }\\n\\n    return true;\\n  };\\n\\n  const getEventStatistics = () => {\\n    return {\\n      queueLength: eventQueue.length,\\n      isProcessingEvents,\\n      lastEventId: eventQueue.length > 0 ? eventQueue[eventQueue.length - 1].id : null,\\n      totalEventsProcessed: 0 // This would be tracked in a real implementation\\n    };\\n  };\\n\\n  const clearEventQueue = () => {\\n    eventQueue = [];\\n    isProcessingEvents = false;\\n    console.log('🧹 Event queue cleared');\\n  };\\n\\n  return {\\n    initializeCallbacks,\\n    addCallback,\\n    removeCallback,\\n    clearCallbacks,\\n    notifyCallbacks,\\n    queueEvent,\\n    processEventQueue,\\n    createStateChangeEvent,\\n    notifyStateChange,\\n    trackStateChanges,\\n    createErrorEvent,\\n    handleError,\\n    validateCallbackRegistration,\\n    getEventStatistics,\\n    clearEventQueue\\n  };\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/features/speech-analysis/recognition/metrics-calculator.js\",\"messages\":[{\"ruleId\":\"max-lines-per-function\",\"severity\":1,\"message\":\"Arrow function has too many lines (360). Maximum allowed is 150.\",\"line\":6,\"column\":40,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"exceed\",\"endLine\":471,\"endColumn\":2},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":100,\"column\":22,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":100,\"endColumn\":23},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":100,\"column\":43,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":100,\"endColumn\":44},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":100,\"column\":43,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":100,\"endColumn\":44},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":100,\"column\":56,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":100,\"endColumn\":57},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":322,\"column\":27,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":322,\"endColumn\":28},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":322,\"column\":41,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":322,\"endColumn\":42},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":322,\"column\":41,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":322,\"endColumn\":42},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":322,\"column\":52,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":322,\"endColumn\":53}],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":9,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Speech Recognition Metrics Calculator\\n * Comprehensive metrics tracking, analysis, and reporting\\n */\\n\\nexport const createMetricsCalculator = () => {\\n  const initializeMetrics = (state) => {\\n    if (!state.metrics) {\\n      state.metrics = {};\\n    }\\n\\n    // Core speech recognition metrics\\n    const coreMetrics = {\\n      totalWords: 0,\\n      totalCharacters: 0,\\n      totalSessions: 0,\\n      averageConfidence: 0,\\n      errors: 0,\\n      totalProcessingTime: 0,\\n      sessionStartTime: null,\\n      sessionDuration: 0\\n    };\\n\\n    // Advanced metrics\\n    const advancedMetrics = {\\n      wordsPerMinute: 0,\\n      charactersPerSecond: 0,\\n      averageWordLength: 0,\\n      confidenceDistribution: {\\n        high: 0, // > 0.8\\n        medium: 0, // 0.5 - 0.8\\n        low: 0 // < 0.5\\n      },\\n      errorTypes: {},\\n      backendUsage: {},\\n      languageDistribution: {},\\n      sessionHistory: []\\n    };\\n\\n    // Performance metrics\\n    const performanceMetrics = {\\n      averageResponseTime: 0,\\n      minResponseTime: Infinity,\\n      maxResponseTime: 0,\\n      totalResponses: 0,\\n      timeouts: 0,\\n      retries: 0\\n    };\\n\\n    // Audio quality metrics (if available)\\n    const audioMetrics = {\\n      averageVolumeLevel: 0,\\n      averageSignalLevel: 0,\\n      averageBackgroundNoise: 0,\\n      averageSNR: 0,\\n      silencePeriods: 0,\\n      totalAudioDuration: 0\\n    };\\n\\n    // Merge with existing metrics to preserve any existing data\\n    state.metrics = {\\n      ...coreMetrics,\\n      ...advancedMetrics,\\n      ...performanceMetrics,\\n      ...audioMetrics,\\n      ...state.metrics\\n    };\\n\\n    console.log('📊 Metrics calculator initialized');\\n    return state.metrics;\\n  };\\n\\n  const updateWordMetrics = (state, words, confidence) => {\\n    if (!words || !Array.isArray(words)) {\\n      return;\\n    }\\n\\n    const previousTotalWords = state.metrics.totalWords;\\n    const newWordCount = words.length;\\n    \\n    // Update word count\\n    state.metrics.totalWords += newWordCount;\\n    \\n    // Update character count\\n    const newCharacterCount = words.reduce((sum, word) => sum + (word.word || '').length, 0);\\n    state.metrics.totalCharacters += newCharacterCount;\\n    \\n    // Update average word length\\n    if (state.metrics.totalWords > 0) {\\n      state.metrics.averageWordLength = state.metrics.totalCharacters / state.metrics.totalWords;\\n    }\\n\\n    // Update confidence metrics\\n    if (confidence > 0) {\\n      const {totalWords} = state.metrics;\\n      const previousAvg = state.metrics.averageConfidence;\\n      \\n      // Weighted average confidence\\n      state.metrics.averageConfidence = \\n        (previousAvg * previousTotalWords + confidence * newWordCount) / totalWords;\\n        \\n      // Update confidence distribution\\n      updateConfidenceDistribution(state, confidence, newWordCount);\\n    }\\n\\n    // Calculate speaking rate if we have timing info\\n    updateSpeakingRate(state);\\n  };\\n\\n  const updateConfidenceDistribution = (state, confidence, wordCount) => {\\n    if (confidence > 0.8) {\\n      state.metrics.confidenceDistribution.high += wordCount;\\n    } else if (confidence >= 0.5) {\\n      state.metrics.confidenceDistribution.medium += wordCount;\\n    } else {\\n      state.metrics.confidenceDistribution.low += wordCount;\\n    }\\n  };\\n\\n  const updateSpeakingRate = (state) => {\\n    if (!state.metrics.sessionStartTime || state.metrics.totalWords === 0) {\\n      return;\\n    }\\n\\n    const sessionDuration = (Date.now() - state.metrics.sessionStartTime) / 1000; // seconds\\n    state.metrics.sessionDuration = sessionDuration;\\n\\n    if (sessionDuration > 0) {\\n      // Words per minute\\n      state.metrics.wordsPerMinute = (state.metrics.totalWords / sessionDuration) * 60;\\n      \\n      // Characters per second\\n      state.metrics.charactersPerSecond = state.metrics.totalCharacters / sessionDuration;\\n    }\\n  };\\n\\n  const updateProcessingTime = (state, processingTime) => {\\n    if (typeof processingTime !== 'number' || processingTime < 0) {\\n      return;\\n    }\\n\\n    state.metrics.totalProcessingTime += processingTime;\\n    state.metrics.totalResponses++;\\n\\n    // Update response time statistics\\n    state.metrics.averageResponseTime = \\n      state.metrics.totalProcessingTime / state.metrics.totalResponses;\\n      \\n    state.metrics.minResponseTime = Math.min(state.metrics.minResponseTime, processingTime);\\n    state.metrics.maxResponseTime = Math.max(state.metrics.maxResponseTime, processingTime);\\n  };\\n\\n  const updateErrorMetrics = (state, error) => {\\n    state.metrics.errors++;\\n\\n    // Track error types\\n    const errorType = error.code || error.error || error.name || 'unknown';\\n    if (!state.metrics.errorTypes[errorType]) {\\n      state.metrics.errorTypes[errorType] = 0;\\n    }\\n    state.metrics.errorTypes[errorType]++;\\n\\n    // Update last error info\\n    state.metrics.lastError = {\\n      type: errorType,\\n      message: error.message || error,\\n      timestamp: Date.now()\\n    };\\n  };\\n\\n  const updateBackendUsage = (state, backendName) => {\\n    if (!backendName) {\\n      return;\\n    }\\n\\n    if (!state.metrics.backendUsage[backendName]) {\\n      state.metrics.backendUsage[backendName] = {\\n        sessions: 0,\\n        totalWords: 0,\\n        averageConfidence: 0,\\n        errors: 0\\n      };\\n    }\\n\\n    const backend = state.metrics.backendUsage[backendName];\\n    backend.sessions++;\\n    \\n    // This will be updated when words are processed\\n    backend.currentSessionStart = Date.now();\\n  };\\n\\n  const updateLanguageDistribution = (state, language) => {\\n    if (!language) {\\n      return;\\n    }\\n\\n    if (!state.metrics.languageDistribution[language]) {\\n      state.metrics.languageDistribution[language] = {\\n        sessions: 0,\\n        totalWords: 0,\\n        averageConfidence: 0\\n      };\\n    }\\n\\n    state.metrics.languageDistribution[language].sessions++;\\n  };\\n\\n  const startSession = (state, backendName, language) => {\\n    state.metrics.totalSessions++;\\n    state.metrics.sessionStartTime = Date.now();\\n    \\n    // Reset session-specific metrics\\n    const sessionMetrics = {\\n      sessionWords: 0,\\n      sessionCharacters: 0,\\n      sessionStartTime: Date.now(),\\n      sessionDuration: 0,\\n      sessionBackend: backendName,\\n      sessionLanguage: language,\\n      sessionErrors: 0\\n    };\\n\\n    // Store current session info\\n    state.currentSession = sessionMetrics;\\n\\n    updateBackendUsage(state, backendName);\\n    updateLanguageDistribution(state, language);\\n\\n    console.log(`📈 Started metrics session: ${backendName} (${language})`);\\n  };\\n\\n  const endSession = (state) => {\\n    if (!state.currentSession || !state.metrics.sessionStartTime) {\\n      return null;\\n    }\\n\\n    const sessionEndTime = Date.now();\\n    const sessionDuration = (sessionEndTime - state.metrics.sessionStartTime) / 1000;\\n    \\n    // Update session duration\\n    state.metrics.sessionDuration = sessionDuration;\\n    state.currentSession.sessionDuration = sessionDuration;\\n    state.currentSession.endTime = sessionEndTime;\\n\\n    // Calculate session-specific rates\\n    if (sessionDuration > 0) {\\n      state.currentSession.wordsPerMinute = (state.currentSession.sessionWords / sessionDuration) * 60;\\n      state.currentSession.charactersPerSecond = state.currentSession.sessionCharacters / sessionDuration;\\n    }\\n\\n    // Store in session history\\n    if (!state.metrics.sessionHistory) {\\n      state.metrics.sessionHistory = [];\\n    }\\n    \\n    state.metrics.sessionHistory.push({...state.currentSession});\\n    \\n    // Keep only last 50 sessions\\n    if (state.metrics.sessionHistory.length > 50) {\\n      state.metrics.sessionHistory = state.metrics.sessionHistory.slice(-50);\\n    }\\n\\n    const sessionSummary = {\\n      duration: sessionDuration,\\n      words: state.currentSession.sessionWords,\\n      characters: state.currentSession.sessionCharacters,\\n      wordsPerMinute: state.currentSession.wordsPerMinute || 0,\\n      charactersPerSecond: state.currentSession.charactersPerSecond || 0,\\n      backend: state.currentSession.sessionBackend,\\n      language: state.currentSession.sessionLanguage,\\n      errors: state.currentSession.sessionErrors\\n    };\\n\\n    // Clear current session\\n    state.currentSession = null;\\n    state.metrics.sessionStartTime = null;\\n\\n    console.log('📊 Session ended:', sessionSummary);\\n    return sessionSummary;\\n  };\\n\\n  const updateAudioMetrics = (state, audioData) => {\\n    if (!audioData || typeof audioData !== 'object') {\\n      return;\\n    }\\n\\n    const {metrics} = state;\\n\\n    // Update rolling averages for audio metrics\\n    if (typeof audioData.volumeLevel === 'number') {\\n      metrics.averageVolumeLevel = updateRollingAverage(\\n        metrics.averageVolumeLevel, audioData.volumeLevel, 0.1\\n      );\\n    }\\n\\n    if (typeof audioData.signalLevel === 'number') {\\n      metrics.averageSignalLevel = updateRollingAverage(\\n        metrics.averageSignalLevel, audioData.signalLevel, 0.1\\n      );\\n    }\\n\\n    if (typeof audioData.backgroundNoise === 'number') {\\n      metrics.averageBackgroundNoise = updateRollingAverage(\\n        metrics.averageBackgroundNoise, audioData.backgroundNoise, 0.1\\n      );\\n    }\\n\\n    if (typeof audioData.snrEstimate === 'number') {\\n      metrics.averageSNR = updateRollingAverage(\\n        metrics.averageSNR, audioData.snrEstimate, 0.1\\n      );\\n    }\\n\\n    // Detect silence periods (low volume levels)\\n    if (typeof audioData.volumeLevel === 'number' && audioData.volumeLevel < 0.01) {\\n      metrics.silencePeriods++;\\n    }\\n  };\\n\\n  const updateRollingAverage = (currentAverage, newValue, alpha = 0.1) => {\\n    // Exponential moving average\\n    return currentAverage * (1 - alpha) + newValue * alpha;\\n  };\\n\\n  const generateMetricsReport = (state, format = 'summary') => {\\n    const {metrics} = state;\\n    const now = Date.now();\\n\\n    const baseReport = {\\n      timestamp: now,\\n      totalSessions: metrics.totalSessions,\\n      totalWords: metrics.totalWords,\\n      totalCharacters: metrics.totalCharacters,\\n      averageConfidence: Math.round(metrics.averageConfidence * 100) / 100,\\n      totalErrors: metrics.errors,\\n      wordsPerMinute: Math.round(metrics.wordsPerMinute * 10) / 10,\\n      charactersPerSecond: Math.round(metrics.charactersPerSecond * 10) / 10\\n    };\\n\\n    if (format === 'summary') {\\n      return baseReport;\\n    }\\n\\n    const detailedReport = {\\n      ...baseReport,\\n      performance: {\\n        averageResponseTime: Math.round(metrics.averageResponseTime * 10) / 10,\\n        minResponseTime: metrics.minResponseTime === Infinity ? 0 : metrics.minResponseTime,\\n        maxResponseTime: metrics.maxResponseTime,\\n        totalResponses: metrics.totalResponses,\\n        timeouts: metrics.timeouts,\\n        retries: metrics.retries\\n      },\\n      confidence: {\\n        average: Math.round(metrics.averageConfidence * 100) / 100,\\n        distribution: {\\n          high: Math.round((metrics.confidenceDistribution.high / metrics.totalWords) * 100) || 0,\\n          medium: Math.round((metrics.confidenceDistribution.medium / metrics.totalWords) * 100) || 0,\\n          low: Math.round((metrics.confidenceDistribution.low / metrics.totalWords) * 100) || 0\\n        }\\n      },\\n      errors: {\\n        total: metrics.errors,\\n        types: metrics.errorTypes,\\n        errorRate: metrics.totalSessions > 0 ? Math.round((metrics.errors / metrics.totalSessions) * 100) / 100 : 0\\n      },\\n      backends: metrics.backendUsage,\\n      languages: metrics.languageDistribution,\\n      audio: {\\n        averageVolumeLevel: Math.round(metrics.averageVolumeLevel * 100) / 100,\\n        averageSignalLevel: Math.round(metrics.averageSignalLevel),\\n        averageBackgroundNoise: Math.round(metrics.averageBackgroundNoise),\\n        averageSNR: Math.round(metrics.averageSNR * 10) / 10,\\n        silencePeriods: metrics.silencePeriods\\n      }\\n    };\\n\\n    if (format === 'detailed') {\\n      return detailedReport;\\n    }\\n\\n    // Full report includes session history\\n    return {\\n      ...detailedReport,\\n      sessionHistory: metrics.sessionHistory || []\\n    };\\n  };\\n\\n  const resetMetrics = (state, preserveHistory = false) => {\\n    const currentHistory = preserveHistory ? (state.metrics.sessionHistory || []) : [];\\n    \\n    initializeMetrics(state);\\n    \\n    if (preserveHistory) {\\n      state.metrics.sessionHistory = currentHistory;\\n    }\\n\\n    console.log(`📊 Metrics reset (history ${preserveHistory ? 'preserved' : 'cleared'})`);\\n  };\\n\\n  const exportMetrics = (state, format = 'json') => {\\n    const report = generateMetricsReport(state, 'full');\\n    \\n    switch (format.toLowerCase()) {\\n      case 'csv':\\n        return convertToCSV(report);\\n      case 'txt':\\n        return convertToText(report);\\n      case 'json':\\n      default:\\n        return JSON.stringify(report, null, 2);\\n    }\\n  };\\n\\n  const convertToCSV = (report) => {\\n    // Simple CSV conversion for basic metrics\\n    const rows = [\\n      ['Metric', 'Value'],\\n      ['Total Sessions', report.totalSessions],\\n      ['Total Words', report.totalWords],\\n      ['Total Characters', report.totalCharacters],\\n      ['Average Confidence', report.averageConfidence],\\n      ['Total Errors', report.totalErrors],\\n      ['Words per Minute', report.wordsPerMinute],\\n      ['Characters per Second', report.charactersPerSecond],\\n      ['Error Rate', report.errors?.errorRate || 0]\\n    ];\\n\\n    return rows.map(row => row.join(',')).join('\\\\n');\\n  };\\n\\n  const convertToText = (report) => {\\n    return `\\nSpeech Recognition Metrics Report\\nGenerated: ${new Date(report.timestamp).toLocaleString()}\\n\\n=== SUMMARY ===\\nTotal Sessions: ${report.totalSessions}\\nTotal Words: ${report.totalWords}\\nTotal Characters: ${report.totalCharacters}\\nAverage Confidence: ${report.averageConfidence}%\\nTotal Errors: ${report.totalErrors}\\n\\n=== PERFORMANCE ===\\nWords per Minute: ${report.wordsPerMinute}\\nCharacters per Second: ${report.charactersPerSecond}\\nAverage Response Time: ${report.performance?.averageResponseTime || 0}ms\\nError Rate: ${report.errors?.errorRate || 0}%\\n\\n=== AUDIO QUALITY ===\\nAverage Volume Level: ${report.audio?.averageVolumeLevel || 0}\\nAverage Signal Level: ${report.audio?.averageSignalLevel || 0}\\nAverage SNR: ${report.audio?.averageSNR || 0}dB\\n    `.trim();\\n  };\\n\\n  return {\\n    initializeMetrics,\\n    updateWordMetrics,\\n    updateProcessingTime,\\n    updateErrorMetrics,\\n    updateBackendUsage,\\n    updateLanguageDistribution,\\n    updateAudioMetrics,\\n    startSession,\\n    endSession,\\n    generateMetricsReport,\\n    resetMetrics,\\n    exportMetrics\\n  };\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/features/speech-analysis/recognition/web-speech-backend.js\",\"messages\":[{\"ruleId\":\"max-lines-per-function\",\"severity\":1,\"message\":\"Arrow function has too many lines (344). Maximum allowed is 150.\",\"line\":12,\"column\":42,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"exceed\",\"endLine\":461,\"endColumn\":2},{\"ruleId\":\"no-undef\",\"severity\":2,\"message\":\"'location' is not defined.\",\"line\":37,\"column\":9,\"nodeType\":\"Identifier\",\"messageId\":\"undef\",\"endLine\":37,\"endColumn\":17},{\"ruleId\":\"no-undef\",\"severity\":2,\"message\":\"'location' is not defined.\",\"line\":37,\"column\":43,\"nodeType\":\"Identifier\",\"messageId\":\"undef\",\"endLine\":37,\"endColumn\":51},{\"ruleId\":\"prefer-destructuring\",\"severity\":1,\"message\":\"Use array destructuring.\",\"line\":121,\"column\":13,\"nodeType\":\"VariableDeclarator\",\"messageId\":\"preferDestructuring\",\"endLine\":121,\"endColumn\":37},{\"ruleId\":\"prefer-destructuring\",\"severity\":1,\"message\":\"Use array destructuring.\",\"line\":122,\"column\":13,\"nodeType\":\"VariableDeclarator\",\"messageId\":\"preferDestructuring\",\"endLine\":122,\"endColumn\":37},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'index' is defined but never used. Allowed unused args must match /^_/u.\",\"line\":128,\"column\":63,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":128,\"endColumn\":68,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"index\"},\"fix\":{\"range\":[3699,3706],\"text\":\"\"},\"desc\":\"Remove unused variable 'index'.\"}]},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":147,\"column\":26,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":147,\"endColumn\":27},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":147,\"column\":42,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":147,\"endColumn\":43},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":147,\"column\":42,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":147,\"endColumn\":43},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":147,\"column\":55,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":147,\"endColumn\":56}],\"suppressedMessages\":[],\"errorCount\":3,\"fatalErrorCount\":0,\"warningCount\":7,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Web Speech API Backend with Web Audio API Integration\\n * Comprehensive implementation with real-time audio processing\\n */\\n\\nimport {\\n  createSpeechEvent,\\n  createSpeechRecognitionResult,\\n  createSpeechWord\\n} from '../../../core/configuration/types.ts';\\n\\nexport const createWebSpeechAPIBackend = () => {\\n  // Audio processing state\\n  let audioContext = null;\\n  let analyser = null;\\n  let microphone = null;\\n  let processor = null;\\n  let audioStream = null;\\n\\n  const checkAvailability = async (state) => {\\n    console.log('🔍 Checking Web Speech API availability...');\\n    console.log('Runtime check:', state.runtime);\\n    \\n    if (!state.runtime.isBrowser) {\\n      console.log('⚠️ Not in browser environment');\\n      return false;\\n    }\\n\\n    // Check for Web Speech API support\\n    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\\n    if (!SpeechRecognition) {\\n      console.log('⚠️ Web Speech API not supported in this browser');\\n      return false;\\n    }\\n\\n    // Check for HTTPS (required for Web Speech API)\\n    if (location.protocol !== 'https:' && location.hostname !== 'localhost') {\\n      console.log('⚠️ Web Speech API requires HTTPS');\\n      return false;\\n    }\\n\\n    console.log('✅ Web Speech API is available');\\n    return true;\\n  };\\n\\n  const initialize = async (state) => {\\n    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\\n    state.recognition = new SpeechRecognition();\\n\\n    // Configure recognition\\n    state.recognition.continuous = state.continuous;\\n    state.recognition.interimResults = state.interimResults;\\n    state.recognition.lang = state.language;\\n    state.recognition.maxAlternatives = state.maxAlternatives;\\n\\n    // Setup comprehensive event handlers\\n    setupEventHandlers(state);\\n\\n    console.log('✅ Web Speech API configured');\\n  };\\n\\n  const setupEventHandlers = (state) => {\\n    state.recognition.onstart = () => {\\n      console.log('🎤 Web Speech API started listening');\\n    };\\n\\n    state.recognition.onend = () => {\\n      console.log('🔇 Web Speech API stopped listening');\\n    };\\n\\n    state.recognition.onspeechstart = () => {\\n      notifyCallbacks(state.callbacks.onSpeechStart, createSpeechEvent({\\n        type: 'speech_start',\\n        data: {}\\n      }));\\n    };\\n\\n    state.recognition.onspeechend = () => {\\n      notifyCallbacks(state.callbacks.onSpeechEnd, createSpeechEvent({\\n        type: 'speech_end',\\n        data: {}\\n      }));\\n    };\\n\\n    state.recognition.onresult = (event) => {\\n      handleRecognitionResult(event, state);\\n    };\\n\\n    state.recognition.onerror = (event) => {\\n      handleRecognitionError(event, state);\\n    };\\n\\n    // Additional event handlers for comprehensive coverage\\n    state.recognition.onaudiostart = () => {\\n      console.log('🎧 Audio capture started');\\n    };\\n\\n    state.recognition.onaudioend = () => {\\n      console.log('🎧 Audio capture ended');\\n    };\\n\\n    state.recognition.onsoundstart = () => {\\n      console.log('🔊 Sound detected');\\n    };\\n\\n    state.recognition.onsoundend = () => {\\n      console.log('🔇 Sound ended');\\n    };\\n\\n    state.recognition.onnomatch = () => {\\n      console.log('❌ No speech match found');\\n    };\\n  };\\n\\n  const handleRecognitionResult = (event, state) => {\\n    let interimTranscript = '';\\n    let finalTranscript = '';\\n\\n    for (let i = event.resultIndex; i < event.results.length; i++) {\\n      const result = event.results[i];\\n      const {transcript} = result[0];\\n      const {confidence} = result[0];\\n\\n      if (result.isFinal) {\\n        finalTranscript += transcript;\\n        \\n        // Create final result with comprehensive word analysis\\n        const words = transcript.trim().split(' ').map((word, index) => \\n          createSpeechWord({\\n            word: word.trim(),\\n            confidence,\\n            startTime: 0, // Web Speech API doesn't provide word timing\\n            endTime: 0\\n          })\\n        ).filter(word => word.word.length > 0);\\n\\n        state.finalTranscript += finalTranscript;\\n        state.metrics.totalWords += words.length;\\n        \\n        // Update average confidence with proper weighting\\n        if (confidence > 0) {\\n          const currentWords = state.metrics.totalWords;\\n          const previousWords = currentWords - words.length;\\n          const previousAvg = state.metrics.averageConfidence;\\n          \\n          state.metrics.averageConfidence = \\n            (previousAvg * previousWords + confidence * words.length) / currentWords;\\n        }\\n\\n        const speechResult = createSpeechRecognitionResult({\\n          transcript: finalTranscript.trim(),\\n          confidence,\\n          isFinal: true,\\n          isInterim: false,\\n          words,\\n          language: state.language,\\n          processingTime: 0,\\n          alternatives: extractAlternatives(result)\\n        });\\n\\n        // Notify final result callbacks\\n        notifyCallbacks(state.callbacks.onResult, speechResult);\\n\\n      } else {\\n        interimTranscript += transcript;\\n      }\\n    }\\n\\n    if (interimTranscript) {\\n      state.currentTranscript = interimTranscript;\\n      \\n      const interimResult = createSpeechRecognitionResult({\\n        transcript: interimTranscript.trim(),\\n        confidence: 0.5, // Lower confidence for interim results\\n        isFinal: false,\\n        isInterim: true,\\n        words: [],\\n        language: state.language,\\n        processingTime: 0\\n      });\\n\\n      // Notify interim result callbacks\\n      notifyCallbacks(state.callbacks.onInterimResult, interimResult);\\n    }\\n  };\\n\\n  const handleRecognitionError = (event, state) => {\\n    console.error('Speech recognition error:', event.error);\\n    state.metrics.errors++;\\n    \\n    const errorEvent = createSpeechEvent({\\n      type: 'speech_recognition_error',\\n      data: { \\n        error: event.error, \\n        message: event.message || 'Speech recognition error',\\n        details: getErrorDetails(event.error)\\n      },\\n      severity: 'error'\\n    });\\n\\n    notifyCallbacks(state.callbacks.onError, errorEvent);\\n  };\\n\\n  const extractAlternatives = (result) => {\\n    const alternatives = [];\\n    for (let j = 0; j < Math.min(result.length, 3); j++) {\\n      alternatives.push({\\n        transcript: result[j].transcript,\\n        confidence: result[j].confidence || 0\\n      });\\n    }\\n    return alternatives;\\n  };\\n\\n  const getErrorDetails = (error) => {\\n    const errorMap = {\\n      'no-speech': 'No speech detected within timeout period',\\n      'aborted': 'Speech recognition was aborted',\\n      'audio-capture': 'Audio capture failed - check microphone permissions',\\n      'network': 'Network error occurred during recognition',\\n      'not-allowed': 'Microphone access denied by user',\\n      'service-not-allowed': 'Speech recognition service not allowed',\\n      'bad-grammar': 'Grammar compilation failed',\\n      'language-not-supported': 'Language not supported by recognition service'\\n    };\\n    return errorMap[error] || `Unknown error: ${error}`;\\n  };\\n\\n  const start = async (state) => {\\n    if (!state.recognition) {\\n      throw new Error('Web Speech API not initialized');\\n    }\\n    \\n    // Initialize Web Audio API when starting (requires user gesture)\\n    if (!audioStream) {\\n      await initializeWebAudioAPI(state);\\n    }\\n    \\n    state.recognition.start();\\n  };\\n\\n  const stop = async (state) => {\\n    if (state.recognition) {\\n      state.recognition.stop();\\n    }\\n  };\\n\\n  const abort = async (state) => {\\n    if (state.recognition) {\\n      state.recognition.abort();\\n    }\\n  };\\n\\n  // Initialize Web Audio API for real-time audio processing\\n  const initializeWebAudioAPI = async (state) => {\\n    try {\\n      console.log('🎧 Initializing Web Audio API integration...');\\n      \\n      // Request microphone access with comprehensive audio constraints\\n      audioStream = await navigator.mediaDevices.getUserMedia({\\n        audio: {\\n          echoCancellation: true,\\n          noiseSuppression: true,\\n          autoGainControl: true,\\n          sampleRate: 44100,\\n          channelCount: 1,\\n          latency: 0.01,\\n          volume: 1.0\\n        }\\n      });\\n\\n      // Create audio context with optimal settings\\n      audioContext = new (window.AudioContext || window.webkitAudioContext)({\\n        sampleRate: 44100,\\n        latencyHint: 'interactive'\\n      });\\n\\n      // Create analyser for comprehensive real-time audio analysis\\n      analyser = audioContext.createAnalyser();\\n      analyser.fftSize = 2048;\\n      analyser.smoothingTimeConstant = 0.8;\\n      analyser.minDecibels = -90;\\n      analyser.maxDecibels = -10;\\n\\n      // Connect microphone to analyser\\n      microphone = audioContext.createMediaStreamSource(audioStream);\\n      microphone.connect(analyser);\\n\\n      // Create script processor for real-time analysis\\n      processor = audioContext.createScriptProcessor(4096, 1, 1);\\n      processor.onaudioprocess = (event) => {\\n        processAudioFrame(event, state);\\n      };\\n\\n      analyser.connect(processor);\\n      processor.connect(audioContext.destination);\\n\\n      console.log('✅ Web Audio API integration initialized');\\n      \\n    } catch (error) {\\n      console.warn('⚠️ Web Audio API initialization failed:', error);\\n      // Continue without Web Audio API enhancement\\n    }\\n  };\\n\\n  const processAudioFrame = (event, state) => {\\n    // Get comprehensive frequency and time domain data\\n    const frequencyData = new Uint8Array(analyser.frequencyBinCount);\\n    const timeData = new Uint8Array(analyser.frequencyBinCount);\\n    analyser.getByteFrequencyData(frequencyData);\\n    analyser.getByteTimeDomainData(timeData);\\n\\n    // Calculate comprehensive real-time audio metrics\\n    const audioMetrics = calculateComprehensiveAudioMetrics(frequencyData, timeData);\\n    \\n    // Notify audio processing callbacks if available\\n    if (state.callbacks.onAudioProcessing) {\\n      notifyCallbacks(state.callbacks.onAudioProcessing, {\\n        type: 'audio_processing',\\n        data: audioMetrics,\\n        timestamp: Date.now()\\n      });\\n    }\\n  };\\n\\n  // Calculate comprehensive real-time audio metrics\\n  const calculateComprehensiveAudioMetrics = (frequencyData, timeData) => {\\n    // Volume level (RMS)\\n    let sum = 0;\\n    for (let i = 0; i < timeData.length; i++) {\\n      const normalized = (timeData[i] - 128) / 128;\\n      sum += normalized * normalized;\\n    }\\n    const volumeLevel = Math.sqrt(sum / timeData.length);\\n\\n    // Comprehensive frequency analysis\\n    const signalLevel = frequencyData.reduce((sum, value) => sum + value, 0) / frequencyData.length;\\n    \\n    // Background noise estimation (low frequencies)\\n    const lowFreqBins = frequencyData.slice(0, Math.floor(frequencyData.length * 0.3));\\n    const backgroundNoise = lowFreqBins.reduce((sum, value) => sum + value, 0) / lowFreqBins.length;\\n    \\n    // Mid-range frequencies (speech content)\\n    const midFreqStart = Math.floor(frequencyData.length * 0.3);\\n    const midFreqEnd = Math.floor(frequencyData.length * 0.6);\\n    const midFreqBins = frequencyData.slice(midFreqStart, midFreqEnd);\\n    const speechContent = midFreqBins.reduce((sum, value) => sum + value, 0) / midFreqBins.length;\\n    \\n    // High frequency content (clarity indicator)\\n    const highFreqStart = Math.floor(frequencyData.length * 0.6);\\n    const highFreqBins = frequencyData.slice(highFreqStart);\\n    const clarity = highFreqBins.reduce((sum, value) => sum + value, 0) / highFreqBins.length;\\n\\n    // Peak frequency detection\\n    const peakIndex = frequencyData.indexOf(Math.max(...frequencyData));\\n    const peakFrequency = (peakIndex * audioContext.sampleRate) / (2 * frequencyData.length);\\n\\n    // Zero crossing rate for voice activity detection\\n    let zeroCrossings = 0;\\n    for (let i = 1; i < timeData.length; i++) {\\n      if ((timeData[i] - 128) * (timeData[i - 1] - 128) < 0) {\\n        zeroCrossings++;\\n      }\\n    }\\n    const zeroCrossingRate = zeroCrossings / timeData.length;\\n\\n    // Signal-to-noise ratio estimation\\n    const signalPower = speechContent;\\n    const noisePower = Math.max(backgroundNoise, 1); // Avoid division by zero\\n    const snrEstimate = 20 * Math.log10(signalPower / noisePower);\\n\\n    return {\\n      volumeLevel: Math.round(volumeLevel * 100) / 100,\\n      signalLevel: Math.round(signalLevel),\\n      backgroundNoise: Math.round(backgroundNoise),\\n      speechContent: Math.round(speechContent),\\n      clarity: Math.round(clarity),\\n      peakFrequency: Math.round(peakFrequency),\\n      zeroCrossingRate: Math.round(zeroCrossingRate * 1000) / 1000,\\n      snrEstimate: Math.round(snrEstimate * 10) / 10,\\n      timestamp: Date.now(),\\n      audioContextState: audioContext ? audioContext.state : 'unavailable'\\n    };\\n  };\\n\\n  const cleanup = async (state) => {\\n    // Cleanup Web Audio API resources\\n    if (processor) {\\n      processor.disconnect();\\n      processor.onaudioprocess = null;\\n      processor = null;\\n    }\\n    \\n    if (microphone) {\\n      microphone.disconnect();\\n      microphone = null;\\n    }\\n    \\n    if (analyser) {\\n      analyser.disconnect();\\n      analyser = null;\\n    }\\n    \\n    if (audioContext && audioContext.state !== 'closed') {\\n      try {\\n        await audioContext.close();\\n      } catch (error) {\\n        console.warn('Error closing audio context:', error);\\n      }\\n      audioContext = null;\\n    }\\n    \\n    if (audioStream) {\\n      audioStream.getTracks().forEach(track => {\\n        track.stop();\\n        console.log(`Stopped audio track: ${track.kind}, ${track.label}`);\\n      });\\n      audioStream = null;\\n    }\\n\\n    // Cleanup speech recognition with comprehensive event handler cleanup\\n    if (state.recognition) {\\n      state.recognition.onstart = null;\\n      state.recognition.onend = null;\\n      state.recognition.onresult = null;\\n      state.recognition.onerror = null;\\n      state.recognition.onspeechstart = null;\\n      state.recognition.onspeechend = null;\\n      state.recognition.onaudiostart = null;\\n      state.recognition.onaudioend = null;\\n      state.recognition.onsoundstart = null;\\n      state.recognition.onsoundend = null;\\n      state.recognition.onnomatch = null;\\n      state.recognition = null;\\n    }\\n\\n    console.log('🧹 Web Speech API + Web Audio API cleaned up');\\n  };\\n\\n  // Utility function to notify callbacks safely\\n  const notifyCallbacks = (callbacks, data) => {\\n    if (callbacks && Array.isArray(callbacks)) {\\n      callbacks.forEach(callback => {\\n        try {\\n          callback(data);\\n        } catch (error) {\\n          console.warn('Callback error:', error);\\n        }\\n      });\\n    }\\n  };\\n\\n  return {\\n    checkAvailability,\\n    initialize,\\n    start,\\n    stop,\\n    abort,\\n    cleanup\\n  };\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/features/speech-analysis/speech-recognition.js\",\"messages\":[{\"ruleId\":\"max-lines-per-function\",\"severity\":1,\"message\":\"Arrow function has too many lines (246). Maximum allowed is 150.\",\"line\":34,\"column\":40,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"exceed\",\"endLine\":377,\"endColumn\":2},{\"ruleId\":\"no-undef\",\"severity\":2,\"message\":\"'createFallbackBackend' is not defined.\",\"line\":64,\"column\":34,\"nodeType\":\"Identifier\",\"messageId\":\"undef\",\"endLine\":64,\"endColumn\":55},{\"ruleId\":\"consistent-return\",\"severity\":1,\"message\":\"Expected to return a value at the end of async arrow function.\",\"line\":75,\"column\":31,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"missingReturn\",\"endLine\":75,\"endColumn\":33},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'errorEvent' is assigned a value but never used. Allowed unused vars must match /^_/u.\",\"line\":85,\"column\":13,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":85,\"endColumn\":23,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"errorEvent\"},\"fix\":{\"range\":[2950,3093],\"text\":\"\"},\"desc\":\"Remove unused variable 'errorEvent'.\"}]}],\"suppressedMessages\":[],\"errorCount\":2,\"fatalErrorCount\":0,\"warningCount\":2,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Speech Recognition with Hybrid Fallbacks\\n * Provides unified speech recognition interface across environments\\n * Following functional programming patterns with factory functions\\n * \\n * Refactored into modular components for maintainability:\\n * - Backend Manager: Handles backend selection and lifecycle\\n * - Event Manager: Manages callbacks and event processing\\n * - Metrics Calculator: Tracks and analyzes speech recognition metrics\\n * - Individual Backends: Web Speech API and Fallback implementations\\n */\\n\\nimport { checkFeatures } from '../../shared/utils/runtime-detector.js';\\nimport { createSpeechEvent } from '../../core/configuration/types.ts';\\n\\n// Import modular components\\nimport { createBackendManager } from './recognition/backend-manager.js';\\nimport { createEventManager } from './recognition/event-manager.js';\\nimport { createMetricsCalculator } from './recognition/metrics-calculator.js';\\nimport { createWebSpeechAPIBackend } from './recognition/web-speech-backend.js';\\n// Fallback backend removed - Web Speech API only\\n\\n// Speech recognition backends configuration\\nconst SPEECH_BACKENDS = {\\n  web_speech_api: {\\n    name: 'Web Speech API',\\n    description: 'Browser native speech recognition with Web Audio API integration',\\n    requirements: ['browser', 'https'],\\n    availability: 'chrome_edge'\\n  },\\n};\\n\\n// Create speech recognition factory\\nexport const createSpeechRecognition = (config = {}) => {\\n  // Initialize comprehensive state\\n  const state = {\\n    runtime: checkFeatures(),\\n    features: checkFeatures(),\\n    activeBackend: null,\\n    isListening: false,\\n    isInitialized: false,\\n    language: config.language || 'en-US',\\n    continuous: config.continuous !== false,\\n    interimResults: config.interimResults !== false,\\n    maxAlternatives: config.maxAlternatives || 3,\\n    \\n    // Recognition state\\n    recognition: null,\\n    currentTranscript: '',\\n    finalTranscript: '',\\n    \\n    // Metrics and callbacks will be initialized by respective managers\\n    metrics: null,\\n    callbacks: null\\n  };\\n\\n  // Initialize modular components\\n  const eventManager = createEventManager();\\n  const metricsCalculator = createMetricsCalculator();\\n  \\n  // Initialize backends\\n  const backends = {\\n    web_speech_api: createWebSpeechAPIBackend(),\\n    speech_recognition_fallback: createFallbackBackend()\\n  };\\n  \\n  // Initialize backend manager with backends\\n  const backendManager = createBackendManager(backends, SPEECH_BACKENDS);\\n  \\n  // Initialize event callbacks and metrics\\n  eventManager.initializeCallbacks(state);\\n  metricsCalculator.initializeMetrics(state);\\n\\n  // Initialize the best available speech recognition backend\\n  const initialize = async () => {\\n    try {\\n      const success = await backendManager.initializeBestBackend(state);\\n      \\n      if (success) {\\n        console.log(`✅ Speech recognition initialized with backend: ${state.activeBackend}`);\\n        return true;\\n      }\\n      \\n    } catch (error) {\\n      const errorEvent = eventManager.handleError(state, error, {\\n        context: 'initialization',\\n        attempted: 'backend_selection'\\n      });\\n      throw error;\\n    }\\n  };\\n\\n  // Start listening for speech\\n  const startListening = async () => {\\n    try {\\n      const backendName = await backendManager.startBackend(state);\\n      \\n      // Start metrics session\\n      metricsCalculator.startSession(state, backendName, state.language);\\n      \\n      // Clear transcripts\\n      state.currentTranscript = '';\\n      state.finalTranscript = '';\\n      \\n      // Notify start callbacks\\n      const startEvent = createSpeechEvent({\\n        type: 'speech_recognition_start',\\n        data: { \\n          backend: backendName,\\n          language: state.language,\\n          continuous: state.continuous,\\n          interimResults: state.interimResults\\n        }\\n      });\\n      \\n      eventManager.notifyCallbacks(state.callbacks.onStart, startEvent, 'onStart');\\n      \\n      console.log(`🎤 Speech recognition started with ${backendName}`);\\n      \\n    } catch (error) {\\n      eventManager.handleError(state, error, {\\n        context: 'start_listening',\\n        backend: state.activeBackend\\n      });\\n      throw error;\\n    }\\n  };\\n\\n  // Stop listening\\n  const stopListening = async () => {\\n    try {\\n      const backendName = await backendManager.stopBackend(state);\\n      \\n      if (backendName) {\\n        // End metrics session and get summary\\n        const sessionSummary = metricsCalculator.endSession(state);\\n        \\n        // Notify end callbacks with session summary\\n        const endEvent = createSpeechEvent({\\n          type: 'speech_recognition_end',\\n          data: { \\n            backend: backendName,\\n            session: sessionSummary,\\n            totalTranscript: state.finalTranscript\\n          }\\n        });\\n        \\n        eventManager.notifyCallbacks(state.callbacks.onEnd, endEvent, 'onEnd');\\n        \\n        console.log(`🔇 Speech recognition stopped. Session summary:`, sessionSummary);\\n      }\\n      \\n    } catch (error) {\\n      eventManager.handleError(state, error, {\\n        context: 'stop_listening',\\n        backend: state.activeBackend\\n      });\\n    }\\n  };\\n\\n  // Abort listening immediately\\n  const abortListening = async () => {\\n    try {\\n      const backendName = await backendManager.abortBackend(state);\\n      \\n      if (backendName) {\\n        // End metrics session for aborted session\\n        const sessionSummary = metricsCalculator.endSession(state);\\n        \\n        console.log(`🛑 Speech recognition aborted. Backend: ${backendName}`);\\n        \\n        // Optionally notify abort event\\n        const abortEvent = createSpeechEvent({\\n          type: 'speech_recognition_abort',\\n          data: { \\n            backend: backendName,\\n            reason: 'user_abort',\\n            session: sessionSummary\\n          }\\n        });\\n        \\n        eventManager.notifyCallbacks(state.callbacks.onEnd, abortEvent, 'onEnd');\\n      }\\n      \\n    } catch (error) {\\n      eventManager.handleError(state, error, {\\n        context: 'abort_listening',\\n        backend: state.activeBackend\\n      });\\n    }\\n  };\\n\\n  // Get comprehensive current status\\n  const getStatus = () => ({\\n    isInitialized: state.isInitialized,\\n    isListening: state.isListening,\\n    activeBackend: state.activeBackend,\\n    backendInfo: state.activeBackend ? SPEECH_BACKENDS[state.activeBackend] : null,\\n    language: state.language,\\n    continuous: state.continuous,\\n    interimResults: state.interimResults,\\n    maxAlternatives: state.maxAlternatives,\\n    \\n    // Enhanced metrics through metrics calculator\\n    metrics: metricsCalculator.generateMetricsReport(state, 'summary'),\\n    detailedMetrics: metricsCalculator.generateMetricsReport(state, 'detailed'),\\n    \\n    // Current transcripts\\n    currentTranscript: state.currentTranscript,\\n    finalTranscript: state.finalTranscript,\\n    \\n    // Event system status\\n    eventStats: eventManager.getEventStatistics(),\\n    \\n    // Runtime info\\n    runtime: state.runtime,\\n    features: state.features\\n  });\\n\\n  // Comprehensive cleanup of all resources\\n  const cleanup = async () => {\\n    try {\\n      // Stop listening if active\\n      if (state.isListening) {\\n        await stopListening();\\n      }\\n\\n      // Cleanup backend resources\\n      await backendManager.cleanupBackend(state);\\n      \\n      // Clear event queue and callbacks\\n      eventManager.clearEventQueue();\\n      eventManager.clearCallbacks(state);\\n      \\n      // Reset metrics but preserve history\\n      metricsCalculator.resetMetrics(state, true);\\n      \\n      // Clear any remaining event listeners\\n      if (state.cleanupEventListeners) {\\n        state.cleanupEventListeners();\\n      }\\n      \\n      console.log('🧹 Speech recognition fully cleaned up');\\n      \\n    } catch (error) {\\n      console.error('❌ Error during cleanup:', error);\\n      // Force cleanup even if errors occur\\n      state.recognition = null;\\n      state.isInitialized = false;\\n      state.activeBackend = null;\\n    }\\n  };\\n\\n  // Enhanced event subscription methods with validation\\n  const onStart = (callback) => {\\n    eventManager.validateCallbackRegistration('onStart', callback);\\n    eventManager.addCallback(state, 'onStart', callback);\\n    return () => eventManager.removeCallback(state, 'onStart', callback);\\n  };\\n  \\n  const onEnd = (callback) => {\\n    eventManager.validateCallbackRegistration('onEnd', callback);\\n    eventManager.addCallback(state, 'onEnd', callback);\\n    return () => eventManager.removeCallback(state, 'onEnd', callback);\\n  };\\n  \\n  const onResult = (callback) => {\\n    eventManager.validateCallbackRegistration('onResult', callback);\\n    eventManager.addCallback(state, 'onResult', callback);\\n    return () => eventManager.removeCallback(state, 'onResult', callback);\\n  };\\n  \\n  const onInterimResult = (callback) => {\\n    eventManager.validateCallbackRegistration('onInterimResult', callback);\\n    eventManager.addCallback(state, 'onInterimResult', callback);\\n    return () => eventManager.removeCallback(state, 'onInterimResult', callback);\\n  };\\n  \\n  const onError = (callback) => {\\n    eventManager.validateCallbackRegistration('onError', callback);\\n    eventManager.addCallback(state, 'onError', callback);\\n    return () => eventManager.removeCallback(state, 'onError', callback);\\n  };\\n  \\n  const onSpeechStart = (callback) => {\\n    eventManager.validateCallbackRegistration('onSpeechStart', callback);\\n    eventManager.addCallback(state, 'onSpeechStart', callback);\\n    return () => eventManager.removeCallback(state, 'onSpeechStart', callback);\\n  };\\n  \\n  const onSpeechEnd = (callback) => {\\n    eventManager.validateCallbackRegistration('onSpeechEnd', callback);\\n    eventManager.addCallback(state, 'onSpeechEnd', callback);\\n    return () => eventManager.removeCallback(state, 'onSpeechEnd', callback);\\n  };\\n  \\n  const onAudioProcessing = (callback) => {\\n    eventManager.validateCallbackRegistration('onAudioProcessing', callback);\\n    eventManager.addCallback(state, 'onAudioProcessing', callback);\\n    return () => eventManager.removeCallback(state, 'onAudioProcessing', callback);\\n  };\\n  \\n  // New event subscription for state changes\\n  const onStateChange = (callback) => {\\n    eventManager.validateCallbackRegistration('onStateChange', callback);\\n    eventManager.addCallback(state, 'onStateChange', callback);\\n    return () => eventManager.removeCallback(state, 'onStateChange', callback);\\n  };\\n\\n\\n  return {\\n    // Core functionality\\n    initialize,\\n    startListening,\\n    stopListening,\\n    abortListening,\\n    cleanup,\\n\\n    // Status and information\\n    getStatus,\\n    isListening: () => state.isListening,\\n    isInitialized: () => state.isInitialized,\\n    getActiveBackend: () => state.activeBackend,\\n    getCurrentTranscript: () => state.currentTranscript,\\n    getFinalTranscript: () => state.finalTranscript,\\n\\n    // Enhanced event handlers\\n    onStart,\\n    onEnd,\\n    onResult,\\n    onInterimResult,\\n    onError,\\n    onSpeechStart,\\n    onSpeechEnd,\\n    onAudioProcessing,\\n    onStateChange,\\n\\n    // Configuration with state change tracking\\n    setLanguage: (language) => {\\n      const previous = state.language;\\n      state.language = language;\\n      eventManager.notifyStateChange(state, { language: previous }, ['language']);\\n    },\\n    setContinuous: (continuous) => {\\n      const previous = state.continuous;\\n      state.continuous = continuous;\\n      eventManager.notifyStateChange(state, { continuous: previous }, ['continuous']);\\n    },\\n    setInterimResults: (interimResults) => {\\n      const previous = state.interimResults;\\n      state.interimResults = interimResults;\\n      eventManager.notifyStateChange(state, { interimResults: previous }, ['interimResults']);\\n    },\\n    setMaxAlternatives: (maxAlternatives) => {\\n      state.maxAlternatives = maxAlternatives;\\n    },\\n\\n    // Backend information\\n    getSupportedBackends: () => backendManager.getSupportedBackends(),\\n    getBackendInfo: (backendName) => backendManager.getBackendInfo(backendName),\\n    checkBackendAvailability: (backendName) => backendManager.checkBackendAvailability(backendName, state),\\n\\n    // Enhanced metrics\\n    getMetrics: (format = 'summary') => metricsCalculator.generateMetricsReport(state, format),\\n    resetMetrics: (preserveHistory = false) => metricsCalculator.resetMetrics(state, preserveHistory),\\n    exportMetrics: (format = 'json') => metricsCalculator.exportMetrics(state, format),\\n\\n    // Event management\\n    clearCallbacks: (eventType = null) => eventManager.clearCallbacks(state, eventType),\\n    getEventStatistics: () => eventManager.getEventStatistics(),\\n\\n    // Advanced features\\n    getRuntimeInfo: () => state.runtime,\\n    getFeatureInfo: () => state.features,\\n    getState: () => ({ ...state }) // For debugging purposes\\n  };\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/features/speech-analysis/streaming.js\",\"messages\":[{\"ruleId\":null,\"nodeType\":null,\"fatal\":true,\"severity\":2,\"message\":\"Parsing error: Unexpected token ,\",\"line\":361,\"column\":45}],\"suppressedMessages\":[],\"errorCount\":1,\"fatalErrorCount\":1,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Real-time Speech Analysis Streaming\\n * Integrates speech analysis with existing multimodal synchronization\\n * Following functional programming patterns with factory functions\\n */\\n\\nimport { createDataStream } from '../../core/state/streams.js';\\nimport { createSynchronizationEngine } from '../../core/orchestration/synchronization.js';\\nimport { createSpeechRecognition } from './speech-recognition.js';\\nimport { createAnalysisEngine } from './analysis-engine.js';\\nimport { createContextManager } from './context-manager.js';\\nimport {\\n  createSpeechAnalysisResult,\\n  createSpeechEvent,\\n  createSpeechPipelineStatus\\n} from '../../core/configuration/types.ts';\\n\\n// Streaming configuration defaults\\nconst DEFAULT_STREAM_CONFIG = {\\n  sampleRate: 30, // Hz\\n  bufferSize: 1000,\\n  syncTolerance: 50, // ms\\n  enableQualityMonitoring: true,\\n  autoStart: false,\\n  autoAnalyze: true,\\n  enableSynchronization: true\\n};\\n\\n// Create speech streaming system factory\\nexport const createSpeechStreaming = (config = {}) => {\\n  const streamConfig = { ...DEFAULT_STREAM_CONFIG, ...config };\\n  \\n  const state = {\\n    // Core components\\n    speechRecognition: null,\\n    analysisEngine: null,\\n    contextManager: null,\\n    synchronization: null,\\n    \\n    // Streaming state\\n    isInitialized: false,\\n    isActive: false,\\n    isListening: false,\\n    isAnalyzing: false,\\n    \\n    // Stream management\\n    streams: new Map(),\\n    activeSession: null,\\n    \\n    // Configuration\\n    config: streamConfig,\\n    \\n    // Performance metrics\\n    metrics: {\\n      sessionsStarted: 0,\\n      totalTranscriptions: 0,\\n      totalAnalyses: 0,\\n      averageLatency: 0,\\n      uptime: 0,\\n      lastActivity: null,\\n      errorCount: 0\\n    },\\n    \\n    startTime: null,\\n\\n    // Event callbacks\\n    callbacks: {\\n      onSystemReady: [],\\n      onStreamStart: [],\\n      onStreamEnd: [],\\n      onTranscription: [],\\n      onAnalysis: [],\\n      onError: [],\\n      onStatusChange: []\\n    }\\n  };\\n\\n  // Initialize the streaming system\\n  const initialize = async (options = {}) => {\\n    if (state.isInitialized) {\\n      console.warn('Speech streaming system already initialized');\\n      return true;\\n    }\\n\\n    console.log('🔄 Initializing speech streaming system...');\\n\\n    try {\\n      // Initialize core components\\n      console.log('🎤 Initializing speech recognition...');\\n      state.speechRecognition = createSpeechRecognition({\\n        continuous: true,\\n        interimResults: true,\\n        language: options.language || 'en-US'\\n      });\\n      await state.speechRecognition.initialize();\\n\\n      console.log('🤖 Initializing analysis engine...');\\n      state.analysisEngine = createAnalysisEngine({\\n        prompts: options.prompts,\\n        systemPrompt: options.systemPrompt,\\n        maxConcurrency: 2\\n      });\\n      await state.analysisEngine.initialize(options.llmConfig);\\n\\n      console.log('📝 Initializing context manager...');\\n      state.contextManager = createContextManager({\\n        strategy: options.contextStrategy || 'hybrid',\\n        maxChunks: options.maxChunks || 10,\\n        summaryThreshold: options.summaryThreshold || 20\\n      });\\n      await state.contextManager.initialize(options.llmConfig);\\n\\n      // Initialize synchronization if enabled\\n      if (state.config.enableSynchronization && options.enableSync !== false) {\\n        console.log('🔄 Initializing synchronization engine...');\\n        state.synchronization = createSynchronizationEngine({\\n          tolerance: state.config.syncTolerance,\\n          strategy: 'software_timestamp',\\n          bufferSize: 100\\n        });\\n        setupSynchronizationHandlers();\\n      }\\n\\n      // Setup event handlers\\n      setupEventHandlers();\\n\\n      // Create default session\\n      state.activeSession = await createSession('default');\\n\\n      state.isInitialized = true;\\n      state.startTime = Date.now();\\n\\n      console.log('✅ Speech streaming system initialized successfully');\\n\\n      // Notify system ready\\n      notifyCallbacks('onSystemReady', createSpeechEvent({\\n        type: 'system_ready',\\n        data: { \\n          components: ['speech_recognition', 'analysis_engine', 'context_manager'],\\n          sessionId: state.activeSession\\n        }\\n      }));\\n\\n      return true;\\n\\n    } catch (error) {\\n      console.error('Speech streaming system initialization failed:', error);\\n      throw new Error(`Speech streaming initialization failed: ${error.message}`);\\n    }\\n  };\\n\\n  // Start streaming session\\n  const startStreaming = async (sessionId = null) => {\\n    if (!state.isInitialized) {\\n      throw new Error('System not initialized');\\n    }\\n\\n    if (state.isActive) {\\n      console.warn('Streaming already active');\\n      return;\\n    }\\n\\n    const targetSession = sessionId || state.activeSession;\\n    console.log(`🎤 Starting speech streaming session: ${targetSession}`);\\n\\n    try {\\n      // Start speech recognition\\n      await state.speechRecognition.startListening();\\n      \\n      state.isActive = true;\\n      state.isListening = true;\\n      state.metrics.sessionsStarted++;\\n      state.metrics.lastActivity = Date.now();\\n\\n      // Start synchronization if available\\n      if (state.synchronization) {\\n        // Register speech analysis stream\\n        const speechStream = createDataStream({\\n          id: 'speech_analysis',\\n          type: 'speech',\\n          sampleRate: state.config.sampleRate\\n        });\\n        state.synchronization.addStream('speech_analysis', speechStream);\\n      }\\n\\n      console.log('✅ Speech streaming started');\\n\\n      // Notify stream start\\n      notifyCallbacks('onStreamStart', createSpeechEvent({\\n        type: 'stream_start',\\n        data: { sessionId: targetSession }\\n      }));\\n\\n      // Notify status change\\n      notifyStatusChange();\\n\\n    } catch (error) {\\n      state.isActive = false;\\n      state.isListening = false;\\n      console.error('Failed to start streaming:', error);\\n      \\n      notifyError(new Error(`Failed to start streaming: ${error.message}`));\\n      throw error;\\n    }\\n  };\\n\\n  // Stop streaming session\\n  const stopStreaming = async () => {\\n    if (!state.isActive) {\\n      console.warn('Streaming not active');\\n      return;\\n    }\\n\\n    console.log('🔇 Stopping speech streaming...');\\n\\n    try {\\n      // Stop speech recognition\\n      if (state.isListening) {\\n        await state.speechRecognition.stopListening();\\n        state.isListening = false;\\n      }\\n\\n      // Stop synchronization\\n      if (state.synchronization) {\\n        state.synchronization.removeStream('speech_analysis');\\n      }\\n\\n      state.isActive = false;\\n      console.log('✅ Speech streaming stopped');\\n\\n      // Notify stream end\\n      notifyCallbacks('onStreamEnd', createSpeechEvent({\\n        type: 'stream_end',\\n        data: { sessionId: state.activeSession }\\n      }));\\n\\n      // Notify status change\\n      notifyStatusChange();\\n\\n    } catch (error) {\\n      console.error('Error stopping streaming:', error);\\n      notifyError(new Error(`Error stopping streaming: ${error.message}`));\\n    }\\n  };\\n\\n  // Create new session\\n  const createSession = async (sessionId) => {\\n    if (!sessionId) {\\n      sessionId = `session_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;\\n    }\\n\\n    // Create context for this session\\n    const contextId = await state.contextManager.createContext(sessionId);\\n    \\n    console.log(`📋 Created streaming session: ${sessionId}`);\\n    return sessionId;\\n  };\\n\\n  // Switch to different session\\n  const switchSession = async (sessionId) => {\\n    const wasActive = state.isActive;\\n    \\n    if (wasActive) {\\n      await stopStreaming();\\n    }\\n\\n    state.activeSession = sessionId;\\n    await state.contextManager.switchContext(sessionId);\\n\\n    if (wasActive) {\\n      await startStreaming(sessionId);\\n    }\\n\\n    console.log(`🔄 Switched to session: ${sessionId}`);\\n    return true;\\n  };\\n\\n  // Get system status\\n  const getStatus = () => {\\n    const uptime = state.startTime ? Date.now() - state.startTime : 0;\\n    \\n    return createSpeechPipelineStatus({\\n      isInitialized: state.isInitialized,\\n      isListening: state.isListening,\\n      isProcessing: state.isAnalyzing,\\n      \\n      speechRecognition: {\\n        available: !!state.speechRecognition,\\n        isActive: state.isListening,\\n        ...(state.speechRecognition ? state.speechRecognition.getStatus() : {})\\n      },\\n      \\n      llm: state.analysisEngine ? {\\n        backend: state.analysisEngine.getStatus().llmStatus?.activeBackend,\\n        modelLoaded: state.analysisEngine.getStatus().llmStatus?.isReady,\\n        isReady: state.analysisEngine.isInitialized()\\n      } : {},\\n      \\n      context: state.contextManager ? {\\n        activeSession: state.activeSession,\\n        chunkCount: state.contextManager.getContextData()?.chunks?.length || 0,\\n        lastActivity: state.metrics.lastActivity\\n      } : {},\\n      \\n      metrics: {\\n        ...state.metrics,\\n        uptime\\n      },\\n      \\n      health: {\\n        overall: calculateOverallHealth(),\\n        speechRecognition: state.speechRecognition?.isInitialized() ? 'healthy' : 'unhealthy',\\n        llmBackend: state.analysisEngine?.isInitialized() ? 'healthy' : 'unhealthy',\\n        performance: state.metrics.averageLatency < 1000 ? 'healthy' : 'degraded'\\n      }\\n    });\\n  };\\n\\n  // Cleanup resources\\n  const cleanup = async () => {\\n    console.log('🧹 Cleaning up speech streaming system...');\\n\\n    if (state.isActive) {\\n      await stopStreaming();\\n    }\\n\\n    // Cleanup components\\n    if (state.speechRecognition) {\\n      await state.speechRecognition.cleanup();\\n      state.speechRecognition = null;\\n    }\\n\\n    if (state.analysisEngine) {\\n      await state.analysisEngine.cleanup();\\n      state.analysisEngine = null;\\n    }\\n\\n    if (state.contextManager) {\\n      await state.contextManager.cleanup();\\n      state.contextManager = null;\\n    }\\n\\n    if (state.synchronization) {\\n      state.synchronization.stop();\\n      state.synchronization = null;\\n    }\\n\\n    // Clear state\\n    state.streams.clear();\\n    state.isInitialized = false;\\n    state.activeSession = null;\\n\\n    console.log('✅ Speech streaming system cleanup complete');\\n  };\\n\\n  // Private helper functions\\n  const setupEventHandlers = () => {\\n    if (!state.speechRecognition || !state.analysisEngine) return;\\n\\n    // Handle speech recognition results\\n    state.speechRecognition.onResult(async (,result) => {\\n      state.metrics.totalTranscriptions++;\\n      state.metrics.lastActivity = Date.now();\\n\\n      console.log(`🎤 Final transcription: \\\"${result.transcript}\\\"`);\\n\\n      // Notify transcription\\n      notifyCallbacks('onTranscription', createSpeechEvent({\\n        type: 'transcription',\\n        data: { result }\\n      }));\\n\\n      // Add to context and analyze if auto-analyze is enabled\\n      if (state.config.autoAnalyze && result.transcript.trim()) {\\n        await processTranscription(result.transcript, result);\\n      }\\n    });\\n\\n    state.speechRecognition.onInterimResult((,result) => {\\n      // Handle interim results - could be used for real-time feedback\\n      console.log(`🎤 Interim: \\\"${result.transcript}\\\"`);\\n    });\\n\\n    state.speechRecognition.onError((error) => {\\n      state.metrics.errorCount++;\\n      notifyError(new Error(`Speech recognition error: ${error.data?.error || error.message}`));\\n    });\\n\\n    // Handle analysis results\\n    state.analysisEngine.onAnalysisComplete((event) => {\\n      console.log(`🤖 Analysis complete: ${event.data.result.analyses.length} results`);\\n      \\n      // Notify analysis complete\\n      notifyCallbacks('onAnalysis', createSpeechEvent({\\n        type: 'analysis_complete',\\n        data: { result: event.data.result }\\n      }));\\n    });\\n\\n    state.analysisEngine.onAnalysisError((error) => {\\n      state.metrics.errorCount++;\\n      notifyError(new Error(`Analysis error: ${error.data?.error || error.message}`));\\n    });\\n  };\\n\\n  const setupSynchronizationHandlers = () => {\\n    if (!state.synchronization) return;\\n\\n    state.synchronization.onSync((syncedStreams) => {\\n      // Handle synchronized multimodal data\\n      console.log(`🔄 Synchronized data: ${syncedStreams.size} streams`);\\n    });\\n  };\\n\\n  const processTranscription = async (text, originalResult) => {\\n    try {\\n      state.isAnalyzing = true;\\n      \\n      // Add to context\\n      await state.contextManager.addChunk(text, state.activeSession, {\\n        confidence: originalResult.confidence,\\n        duration: originalResult.audioLength || 0\\n      });\\n\\n      // Get context for analysis\\n      const context = state.contextManager.getContext(state.activeSession);\\n\\n      // Analyze with context\\n      const startTime = performance.now();\\n      const analysisResult = await state.analysisEngine.analyzeText(text, context, {\\n        conversationContext: {\\n          chunkIndex: state.contextManager.getContextData(state.activeSession)?.totalChunks || 0,\\n          totalChunks: state.contextManager.getContextData(state.activeSession)?.totalChunks || 1\\n        }\\n      });\\n\\n      // Update metrics\\n      const latency = performance.now() - startTime;\\n      state.metrics.totalAnalyses++;\\n      state.metrics.averageLatency = \\n        (state.metrics.averageLatency * (state.metrics.totalAnalyses - 1) + latency) / \\n        state.metrics.totalAnalyses;\\n\\n      console.log(`✅ Processed transcription in ${latency.toFixed(2)}ms`);\\n\\n    } catch (error) {\\n      console.error('Error processing transcription:', error);\\n      notifyError(error);\\n    } finally {\\n      state.isAnalyzing = false;\\n      notifyStatusChange();\\n    }\\n  };\\n\\n  const calculateOverallHealth = () => {\\n    if (!state.isInitialized) return 'uninitialized';\\n    \\n    const components = [\\n      state.speechRecognition?.isInitialized(),\\n      state.analysisEngine?.isInitialized(),\\n      state.contextManager?.isInitialized()\\n    ];\\n    \\n    const healthyComponents = components.filter(Boolean).length;\\n    const totalComponents = components.length;\\n    \\n    if (healthyComponents === totalComponents) return 'healthy';\\n    if (healthyComponents > totalComponents / 2) return 'degraded';\\n    return 'unhealthy';\\n  };\\n\\n  const notifyStatusChange = () => {\\n    const status = getStatus();\\n    notifyCallbacks('onStatusChange', createSpeechEvent({\\n      type: 'status_change',\\n      data: { status }\\n    }));\\n  };\\n\\n  const notifyError = (error) => {\\n    notifyCallbacks('onError', createSpeechEvent({\\n      type: 'error',\\n      data: { error: error.message },\\n      severity: 'error'\\n    }));\\n  };\\n\\n  // Event subscription methods\\n  const onSystemReady = (callback) => subscribeCallback('onSystemReady', callback);\\n  const onStreamStart = (callback) => subscribeCallback('onStreamStart', callback);\\n  const onStreamEnd = (callback) => subscribeCallback('onStreamEnd', callback);\\n  const onTranscription = (callback) => subscribeCallback('onTranscription', callback);\\n  const onAnalysis = (callback) => subscribeCallback('onAnalysis', callback);\\n  const onError = (callback) => subscribeCallback('onError', callback);\\n  const onStatusChange = (callback) => subscribeCallback('onStatusChange', callback);\\n\\n  // Helper functions\\n  const subscribeCallback = (eventType, callback) => {\\n    state.callbacks[eventType].push(callback);\\n    return () => {\\n      const index = state.callbacks[eventType].indexOf(callback);\\n      if (index !== -1) state.callbacks[eventType].splice(index, 1);\\n    };\\n  };\\n\\n  const notifyCallbacks = (eventType, event) => {\\n    state.callbacks[eventType].forEach(callback => {\\n      try {\\n        callback(event);\\n      } catch (error) {\\n        console.warn(`Speech streaming ${eventType} callback error:`, error);\\n      }\\n    });\\n  };\\n\\n  return {\\n    // Core functionality\\n    initialize,\\n    startStreaming,\\n    stopStreaming,\\n    cleanup,\\n\\n    // Session management\\n    createSession,\\n    switchSession,\\n    getActiveSession: () => state.activeSession,\\n\\n    // Status and configuration\\n    getStatus,\\n    isInitialized: () => state.isInitialized,\\n    isActive: () => state.isActive,\\n    isListening: () => state.isListening,\\n\\n    // Component access\\n    getSpeechRecognition: () => state.speechRecognition,\\n    getAnalysisEngine: () => state.analysisEngine,\\n    getContextManager: () => state.contextManager,\\n    getSynchronization: () => state.synchronization,\\n\\n    // Event handlers\\n    onSystemReady,\\n    onStreamStart,\\n    onStreamEnd,\\n    onTranscription,\\n    onAnalysis,\\n    onError,\\n    onStatusChange,\\n\\n    // Configuration updates\\n    updateConfig: (newConfig) => {\\n      Object.assign(state.config, newConfig);\\n    },\\n\\n    // Metrics and monitoring\\n    getMetrics: () => ({ ...state.metrics }),\\n    resetMetrics: () => {\\n      state.metrics = {\\n        sessionsStarted: 0,\\n        totalTranscriptions: 0,\\n        totalAnalyses: 0,\\n        averageLatency: 0,\\n        uptime: 0,\\n        lastActivity: null,\\n        errorCount: 0\\n      };\\n    },\\n\\n    // Advanced features\\n    addExternalStream: (streamId, stream) => {\\n      if (state.synchronization) {\\n        state.synchronization.addStream(streamId, stream);\\n      }\\n    },\\n\\n    // Manual processing (for testing/development)\\n    processText: async (text, options = {}) => {\\n      if (!state.isInitialized) {\\n        throw new Error('System not initialized');\\n      }\\n      return await processTranscription(text, { \\n        confidence: 0.95, \\n        ...options \\n      });\\n    }\\n  };\\n};\\n\\n// Export streaming configuration\\nexport { DEFAULT_STREAM_CONFIG };\\n\\n// Export default factory\\n// Export default factory (already exported above as const)\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/index.js\",\"messages\":[{\"ruleId\":\"no-undef\",\"severity\":2,\"message\":\"'createLazyPipelineRegistry' is not defined.\",\"line\":27,\"column\":20,\"nodeType\":\"Identifier\",\"messageId\":\"undef\",\"endLine\":27,\"endColumn\":46},{\"ruleId\":\"no-undef\",\"severity\":2,\"message\":\"'createLazyPipelineRegistry' is not defined.\",\"line\":35,\"column\":20,\"nodeType\":\"Identifier\",\"messageId\":\"undef\",\"endLine\":35,\"endColumn\":46},{\"ruleId\":\"no-undef\",\"severity\":2,\"message\":\"'createPipelinePreloader' is not defined.\",\"line\":36,\"column\":21,\"nodeType\":\"Identifier\",\"messageId\":\"undef\",\"endLine\":36,\"endColumn\":44}],\"suppressedMessages\":[],\"errorCount\":3,\"fatalErrorCount\":0,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Synopticon API - Main Entry Point with Code Splitting\\n * Open-source platform for real-time multi-modal behavioral analysis and sensor synchronization\\n * \\n * This version uses lazy loading for optimal performance:\\n * - Core components are loaded immediately\\n * - Pipeline modules are loaded on-demand\\n * - Critical pipelines can be preloaded intelligently\\n */\\n\\n// Import and re-export core orchestrator (always loaded)\\nimport { createOrchestrator } from './core/orchestration/orchestrator.ts';\\nexport { createOrchestrator };\\n\\n// Export lazy loading infrastructure (always loaded)\\nexport { createLazyPipelineRegistry } from './core/pipeline/lazy-pipeline-registry.ts';\\nexport { createLoadingStateManager, LoadingStates, ProgressStages } from './core/state/loading-state-manager.js';\\nexport { createPipelinePreloader, PreloadingStrategies, UsageContexts } from './core/pipeline/pipeline-preloader.js';\\n\\n// Export UI components for loading states\\nexport * from './shared/utils/ui/loading-components.js';\\n\\n// Modern lazy loading approach only\\n\\n// Lazy pipeline factory - creates pipelines on demand\\nexport const createPipelineFactory = async (type, config = {}) => {\\n  const registry = createLazyPipelineRegistry();\\n  const factory = await registry.loadPipeline(type);\\n  return factory(config);\\n};\\n\\n// Convenience function to create orchestrator with lazy loading\\nexport const createLazyOrchestrator = (config = {}) => {\\n  const orchestrator = createOrchestrator(config);\\n  const registry = createLazyPipelineRegistry(config.lazyLoading);\\n  const preloader = createPipelinePreloader(config.preloading);\\n  \\n  // Initialize preloader with registry\\n  preloader.initialize(registry);\\n  \\n  // Enhanced orchestrator with lazy loading capabilities\\n  return {\\n    ...orchestrator,\\n    \\n    // Lazy pipeline registration\\n    registerPipelineByType: async (type, pipelineConfig = {}) => {\\n      const factory = await registry.loadPipeline(type);\\n      const pipeline = factory(pipelineConfig);\\n      return orchestrator.registerPipeline(pipeline);\\n    },\\n    \\n    // Batch register pipelines with intelligent loading\\n    registerPipelinesLazy: async (pipelineTypes, configs = {}) => {\\n      const pipelines = [];\\n      \\n      for (const type of pipelineTypes) {\\n        try {\\n          const factory = await registry.loadPipeline(type);\\n          const pipeline = factory(configs[type] || {});\\n          pipelines.push(pipeline);\\n        } catch (error) {\\n          console.warn(`Failed to load pipeline ${type}:`, error);\\n        }\\n      }\\n      \\n      return orchestrator.registerPipelinesParallel(pipelines, configs);\\n    },\\n    \\n    // Preloading control\\n    preloadPipeline: (type, strategy) => preloader.preloadPipeline(type, strategy),\\n    scheduleIntelligentPreloading: () => preloader.scheduleIntelligentPreloading(),\\n    \\n    // Lazy loading utilities\\n    isPipelineLoaded: (type) => registry.isPipelineLoaded(type),\\n    getLoadingState: (type) => registry.getLoadingState(type),\\n    onLoadingStateChange: (listener) => registry.onLoadingStateChange(listener),\\n    \\n    // Registry and preloader access\\n    getRegistry: () => registry,\\n    getPreloader: () => preloader,\\n    \\n    // Metrics\\n    getLazyLoadingMetrics: () => ({\\n      registry: registry.getMetrics(),\\n      preloader: preloader.getStatistics()\\n    })\\n  };\\n};\\n\\n// Quick-start factory for common scenarios\\nexport const createQuickStartOrchestrator = async (requirements = {}) => {\\n  const orchestrator = createLazyOrchestrator();\\n  \\n  // Determine pipelines needed based on requirements\\n  const pipelineTypes = [];\\n  \\n  if (requirements.faceDetection !== false) {\\n    pipelineTypes.push('mediapipe-face');\\n  }\\n  \\n  if (requirements.emotionAnalysis) {\\n    pipelineTypes.push('emotion-analysis');\\n  }\\n  \\n  if (requirements.ageEstimation) {\\n    pipelineTypes.push('age-estimation');\\n  }\\n  \\n  if (requirements.eyeTracking) {\\n    pipelineTypes.push('eye-tracking');\\n  }\\n  \\n  if (requirements.advancedFaceAnalysis) {\\n    pipelineTypes.push('mediapipe-face-mesh', 'iris-tracking');\\n  }\\n  \\n  // Register pipelines with intelligent loading\\n  await orchestrator.registerPipelinesLazy(pipelineTypes);\\n  \\n  return orchestrator;\\n};\\n\\n// Export core components\\nexport { createPipeline } from './core/pipeline/pipeline.ts';\\nexport { \\n  StreamCapability as Capability, \\n  createPerformanceProfile, \\n  createFaceResult, \\n  createAnalysisResult,\\n  createPose3DOF,\\n  createPose6DOF \\n} from './core/configuration/types.ts';\\n\\n// Export utilities\\nexport { \\n  detectRuntime, \\n  checkFeatures, \\n  createUniversalCanvas,\\n  loadMediaPipe,\\n  imageToMediaPipe,\\n  getRuntimeInfo\\n} from './shared/utils/runtime-detector.js';\\n\\n// Export performance monitoring\\nexport { \\n  createPerformanceMonitor,\\n  getGlobalMonitor,\\n  measureAsync \\n} from './core/performance/performance-monitor.js';\\n\\n// Export API server\\nexport { createFaceAnalysisServer } from './services/api/server.ts';\\n\\n// Export speech analysis components\\nexport { createSpeechAnalysisAPI, createSpeechRecognition, createLLMClient } from './features/speech-analysis/index.js';\\n\\n// Version information\\nexport const VERSION = '0.5.8'; // Breaking changes - clean modern API\\nexport const BUILD = 'knip-optimized';\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/server-analysis-endpoint.js\",\"messages\":[],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/server-analysis/analysis-processor.js\",\"messages\":[],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/server-analysis/bun-handlers.js\",\"messages\":[],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/server-analysis/config-manager.js\",\"messages\":[],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/server-analysis/session-manager.js\",\"messages\":[],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/server-analysis/transcript-processor.js\",\"messages\":[{\"ruleId\":\"max-lines-per-function\",\"severity\":1,\"message\":\"Arrow function has too many lines (213). Maximum allowed is 150.\",\"line\":8,\"column\":42,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"exceed\",\"endLine\":284,\"endColumn\":2},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'session' is defined but never used. Allowed unused args must match /^_/u.\",\"line\":122,\"column\":51,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":122,\"endColumn\":58,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"session\"},\"fix\":{\"range\":[3737,3746],\"text\":\"\"},\"desc\":\"Remove unused variable 'session'.\"}]}],\"suppressedMessages\":[],\"errorCount\":1,\"fatalErrorCount\":0,\"warningCount\":1,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Transcript processing logic for server analysis\\n */\\n\\nimport { createContextManager } from '../features/speech-analysis/context-manager.js';\\nimport { createConversationAnalytics } from '../features/speech-analysis/conversation-analytics.js';\\n\\nexport const createTranscriptProcessor = (analysisEngine, config) => {\\n\\n  // Create session with all components\\n  const createSessionComponents = (sessionId) => {\\n    const contextManager = createContextManager(config.contextConfig);\\n    const analytics = config.analyticsConfig.enabled \\n      ? createConversationAnalytics(config.analyticsConfig)\\n      : null;\\n    \\n    if (analytics) {\\n      analytics.initialize();\\n      analytics.startAnalysis();\\n    }\\n    \\n    return {\\n      id: sessionId,\\n      contextManager,\\n      analytics,\\n      transcripts: [],\\n      analysisResults: [],\\n      createdAt: Date.now(),\\n      lastActivity: Date.now(),\\n      metadata: {}\\n    };\\n  };\\n\\n  // Process incoming transcripts\\n  const processTranscripts = async (sessionManager, sessionId, transcripts) => {\\n    // Get or create session\\n    let session = sessionManager.getSession(sessionId);\\n    if (!session) {\\n      const components = createSessionComponents(sessionId);\\n      session = sessionManager.createSession(sessionId, components.config);\\n      \\n      // Add components to session\\n      session.contextManager = components.contextManager;\\n      session.analytics = components.analytics;\\n      session.transcripts = components.transcripts;\\n      session.analysisResults = components.analysisResults;\\n      session.metadata = components.metadata;\\n      \\n      console.log(`📝 Created new session: ${sessionId}`);\\n    }\\n    \\n    // Update last activity\\n    sessionManager.updateActivity(sessionId);\\n    \\n    // Process each transcript\\n    const results = [];\\n    \\n    for (const transcript of transcripts) {\\n      try {\\n        // Add to session transcripts\\n        session.transcripts.push(transcript);\\n        \\n        // Add to context manager\\n        const context = session.contextManager.addChunk(transcript.text, {\\n          timestamp: transcript.timestamp,\\n          confidence: transcript.confidence\\n        });\\n        \\n        // Add to analytics if enabled\\n        if (session.analytics) {\\n          session.analytics.addChunk(\\n            { text: transcript.text, timestamp: transcript.timestamp },\\n            transcript.participantId || 'default'\\n          );\\n        }\\n        \\n        // Perform analysis if text is substantial\\n        if (transcript.text.split(' ').length > 5) {\\n          const analysisResult = await analyzeTranscript(\\n            transcript.text,\\n            context,\\n            session\\n          );\\n          \\n          if (analysisResult) {\\n            session.analysisResults.push(analysisResult);\\n            results.push(analysisResult);\\n            \\n            // Add analysis results to analytics\\n            if (session.analytics && analysisResult.analyses) {\\n              analysisResult.analyses.forEach(analysis => {\\n                session.analytics.addChunk(\\n                  { text: transcript.text, timestamp: transcript.timestamp },\\n                  'default',\\n                  [analysis]\\n                );\\n              });\\n            }\\n          }\\n        }\\n      } catch (error) {\\n        console.error(`Error processing transcript:`, error);\\n        results.push({\\n          error: error.message,\\n          transcript: transcript.text\\n        });\\n      }\\n    }\\n    \\n    // Get session summary\\n    const summary = getSessionSummary(session);\\n    \\n    return {\\n      sessionId,\\n      results,\\n      summary,\\n      timestamp: Date.now()\\n    };\\n  };\\n\\n  // Analyze individual transcript\\n  const analyzeTranscript = async (text, context, session) => {\\n    try {\\n      // Build context for analysis\\n      const analysisContext = {\\n        currentText: text,\\n        previousChunks: context.chunks.slice(-5),\\n        summary: context.summary\\n      };\\n      \\n      // Perform analysis with multiple prompts\\n      const analyses = await Promise.all(\\n        config.analysisConfig.prompts.map(async (prompt) => {\\n          try {\\n            const result = await analysisEngine.analyze(\\n              text,\\n              prompt,\\n              analysisContext\\n            );\\n            \\n            return {\\n              prompt,\\n              result: result.response,\\n              confidence: result.confidence || 0.8,\\n              timestamp: Date.now()\\n            };\\n          } catch (error) {\\n            console.warn(`Analysis failed for prompt \\\"${prompt}\\\":`, error);\\n            return null;\\n          }\\n        })\\n      );\\n      \\n      // Filter out failed analyses\\n      const validAnalyses = analyses.filter(a => a !== null);\\n      \\n      if (validAnalyses.length === 0) {\\n        return null;\\n      }\\n      \\n      return {\\n        text,\\n        analyses: validAnalyses,\\n        context: {\\n          chunkCount: context.chunks.length,\\n          hasSummary: !!context.summary\\n        },\\n        timestamp: Date.now()\\n      };\\n      \\n    } catch (error) {\\n      console.error('Analysis error:', error);\\n      return null;\\n    }\\n  };\\n\\n  // Get session summary\\n  const getSessionSummary = (session) => {\\n    const summary = {\\n      transcriptCount: session.transcripts.length,\\n      analysisCount: session.analysisResults.length,\\n      duration: Date.now() - session.createdAt,\\n      lastActivity: session.lastActivity\\n    };\\n    \\n    // Add analytics summary if available\\n    if (session.analytics) {\\n      summary.analytics = session.analytics.getSummary();\\n    }\\n    \\n    // Add context summary\\n    const context = session.contextManager.getContext();\\n    summary.context = {\\n      chunkCount: context.chunks.length,\\n      hasSummary: !!context.summary,\\n      totalWords: context.chunks.reduce((sum, chunk) => \\n        sum + chunk.text.split(' ').length, 0\\n      )\\n    };\\n    \\n    return summary;\\n  };\\n\\n  // Get full session data\\n  const getSession = (sessionManager, sessionId) => {\\n    const session = sessionManager.getSession(sessionId);\\n    if (!session) {\\n      return null;\\n    }\\n    \\n    return {\\n      id: session.id,\\n      transcripts: session.transcripts,\\n      analysisResults: session.analysisResults,\\n      summary: getSessionSummary(session),\\n      analytics: session.analytics ? session.analytics.getMetrics() : null,\\n      context: session.contextManager.getContext(),\\n      metadata: session.metadata,\\n      createdAt: session.createdAt,\\n      lastActivity: session.lastActivity\\n    };\\n  };\\n\\n  // Update session metadata\\n  const updateSessionMetadata = (sessionManager, sessionId, metadata) => {\\n    const session = sessionManager.getSession(sessionId);\\n    if (!session) {\\n      throw new Error(`Session ${sessionId} not found`);\\n    }\\n    \\n    Object.assign(session.metadata, metadata);\\n    sessionManager.updateActivity(sessionId);\\n    \\n    return session.metadata;\\n  };\\n\\n  // End session\\n  const endSession = (sessionManager, sessionId) => {\\n    const session = sessionManager.getSession(sessionId);\\n    if (!session) {\\n      return false;\\n    }\\n    \\n    // Cleanup analytics\\n    if (session.analytics) {\\n      session.analytics.stopAnalysis();\\n      session.analytics.cleanup();\\n    }\\n    \\n    // Remove session via session manager\\n    sessionManager.removeSession(sessionId);\\n    console.log(`🏁 Ended session: ${sessionId}`);\\n    \\n    return true;\\n  };\\n\\n  // Get statistics\\n  const getStatistics = (sessionManager) => {\\n    const sessions = sessionManager.getAllSessions();\\n    const sessionStats = sessions.map(session => ({\\n      id: session.id,\\n      transcripts: session.transcripts.length,\\n      analyses: session.analysisResults.length,\\n      duration: Date.now() - session.createdAt,\\n      lastActivity: session.lastActivity\\n    }));\\n    \\n    return {\\n      activeSessions: sessions.length,\\n      totalTranscripts: sessionStats.reduce((sum, s) => sum + s.transcripts, 0),\\n      totalAnalyses: sessionStats.reduce((sum, s) => sum + s.analyses, 0),\\n      sessions: sessionStats,\\n      config\\n    };\\n  };\\n\\n  return {\\n    processTranscripts,\\n    getSession,\\n    updateSessionMetadata,\\n    endSession,\\n    getStatistics\\n  };\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/services/api/media-streaming-api.js\",\"messages\":[{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'createMediaStreamingPipeline' is defined but never used. Allowed unused vars must match /^_/u.\",\"line\":8,\"column\":10,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":8,\"endColumn\":38,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"createMediaStreamingPipeline\"},\"fix\":{\"range\":[243,349],\"text\":\"\"},\"desc\":\"Remove unused variable 'createMediaStreamingPipeline'.\"}]},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'createMediaWebSocketDistributor' is defined but never used. Allowed unused vars must match /^_/u.\",\"line\":9,\"column\":10,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":9,\"endColumn\":41,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"createMediaWebSocketDistributor\"},\"fix\":{\"range\":[350,468],\"text\":\"\"},\"desc\":\"Remove unused variable 'createMediaWebSocketDistributor'.\"}]},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'server' is defined but never used. Allowed unused args must match /^_/u.\",\"line\":92,\"column\":33,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":92,\"endColumn\":39,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"server\"},\"fix\":{\"range\":[3458,3464],\"text\":\"\"},\"desc\":\"Remove unused variable 'server'.\"}]}],\"suppressedMessages\":[],\"errorCount\":3,\"fatalErrorCount\":0,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Media Streaming API\\n * RESTful API for device discovery and stream control\\n * WebSocket endpoints for real-time streaming\\n */\\n\\nimport { createDeviceDiscoveryPipeline } from '../../features/media-streaming/device-discovery-pipeline.js';\\nimport { createMediaStreamingPipeline } from '../../features/media-streaming/media-streaming-pipeline.js';\\nimport { createMediaWebSocketDistributor } from '../../core/distribution/distributors/media-websocket-distributor.ts';\\nimport { createOrchestrator } from '../../core/orchestration/orchestrator.js';\\nimport { createStrategyRegistry } from '../../core/orchestration/strategies.js';\\nimport { createDistributionSessionManager } from '../../core/distribution/distribution-session-manager.ts';\\n\\n// Import route modules\\nimport { setupDeviceRoutes } from './routes/device-routes.js';\\nimport { setupStreamRoutes } from './routes/stream-routes.js';\\nimport { setupSystemRoutes } from './routes/system-routes.js';\\n\\n/**\\n * Create media streaming API system\\n * @param {Object} config - Configuration options\\n * @returns {Object} API system with routes and handlers\\n */\\nexport const createMediaStreamingAPI = (config = {}) => {\\n  const state = {\\n    orchestrator: null,\\n    distributionManager: null,\\n    deviceDiscoveryPipeline: null,\\n    activeStreams: new Map(), // streamId -> pipeline\\n    connectedDevices: new Map(), // deviceId -> device info\\n    isInitialized: false\\n  };\\n\\n  // Initialize the media streaming system\\n  const initialize = async () => {\\n    if (state.isInitialized) return true;\\n\\n    console.log('🚀 Initializing Media Streaming API...');\\n\\n    try {\\n      // Create orchestrator for pipeline management\\n      const strategyRegistry = createStrategyRegistry();\\n      state.orchestrator = createOrchestrator({\\n        strategies: strategyRegistry,\\n        defaultStrategy: 'performance_first',\\n        performance: {\\n          maxConcurrentPipelines: 10,\\n          timeoutMs: 30000\\n        }\\n      });\\n\\n      // Create distribution session manager\\n      state.distributionManager = createDistributionSessionManager({\\n        enableHealthCheck: true,\\n        healthCheckInterval: 30000\\n      });\\n\\n      // WebSocket distribution handled by multi-device coordinator\\n      console.log('📝 WebSocket streaming handled by multi-device coordinator');\\n\\n      // Create and register device discovery pipeline\\n      state.deviceDiscoveryPipeline = createDeviceDiscoveryPipeline({\\n        discoveryInterval: config.discoveryInterval || 10000,\\n        streamingPort: config.websocketPort || 8081\\n      });\\n\\n      await state.orchestrator.registerPipeline(state.deviceDiscoveryPipeline);\\n\\n      // Distribution sessions handled by multi-device coordinator\\n      console.log('📝 Complex distribution sessions handled by multi-device coordinator');\\n\\n      state.isInitialized = true;\\n      console.log('✅ Media Streaming API initialized successfully');\\n      return true;\\n\\n    } catch (error) {\\n      console.error('Failed to initialize Media Streaming API:', error);\\n      throw error;\\n    }\\n  };\\n\\n  // Device discovery and management endpoints\\n  const setupDeviceRoutesLocal = (app) => setupDeviceRoutes(app, state);\\n\\n  // Stream management endpoints\\n  const setupStreamRoutesLocal = (app) => setupStreamRoutes(app, state);\\n\\n  // System status and health endpoints\\n  const setupSystemRoutesLocal = (app) => setupSystemRoutes(app, state);\\n\\n  // WebSocket setup for real-time streaming\\n  const setupWebSocketRoutes = (server) => {\\n    // This will be handled by the media WebSocket distributor\\n    // through the distribution session manager\\n    console.log('📡 WebSocket streaming available on configured port');\\n  };\\n\\n  // Cleanup function\\n  const cleanup = async () => {\\n    console.log('🧹 Cleaning up Media Streaming API...');\\n    \\n    // Stop all active streams\\n    for (const [streamId, pipeline] of state.activeStreams) {\\n      try {\\n        if (pipeline.isStreaming()) {\\n          await pipeline.process({ action: 'STOP_STREAM' });\\n        }\\n        await pipeline.cleanup();\\n      } catch (error) {\\n        console.warn(`Error cleaning up stream ${streamId}:`, error);\\n      }\\n    }\\n    \\n    state.activeStreams.clear();\\n    \\n    // Cleanup orchestrator and distribution manager\\n    if (state.orchestrator) {\\n      await state.orchestrator.cleanup();\\n    }\\n    \\n    if (state.distributionManager) {\\n      await state.distributionManager.cleanup();\\n    }\\n    \\n    state.isInitialized = false;\\n    console.log('✅ Media Streaming API cleanup completed');\\n  };\\n\\n  return {\\n    // Initialization\\n    initialize,\\n    cleanup,\\n    \\n    // Route setup functions\\n    setupDeviceRoutes: setupDeviceRoutesLocal,\\n    setupStreamRoutes: setupStreamRoutesLocal, \\n    setupSystemRoutes: setupSystemRoutesLocal,\\n    setupWebSocketRoutes,\\n    \\n    // Status\\n    isInitialized: () => state.isInitialized,\\n    getActiveStreams: () => Array.from(state.activeStreams.keys()),\\n    \\n    // Access to internal components\\n    getOrchestrator: () => state.orchestrator,\\n    getDistributionManager: () => state.distributionManager,\\n    getDeviceDiscovery: () => state.deviceDiscoveryPipeline\\n  };\\n};\\n\\n\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}},{\"ruleId\":\"no-process-exit\",\"replacedBy\":[\"n/no-process-exit\"],\"info\":{\"message\":\"Node.js rules were moved out of ESLint core.\",\"url\":\"https://eslint.org/docs/latest/use/migrating-to-7.0.0#deprecate-node-rules\",\"deprecatedSince\":\"7.0.0\",\"availableUntil\":null,\"replacedBy\":[{\"message\":\"eslint-plugin-n now maintains deprecated Node.js-related rules.\",\"plugin\":{\"name\":\"eslint-plugin-n\",\"url\":\"https://github.com/eslint-community/eslint-plugin-n\"},\"rule\":{\"name\":\"no-process-exit\",\"url\":\"https://github.com/eslint-community/eslint-plugin-n/tree/master/docs/rules/no-process-exit.md\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/services/api/middleware/cors.js\",\"messages\":[{\"ruleId\":\"max-lines-per-function\",\"severity\":1,\"message\":\"Arrow function has too many lines (205). Maximum allowed is 150.\",\"line\":11,\"column\":37,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"exceed\",\"endLine\":327,\"endColumn\":2}],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":1,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * CORS Middleware Module\\n * Enhanced Cross-Origin Resource Sharing handling\\n */\\n\\n/**\\n * Create CORS middleware\\n * @param {Object} config - CORS configuration\\n * @returns {Object} CORS middleware functions\\n */\\nexport const createCORSMiddleware = (config = {}) => {\\n  const state = {\\n    config: {\\n      allowedOrigins: config.allowedOrigins || [\\n        'http://localhost:3000',\\n        'http://127.0.0.1:3000',\\n        'http://localhost:8080',\\n        'http://127.0.0.1:8080'\\n      ],\\n      allowedMethods: config.allowedMethods || ['GET', 'POST', 'PUT', 'DELETE', 'OPTIONS'],\\n      allowedHeaders: config.allowedHeaders || [\\n        'Content-Type', \\n        'Authorization', \\n        'X-API-Key', \\n        'X-Requested-With',\\n        'X-Session-ID'\\n      ],\\n      allowCredentials: config.allowCredentials || false,\\n      maxAge: config.maxAge || 3600, // Preflight cache duration\\n      exposeHeaders: config.exposeHeaders || ['X-Total-Count', 'X-Rate-Limit'],\\n      strictMode: config.strictMode !== false,\\n      logRequests: config.logRequests || false,\\n      ...config\\n    },\\n    stats: {\\n      totalRequests: 0,\\n      preflightRequests: 0,\\n      blockedRequests: 0,\\n      allowedOrigins: new Map(), // origin -> count\\n      requestsByMethod: new Map()\\n    }\\n  };\\n\\n  /**\\n   * Check if origin is allowed\\n   * @param {string} origin - Request origin\\n   * @returns {boolean} Whether origin is allowed\\n   */\\n  const isOriginAllowed = (origin) => {\\n    if (!origin) return !state.config.strictMode;\\n\\n    // Exact match\\n    if (state.config.allowedOrigins.includes(origin)) {\\n      return true;\\n    }\\n\\n    // Wildcard support (if configured)\\n    if (state.config.allowedOrigins.includes('*')) {\\n      return true;\\n    }\\n\\n    // Pattern matching for development (localhost with any port)\\n    if (state.config.allowedOrigins.some(allowed => {\\n      if (allowed.includes('localhost') && origin.includes('localhost')) {\\n        return true;\\n      }\\n      if (allowed.includes('127.0.0.1') && origin.includes('127.0.0.1')) {\\n        return true;\\n      }\\n      return false;\\n    })) {\\n      return true;\\n    }\\n\\n    return false;\\n  };\\n\\n  /**\\n   * Create CORS headers for response\\n   * @param {Request} request - HTTP request\\n   * @param {string} overrideOrigin - Optional origin override\\n   * @returns {Object} CORS headers\\n   */\\n  const createCORSHeaders = (request, overrideOrigin = null) => {\\n    const origin = overrideOrigin || request.headers.get('origin');\\n    const {method} = request;\\n    \\n    // Update statistics\\n    state.stats.totalRequests++;\\n    state.stats.requestsByMethod.set(method, (state.stats.requestsByMethod.get(method) || 0) + 1);\\n\\n    if (method === 'OPTIONS') {\\n      state.stats.preflightRequests++;\\n    }\\n\\n    // Determine allowed origin\\n    let allowedOrigin = 'null';\\n    if (origin && isOriginAllowed(origin)) {\\n      allowedOrigin = origin;\\n      state.stats.allowedOrigins.set(origin, (state.stats.allowedOrigins.get(origin) || 0) + 1);\\n    } else if (origin && state.config.strictMode) {\\n      state.stats.blockedRequests++;\\n      if (state.config.logRequests) {\\n        console.warn(`🚫 CORS: Blocked request from origin: ${origin}`);\\n      }\\n    }\\n\\n    // Build headers\\n    const headers = {\\n      'Access-Control-Allow-Origin': allowedOrigin,\\n      'Access-Control-Allow-Methods': state.config.allowedMethods.join(', '),\\n      'Access-Control-Allow-Headers': state.config.allowedHeaders.join(', '),\\n      'Access-Control-Allow-Credentials': state.config.allowCredentials.toString(),\\n      'Access-Control-Max-Age': state.config.maxAge.toString()\\n    };\\n\\n    // Add expose headers if configured\\n    if (state.config.exposeHeaders.length > 0) {\\n      headers['Access-Control-Expose-Headers'] = state.config.exposeHeaders.join(', ');\\n    }\\n\\n    // Security headers\\n    headers['X-Content-Type-Options'] = 'nosniff';\\n    headers['X-Frame-Options'] = 'DENY';\\n    headers['X-XSS-Protection'] = '1; mode=block';\\n\\n    // Log if enabled\\n    if (state.config.logRequests) {\\n      console.log(`🌐 CORS: ${method} request from ${origin || 'no-origin'} -> ${allowedOrigin}`);\\n    }\\n\\n    return headers;\\n  };\\n\\n  /**\\n   * Handle preflight OPTIONS request\\n   * @param {Request} request - HTTP request\\n   * @returns {Response} Preflight response\\n   */\\n  const handlePreflight = (request) => {\\n    const headers = createCORSHeaders(request);\\n    \\n    // Check if the requested method is allowed\\n    const requestedMethod = request.headers.get('access-control-request-method');\\n    if (requestedMethod && !state.config.allowedMethods.includes(requestedMethod)) {\\n      headers['Access-Control-Allow-Origin'] = 'null';\\n      state.stats.blockedRequests++;\\n      \\n      if (state.config.logRequests) {\\n        console.warn(`🚫 CORS: Blocked preflight for method: ${requestedMethod}`);\\n      }\\n    }\\n\\n    // Check if the requested headers are allowed\\n    const requestedHeaders = request.headers.get('access-control-request-headers');\\n    if (requestedHeaders) {\\n      const requestedHeadersList = requestedHeaders.split(',').map(h => h.trim().toLowerCase());\\n      const allowedHeadersLower = state.config.allowedHeaders.map(h => h.toLowerCase());\\n      \\n      const unauthorizedHeaders = requestedHeadersList.filter(h => !allowedHeadersLower.includes(h));\\n      if (unauthorizedHeaders.length > 0) {\\n        headers['Access-Control-Allow-Origin'] = 'null';\\n        state.stats.blockedRequests++;\\n        \\n        if (state.config.logRequests) {\\n          console.warn(`🚫 CORS: Blocked preflight for headers: ${unauthorizedHeaders.join(', ')}`);\\n        }\\n      }\\n    }\\n\\n    return new Response(null, {\\n      status: 204,\\n      headers\\n    });\\n  };\\n\\n  /**\\n   * Apply CORS headers to existing response\\n   * @param {Response} response - Original response\\n   * @param {Request} request - Original request\\n   * @returns {Response} Response with CORS headers\\n   */\\n  const applyCORSHeaders = (response, request) => {\\n    const corsHeaders = createCORSHeaders(request);\\n    const newHeaders = new Headers(response.headers);\\n    \\n    // Add CORS headers\\n    Object.entries(corsHeaders).forEach(([key, value]) => {\\n      newHeaders.set(key, value);\\n    });\\n\\n    return new Response(response.body, {\\n      status: response.status,\\n      statusText: response.statusText,\\n      headers: newHeaders\\n    });\\n  };\\n\\n  /**\\n   * Middleware function for request processing\\n   * @param {Request} request - HTTP request\\n   * @param {Function} next - Next middleware function\\n   * @returns {Response} Response with CORS handling\\n   */\\n  const corsMiddleware = async (request, next) => {\\n    // Handle preflight requests\\n    if (request.method === 'OPTIONS') {\\n      return handlePreflight(request);\\n    }\\n\\n    // Process request through next middleware/handler\\n    const response = await next(request);\\n    \\n    // Apply CORS headers to response\\n    return applyCORSHeaders(response, request);\\n  };\\n\\n  /**\\n   * Update CORS configuration\\n   * @param {Object} updates - Configuration updates\\n   */\\n  const updateConfig = (updates) => {\\n    state.config = { ...state.config, ...updates };\\n    console.log('🔧 CORS configuration updated');\\n  };\\n\\n  /**\\n   * Add allowed origin\\n   * @param {string} origin - Origin to allow\\n   */\\n  const addAllowedOrigin = (origin) => {\\n    if (!state.config.allowedOrigins.includes(origin)) {\\n      state.config.allowedOrigins.push(origin);\\n      console.log(`✅ CORS: Added allowed origin: ${origin}`);\\n    }\\n  };\\n\\n  /**\\n   * Remove allowed origin\\n   * @param {string} origin - Origin to remove\\n   */\\n  const removeAllowedOrigin = (origin) => {\\n    const index = state.config.allowedOrigins.indexOf(origin);\\n    if (index > -1) {\\n      state.config.allowedOrigins.splice(index, 1);\\n      console.log(`❌ CORS: Removed allowed origin: ${origin}`);\\n    }\\n  };\\n\\n  /**\\n   * Get CORS statistics\\n   * @returns {Object} CORS statistics\\n   */\\n  const getStatistics = () => {\\n    return {\\n      totalRequests: state.stats.totalRequests,\\n      preflightRequests: state.stats.preflightRequests,\\n      blockedRequests: state.stats.blockedRequests,\\n      blockRate: state.stats.totalRequests > 0 \\n        ? state.stats.blockedRequests / state.stats.totalRequests \\n        : 0,\\n      allowedOrigins: Array.from(state.stats.allowedOrigins.entries()),\\n      requestsByMethod: Array.from(state.stats.requestsByMethod.entries()),\\n      topOrigins: Array.from(state.stats.allowedOrigins.entries())\\n        .sort(([,a], [,b]) => b - a)\\n        .slice(0, 10),\\n      timestamp: Date.now()\\n    };\\n  };\\n\\n  /**\\n   * Reset statistics\\n   */\\n  const resetStatistics = () => {\\n    state.stats = {\\n      totalRequests: 0,\\n      preflightRequests: 0,\\n      blockedRequests: 0,\\n      allowedOrigins: new Map(),\\n      requestsByMethod: new Map()\\n    };\\n    console.log('📊 CORS statistics reset');\\n  };\\n\\n  /**\\n   * Get health status\\n   * @returns {Object} Health information\\n   */\\n  const getHealthStatus = () => {\\n    const stats = getStatistics();\\n    const isHealthy = stats.blockRate < 0.1; // Less than 10% blocked\\n\\n    return {\\n      status: isHealthy ? 'healthy' : 'warning',\\n      blockRate: Math.round(stats.blockRate * 100),\\n      totalRequests: stats.totalRequests,\\n      issues: isHealthy ? [] : ['High block rate - check allowed origins']\\n    };\\n  };\\n\\n  return {\\n    // Core middleware function\\n    corsMiddleware,\\n    \\n    // Header utilities\\n    createCORSHeaders,\\n    applyCORSHeaders,\\n    handlePreflight,\\n    \\n    // Configuration management\\n    updateConfig,\\n    addAllowedOrigin,\\n    removeAllowedOrigin,\\n    \\n    // Monitoring\\n    getStatistics,\\n    resetStatistics,\\n    getHealthStatus,\\n    \\n    // Utilities\\n    isOriginAllowed,\\n    getConfig: () => ({ ...state.config }),\\n    \\n    // Direct access\\n    createHeaders: createCORSHeaders\\n  };\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}},{\"ruleId\":\"no-process-exit\",\"replacedBy\":[\"n/no-process-exit\"],\"info\":{\"message\":\"Node.js rules were moved out of ESLint core.\",\"url\":\"https://eslint.org/docs/latest/use/migrating-to-7.0.0#deprecate-node-rules\",\"deprecatedSince\":\"7.0.0\",\"availableUntil\":null,\"replacedBy\":[{\"message\":\"eslint-plugin-n now maintains deprecated Node.js-related rules.\",\"plugin\":{\"name\":\"eslint-plugin-n\",\"url\":\"https://github.com/eslint-community/eslint-plugin-n\"},\"rule\":{\"name\":\"no-process-exit\",\"url\":\"https://github.com/eslint-community/eslint-plugin-n/tree/master/docs/rules/no-process-exit.md\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/services/api/middleware/error-handler.js\",\"messages\":[{\"ruleId\":\"max-lines-per-function\",\"severity\":1,\"message\":\"Arrow function has too many lines (263). Maximum allowed is 150.\",\"line\":11,\"column\":45,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"exceed\",\"endLine\":384,\"endColumn\":2},{\"ruleId\":\"complexity\",\"severity\":1,\"message\":\"Arrow function has a complexity of 22. Maximum allowed is 20.\",\"line\":37,\"column\":31,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"complex\",\"endLine\":107,\"endColumn\":4},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'method' is assigned a value but never used. Allowed unused vars must match /^_/u.\",\"line\":40,\"column\":11,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":40,\"endColumn\":17,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"method\"},\"fix\":{\"range\":[1226,1278],\"text\":\"\"},\"desc\":\"Remove unused variable 'method'.\"}]},{\"ruleId\":\"prefer-destructuring\",\"severity\":1,\"message\":\"Use object destructuring.\",\"line\":45,\"column\":7,\"nodeType\":\"AssignmentExpression\",\"messageId\":\"preferDestructuring\",\"endLine\":45,\"endColumn\":28}],\"suppressedMessages\":[],\"errorCount\":1,\"fatalErrorCount\":0,\"warningCount\":3,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Error Handler Middleware Module\\n * Centralized error handling and response formatting\\n */\\n\\n/**\\n * Create error handling middleware\\n * @param {Object} config - Error handler configuration\\n * @returns {Object} Error handler middleware functions\\n */\\nexport const createErrorHandlerMiddleware = (config = {}) => {\\n  const state = {\\n    config: {\\n      enableStackTrace: config.enableStackTrace !== false,\\n      enableErrorLogging: config.enableErrorLogging !== false,\\n      enableDetailedErrors: config.enableDetailedErrors || false,\\n      errorCodeMapping: config.errorCodeMapping || {},\\n      excludeFromLogging: config.excludeFromLogging || [],\\n      maxErrorLength: config.maxErrorLength || 1000,\\n      ...config\\n    },\\n    stats: {\\n      totalErrors: 0,\\n      errorsByType: new Map(),\\n      errorsByStatus: new Map(),\\n      lastError: null,\\n      startTime: Date.now()\\n    }\\n  };\\n\\n  /**\\n   * Format error response based on configuration\\n   * @param {Error} error - Error object\\n   * @param {Request} request - HTTP request\\n   * @returns {Object} Formatted error response\\n   */\\n  const formatErrorResponse = (error, request) => {\\n    const timestamp = Date.now();\\n    const url = request ? request.url : 'unknown';\\n    const method = request ? request.method : 'unknown';\\n    \\n    // Determine status code\\n    let status = 500;\\n    if (error.status) {\\n      status = error.status;\\n    } else if (error.name === 'ValidationError') {\\n      status = 400;\\n    } else if (error.name === 'UnauthorizedError') {\\n      status = 401;\\n    } else if (error.name === 'ForbiddenError') {\\n      status = 403;\\n    } else if (error.name === 'NotFoundError') {\\n      status = 404;\\n    } else if (error.name === 'ConflictError') {\\n      status = 409;\\n    } else if (error.name === 'TooManyRequestsError') {\\n      status = 429;\\n    }\\n\\n    // Map custom error codes if configured\\n    if (state.config.errorCodeMapping[error.code]) {\\n      status = state.config.errorCodeMapping[error.code];\\n    }\\n\\n    // Truncate error message if too long\\n    let message = error.message || 'Internal Server Error';\\n    if (message.length > state.config.maxErrorLength) {\\n      message = `${message.substring(0, state.config.maxErrorLength)  }...`;\\n    }\\n\\n    // Base response\\n    const response = {\\n      error: true,\\n      message,\\n      status,\\n      timestamp,\\n      requestId: generateRequestId(),\\n      path: url\\n    };\\n\\n    // Add error code if present\\n    if (error.code) {\\n      response.code = error.code;\\n    }\\n\\n    // Add error type\\n    if (error.name && error.name !== 'Error') {\\n      response.type = error.name;\\n    }\\n\\n    // Add stack trace in development mode\\n    if (state.config.enableStackTrace && state.config.enableDetailedErrors) {\\n      response.stack = error.stack;\\n    }\\n\\n    // Add validation details if present\\n    if (error.details || error.validation) {\\n      response.details = error.details || error.validation;\\n    }\\n\\n    // Add context if present\\n    if (error.context) {\\n      response.context = error.context;\\n    }\\n\\n    return { response, status };\\n  };\\n\\n  /**\\n   * Generate unique request ID for error tracking\\n   * @returns {string} Request ID\\n   */\\n  const generateRequestId = () => {\\n    const timestamp = Date.now();\\n    const random = Math.random().toString(36).substring(2, 15);\\n    return `err_${timestamp}_${random}`;\\n  };\\n\\n  /**\\n   * Log error with context\\n   * @param {Error} error - Error object\\n   * @param {Request} request - HTTP request\\n   * @param {Object} errorResponse - Formatted error response\\n   */\\n  const logError = (error, request, errorResponse) => {\\n    if (!state.config.enableErrorLogging) return;\\n    \\n    // Skip excluded errors\\n    if (state.config.excludeFromLogging.includes(error.name)) {\\n      return;\\n    }\\n\\n    // Skip logging for certain status codes (like 404)\\n    if (errorResponse.status === 404) {\\n      return;\\n    }\\n\\n    const logData = {\\n      timestamp: new Date().toISOString(),\\n      requestId: errorResponse.requestId,\\n      error: {\\n        name: error.name,\\n        message: error.message,\\n        code: error.code,\\n        stack: error.stack\\n      },\\n      request: {\\n        method: request ? request.method : 'unknown',\\n        url: request ? request.url : 'unknown',\\n        userAgent: request ? request.headers.get('user-agent') : null,\\n        origin: request ? request.headers.get('origin') : null\\n      },\\n      response: {\\n        status: errorResponse.status\\n      }\\n    };\\n\\n    // Log based on severity\\n    if (errorResponse.status >= 500) {\\n      console.error('🚨 Server Error:', JSON.stringify(logData, null, 2));\\n    } else if (errorResponse.status >= 400) {\\n      console.warn('⚠️  Client Error:', logData.requestId, error.message);\\n    } else {\\n      console.log('ℹ️  Error:', logData.requestId, error.message);\\n    }\\n  };\\n\\n  /**\\n   * Update error statistics\\n   * @param {Error} error - Error object\\n   * @param {number} status - HTTP status code\\n   */\\n  const updateStatistics = (error, status) => {\\n    state.stats.totalErrors++;\\n    state.stats.lastError = {\\n      name: error.name,\\n      message: error.message,\\n      status,\\n      timestamp: Date.now()\\n    };\\n\\n    // Track by error type\\n    const errorType = error.name || 'UnknownError';\\n    state.stats.errorsByType.set(\\n      errorType, \\n      (state.stats.errorsByType.get(errorType) || 0) + 1\\n    );\\n\\n    // Track by status code\\n    state.stats.errorsByStatus.set(\\n      status, \\n      (state.stats.errorsByStatus.get(status) || 0) + 1\\n    );\\n  };\\n\\n  /**\\n   * Main error handling middleware\\n   * @param {Error} error - Error to handle\\n   * @param {Request} request - HTTP request\\n   * @returns {Response} Error response\\n   */\\n  const handleError = (error, request) => {\\n    try {\\n      const { response, status } = formatErrorResponse(error, request);\\n      \\n      // Log the error\\n      logError(error, request, response);\\n      \\n      // Update statistics\\n      updateStatistics(error, status);\\n\\n      // Create HTTP response\\n      return new Response(JSON.stringify(response), {\\n        status,\\n        headers: {\\n          'Content-Type': 'application/json',\\n          'X-Error-ID': response.requestId,\\n          'X-Content-Type-Options': 'nosniff'\\n        }\\n      });\\n      \\n    } catch (handlingError) {\\n      console.error('🔥 Error in error handler:', handlingError);\\n      \\n      // Fallback response\\n      return new Response(JSON.stringify({\\n        error: true,\\n        message: 'Internal error processing request',\\n        timestamp: Date.now(),\\n        status: 500\\n      }), {\\n        status: 500,\\n        headers: {\\n          'Content-Type': 'application/json'\\n        }\\n      });\\n    }\\n  };\\n\\n  /**\\n   * Async error wrapper for middleware chains\\n   * @param {Function} handler - Handler function to wrap\\n   * @returns {Function} Wrapped handler\\n   */\\n  const asyncErrorWrapper = (handler) => {\\n    return async (request, ...args) => {\\n      try {\\n        return await handler(request, ...args);\\n      } catch (error) {\\n        return handleError(error, request);\\n      }\\n    };\\n  };\\n\\n  /**\\n   * Create standard error types\\n   */\\n  const createError = {\\n    validation: (message, details = null) => {\\n      const error = new Error(message);\\n      error.name = 'ValidationError';\\n      error.status = 400;\\n      if (details) error.details = details;\\n      return error;\\n    },\\n    \\n    unauthorized: (message = 'Unauthorized') => {\\n      const error = new Error(message);\\n      error.name = 'UnauthorizedError';\\n      error.status = 401;\\n      return error;\\n    },\\n    \\n    forbidden: (message = 'Forbidden') => {\\n      const error = new Error(message);\\n      error.name = 'ForbiddenError';\\n      error.status = 403;\\n      return error;\\n    },\\n    \\n    notFound: (message = 'Not Found') => {\\n      const error = new Error(message);\\n      error.name = 'NotFoundError';\\n      error.status = 404;\\n      return error;\\n    },\\n    \\n    conflict: (message = 'Conflict') => {\\n      const error = new Error(message);\\n      error.name = 'ConflictError';\\n      error.status = 409;\\n      return error;\\n    },\\n    \\n    tooManyRequests: (message = 'Too Many Requests') => {\\n      const error = new Error(message);\\n      error.name = 'TooManyRequestsError';\\n      error.status = 429;\\n      return error;\\n    },\\n    \\n    internal: (message = 'Internal Server Error', context = null) => {\\n      const error = new Error(message);\\n      error.name = 'InternalError';\\n      error.status = 500;\\n      if (context) error.context = context;\\n      return error;\\n    }\\n  };\\n\\n  /**\\n   * Get error statistics\\n   * @returns {Object} Error statistics\\n   */\\n  const getStatistics = () => {\\n    const uptime = Date.now() - state.stats.startTime;\\n    \\n    return {\\n      totalErrors: state.stats.totalErrors,\\n      errorRate: state.stats.totalErrors / Math.max(uptime / 1000 / 60, 1), // errors per minute\\n      errorsByType: Array.from(state.stats.errorsByType.entries()),\\n      errorsByStatus: Array.from(state.stats.errorsByStatus.entries()),\\n      lastError: state.stats.lastError,\\n      uptime,\\n      topErrorTypes: Array.from(state.stats.errorsByType.entries())\\n        .sort(([,a], [,b]) => b - a)\\n        .slice(0, 5),\\n      timestamp: Date.now()\\n    };\\n  };\\n\\n  /**\\n   * Reset error statistics\\n   */\\n  const resetStatistics = () => {\\n    state.stats = {\\n      totalErrors: 0,\\n      errorsByType: new Map(),\\n      errorsByStatus: new Map(),\\n      lastError: null,\\n      startTime: Date.now()\\n    };\\n    console.log('📊 Error statistics reset');\\n  };\\n\\n  /**\\n   * Health check for error handling system\\n   * @returns {Object} Health status\\n   */\\n  const getHealthStatus = () => {\\n    const stats = getStatistics();\\n    const recentErrorRate = stats.errorRate;\\n    const isHealthy = recentErrorRate < 10; // Less than 10 errors per minute\\n\\n    return {\\n      status: isHealthy ? 'healthy' : 'degraded',\\n      errorRate: Math.round(recentErrorRate * 100) / 100,\\n      totalErrors: stats.totalErrors,\\n      lastError: stats.lastError,\\n      issues: isHealthy ? [] : ['High error rate detected']\\n    };\\n  };\\n\\n  return {\\n    // Core error handling\\n    handleError,\\n    asyncErrorWrapper,\\n    \\n    // Error creation utilities\\n    createError,\\n    \\n    // Monitoring\\n    getStatistics,\\n    resetStatistics,\\n    getHealthStatus,\\n    \\n    // Configuration\\n    updateConfig: (updates) => {\\n      state.config = { ...state.config, ...updates };\\n      console.log('🔧 Error handler configuration updated');\\n    },\\n    getConfig: () => ({ ...state.config })\\n  };\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}},{\"ruleId\":\"no-process-exit\",\"replacedBy\":[\"n/no-process-exit\"],\"info\":{\"message\":\"Node.js rules were moved out of ESLint core.\",\"url\":\"https://eslint.org/docs/latest/use/migrating-to-7.0.0#deprecate-node-rules\",\"deprecatedSince\":\"7.0.0\",\"availableUntil\":null,\"replacedBy\":[{\"message\":\"eslint-plugin-n now maintains deprecated Node.js-related rules.\",\"plugin\":{\"name\":\"eslint-plugin-n\",\"url\":\"https://github.com/eslint-community/eslint-plugin-n\"},\"rule\":{\"name\":\"no-process-exit\",\"url\":\"https://github.com/eslint-community/eslint-plugin-n/tree/master/docs/rules/no-process-exit.md\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/services/api/middleware/index.js\",\"messages\":[],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}},{\"ruleId\":\"no-process-exit\",\"replacedBy\":[\"n/no-process-exit\"],\"info\":{\"message\":\"Node.js rules were moved out of ESLint core.\",\"url\":\"https://eslint.org/docs/latest/use/migrating-to-7.0.0#deprecate-node-rules\",\"deprecatedSince\":\"7.0.0\",\"availableUntil\":null,\"replacedBy\":[{\"message\":\"eslint-plugin-n now maintains deprecated Node.js-related rules.\",\"plugin\":{\"name\":\"eslint-plugin-n\",\"url\":\"https://github.com/eslint-community/eslint-plugin-n\"},\"rule\":{\"name\":\"no-process-exit\",\"url\":\"https://github.com/eslint-community/eslint-plugin-n/tree/master/docs/rules/no-process-exit.md\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/services/api/middleware/rate-limiting-algorithms.js\",\"messages\":[{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '/'. Use parentheses to clarify the intended order of operations.\",\"line\":126,\"column\":49,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":126,\"endColumn\":50},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '/'. Use parentheses to clarify the intended order of operations.\",\"line\":126,\"column\":65,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":126,\"endColumn\":66}],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":2,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Rate limiting algorithms for different strategies\\n */\\n\\n/**\\n * Fixed window rate limiting algorithm\\n * @param {Map} storage - Storage for fixed window data\\n * @param {string} key - Client identifier\\n * @param {Object} routeConfig - Route-specific config\\n * @returns {Object} Rate limit result\\n */\\nexport const checkFixedWindow = (storage, key, routeConfig) => {\\n  const now = Date.now();\\n  const windowStart = Math.floor(now / routeConfig.windowMs) * routeConfig.windowMs;\\n  const resetTime = windowStart + routeConfig.windowMs;\\n  \\n  if (!storage.has(key)) {\\n    storage.set(key, { count: 0, resetTime });\\n  }\\n  \\n  const record = storage.get(key);\\n  \\n  // Reset if window has passed\\n  if (now >= record.resetTime) {\\n    record.count = 0;\\n    record.resetTime = resetTime;\\n  }\\n  \\n  const allowed = record.count < routeConfig.maxRequests;\\n  const remaining = Math.max(0, routeConfig.maxRequests - record.count - (allowed ? 1 : 0));\\n  \\n  if (allowed) {\\n    record.count++;\\n  }\\n  \\n  return {\\n    allowed,\\n    limit: routeConfig.maxRequests,\\n    remaining,\\n    resetTime,\\n    retryAfter: Math.ceil((resetTime - now) / 1000)\\n  };\\n};\\n\\n/**\\n * Sliding window rate limiting algorithm\\n * @param {Map} storage - Storage for sliding window data\\n * @param {string} key - Client identifier\\n * @param {Object} routeConfig - Route-specific config\\n * @returns {Object} Rate limit result\\n */\\nexport const checkSlidingWindow = (storage, key, routeConfig) => {\\n  const now = Date.now();\\n  const windowStart = now - routeConfig.windowMs;\\n  \\n  if (!storage.has(key)) {\\n    storage.set(key, { requests: [] });\\n  }\\n  \\n  const record = storage.get(key);\\n  \\n  // Remove old requests outside the window\\n  record.requests = record.requests.filter(timestamp => timestamp > windowStart);\\n  \\n  const currentRequests = record.requests.length;\\n  const allowed = currentRequests < routeConfig.maxRequests;\\n  \\n  if (allowed) {\\n    record.requests.push(now);\\n  }\\n  \\n  // Calculate when the oldest request will expire\\n  const oldestRequest = record.requests[0] || now;\\n  const resetTime = oldestRequest + routeConfig.windowMs;\\n  const retryAfter = Math.ceil((resetTime - now) / 1000);\\n  \\n  return {\\n    allowed,\\n    limit: routeConfig.maxRequests,\\n    remaining: Math.max(0, routeConfig.maxRequests - currentRequests - (allowed ? 1 : 0)),\\n    resetTime,\\n    retryAfter: Math.max(1, retryAfter)\\n  };\\n};\\n\\n/**\\n * Token bucket rate limiting algorithm\\n * @param {Map} storage - Storage for token bucket data\\n * @param {string} key - Client identifier\\n * @param {Object} routeConfig - Route-specific config\\n * @returns {Object} Rate limit result\\n */\\nexport const checkTokenBucket = (storage, key, routeConfig) => {\\n  const now = Date.now();\\n  const refillRate = routeConfig.maxRequests / (routeConfig.windowMs / 1000); // tokens per second\\n  const bucketSize = routeConfig.maxRequests + Math.floor(routeConfig.maxRequests * routeConfig.burstAllowance);\\n  \\n  if (!storage.has(key)) {\\n    storage.set(key, { \\n      tokens: bucketSize, \\n      lastRefill: now \\n    });\\n  }\\n  \\n  const bucket = storage.get(key);\\n  \\n  // Refill tokens based on time passed\\n  const timePassed = (now - bucket.lastRefill) / 1000;\\n  const tokensToAdd = timePassed * refillRate;\\n  bucket.tokens = Math.min(bucketSize, bucket.tokens + tokensToAdd);\\n  bucket.lastRefill = now;\\n  \\n  const allowed = bucket.tokens >= 1;\\n  \\n  if (allowed) {\\n    bucket.tokens -= 1;\\n  }\\n  \\n  // Calculate retry after based on when next token will be available\\n  const retryAfter = allowed ? 0 : Math.ceil((1 - bucket.tokens) / refillRate);\\n  \\n  return {\\n    allowed,\\n    limit: routeConfig.maxRequests,\\n    remaining: Math.floor(bucket.tokens),\\n    resetTime: now + (routeConfig.windowMs * (1 - bucket.tokens / bucketSize)),\\n    retryAfter\\n  };\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}},{\"ruleId\":\"no-process-exit\",\"replacedBy\":[\"n/no-process-exit\"],\"info\":{\"message\":\"Node.js rules were moved out of ESLint core.\",\"url\":\"https://eslint.org/docs/latest/use/migrating-to-7.0.0#deprecate-node-rules\",\"deprecatedSince\":\"7.0.0\",\"availableUntil\":null,\"replacedBy\":[{\"message\":\"eslint-plugin-n now maintains deprecated Node.js-related rules.\",\"plugin\":{\"name\":\"eslint-plugin-n\",\"url\":\"https://github.com/eslint-community/eslint-plugin-n\"},\"rule\":{\"name\":\"no-process-exit\",\"url\":\"https://github.com/eslint-community/eslint-plugin-n/tree/master/docs/rules/no-process-exit.md\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/services/api/middleware/rate-limiting-config.js\",\"messages\":[],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}},{\"ruleId\":\"no-process-exit\",\"replacedBy\":[\"n/no-process-exit\"],\"info\":{\"message\":\"Node.js rules were moved out of ESLint core.\",\"url\":\"https://eslint.org/docs/latest/use/migrating-to-7.0.0#deprecate-node-rules\",\"deprecatedSince\":\"7.0.0\",\"availableUntil\":null,\"replacedBy\":[{\"message\":\"eslint-plugin-n now maintains deprecated Node.js-related rules.\",\"plugin\":{\"name\":\"eslint-plugin-n\",\"url\":\"https://github.com/eslint-community/eslint-plugin-n\"},\"rule\":{\"name\":\"no-process-exit\",\"url\":\"https://github.com/eslint-community/eslint-plugin-n/tree/master/docs/rules/no-process-exit.md\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/services/api/middleware/rate-limiting-stats.js\",\"messages\":[],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}},{\"ruleId\":\"no-process-exit\",\"replacedBy\":[\"n/no-process-exit\"],\"info\":{\"message\":\"Node.js rules were moved out of ESLint core.\",\"url\":\"https://eslint.org/docs/latest/use/migrating-to-7.0.0#deprecate-node-rules\",\"deprecatedSince\":\"7.0.0\",\"availableUntil\":null,\"replacedBy\":[{\"message\":\"eslint-plugin-n now maintains deprecated Node.js-related rules.\",\"plugin\":{\"name\":\"eslint-plugin-n\",\"url\":\"https://github.com/eslint-community/eslint-plugin-n\"},\"rule\":{\"name\":\"no-process-exit\",\"url\":\"https://github.com/eslint-community/eslint-plugin-n/tree/master/docs/rules/no-process-exit.md\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/services/api/middleware/rate-limiting-storage.js\",\"messages\":[],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}},{\"ruleId\":\"no-process-exit\",\"replacedBy\":[\"n/no-process-exit\"],\"info\":{\"message\":\"Node.js rules were moved out of ESLint core.\",\"url\":\"https://eslint.org/docs/latest/use/migrating-to-7.0.0#deprecate-node-rules\",\"deprecatedSince\":\"7.0.0\",\"availableUntil\":null,\"replacedBy\":[{\"message\":\"eslint-plugin-n now maintains deprecated Node.js-related rules.\",\"plugin\":{\"name\":\"eslint-plugin-n\",\"url\":\"https://github.com/eslint-community/eslint-plugin-n\"},\"rule\":{\"name\":\"no-process-exit\",\"url\":\"https://github.com/eslint-community/eslint-plugin-n/tree/master/docs/rules/no-process-exit.md\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/services/api/middleware/rate-limiting.js\",\"messages\":[],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}},{\"ruleId\":\"no-process-exit\",\"replacedBy\":[\"n/no-process-exit\"],\"info\":{\"message\":\"Node.js rules were moved out of ESLint core.\",\"url\":\"https://eslint.org/docs/latest/use/migrating-to-7.0.0#deprecate-node-rules\",\"deprecatedSince\":\"7.0.0\",\"availableUntil\":null,\"replacedBy\":[{\"message\":\"eslint-plugin-n now maintains deprecated Node.js-related rules.\",\"plugin\":{\"name\":\"eslint-plugin-n\",\"url\":\"https://github.com/eslint-community/eslint-plugin-n\"},\"rule\":{\"name\":\"no-process-exit\",\"url\":\"https://github.com/eslint-community/eslint-plugin-n/tree/master/docs/rules/no-process-exit.md\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/services/api/routes/device-routes.js\",\"messages\":[{\"ruleId\":\"consistent-return\",\"severity\":1,\"message\":\"Expected to return a value at the end of async arrow function.\",\"line\":81,\"column\":66,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"missingReturn\",\"endLine\":81,\"endColumn\":68}],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":1,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Device discovery and management routes for media streaming API\\n */\\n\\nimport { createMediaStreamingPipeline } from '../../../features/media-streaming/media-streaming-pipeline.js';\\n\\nexport const setupDeviceRoutes = (app, state) => {\\n  // Get all available devices\\n  app.get('/api/media/devices', async (req, res) => {\\n    try {\\n      const { refresh = false, capabilities = true } = req.query;\\n      \\n      const result = await state.deviceDiscoveryPipeline.process({\\n        forceRefresh: refresh === 'true',\\n        includeCapabilities: capabilities === 'true'\\n      });\\n\\n      if (result.status === 'success') {\\n        res.json({\\n          success: true,\\n          devices: result.data.devices,\\n          networkInfo: result.data.networkInfo,\\n          statistics: result.data.statistics,\\n          timestamp: result.timestamp\\n        });\\n      } else {\\n        res.status(500).json({\\n          success: false,\\n          error: result.error.message\\n        });\\n      }\\n    } catch (error) {\\n      console.error('Device discovery failed:', error);\\n      res.status(500).json({\\n        success: false,\\n        error: error.message\\n      });\\n    }\\n  });\\n\\n  // Get specific device details\\n  app.get('/api/media/devices/:deviceId', async (req, res) => {\\n    try {\\n      const { deviceId } = req.params;\\n      \\n      // Get all devices first\\n      const result = await state.deviceDiscoveryPipeline.process({\\n        forceRefresh: false,\\n        includeCapabilities: true\\n      });\\n\\n      if (result.status === 'success') {\\n        const device = result.data.devices.find(d => d.id === deviceId);\\n        if (device) {\\n          res.json({\\n            success: true,\\n            device\\n          });\\n        } else {\\n          res.status(404).json({\\n            success: false,\\n            error: 'Device not found'\\n          });\\n        }\\n      } else {\\n        res.status(500).json({\\n          success: false,\\n          error: result.error.message\\n        });\\n      }\\n    } catch (error) {\\n      console.error('Device lookup failed:', error);\\n      res.status(500).json({\\n        success: false,\\n        error: error.message\\n      });\\n    }\\n  });\\n\\n  // Test device functionality\\n  app.post('/api/media/devices/:deviceId/test', async (req, res) => {\\n    try {\\n      const { deviceId } = req.params;\\n      const { duration = 5000 } = req.body;\\n\\n      // Get device info\\n      const discoveryResult = await state.deviceDiscoveryPipeline.process({});\\n      if (discoveryResult.status !== 'success') {\\n        throw new Error('Failed to discover devices');\\n      }\\n\\n      const device = discoveryResult.data.devices.find(d => d.id === deviceId);\\n      if (!device) {\\n        return res.status(404).json({\\n          success: false,\\n          error: 'Device not found'\\n        });\\n      }\\n\\n      // Create temporary streaming pipeline for testing\\n      const testPipeline = createMediaStreamingPipeline(device, {\\n        defaultQuality: 'low',\\n        bufferSize: 10\\n      });\\n\\n      await testPipeline.initialize();\\n\\n      // Start streaming briefly to test\\n      const startResult = await testPipeline.process({\\n        action: 'START_STREAM'\\n      });\\n\\n      if (startResult.status === 'success') {\\n        // Wait for specified duration\\n        await new Promise(resolve => setTimeout(resolve, Math.min(duration, 10000)));\\n\\n        // Stop streaming\\n        await testPipeline.process({ action: 'STOP_STREAM' });\\n        \\n        // Get stats\\n        const stats = testPipeline.getStats();\\n        \\n        await testPipeline.cleanup();\\n\\n        res.json({\\n          success: true,\\n          message: 'Device test completed successfully',\\n          testResults: {\\n            device: device.label,\\n            duration,\\n            stats\\n          }\\n        });\\n      } else {\\n        await testPipeline.cleanup();\\n        res.status(400).json({\\n          success: false,\\n          error: startResult.error.message\\n        });\\n      }\\n\\n    } catch (error) {\\n      console.error('Device test failed:', error);\\n      res.status(500).json({\\n        success: false,\\n        error: error.message\\n      });\\n    }\\n  });\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}},{\"ruleId\":\"no-process-exit\",\"replacedBy\":[\"n/no-process-exit\"],\"info\":{\"message\":\"Node.js rules were moved out of ESLint core.\",\"url\":\"https://eslint.org/docs/latest/use/migrating-to-7.0.0#deprecate-node-rules\",\"deprecatedSince\":\"7.0.0\",\"availableUntil\":null,\"replacedBy\":[{\"message\":\"eslint-plugin-n now maintains deprecated Node.js-related rules.\",\"plugin\":{\"name\":\"eslint-plugin-n\",\"url\":\"https://github.com/eslint-community/eslint-plugin-n\"},\"rule\":{\"name\":\"no-process-exit\",\"url\":\"https://github.com/eslint-community/eslint-plugin-n/tree/master/docs/rules/no-process-exit.md\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/services/api/routes/distribution.js\",\"messages\":[{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'middlewareSystem' is defined but never used. Allowed unused args must match /^_/u.\",\"line\":12,\"column\":3,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":12,\"endColumn\":19,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"middlewareSystem\"},\"fix\":{\"range\":[281,301],\"text\":\"\"},\"desc\":\"Remove unused variable 'middlewareSystem'.\"}]},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'request' is defined but never used. Allowed unused args must match /^_/u.\",\"line\":20,\"column\":60,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":20,\"endColumn\":67,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"request\"},\"fix\":{\"range\":[481,488],\"text\":\"\"},\"desc\":\"Remove unused variable 'request'.\"}]},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'request' is defined but never used. Allowed unused args must match /^_/u.\",\"line\":32,\"column\":63,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":32,\"endColumn\":70,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"request\"},\"fix\":{\"range\":[825,832],\"text\":\"\"},\"desc\":\"Remove unused variable 'request'.\"}]},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'request' is defined but never used. Allowed unused args must match /^_/u.\",\"line\":67,\"column\":61,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":67,\"endColumn\":68,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"request\"},\"fix\":{\"range\":[1890,1897],\"text\":\"\"},\"desc\":\"Remove unused variable 'request'.\"}]},{\"ruleId\":\"prefer-destructuring\",\"severity\":1,\"message\":\"Use array destructuring.\",\"line\":86,\"column\":13,\"nodeType\":\"VariableDeclarator\",\"messageId\":\"preferDestructuring\",\"endLine\":86,\"endColumn\":33},{\"ruleId\":\"prefer-destructuring\",\"severity\":1,\"message\":\"Use array destructuring.\",\"line\":107,\"column\":13,\"nodeType\":\"VariableDeclarator\",\"messageId\":\"preferDestructuring\",\"endLine\":107,\"endColumn\":33},{\"ruleId\":\"prefer-destructuring\",\"severity\":1,\"message\":\"Use array destructuring.\",\"line\":133,\"column\":13,\"nodeType\":\"VariableDeclarator\",\"messageId\":\"preferDestructuring\",\"endLine\":133,\"endColumn\":33},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'request' is defined but never used. Allowed unused args must match /^_/u.\",\"line\":192,\"column\":63,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":192,\"endColumn\":70,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"request\"},\"fix\":{\"range\":[5412,5419],\"text\":\"\"},\"desc\":\"Remove unused variable 'request'.\"}]}],\"suppressedMessages\":[],\"errorCount\":5,\"fatalErrorCount\":0,\"warningCount\":3,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Distribution System Routes Module\\n * Handles data distribution, streaming, and client management\\n */\\n\\nexport const createDistributionRoutes = ({\\n  getDistributionSystem,\\n  getDistributionOverallStatus,\\n  createDistributionStream,\\n  distributionStreams,\\n  distributionClients,\\n  middlewareSystem,\\n  createJSONResponse,\\n  createErrorResponse,\\n  generateSecureId\\n}) => {\\n  const routes = [];\\n\\n  // Distribution status\\n  routes.push(['GET', '^/api/distribution/status$', async (request) => {\\n    try {\\n      \\n      const status = getDistributionOverallStatus();\\n      return createJSONResponse(status, 200);\\n    } catch (error) {\\n      \\n      return createErrorResponse(`Distribution status error: ${error.message}`, 500);\\n    }\\n  }]);\\n\\n  // Service discovery\\n  routes.push(['GET', '^/api/distribution/discovery$', async (request) => {\\n    try {\\n      \\n      return createJSONResponse({\\n        services: ['udp', 'websocket', 'mqtt', 'sse'],\\n        timestamp: Date.now()\\n      }, 200);\\n    } catch (error) {\\n      \\n      return createErrorResponse(`Discovery error: ${error.message}`, 500);\\n    }\\n  }]);\\n\\n  // Create new distribution stream\\n  routes.push(['POST', '^/api/distribution/streams$', async (request) => {\\n    try {\\n      const body = await request.json();\\n      \\n      \\n      const stream = await createDistributionStream(body);\\n      const host = request.headers.get('host') || 'localhost:3000';\\n      \\n      return createJSONResponse({\\n        stream_id: stream.id,\\n        data: stream,\\n        websocket_status_url: `ws://${host}/ws/distribution/events?stream=${stream.id}`,\\n        message: 'Distribution stream created successfully'\\n      }, 200);\\n    } catch (error) {\\n      \\n      return createErrorResponse(`Failed to create stream: ${error.message}`, 400);\\n    }\\n  }]);\\n\\n  // Get all distribution streams\\n  routes.push(['GET', '^/api/distribution/streams$', async (request) => {\\n    try {\\n      \\n      const streams = Array.from(distributionStreams.values());\\n      \\n      return createJSONResponse({\\n        streams,\\n        total: streams.length,\\n        active: streams.filter(s => s.status === 'active').length\\n      }, 200);\\n    } catch (error) {\\n      \\n      return createErrorResponse(`Failed to get streams: ${error.message}`, 500);\\n    }\\n  }]);\\n\\n  // Get specific distribution stream\\n  routes.push(['GET', '^/api/distribution/streams/([^/]+)$', async (request, params) => {\\n    try {\\n      const streamId = params[0];\\n      \\n      \\n      const stream = distributionStreams.get(streamId);\\n      if (!stream) {\\n        return createErrorResponse('Stream not found', 404);\\n      }\\n      \\n      return createJSONResponse({\\n        stream,\\n        clients: Array.from(distributionClients.values()).filter(c => c.streams.includes(streamId))\\n      }, 200);\\n    } catch (error) {\\n      \\n      return createErrorResponse(`Failed to get stream: ${error.message}`, 500);\\n    }\\n  }]);\\n\\n  // Update distribution stream\\n  routes.push(['PUT', '^/api/distribution/streams/([^/]+)$', async (request, params) => {\\n    try {\\n      const streamId = params[0];\\n      const body = await request.json();\\n      \\n      \\n      const stream = distributionStreams.get(streamId);\\n      if (!stream) {\\n        return createErrorResponse('Stream not found', 404);\\n      }\\n      \\n      // Update stream configuration\\n      Object.assign(stream.config, body);\\n      stream.updated_at = Date.now();\\n      \\n      return createJSONResponse({\\n        stream,\\n        message: 'Stream updated successfully'\\n      }, 200);\\n    } catch (error) {\\n      \\n      return createErrorResponse(`Failed to update stream: ${error.message}`, 400);\\n    }\\n  }]);\\n\\n  // Delete distribution stream\\n  routes.push(['DELETE', '^/api/distribution/streams/([^/]+)$', async (request, params) => {\\n    try {\\n      const streamId = params[0];\\n      \\n      \\n      const stream = distributionStreams.get(streamId);\\n      if (!stream) {\\n        return createErrorResponse('Stream not found', 404);\\n      }\\n      \\n      // Stop stream and remove\\n      stream.status = 'stopped';\\n      distributionStreams.delete(streamId);\\n      \\n      // Remove from clients\\n      for (const client of distributionClients.values()) {\\n        const index = client.streams.indexOf(streamId);\\n        if (index > -1) {\\n          client.streams.splice(index, 1);\\n        }\\n      }\\n      \\n      return createJSONResponse({\\n        message: 'Stream deleted successfully'\\n      }, 200);\\n    } catch (error) {\\n      \\n      return createErrorResponse(`Failed to delete stream: ${error.message}`, 500);\\n    }\\n  }]);\\n\\n  // Register distribution client\\n  routes.push(['POST', '^/api/distribution/clients$', async (request) => {\\n    try {\\n      const body = await request.json();\\n      \\n      \\n      const clientId = generateSecureId('client');\\n      const client = {\\n        id: clientId,\\n        ...body,\\n        streams: body.streams || [],\\n        registered_at: Date.now(),\\n        last_seen: Date.now(),\\n        status: 'active'\\n      };\\n      \\n      distributionClients.set(clientId, client);\\n      \\n      return createJSONResponse({\\n        client_id: clientId,\\n        client,\\n        message: 'Client registered successfully'\\n      }, 200);\\n    } catch (error) {\\n      \\n      return createErrorResponse(`Failed to register client: ${error.message}`, 400);\\n    }\\n  }]);\\n\\n  // Get distribution templates\\n  routes.push(['GET', '^/api/distribution/templates$', async (request) => {\\n    try {\\n      \\n      const { distributionPresets } = await getDistributionSystem();\\n      \\n      return createJSONResponse({\\n        templates: distributionPresets || {},\\n        timestamp: Date.now()\\n      }, 200);\\n    } catch (error) {\\n      \\n      return createErrorResponse(`Failed to get templates: ${error.message}`, 500);\\n    }\\n  }]);\\n\\n  return routes;\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}},{\"ruleId\":\"no-process-exit\",\"replacedBy\":[\"n/no-process-exit\"],\"info\":{\"message\":\"Node.js rules were moved out of ESLint core.\",\"url\":\"https://eslint.org/docs/latest/use/migrating-to-7.0.0#deprecate-node-rules\",\"deprecatedSince\":\"7.0.0\",\"availableUntil\":null,\"replacedBy\":[{\"message\":\"eslint-plugin-n now maintains deprecated Node.js-related rules.\",\"plugin\":{\"name\":\"eslint-plugin-n\",\"url\":\"https://github.com/eslint-community/eslint-plugin-n\"},\"rule\":{\"name\":\"no-process-exit\",\"url\":\"https://github.com/eslint-community/eslint-plugin-n/tree/master/docs/rules/no-process-exit.md\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/services/api/routes/emotion.js\",\"messages\":[{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'middlewareSystem' is defined but never used. Allowed unused args must match /^_/u.\",\"line\":10,\"column\":3,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":10,\"endColumn\":19,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"middlewareSystem\"},\"fix\":{\"range\":[191,211],\"text\":\"\"},\"desc\":\"Remove unused variable 'middlewareSystem'.\"}]},{\"ruleId\":\"prefer-destructuring\",\"severity\":1,\"message\":\"Use array destructuring.\",\"line\":61,\"column\":13,\"nodeType\":\"VariableDeclarator\",\"messageId\":\"preferDestructuring\",\"endLine\":61,\"endColumn\":34},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'request' is defined but never used. Allowed unused args must match /^_/u.\",\"line\":111,\"column\":55,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":111,\"endColumn\":62,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"request\"},\"fix\":{\"range\":[3785,3792],\"text\":\"\"},\"desc\":\"Remove unused variable 'request'.\"}]}],\"suppressedMessages\":[],\"errorCount\":2,\"fatalErrorCount\":0,\"warningCount\":1,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Emotion Analysis Routes Module\\n * Handles emotion detection and analysis endpoints\\n */\\n\\nexport const createEmotionRoutes = ({\\n  orchestrator,\\n  initializeEmotionPipeline,\\n  decodeFrame,\\n  middlewareSystem,\\n  createJSONResponse,\\n  createErrorResponse\\n}) => {\\n  const routes = [];\\n\\n  // Emotion analysis endpoint\\n  routes.push(['POST', '^/api/emotion/analyze$', async (request) => {\\n    try {\\n      const body = await request.json();\\n      \\n      \\n      if (!body.frame && !body.image) {\\n        return createErrorResponse('Frame or image data required', 400);\\n      }\\n\\n      // Lazy load emotion pipeline if needed\\n      await initializeEmotionPipeline();\\n      \\n      const emotionPipeline = orchestrator.getPipeline('emotion-analysis');\\n      if (!emotionPipeline) {\\n        return createErrorResponse('Emotion analysis pipeline failed to load', 500);\\n      }\\n\\n      const frameData = decodeFrame(body.frame || body.image);\\n      console.log('🖼️ Decoded frame data:', { width: frameData?.width, height: frameData?.height, hasData: !!frameData?.data });\\n      \\n      const result = await emotionPipeline.process(frameData);\\n      \\n      console.log('🔍 RAW pipeline result:', JSON.stringify(result, null, 2));\\n      \\n      // Handle different result formats\\n      const faces = result.data?.faces || result.faces || [];\\n      console.log('🔍 faces array:', faces);\\n      console.log('🔍 First face:', faces[0]);\\n      \\n      if (faces.length === 0) {\\n        return createJSONResponse({\\n          success: true,\\n          faces: [],\\n          message: 'No faces detected',\\n          debug: {\\n            hasResult: !!result,\\n            hasData: !!result.data,\\n            hasEmotion: false,\\n            emotionKeys: []\\n          }\\n        }, 200);\\n      }\\n      \\n      // Extract emotion data from pipeline result\\n      const faceResult = faces[0];\\n      console.log('🔍 faceResult:', faceResult);\\n      console.log('🔍 faceResult.emotion:', faceResult?.emotion);\\n      \\n      if (!faceResult || !faceResult.emotion) {\\n        console.log('❌ No valid faceResult or emotion, returning fallback');\\n        return createJSONResponse({\\n          emotions: {\\n            happy: 0.1, sad: 0.1, angry: 0.1, fearful: 0.1, \\n            disgusted: 0.1, surprised: 0.1, neutral: 0.5\\n          },\\n          dominant_emotion: { emotion: 'neutral', confidence: 0.5 },\\n          confidence: 0.5,\\n          faces_detected: faces.length,\\n          message: 'Emotion data not available, returning neutral fallback'\\n        }, 200);\\n      } else {\\n        // Build response with emotion probabilities\\n        const emotions = faceResult.emotion.probabilities || faceResult.emotion.emotions;\\n        console.log('🔍 Building response - emotions:', emotions);\\n        console.log('🔍 Building response - faceResult.emotion:', faceResult.emotion);\\n        \\n        return createJSONResponse({\\n          emotions,\\n          dominant_emotion: {\\n            emotion: faceResult.emotion.emotion,\\n            confidence: faceResult.emotion.confidence\\n          },\\n          confidence: faceResult.emotion.confidence,\\n          valence: faceResult.emotion.valence,\\n          arousal: faceResult.emotion.arousal,\\n          faces_detected: faces.length,\\n          timestamp: Date.now(),\\n          debug: {\\n            hasEmotion: true,\\n            emotionKeys: Object.keys(emotions || {}),\\n            rawEmotion: faceResult.emotion\\n          }\\n        }, 200);\\n      }\\n      \\n    } catch (error) {\\n      console.error('❌ Server emotion analysis error:', error.message);\\n      console.error('❌ Error stack:', error.stack);\\n      \\n      return createErrorResponse(`Emotion analysis failed: ${error.message}`, 500);\\n    }\\n  }]);\\n\\n  // Get emotion labels\\n  routes.push(['GET', '^/api/emotion/labels$', async (request) => {\\n    try {\\n      \\n      return createJSONResponse({\\n        emotions: ['happy', 'sad', 'angry', 'fearful', 'disgusted', 'surprised', 'neutral'],\\n        model: 'CNN-7-emotion',\\n        version: '1.0',\\n        description: '7-emotion classification with valence-arousal mapping'\\n      }, 200);\\n    } catch (error) {\\n      \\n      return createErrorResponse(`Failed to get emotion labels: ${error.message}`, 500);\\n    }\\n  }]);\\n\\n  return routes;\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}},{\"ruleId\":\"no-process-exit\",\"replacedBy\":[\"n/no-process-exit\"],\"info\":{\"message\":\"Node.js rules were moved out of ESLint core.\",\"url\":\"https://eslint.org/docs/latest/use/migrating-to-7.0.0#deprecate-node-rules\",\"deprecatedSince\":\"7.0.0\",\"availableUntil\":null,\"replacedBy\":[{\"message\":\"eslint-plugin-n now maintains deprecated Node.js-related rules.\",\"plugin\":{\"name\":\"eslint-plugin-n\",\"url\":\"https://github.com/eslint-community/eslint-plugin-n\"},\"rule\":{\"name\":\"no-process-exit\",\"url\":\"https://github.com/eslint-community/eslint-plugin-n/tree/master/docs/rules/no-process-exit.md\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/services/api/routes/index.js\",\"messages\":[],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}},{\"ruleId\":\"no-process-exit\",\"replacedBy\":[\"n/no-process-exit\"],\"info\":{\"message\":\"Node.js rules were moved out of ESLint core.\",\"url\":\"https://eslint.org/docs/latest/use/migrating-to-7.0.0#deprecate-node-rules\",\"deprecatedSince\":\"7.0.0\",\"availableUntil\":null,\"replacedBy\":[{\"message\":\"eslint-plugin-n now maintains deprecated Node.js-related rules.\",\"plugin\":{\"name\":\"eslint-plugin-n\",\"url\":\"https://github.com/eslint-community/eslint-plugin-n\"},\"rule\":{\"name\":\"no-process-exit\",\"url\":\"https://github.com/eslint-community/eslint-plugin-n/tree/master/docs/rules/no-process-exit.md\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/services/api/routes/media.js\",\"messages\":[{\"ruleId\":\"max-lines-per-function\",\"severity\":1,\"message\":\"Arrow function has too many lines (337). Maximum allowed is 150.\",\"line\":8,\"column\":34,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"exceed\",\"endLine\":449,\"endColumn\":2},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'middlewareSystem' is defined but never used. Allowed unused args must match /^_/u.\",\"line\":12,\"column\":3,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":12,\"endColumn\":19,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"middlewareSystem\"},\"fix\":{\"range\":[296,316],\"text\":\"\"},\"desc\":\"Remove unused variable 'middlewareSystem'.\"}]},{\"ruleId\":\"max-depth\",\"severity\":1,\"message\":\"Blocks are nested too deeply (6). Maximum allowed is 5.\",\"line\":46,\"column\":15,\"nodeType\":\"IfStatement\",\"messageId\":\"tooDeeply\",\"endLine\":53,\"endColumn\":16},{\"ruleId\":\"prefer-destructuring\",\"severity\":1,\"message\":\"Use array destructuring.\",\"line\":85,\"column\":13,\"nodeType\":\"VariableDeclarator\",\"messageId\":\"preferDestructuring\",\"endLine\":85,\"endColumn\":33},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'request' is defined but never used. Allowed unused args must match /^_/u.\",\"line\":179,\"column\":54,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":179,\"endColumn\":61,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"request\"},\"fix\":{\"range\":[5784,5791],\"text\":\"\"},\"desc\":\"Remove unused variable 'request'.\"}]},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'mediaAPI' is assigned a value but never used. Allowed unused vars must match /^_/u.\",\"line\":181,\"column\":13,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":181,\"endColumn\":21,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"mediaAPI\"},\"fix\":{\"range\":[5814,5860],\"text\":\"\"},\"desc\":\"Remove unused variable 'mediaAPI'.\"}]},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'request' is defined but never used. Allowed unused args must match /^_/u.\",\"line\":230,\"column\":53,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":230,\"endColumn\":60,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"request\"},\"fix\":{\"range\":[7463,7470],\"text\":\"\"},\"desc\":\"Remove unused variable 'request'.\"}]},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'request' is defined but never used. Allowed unused args must match /^_/u.\",\"line\":302,\"column\":65,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":302,\"endColumn\":72,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"request\"},\"fix\":{\"range\":[9638,9645],\"text\":\"\"},\"desc\":\"Remove unused variable 'request'.\"}]},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'request' is defined but never used. Allowed unused args must match /^_/u.\",\"line\":370,\"column\":69,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":370,\"endColumn\":76,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"request\"},\"fix\":{\"range\":[11599,11606],\"text\":\"\"},\"desc\":\"Remove unused variable 'request'.\"}]},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'request' is defined but never used. Allowed unused args must match /^_/u.\",\"line\":392,\"column\":62,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":392,\"endColumn\":69,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"request\"},\"fix\":{\"range\":[12237,12244],\"text\":\"\"},\"desc\":\"Remove unused variable 'request'.\"}]},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'request' is defined but never used. Allowed unused args must match /^_/u.\",\"line\":421,\"column\":59,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":421,\"endColumn\":66,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"request\"},\"fix\":{\"range\":[13108,13115],\"text\":\"\"},\"desc\":\"Remove unused variable 'request'.\"}]}],\"suppressedMessages\":[],\"errorCount\":8,\"fatalErrorCount\":0,\"warningCount\":3,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Media Streaming Routes Module\\n * Handles device discovery, stream management, and coordinator operations\\n */\\n\\nimport { parseRequestURL } from '../../../shared/utils/url-utils.js';\\n\\nexport const createMediaRoutes = ({ \\n  getMediaStreamingAPI, \\n  getMultiDeviceCoordinator,\\n  memoryOptimizer,\\n  middlewareSystem,\\n  createJSONResponse,\\n  createErrorResponse \\n}) => {\\n  const routes = [];\\n\\n  // Device Management Routes\\n  routes.push(['GET', '^/api/media/devices$', async (request) => {\\n    try {\\n      const mediaAPI = await getMediaStreamingAPI();\\n      const discovery = mediaAPI.getDeviceDiscovery();\\n      \\n      const urlParams = parseRequestURL(request.url).searchParams || new Map();\\n      const refresh = urlParams.get('refresh') === 'true';\\n      const capabilities = urlParams.get('capabilities') !== 'false';\\n      const registerDevices = urlParams.get('register') !== 'false';\\n      \\n      console.log(`🔍 Enhanced device discovery requested (refresh: ${refresh}, capabilities: ${capabilities}, register: ${registerDevices})`);\\n      \\n      const result = await discovery.process({\\n        forceRefresh: refresh,\\n        includeCapabilities: capabilities\\n      });\\n\\n      \\n      \\n      if (result.status === 'success') {\\n        // Register devices with coordinator if requested\\n        const registrationResults = [];\\n        if (registerDevices && result.data.devices) {\\n          const coordinator = await getMultiDeviceCoordinator();\\n          for (const device of result.data.devices) {\\n            try {\\n              // Skip if device already registered\\n              if (!coordinator.getDevice(device.id)) {\\n                const regResult = await coordinator.addDevice(device);\\n                registrationResults.push({\\n                  deviceId: device.id,\\n                  registered: regResult.success,\\n                  message: regResult.success ? 'Registered' : regResult.error\\n                });\\n              }\\n            } catch (error) {\\n              registrationResults.push({\\n                deviceId: device.id,\\n                registered: false,\\n                error: error.message\\n              });\\n            }\\n          }\\n        }\\n\\n        return createJSONResponse({\\n          success: true,\\n          devices: result.data.devices,\\n          networkInfo: result.data.networkInfo,\\n          statistics: result.data.statistics,\\n          registrationResults,\\n          timestamp: result.timestamp\\n        }, 200);\\n      } else {\\n        return createErrorResponse(result.error.message, 500);\\n      }\\n    } catch (error) {\\n      console.error('Device discovery failed:', error);\\n      \\n      return createErrorResponse(error.message, 500);\\n    }\\n  }]);\\n\\n  // Get specific device details\\n  routes.push(['GET', '^/api/media/devices/([^/]+)$', async (request, params) => {\\n    try {\\n      const deviceId = params[0];\\n      const mediaAPI = await getMediaStreamingAPI();\\n      const discovery = mediaAPI.getDeviceDiscovery();\\n      \\n      const result = await discovery.process({});\\n      \\n      \\n      if (result.status === 'success') {\\n        const device = result.data.devices.find(d => d.id === deviceId);\\n        if (device) {\\n          return createJSONResponse({\\n            success: true,\\n            device\\n          }, 200);\\n        } else {\\n          return createErrorResponse('Device not found', 404);\\n        }\\n      } else {\\n        return createErrorResponse(result.error.message, 500);\\n      }\\n    } catch (error) {\\n      console.error('Device lookup failed:', error);\\n      \\n      return createErrorResponse(error.message, 500);\\n    }\\n  }]);\\n\\n  // Create new stream\\n  routes.push(['POST', '^/api/media/streams$', async (request) => {\\n    try {\\n      const body = await request.json();\\n      const { deviceId, quality = 'medium', autoStart = false } = body;\\n\\n      if (!deviceId) {\\n        \\n        return createErrorResponse('deviceId is required', 400);\\n      }\\n\\n      const mediaAPI = await getMediaStreamingAPI();\\n      const activeStreams = mediaAPI.getActiveStreams();\\n      \\n      if (activeStreams.includes(deviceId)) {\\n        \\n        return createErrorResponse('Stream already exists for this device', 409);\\n      }\\n\\n      // Get device info first\\n      const discovery = mediaAPI.getDeviceDiscovery();\\n      const discoveryResult = await discovery.process({});\\n      \\n      if (discoveryResult.status !== 'success') {\\n        \\n        return createErrorResponse('Failed to discover devices', 500);\\n      }\\n\\n      const device = discoveryResult.data.devices.find(d => d.id === deviceId);\\n      if (!device) {\\n        \\n        return createErrorResponse('Device not found', 404);\\n      }\\n\\n      // Ensure device is registered with coordinator\\n      const coordinator = await getMultiDeviceCoordinator();\\n      if (!coordinator.getDevice(deviceId)) {\\n        await coordinator.addDevice(device);\\n        console.log(`📱 Auto-registered device with coordinator: ${device.label}`);\\n      }\\n\\n      // Create stream using coordinator\\n      let streamResult = { success: true, isStreaming: false };\\n      if (autoStart) {\\n        streamResult = await coordinator.startStream(deviceId, { quality });\\n      }\\n\\n      \\n      return createJSONResponse({\\n        success: true,\\n        streamId: deviceId,\\n        device: device.label,\\n        quality,\\n        isStreaming: streamResult.success && autoStart,\\n        coordinator: true,\\n        streamResult: autoStart ? streamResult : undefined,\\n        message: 'Stream created successfully with multi-device coordinator'\\n      }, 200);\\n\\n    } catch (error) {\\n      console.error('Failed to create stream:', error);\\n      \\n      return createErrorResponse(error.message, 500);\\n    }\\n  }]);\\n\\n  // Get all active streams\\n  routes.push(['GET', '^/api/media/streams$', async (request) => {\\n    try {\\n      const mediaAPI = await getMediaStreamingAPI();\\n      const coordinator = await getMultiDeviceCoordinator();\\n      \\n      // Get detailed stream information from coordinator\\n      const coordinatorStatus = coordinator.getCoordinatorStatus();\\n      const activeStreams = coordinator.getActiveStreams();\\n      const devices = coordinator.getDevices();\\n      \\n      // Build detailed stream information\\n      const streamDetails = [];\\n      for (const deviceId of activeStreams) {\\n        const device = devices.find(d => d.id === deviceId);\\n        const pipeline = coordinator.getPipeline(deviceId);\\n        \\n        if (device && pipeline) {\\n          streamDetails.push({\\n            streamId: deviceId,\\n            device: device.label,\\n            deviceType: device.type,\\n            quality: pipeline.getCurrentQuality(),\\n            isStreaming: pipeline.isStreaming(),\\n            stats: pipeline.getStats(),\\n            qualityMetrics: pipeline.getQualityMetrics()\\n          });\\n        }\\n      }\\n\\n      \\n      return createJSONResponse({\\n        success: true,\\n        streams: streamDetails,\\n        totalStreams: streamDetails.length,\\n        activeStreams: streamDetails.filter(s => s.isStreaming).length,\\n        coordinator: {\\n          status: coordinatorStatus,\\n          totalDevices: devices.length,\\n          managedStreams: activeStreams.length\\n        },\\n        timestamp: Date.now()\\n      }, 200);\\n\\n    } catch (error) {\\n      console.error('Failed to get streams:', error);\\n      \\n      return createErrorResponse(error.message, 500);\\n    }\\n  }]);\\n\\n  // System health check\\n  routes.push(['GET', '^/api/media/health$', async (request) => {\\n    try {\\n      const mediaAPI = await getMediaStreamingAPI();\\n      const coordinator = await getMultiDeviceCoordinator();\\n      \\n      \\n      return createJSONResponse({\\n        success: true,\\n        status: 'healthy',\\n        components: {\\n          mediaAPI: mediaAPI.isInitialized(),\\n          coordinator: coordinator.getCoordinatorStatus().isActive,\\n          activeStreams: coordinator.getActiveStreams().length,\\n          registeredDevices: coordinator.getDevices().length\\n        },\\n        timestamp: Date.now()\\n      }, 200);\\n\\n    } catch (error) {\\n      console.error('Health check failed:', error);\\n      \\n      return createErrorResponse(error.message, 500);\\n    }\\n  }]);\\n\\n  // Batch stream operations\\n  routes.push(['POST', '^/api/media/streams/batch$', async (request) => {\\n    try {\\n      const body = await request.json();\\n      const { action, deviceIds, quality = 'medium' } = body;\\n\\n      if (!action || !deviceIds || !Array.isArray(deviceIds)) {\\n        \\n        return createErrorResponse('action and deviceIds array are required', 400);\\n      }\\n\\n      const coordinator = await getMultiDeviceCoordinator();\\n      let results = [];\\n\\n      switch (action) {\\n        case 'start':\\n          results = await coordinator.startMultipleStreams(deviceIds, { quality });\\n          break;\\n        case 'stop':\\n          results = await coordinator.stopMultipleStreams(deviceIds);\\n          break;\\n        case 'change_quality':\\n          results = await coordinator.changeQualityForMultiple(deviceIds, quality);\\n          break;\\n        default:\\n          \\n          return createErrorResponse('Invalid action. Use: start, stop, change_quality', 400);\\n      }\\n\\n      \\n      return createJSONResponse({\\n        success: true,\\n        action,\\n        results,\\n        processed: results.length,\\n        successful: results.filter(r => r.success).length,\\n        timestamp: Date.now()\\n      }, 200);\\n\\n    } catch (error) {\\n      console.error('Batch stream operation failed:', error);\\n      \\n      return createErrorResponse(error.message, 500);\\n    }\\n  }]);\\n\\n  // Coordinator status\\n  routes.push(['GET', '^/api/media/coordinator/status$', async (request) => {\\n    try {\\n      const coordinator = await getMultiDeviceCoordinator();\\n      const status = coordinator.getCoordinatorStatus();\\n      const devices = coordinator.getDevices();\\n      const activeStreams = coordinator.getActiveStreams();\\n\\n      \\n      return createJSONResponse({\\n        success: true,\\n        coordinator: status,\\n        devices: devices.length,\\n        activeStreams: activeStreams.length,\\n        deviceList: devices.map(d => ({\\n          id: d.id,\\n          label: d.label,\\n          type: d.type,\\n          isStreaming: activeStreams.includes(d.id)\\n        })),\\n        timestamp: Date.now()\\n      }, 200);\\n\\n    } catch (error) {\\n      console.error('Coordinator status failed:', error);\\n      \\n      return createErrorResponse(error.message, 500);\\n    }\\n  }]);\\n\\n  // Global quality control\\n  routes.push(['PUT', '^/api/media/coordinator/quality$', async (request) => {\\n    try {\\n      const body = await request.json();\\n      const { quality, deviceIds } = body;\\n\\n      if (!quality) {\\n        \\n        return createErrorResponse('quality is required', 400);\\n      }\\n\\n      const coordinator = await getMultiDeviceCoordinator();\\n      let result;\\n\\n      if (deviceIds && Array.isArray(deviceIds)) {\\n        // Change quality for specific devices\\n        result = await coordinator.changeQualityForMultiple(deviceIds, quality);\\n      } else {\\n        // Change quality for all active streams\\n        result = await coordinator.setGlobalQuality(quality);\\n      }\\n\\n      \\n      return createJSONResponse({\\n        success: true,\\n        quality,\\n        affected: Array.isArray(result) ? result.length : 1,\\n        results: result,\\n        timestamp: Date.now()\\n      }, 200);\\n\\n    } catch (error) {\\n      console.error('Quality control failed:', error);\\n      \\n      return createErrorResponse(error.message, 500);\\n    }\\n  }]);\\n\\n  // Load balancing rebalance\\n  routes.push(['POST', '^/api/media/coordinator/rebalance$', async (request) => {\\n    try {\\n      const coordinator = await getMultiDeviceCoordinator();\\n      const result = await coordinator.rebalanceStreams();\\n\\n      \\n      return createJSONResponse({\\n        success: true,\\n        rebalanced: result.success,\\n        changes: result.changes || [],\\n        message: 'Load balancing rebalance completed',\\n        timestamp: Date.now()\\n      }, 200);\\n\\n    } catch (error) {\\n      console.error('Rebalance failed:', error);\\n      \\n      return createErrorResponse(error.message, 500);\\n    }\\n  }]);\\n\\n  // Enhanced health check with network stats\\n  routes.push(['GET', '^/api/media/health/enhanced$', async (request) => {\\n    try {\\n      const mediaAPI = await getMediaStreamingAPI();\\n      const coordinator = await getMultiDeviceCoordinator();\\n      \\n      const coordinatorStatus = coordinator.getCoordinatorStatus();\\n      const networkStats = coordinator.getNetworkStats();\\n\\n      \\n      return createJSONResponse({\\n        success: true,\\n        health: {\\n          overall: 'healthy',\\n          mediaAPI: mediaAPI.isInitialized(),\\n          coordinator: coordinatorStatus,\\n          network: networkStats,\\n          uptime: Date.now() - coordinatorStatus.lastUpdate,\\n          timestamp: Date.now()\\n        }\\n      }, 200);\\n\\n    } catch (error) {\\n      console.error('Enhanced health check failed:', error);\\n      \\n      return createErrorResponse(error.message, 500);\\n    }\\n  }]);\\n\\n  // Memory optimization stats\\n  routes.push(['GET', '^/api/media/memory/stats$', async (request) => {\\n    try {\\n      \\n      const memoryStats = memoryOptimizer.getMemoryStats();\\n      const poolingStats = memoryOptimizer.getPoolingStats();\\n      \\n      return createJSONResponse({\\n        success: true,\\n        memory: {\\n          heapUsed: `${Math.round(memoryStats.heapUsed / 1024 / 1024)  } MB`,\\n          heapTotal: `${Math.round(memoryStats.heapTotal / 1024 / 1024)  } MB`,\\n          external: `${Math.round(memoryStats.external / 1024 / 1024)  } MB`,\\n          rss: `${Math.round(memoryStats.rss / 1024 / 1024)  } MB`,\\n          pressure: `${Math.round((memoryStats.heapUsed / memoryStats.heapTotal) * 100)  }%`\\n        },\\n        pooling: poolingStats,\\n        monitoring: memoryOptimizer.isMonitoring(),\\n        timestamp: Date.now()\\n      }, 200);\\n      \\n    } catch (error) {\\n      console.error('Memory stats failed:', error);\\n      \\n      return createErrorResponse(`Memory stats failed: ${  error.message}`, 500);\\n    }\\n  }]);\\n\\n  return routes;\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}},{\"ruleId\":\"no-process-exit\",\"replacedBy\":[\"n/no-process-exit\"],\"info\":{\"message\":\"Node.js rules were moved out of ESLint core.\",\"url\":\"https://eslint.org/docs/latest/use/migrating-to-7.0.0#deprecate-node-rules\",\"deprecatedSince\":\"7.0.0\",\"availableUntil\":null,\"replacedBy\":[{\"message\":\"eslint-plugin-n now maintains deprecated Node.js-related rules.\",\"plugin\":{\"name\":\"eslint-plugin-n\",\"url\":\"https://github.com/eslint-community/eslint-plugin-n\"},\"rule\":{\"name\":\"no-process-exit\",\"url\":\"https://github.com/eslint-community/eslint-plugin-n/tree/master/docs/rules/no-process-exit.md\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/services/api/routes/stream-routes.js\",\"messages\":[{\"ruleId\":\"max-lines-per-function\",\"severity\":1,\"message\":\"Arrow function has too many lines (217). Maximum allowed is 150.\",\"line\":7,\"column\":34,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"exceed\",\"endLine\":271,\"endColumn\":2},{\"ruleId\":\"consistent-return\",\"severity\":1,\"message\":\"Expected to return a value at the end of async arrow function.\",\"line\":9,\"column\":51,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"missingReturn\",\"endLine\":9,\"endColumn\":53},{\"ruleId\":\"consistent-return\",\"severity\":1,\"message\":\"Expected to return a value at the end of async arrow function.\",\"line\":135,\"column\":60,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"missingReturn\",\"endLine\":135,\"endColumn\":62},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'parameters' is assigned a value but never used. Allowed unused vars must match /^_/u.\",\"line\":138,\"column\":32,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":138,\"endColumn\":42,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"parameters\"},\"fix\":{\"range\":[3938,3955],\"text\":\"\"},\"desc\":\"Remove unused variable 'parameters'.\"}]},{\"ruleId\":\"consistent-return\",\"severity\":1,\"message\":\"Expected to return a value at the end of async arrow function.\",\"line\":193,\"column\":63,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"missingReturn\",\"endLine\":193,\"endColumn\":65},{\"ruleId\":\"consistent-return\",\"severity\":1,\"message\":\"Expected to return a value at the end of async arrow function.\",\"line\":240,\"column\":66,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"missingReturn\",\"endLine\":240,\"endColumn\":68}],\"suppressedMessages\":[],\"errorCount\":1,\"fatalErrorCount\":0,\"warningCount\":5,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Stream management routes for media streaming API\\n */\\n\\nimport { createMediaStreamingPipeline } from '../../../features/media-streaming/media-streaming-pipeline.js';\\n\\nexport const setupStreamRoutes = (app, state) => {\\n  // Create new stream\\n  app.post('/api/media/streams', async (req, res) => {\\n    try {\\n      const { deviceId, quality = 'medium', autoStart = false } = req.body;\\n\\n      if (!deviceId) {\\n        return res.status(400).json({\\n          success: false,\\n          error: 'deviceId is required'\\n        });\\n      }\\n\\n      // Check if stream already exists\\n      if (state.activeStreams.has(deviceId)) {\\n        return res.status(409).json({\\n          success: false,\\n          error: 'Stream already exists for this device'\\n        });\\n      }\\n\\n      // Get device info\\n      const discoveryResult = await state.deviceDiscoveryPipeline.process({});\\n      if (discoveryResult.status !== 'success') {\\n        throw new Error('Failed to discover devices');\\n      }\\n\\n      const device = discoveryResult.data.devices.find(d => d.id === deviceId);\\n      if (!device) {\\n        return res.status(404).json({\\n          success: false,\\n          error: 'Device not found'\\n        });\\n      }\\n\\n      // Create streaming pipeline\\n      const streamPipeline = createMediaStreamingPipeline(device, {\\n        defaultQuality: quality,\\n        autoStart: false\\n      });\\n\\n      await streamPipeline.initialize();\\n      await state.orchestrator.registerPipeline(streamPipeline);\\n\\n      // Store the pipeline\\n      state.activeStreams.set(deviceId, streamPipeline);\\n\\n      // Start streaming if requested\\n      if (autoStart) {\\n        const startResult = await streamPipeline.process({\\n          action: 'START_STREAM'\\n        });\\n\\n        if (startResult.status !== 'success') {\\n          // Clean up on failure\\n          state.activeStreams.delete(deviceId);\\n          await streamPipeline.cleanup();\\n          \\n          return res.status(500).json({\\n            success: false,\\n            error: startResult.error.message\\n          });\\n        }\\n      }\\n\\n      // Get session and start media stream in distribution system\\n      const session = state.distributionManager.getSession('media-streaming');\\n      if (session) {\\n        const mediaDistributor = session.activeDistributors.get('media-websocket');\\n        if (mediaDistributor) {\\n          await mediaDistributor.instance.startStream(deviceId, {\\n            type: device.type,\\n            quality\\n          });\\n        }\\n      }\\n\\n      res.json({\\n        success: true,\\n        streamId: deviceId,\\n        device: device.label,\\n        quality,\\n        isStreaming: autoStart,\\n        message: 'Stream created successfully'\\n      });\\n\\n    } catch (error) {\\n      console.error('Failed to create stream:', error);\\n      res.status(500).json({\\n        success: false,\\n        error: error.message\\n      });\\n    }\\n  });\\n\\n  // Get all active streams\\n  app.get('/api/media/streams', async (req, res) => {\\n    try {\\n      const streams = Array.from(state.activeStreams.entries()).map(([deviceId, pipeline]) => {\\n        const status = pipeline.getStatus();\\n        return {\\n          streamId: deviceId,\\n          device: status.deviceLabel,\\n          deviceType: status.deviceType,\\n          quality: status.quality,\\n          isStreaming: status.isStreaming,\\n          stats: status.stats,\\n          bufferSize: status.bufferSize\\n        };\\n      });\\n\\n      res.json({\\n        success: true,\\n        streams,\\n        totalStreams: streams.length,\\n        activeStreams: streams.filter(s => s.isStreaming).length\\n      });\\n\\n    } catch (error) {\\n      console.error('Failed to get streams:', error);\\n      res.status(500).json({\\n        success: false,\\n        error: error.message\\n      });\\n    }\\n  });\\n\\n  // Control specific stream\\n  app.put('/api/media/streams/:streamId', async (req, res) => {\\n    try {\\n      const { streamId } = req.params;\\n      const { action, quality, parameters = {} } = req.body;\\n\\n      const pipeline = state.activeStreams.get(streamId);\\n      if (!pipeline) {\\n        return res.status(404).json({\\n          success: false,\\n          error: 'Stream not found'\\n        });\\n      }\\n\\n      let result;\\n      switch (action) {\\n        case 'start':\\n          result = await pipeline.process({ action: 'START_STREAM' });\\n          break;\\n        case 'stop':\\n          result = await pipeline.process({ action: 'STOP_STREAM' });\\n          break;\\n        case 'change_quality':\\n          result = await pipeline.process({ \\n            action: 'CHANGE_QUALITY', \\n            parameters: { quality: quality || 'medium' }\\n          });\\n          break;\\n        default:\\n          return res.status(400).json({\\n            success: false,\\n            error: 'Invalid action. Use: start, stop, change_quality'\\n          });\\n      }\\n\\n      if (result.status === 'success') {\\n        res.json({\\n          success: true,\\n          streamId,\\n          action,\\n          result: result.data.result\\n        });\\n      } else {\\n        res.status(400).json({\\n          success: false,\\n          error: result.error.message\\n        });\\n      }\\n\\n    } catch (error) {\\n      console.error('Stream control failed:', error);\\n      res.status(500).json({\\n        success: false,\\n        error: error.message\\n      });\\n    }\\n  });\\n\\n  // Delete stream\\n  app.delete('/api/media/streams/:streamId', async (req, res) => {\\n    try {\\n      const { streamId } = req.params;\\n\\n      const pipeline = state.activeStreams.get(streamId);\\n      if (!pipeline) {\\n        return res.status(404).json({\\n          success: false,\\n          error: 'Stream not found'\\n        });\\n      }\\n\\n      // Stop streaming if active\\n      if (pipeline.isStreaming()) {\\n        await pipeline.process({ action: 'STOP_STREAM' });\\n      }\\n\\n      // Stop stream in distribution system\\n      const session = state.distributionManager.getSession('media-streaming');\\n      if (session) {\\n        const mediaDistributor = session.activeDistributors.get('media-websocket');\\n        if (mediaDistributor) {\\n          await mediaDistributor.instance.stopStream(streamId);\\n        }\\n      }\\n\\n      // Clean up pipeline\\n      await state.orchestrator.unregisterPipeline(pipeline.name);\\n      await pipeline.cleanup();\\n      state.activeStreams.delete(streamId);\\n\\n      res.json({\\n        success: true,\\n        message: 'Stream deleted successfully',\\n        streamId\\n      });\\n\\n    } catch (error) {\\n      console.error('Failed to delete stream:', error);\\n      res.status(500).json({\\n        success: false,\\n        error: error.message\\n      });\\n    }\\n  });\\n\\n  // Get stream statistics\\n  app.get('/api/media/streams/:streamId/stats', async (req, res) => {\\n    try {\\n      const { streamId } = req.params;\\n\\n      const pipeline = state.activeStreams.get(streamId);\\n      if (!pipeline) {\\n        return res.status(404).json({\\n          success: false,\\n          error: 'Stream not found'\\n        });\\n      }\\n\\n      const status = pipeline.getStatus();\\n      const stats = pipeline.getStats();\\n\\n      res.json({\\n        success: true,\\n        streamId,\\n        status,\\n        stats,\\n        timestamp: Date.now()\\n      });\\n\\n    } catch (error) {\\n      console.error('Failed to get stream stats:', error);\\n      res.status(500).json({\\n        success: false,\\n        error: error.message\\n      });\\n    }\\n  });\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}},{\"ruleId\":\"no-process-exit\",\"replacedBy\":[\"n/no-process-exit\"],\"info\":{\"message\":\"Node.js rules were moved out of ESLint core.\",\"url\":\"https://eslint.org/docs/latest/use/migrating-to-7.0.0#deprecate-node-rules\",\"deprecatedSince\":\"7.0.0\",\"availableUntil\":null,\"replacedBy\":[{\"message\":\"eslint-plugin-n now maintains deprecated Node.js-related rules.\",\"plugin\":{\"name\":\"eslint-plugin-n\",\"url\":\"https://github.com/eslint-community/eslint-plugin-n\"},\"rule\":{\"name\":\"no-process-exit\",\"url\":\"https://github.com/eslint-community/eslint-plugin-n/tree/master/docs/rules/no-process-exit.md\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/services/api/routes/system-routes.js\",\"messages\":[],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}},{\"ruleId\":\"no-process-exit\",\"replacedBy\":[\"n/no-process-exit\"],\"info\":{\"message\":\"Node.js rules were moved out of ESLint core.\",\"url\":\"https://eslint.org/docs/latest/use/migrating-to-7.0.0#deprecate-node-rules\",\"deprecatedSince\":\"7.0.0\",\"availableUntil\":null,\"replacedBy\":[{\"message\":\"eslint-plugin-n now maintains deprecated Node.js-related rules.\",\"plugin\":{\"name\":\"eslint-plugin-n\",\"url\":\"https://github.com/eslint-community/eslint-plugin-n\"},\"rule\":{\"name\":\"no-process-exit\",\"url\":\"https://github.com/eslint-community/eslint-plugin-n/tree/master/docs/rules/no-process-exit.md\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/services/api/routes/system.js\",\"messages\":[{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'middlewareSystem' is defined but never used. Allowed unused args must match /^_/u.\",\"line\":9,\"column\":3,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":9,\"endColumn\":19,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"middlewareSystem\"},\"fix\":{\"range\":[184,204],\"text\":\"\"},\"desc\":\"Remove unused variable 'middlewareSystem'.\"}]},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'request' is defined but never used. Allowed unused args must match /^_/u.\",\"line\":16,\"column\":50,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":16,\"endColumn\":57,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"request\"},\"fix\":{\"range\":[359,366],\"text\":\"\"},\"desc\":\"Remove unused variable 'request'.\"}]},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'request' is defined but never used. Allowed unused args must match /^_/u.\",\"line\":38,\"column\":47,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":38,\"endColumn\":54,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"request\"},\"fix\":{\"range\":[988,995],\"text\":\"\"},\"desc\":\"Remove unused variable 'request'.\"}]},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'request' is defined but never used. Allowed unused args must match /^_/u.\",\"line\":119,\"column\":56,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":119,\"endColumn\":63,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"request\"},\"fix\":{\"range\":[3421,3428],\"text\":\"\"},\"desc\":\"Remove unused variable 'request'.\"}]},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'request' is defined but never used. Allowed unused args must match /^_/u.\",\"line\":133,\"column\":60,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":133,\"endColumn\":67,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"request\"},\"fix\":{\"range\":[3823,3830],\"text\":\"\"},\"desc\":\"Remove unused variable 'request'.\"}]}],\"suppressedMessages\":[],\"errorCount\":5,\"fatalErrorCount\":0,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * System Routes Module\\n * Handles health checks, pipeline management, and system utilities\\n */\\n\\nexport const createSystemRoutes = ({\\n  orchestrator,\\n  getDistributionOverallStatus,\\n  middlewareSystem,\\n  createJSONResponse,\\n  createErrorResponse\\n}) => {\\n  const routes = [];\\n\\n  // Get registered pipelines\\n  routes.push(['GET', '^/api/pipelines$', async (request) => {\\n    try {\\n      \\n      const pipelines = orchestrator.getRegisteredPipelines();\\n      \\n      return createJSONResponse({\\n        pipelines: pipelines.map(p => ({\\n          name: p.name,\\n          type: p.type || 'unknown',\\n          status: p.getStatus ? p.getStatus() : 'active',\\n          capabilities: p.capabilities || []\\n        })),\\n        total: pipelines.length,\\n        timestamp: Date.now()\\n      }, 200);\\n    } catch (error) {\\n      \\n      return createErrorResponse(`Pipeline listing failed: ${error.message}`, 500);\\n    }\\n  }]);\\n\\n  // System health check\\n  routes.push(['GET', '^/api/health$', async (request) => {\\n    try {\\n      \\n      const pipelines = orchestrator.getRegisteredPipelines();\\n      \\n      return createJSONResponse({\\n        status: 'healthy',\\n        timestamp: Date.now(),\\n        uptime: process.uptime() * 1000,\\n        version: '2.0.0',\\n        capabilities: {\\n          pipelines: pipelines.map(p => p.name),\\n          features: [\\n            'face_analysis',\\n            'emotion_detection', \\n            'media_streaming',\\n            'distribution_system',\\n            'websocket_streaming'\\n          ]\\n        },\\n        system: {\\n          node_version: process.version,\\n          platform: process.platform,\\n          memory_usage: process.memoryUsage()\\n        },\\n        endpoints: {\\n          analysis: {\\n            emotions: '/api/emotion/analyze',\\n            labels: '/api/emotion/labels'\\n          },\\n          media: {\\n            devices: '/api/media/devices',\\n            streams: '/api/media/streams',\\n            health: '/api/media/health'\\n          },\\n          distribution: {\\n            streams: '/api/distribution/streams',\\n            status: '/api/distribution/status',\\n            discovery: '/api/distribution/discovery',\\n            clients: '/api/distribution/clients',\\n            templates: '/api/distribution/templates'\\n          },\\n          system: {\\n            health: '/api/health',\\n            pipelines: '/api/pipelines'\\n          }\\n        },\\n        distribution: {\\n          overall_status: getDistributionOverallStatus()\\n        }\\n      }, 200);\\n    } catch (error) {\\n      \\n      return createErrorResponse(`Health check failed: ${error.message}`, 500);\\n    }\\n  }]);\\n\\n  // Register new pipeline\\n  routes.push(['POST', '^/api/pipelines/register$', async (request) => {\\n    try {\\n      const body = await request.json();\\n      \\n      \\n      if (!body.name || !body.type) {\\n        return createErrorResponse('Pipeline name and type are required', 400);\\n      }\\n      \\n      // This would need actual pipeline creation logic\\n      // For now, return a placeholder response\\n      return createJSONResponse({\\n        success: true,\\n        message: 'Pipeline registration endpoint - implementation needed',\\n        requested: body\\n      }, 200);\\n    } catch (error) {\\n      \\n      return createErrorResponse(`Pipeline registration failed: ${error.message}`, 500);\\n    }\\n  }]);\\n\\n  // Speech analysis (placeholder)\\n  routes.push(['POST', '^/api/speech/analyze$', async (request) => {\\n    try {\\n      \\n      return createJSONResponse({\\n        message: 'Speech analysis endpoint - implementation needed',\\n        status: 'placeholder'\\n      }, 200);\\n    } catch (error) {\\n      \\n      return createErrorResponse(`Speech analysis failed: ${error.message}`, 500);\\n    }\\n  }]);\\n\\n  // Speech recognition (placeholder)\\n  routes.push(['POST', '^/api/speech/recognition$', async (request) => {\\n    try {\\n      \\n      return createJSONResponse({\\n        message: 'Speech recognition endpoint - implementation needed',\\n        status: 'placeholder'\\n      }, 200);\\n    } catch (error) {\\n      \\n      return createErrorResponse(`Speech recognition failed: ${error.message}`, 500);\\n    }\\n  }]);\\n\\n  return routes;\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}},{\"ruleId\":\"no-process-exit\",\"replacedBy\":[\"n/no-process-exit\"],\"info\":{\"message\":\"Node.js rules were moved out of ESLint core.\",\"url\":\"https://eslint.org/docs/latest/use/migrating-to-7.0.0#deprecate-node-rules\",\"deprecatedSince\":\"7.0.0\",\"availableUntil\":null,\"replacedBy\":[{\"message\":\"eslint-plugin-n now maintains deprecated Node.js-related rules.\",\"plugin\":{\"name\":\"eslint-plugin-n\",\"url\":\"https://github.com/eslint-community/eslint-plugin-n\"},\"rule\":{\"name\":\"no-process-exit\",\"url\":\"https://github.com/eslint-community/eslint-plugin-n/tree/master/docs/rules/no-process-exit.md\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/services/api/server.js\",\"messages\":[{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'createAnalysisRequirements' is defined but never used. Allowed unused vars must match /^_/u.\",\"line\":9,\"column\":10,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":9,\"endColumn\":36,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"createAnalysisRequirements\"},\"fix\":{\"range\":[330,409],\"text\":\"\"},\"desc\":\"Remove unused variable 'createAnalysisRequirements'.\"}]},{\"ruleId\":\"prefer-destructuring\",\"severity\":1,\"message\":\"Use object destructuring.\",\"line\":23,\"column\":5,\"nodeType\":\"AssignmentExpression\",\"messageId\":\"preferDestructuring\",\"endLine\":23,\"endColumn\":73},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'createSuccessResponse' is assigned a value but never used. Allowed unused vars must match /^_/u.\",\"line\":78,\"column\":7,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":78,\"endColumn\":28,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"createSuccessResponse\"},\"fix\":{\"range\":[2814,2971],\"text\":\"\"},\"desc\":\"Remove unused variable 'createSuccessResponse'.\"}]},{\"ruleId\":\"max-lines-per-function\",\"severity\":1,\"message\":\"Arrow function has too many lines (247). Maximum allowed is 150.\",\"line\":117,\"column\":41,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"exceed\",\"endLine\":431,\"endColumn\":2},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'distributionSessionManager' is assigned a value but never used. Allowed unused vars must match /^_/u.\",\"line\":241,\"column\":13,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":241,\"endColumn\":39,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"distributionSessionManager\"},\"fix\":{\"range\":[8230,8257],\"text\":\"\"},\"desc\":\"Remove unused variable 'distributionSessionManager'.\"}]},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'distributionConfigManager' is assigned a value but never used. Allowed unused vars must match /^_/u.\",\"line\":241,\"column\":41,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":241,\"endColumn\":66,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"distributionConfigManager\"},\"fix\":{\"range\":[8256,8283],\"text\":\"\"},\"desc\":\"Remove unused variable 'distributionConfigManager'.\"}]},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'request' is defined but never used. Allowed unused args must match /^_/u.\",\"line\":329,\"column\":35,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":329,\"endColumn\":42,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"request\"},\"fix\":{\"range\":[10780,10787],\"text\":\"\"},\"desc\":\"Remove unused variable 'request'.\"}]},{\"ruleId\":\"consistent-return\",\"severity\":1,\"message\":\"Async method 'fetch' expected no return value.\",\"line\":357,\"column\":13,\"nodeType\":\"ReturnStatement\",\"messageId\":\"unexpectedReturnValue\",\"endLine\":362,\"endColumn\":16},{\"ruleId\":\"consistent-return\",\"severity\":1,\"message\":\"Async method 'fetch' expected no return value.\",\"line\":368,\"column\":9,\"nodeType\":\"ReturnStatement\",\"messageId\":\"unexpectedReturnValue\",\"endLine\":368,\"endColumn\":64},{\"ruleId\":\"consistent-return\",\"severity\":1,\"message\":\"Async method 'fetch' expected no return value.\",\"line\":372,\"column\":7,\"nodeType\":\"ReturnStatement\",\"messageId\":\"unexpectedReturnValue\",\"endLine\":374,\"endColumn\":10},{\"ruleId\":\"no-process-exit\",\"severity\":1,\"message\":\"Don't use process.exit(); throw an error instead.\",\"line\":450,\"column\":5,\"nodeType\":\"CallExpression\",\"messageId\":\"noProcessExit\",\"endLine\":450,\"endColumn\":20}],\"suppressedMessages\":[],\"errorCount\":5,\"fatalErrorCount\":0,\"warningCount\":6,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Synopticon API Server - Modular Version\\n * Streamlined server with extracted route modules\\n */\\n\\nimport { parseRequestURL } from '../../shared/utils/url-utils.js';\\nimport { createOrchestrator } from '../../core/orchestration/orchestrator.js';\\nimport { createStrategyRegistry } from '../../core/orchestration/strategies.js';\\nimport { createAnalysisRequirements } from '../../core/configuration/types.js';\\nimport { createMemoryOptimizer } from '../../core/state/memory-optimization.js';\\nimport { createRouteRegistry } from './routes/index.js';\\nimport { createWebSocketManager } from './websocket/index.js';\\nimport { createMiddlewareSystem } from './middleware/index.js';\\n\\n// Lazy loading modules\\nlet createEmotionAnalysisPipeline = null;\\nlet distributionModules = null;\\nlet mediaStreamingModules = null;\\n\\nconst getEmotionAnalysisPipeline = async () => {\\n  if (!createEmotionAnalysisPipeline) {\\n    const module = await import('../../features/emotion-analysis/emotion-analysis-pipeline.js');\\n    createEmotionAnalysisPipeline = module.createEmotionAnalysisPipeline;\\n  }\\n  return createEmotionAnalysisPipeline;\\n};\\n\\nconst getDistributionModules = async () => {\\n  if (!distributionModules) {\\n    distributionModules = await import('../../core/distribution/index.ts');\\n  }\\n  return distributionModules;\\n};\\n\\nconst getMediaStreamingModules = async () => {\\n  if (!mediaStreamingModules) {\\n    const [streamingAPI, coordinator] = await Promise.all([\\n      import('./media-streaming-api.js'),\\n      import('../../features/media-streaming/multi-device-coordinator.js')\\n    ]);\\n    mediaStreamingModules = {\\n      createMediaStreamingAPI: streamingAPI.createMediaStreamingAPI,\\n      createMultiDeviceCoordinator: coordinator.createMultiDeviceCoordinator\\n    };\\n  }\\n  return mediaStreamingModules;\\n};\\n\\n// Utility functions\\nconst generateSecureId = (prefix = '') => {\\n  const timestamp = Date.now();\\n  const random = crypto.getRandomValues(new Uint8Array(16));\\n  const randomHex = Array.from(random, byte => byte.toString(16).padStart(2, '0')).join('');\\n  return prefix ? `${prefix}_${timestamp}_${randomHex}` : `${timestamp}_${randomHex}`;\\n};\\n\\nconst getContentType = (filePath) => {\\n  const ext = filePath.split('.').pop()?.toLowerCase();\\n  const mimeTypes = {\\n    'html': 'text/html', 'css': 'text/css', 'js': 'application/javascript',\\n    'json': 'application/json', 'png': 'image/png', 'jpg': 'image/jpeg'\\n  };\\n  return mimeTypes[ext] || 'text/plain';\\n};\\n\\n\\nconst createJSONResponse = (data, status = 200, headers = {}) => {\\n  return new Response(JSON.stringify(data), {\\n    status,\\n    headers: { 'Content-Type': 'application/json', ...headers }\\n  });\\n};\\n\\nconst createErrorResponse = (message, status = 400, headers = {}) => {\\n  return createJSONResponse({ error: message, timestamp: Date.now() }, status, headers);\\n};\\n\\nconst createSuccessResponse = (data = {}, headers = {}) => {\\n  return createJSONResponse({ success: true, ...data, timestamp: Date.now() }, 200, headers);\\n};\\n\\n// Router implementation\\nconst createRouter = () => {\\n  const routes = new Map();\\n  \\n  const add = (method, pattern, handler) => {\\n    const key = `${method}:${pattern}`;\\n    routes.set(key, { pattern: new RegExp(pattern), handler });\\n  };\\n  \\n  const route = async (request) => {\\n    const {method} = request;\\n    const url = parseRequestURL(request.url);\\n    const path = url.pathname;\\n    \\n    for (const [key, { pattern, handler }] of routes.entries()) {\\n      if (key.startsWith(`${method  }:`)) {\\n        const match = path.match(pattern);\\n        if (match) {\\n          const params = match.slice(1);\\n          return await handler(request, params);\\n        }\\n      }\\n    }\\n    \\n    return new Response('Not Found', { status: 404 });\\n  };\\n  \\n  return { add, route };\\n};\\n\\n// WebSocket session management is now handled by the WebSocket module\\n\\n// Frame processing is now handled by the WebSocket frame processor module\\n\\n// Main server factory\\nexport const createFaceAnalysisServer = (config = {}) => {\\n  const port = config.port || 3000;\\n  const strategyRegistry = createStrategyRegistry();\\n  const orchestrator = createOrchestrator({\\n    strategies: strategyRegistry,\\n    ...config.orchestrator\\n  });\\n  \\n  // Initialize memory optimizer\\n  const memoryOptimizer = createMemoryOptimizer({\\n    memoryPressureThreshold: config.memoryPressureThreshold || 0.75\\n  });\\n  memoryOptimizer.startMonitoring();\\n\\n  // Lazy component initialization\\n  let emotionPipelineInitialized = false;\\n  const initializeEmotionPipeline = async () => {\\n    if (emotionPipelineInitialized) return;\\n    \\n    try {\\n      console.log('🔄 Lazy loading emotion analysis pipeline...');\\n      const createEmotionPipeline = await getEmotionAnalysisPipeline();\\n      const emotionPipeline = createEmotionPipeline({\\n        smoothingFactor: 0.3,\\n        confidenceThreshold: 0.5,\\n        enableValenceArousal: true\\n      });\\n      \\n      await emotionPipeline.initialize();\\n      orchestrator.registerPipeline(emotionPipeline);\\n      emotionPipelineInitialized = true;\\n      console.log('✅ Emotion analysis pipeline lazy loaded and registered');\\n    } catch (error) {\\n      console.warn('⚠️ Failed to lazy load emotion analysis pipeline:', error.message);\\n      throw error;\\n    }\\n  };\\n\\n  // Lazy media streaming components\\n  let mediaStreamingAPI = null;\\n  let multiDeviceCoordinator = null;\\n\\n  const getMediaStreamingAPI = async () => {\\n    if (!mediaStreamingAPI) {\\n      console.log('🔄 Lazy loading media streaming API...');\\n      const modules = await getMediaStreamingModules();\\n      mediaStreamingAPI = modules.createMediaStreamingAPI({\\n        httpHost: config.httpHost || 'localhost',\\n        httpPort: port,\\n        websocketHost: config.websocketHost || '0.0.0.0',\\n        websocketPort: config.websocketPort || 8081,\\n        discoveryInterval: config.discoveryInterval || 10000\\n      });\\n      await mediaStreamingAPI.initialize();\\n      console.log('✅ Media streaming API lazy loaded');\\n    }\\n    return mediaStreamingAPI;\\n  };\\n\\n  const getMultiDeviceCoordinator = async () => {\\n    if (!multiDeviceCoordinator) {\\n      console.log('🔄 Lazy loading multi-device coordinator...');\\n      const modules = await getMediaStreamingModules();\\n      multiDeviceCoordinator = modules.createMultiDeviceCoordinator({\\n        defaultQuality: 'medium',\\n        syncStreaming: true,\\n        globalQualityControl: true,\\n        loadBalancing: true,\\n        adaptiveQuality: true,\\n        pipelineConfig: {\\n          bufferSize: 60,\\n          windowMs: 5000,\\n          enableQualityControl: true\\n        }\\n      });\\n      console.log('✅ Multi-device coordinator lazy loaded');\\n    }\\n    return multiDeviceCoordinator;\\n  };\\n\\n  // Lazy distribution system\\n  let distributionSessionManager = null;\\n  let distributionConfigManager = null;\\n  let distributionPresets = null;\\n  \\n  const getDistributionSystem = async () => {\\n    if (!distributionSessionManager) {\\n      console.log('🔄 Lazy loading distribution system...');\\n      const modules = await getDistributionModules();\\n      distributionSessionManager = modules.createDistributionSessionManager();\\n      distributionConfigManager = modules.createDistributionConfigManager();\\n      distributionPresets = modules.getDistributionPresets();\\n      console.log('✅ Distribution system lazy loaded');\\n    }\\n    return { distributionSessionManager, distributionConfigManager, distributionPresets };\\n  };\\n\\n  // Distribution state\\n  const distributionStreams = new Map();\\n  const distributionClients = new Map();\\n\\n  const getDistributionOverallStatus = () => {\\n    const activeStreams = Array.from(distributionStreams.values()).filter(s => s.status === 'active');\\n    \\n    return {\\n      timestamp: Date.now(),\\n      streams: {\\n        total: distributionStreams.size,\\n        active: activeStreams.length,\\n        stopped: distributionStreams.size - activeStreams.length\\n      },\\n      clients: {\\n        total: distributionClients.size,\\n        active: Array.from(distributionClients.values()).filter(c => \\n          Date.now() - c.last_seen < 60000\\n        ).length\\n      }\\n    };\\n  };\\n\\n  const createDistributionStream = async (config) => {\\n    const streamId = generateSecureId('stream');\\n    \\n    // Lazy load distribution system\\n    const { distributionSessionManager, distributionConfigManager } = await getDistributionSystem();\\n    \\n    if (!config.type || !config.destination || !config.source) {\\n      throw new Error('Stream configuration must include type, destination, and source');\\n    }\\n\\n    const stream = {\\n      id: streamId,\\n      config,\\n      status: 'active',\\n      created_at: Date.now(),\\n      updated_at: Date.now()\\n    };\\n    \\n    distributionStreams.set(streamId, stream);\\n    return stream;\\n  };\\n\\n  // WebSocket manager with enhanced capabilities\\n  const wsManager = createWebSocketManager({\\n    orchestrator,\\n    initializeEmotionPipeline,\\n    config: {\\n      maxWebSocketSessions: config.maxWebSocketSessions || 100,\\n      websocketTimeout: config.websocketTimeout || 300000,\\n      maxFrameSize: config.maxFrameSize || 10 * 1024 * 1024,\\n      enableFrameCache: config.enableFrameCache !== false\\n    }\\n  });\\n  \\n  // Initialize middleware system\\n  const middlewareSystem = createMiddlewareSystem({\\n    cors: {\\n      allowedOrigins: config.allowedOrigins || [\\n        'http://localhost:3000',\\n        'http://127.0.0.1:3000',\\n        'http://localhost:8080',\\n        'http://127.0.0.1:8080'\\n      ],\\n      allowCredentials: config.corsAllowCredentials || false,\\n      logRequests: config.corsLogRequests || false\\n    },\\n    rateLimiting: {\\n      windowMs: config.rateLimitWindowMs || 15 * 60 * 1000, // 15 minutes\\n      maxRequests: config.rateLimitMaxRequests || 100,\\n      algorithm: config.rateLimitAlgorithm || 'sliding-window'\\n    },\\n    errorHandler: {\\n      enableDetailedErrors: config.enableDetailedErrors || false,\\n      enableErrorLogging: config.enableErrorLogging !== false\\n    }\\n  });\\n  \\n  // Create router and register all routes\\n  const router = createRouter();\\n  \\n  // Register modular routes\\n  const routeDependencies = {\\n    // Lazy loaders\\n    getMediaStreamingAPI,\\n    getMultiDeviceCoordinator,\\n    getDistributionSystem,\\n    initializeEmotionPipeline,\\n    \\n    // Core components\\n    orchestrator,\\n    memoryOptimizer,\\n    \\n    // Utilities\\n    middlewareSystem,\\n    createJSONResponse,\\n    createErrorResponse,\\n    generateSecureId,\\n    decodeFrame: wsManager.frameProcessor.processFrame,\\n    \\n    // Distribution\\n    getDistributionOverallStatus,\\n    createDistributionStream,\\n    distributionStreams,\\n    distributionClients\\n  };\\n  \\n  const routes = createRouteRegistry(routeDependencies);\\n  routes.forEach(([method, pattern, handler]) => {\\n    router.add(method, pattern, handler);\\n  });\\n\\n  // Add root route\\n  router.add('GET', '^/$', async (request) => {\\n    return createJSONResponse({\\n      message: 'Synopticon API Server - Modular Version',\\n      version: '2.0.0',\\n      routes: routes.length,\\n      middleware: 'enabled',\\n      timestamp: Date.now()\\n    });\\n  });\\n\\n  // Create Bun server\\n  const server = Bun.serve({\\n    port,\\n    fetch: async (request, server) => {\\n      const url = parseRequestURL(request.url);\\n      \\n      // WebSocket upgrade (bypass middleware)\\n      if (url.pathname === '/ws' && server.upgrade(request)) {\\n        return;\\n      }\\n      \\n      // Serve static files from examples directory\\n      if (url.pathname.startsWith('/examples/')) {\\n        try {\\n          const filePath = `.${url.pathname}`;\\n          const file = Bun.file(filePath);\\n          \\n          if (await file.exists()) {\\n            return new Response(file, {\\n              headers: {\\n                'Content-Type': getContentType(filePath),\\n                'Cache-Control': 'public, max-age=3600'\\n              }\\n            });\\n          }\\n        } catch (error) {\\n          console.warn(`Static file error: ${error.message}`);\\n        }\\n        \\n        return new Response('File not found', { status: 404 });\\n      }\\n      \\n      // Process all HTTP requests through middleware system\\n      return await middlewareSystem.processRequest(request, async (req) => {\\n        return await router.route(req);\\n      });\\n    },\\n    \\n    websocket: wsManager.websocketHandlers\\n  });\\n\\n  // Server control\\n  const start = async () => {\\n    console.log(`🚀 Face Analysis API (Modular) running on http://${server.hostname}:${server.port}`);\\n    console.log(`📡 WebSocket endpoint: ws://${server.hostname}:${server.port}/ws`);\\n    console.log(`📝 Registered ${routes.length} routes across ${Object.keys(routeDependencies).length} modules`);\\n    return server;\\n  };\\n  \\n  const stop = async () => {\\n    console.log('🛑 Stopping Face Analysis API...');\\n    \\n    try {\\n      // Cleanup memory optimizer\\n      memoryOptimizer.cleanup();\\n      \\n      // Cleanup WebSocket manager\\n      wsManager.cleanup();\\n      \\n      // Cleanup middleware system\\n      middlewareSystem.cleanup();\\n      \\n      // Cleanup lazy-loaded components\\n      if (multiDeviceCoordinator) {\\n        await multiDeviceCoordinator.cleanup();\\n      }\\n      \\n      if (mediaStreamingAPI) {\\n        await mediaStreamingAPI.cleanup();\\n      }\\n      \\n      if (distributionSessionManager) {\\n        await distributionSessionManager.cleanup();\\n      }\\n      \\n    } catch (error) {\\n      console.warn('Warning during cleanup:', error.message);\\n    }\\n    \\n    server.stop();\\n    console.log('✅ Face Analysis API stopped');\\n  };\\n  \\n  return {\\n    start,\\n    stop,\\n    server,\\n    orchestrator,\\n    strategyRegistry,\\n    middlewareSystem,\\n    routes: routes.length\\n  };\\n};\\n\\n// CLI entry point\\nif (import.meta.url === `file://${process.argv[1]}`) {\\n  const server = createFaceAnalysisServer({\\n    port: process.env.PORT || 3000\\n  });\\n  \\n  server.start().catch(console.error);\\n  \\n  process.on(\\\"SIGINT\\\", async () => {\\n    console.log(\\\"\\\\nShutting down gracefully...\\\");\\n    \\n    try {\\n      await server.stop();\\n    } catch (error) {\\n      console.error(\\\"Error during cleanup:\\\", error);\\n    }\\n    \\n    process.exit(0);\\n  });\\n}\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}},{\"ruleId\":\"no-process-exit\",\"replacedBy\":[\"n/no-process-exit\"],\"info\":{\"message\":\"Node.js rules were moved out of ESLint core.\",\"url\":\"https://eslint.org/docs/latest/use/migrating-to-7.0.0#deprecate-node-rules\",\"deprecatedSince\":\"7.0.0\",\"availableUntil\":null,\"replacedBy\":[{\"message\":\"eslint-plugin-n now maintains deprecated Node.js-related rules.\",\"plugin\":{\"name\":\"eslint-plugin-n\",\"url\":\"https://github.com/eslint-community/eslint-plugin-n\"},\"rule\":{\"name\":\"no-process-exit\",\"url\":\"https://github.com/eslint-community/eslint-plugin-n/tree/master/docs/rules/no-process-exit.md\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/services/api/websocket/frame-processor.js\",\"messages\":[{\"ruleId\":\"max-lines-per-function\",\"severity\":1,\"message\":\"Arrow function has too many lines (216). Maximum allowed is 150.\",\"line\":11,\"column\":46,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"exceed\",\"endLine\":322,\"endColumn\":2},{\"ruleId\":\"no-undef\",\"severity\":2,\"message\":\"'atob' is not defined.\",\"line\":72,\"column\":28,\"nodeType\":\"Identifier\",\"messageId\":\"undef\",\"endLine\":72,\"endColumn\":32},{\"ruleId\":\"complexity\",\"severity\":1,\"message\":\"Arrow function has a complexity of 24. Maximum allowed is 20.\",\"line\":104,\"column\":29,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"complex\",\"endLine\":147,\"endColumn\":4},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":215,\"column\":44,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":215,\"endColumn\":45},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":215,\"column\":80,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":215,\"endColumn\":81}],\"suppressedMessages\":[],\"errorCount\":1,\"fatalErrorCount\":0,\"warningCount\":4,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * WebSocket Frame Processor\\n * Specialized frame decoding and processing utilities for WebSocket streams\\n */\\n\\n/**\\n * Enhanced frame processor for WebSocket streams\\n * @param {Object} config - Configuration options\\n * @returns {Object} Frame processor instance\\n */\\nexport const createWebSocketFrameProcessor = (config = {}) => {\\n  const state = {\\n    config: {\\n      maxFrameSize: config.maxFrameSize || 10 * 1024 * 1024, // 10MB\\n      supportedFormats: config.supportedFormats || ['jpeg', 'png', 'webp'],\\n      enableCompression: config.enableCompression !== false,\\n      enableCaching: config.enableCaching !== false,\\n      cacheSize: config.cacheSize || 50,\\n      ...config\\n    },\\n    frameCache: new Map(), // For frame caching optimization\\n    stats: {\\n      framesProcessed: 0,\\n      bytesProcessed: 0,\\n      cacheHits: 0,\\n      cacheMisses: 0,\\n      errors: 0,\\n      averageProcessingTime: 0\\n    }\\n  };\\n\\n  /**\\n   * Generate frame hash for caching\\n   * @param {ArrayBuffer|Uint8Array} data - Frame data\\n   * @returns {string} Hash string\\n   */\\n  const generateFrameHash = (data) => {\\n    const bytes = data instanceof ArrayBuffer ? new Uint8Array(data) : data;\\n    let hash = 0;\\n    \\n    // Simple hash for performance - sample every 100th byte for large frames\\n    const step = Math.max(1, Math.floor(bytes.length / 1000));\\n    \\n    for (let i = 0; i < bytes.length; i += step) {\\n      hash = ((hash << 5) - hash + bytes[i]) & 0xffffffff;\\n    }\\n    \\n    return hash.toString(16);\\n  };\\n\\n  /**\\n   * Decode base64 data URL frame\\n   * @param {string} dataUrl - Data URL string\\n   * @returns {Object} Decoded frame data\\n   */\\n  const decodeDataUrl = (dataUrl) => {\\n    try {\\n      // Extract format and base64 data\\n      const match = dataUrl.match(/^data:image\\\\/([^;]+);base64,(.+)$/);\\n      if (!match) {\\n        throw new Error('Invalid data URL format');\\n      }\\n\\n      const [, format, base64Data] = match;\\n      \\n      // Validate format\\n      if (!state.config.supportedFormats.includes(format.toLowerCase())) {\\n        throw new Error(`Unsupported image format: ${format}`);\\n      }\\n\\n      // Decode base64\\n      const binaryString = atob(base64Data);\\n      const uint8Array = new Uint8Array(binaryString.length);\\n      \\n      for (let i = 0; i < binaryString.length; i++) {\\n        uint8Array[i] = binaryString.charCodeAt(i);\\n      }\\n\\n      // Check size limits\\n      if (uint8Array.length > state.config.maxFrameSize) {\\n        throw new Error(`Frame size ${uint8Array.length} exceeds limit ${state.config.maxFrameSize}`);\\n      }\\n\\n      return {\\n        data: uint8Array,\\n        format,\\n        size: uint8Array.length,\\n        width: null, // Will be determined by image processor\\n        height: null\\n      };\\n      \\n    } catch (error) {\\n      state.stats.errors++;\\n      throw new Error(`Data URL decoding failed: ${error.message}`);\\n    }\\n  };\\n\\n  /**\\n   * Decode binary frame data\\n   * @param {ArrayBuffer|Uint8Array} binaryData - Binary frame data\\n   * @param {Object} metadata - Optional metadata\\n   * @returns {Object} Decoded frame data\\n   */\\n  const decodeBinaryFrame = (binaryData, metadata = {}) => {\\n    try {\\n      const uint8Array = binaryData instanceof ArrayBuffer ? new Uint8Array(binaryData) : binaryData;\\n      \\n      // Check size limits\\n      if (uint8Array.length > state.config.maxFrameSize) {\\n        throw new Error(`Frame size ${uint8Array.length} exceeds limit ${state.config.maxFrameSize}`);\\n      }\\n\\n      // Try to detect format from magic bytes\\n      let format = metadata.format || 'unknown';\\n      if (uint8Array.length >= 4) {\\n        // JPEG magic bytes\\n        if (uint8Array[0] === 0xFF && uint8Array[1] === 0xD8) {\\n          format = 'jpeg';\\n        }\\n        // PNG magic bytes\\n        else if (uint8Array[0] === 0x89 && uint8Array[1] === 0x50 && \\n                 uint8Array[2] === 0x4E && uint8Array[3] === 0x47) {\\n          format = 'png';\\n        }\\n        // WebP magic bytes (RIFF...WEBP)\\n        else if (uint8Array[0] === 0x52 && uint8Array[1] === 0x49 && \\n                 uint8Array[2] === 0x46 && uint8Array[3] === 0x46 &&\\n                 uint8Array[8] === 0x57 && uint8Array[9] === 0x45 && \\n                 uint8Array[10] === 0x42 && uint8Array[11] === 0x50) {\\n          format = 'webp';\\n        }\\n      }\\n\\n      return {\\n        data: uint8Array,\\n        format,\\n        size: uint8Array.length,\\n        width: metadata.width || null,\\n        height: metadata.height || null,\\n        timestamp: metadata.timestamp || Date.now()\\n      };\\n      \\n    } catch (error) {\\n      state.stats.errors++;\\n      throw new Error(`Binary frame decoding failed: ${error.message}`);\\n    }\\n  };\\n\\n  /**\\n   * Process frame with caching\\n   * @param {*} frameData - Frame data (various formats)\\n   * @param {Object} options - Processing options\\n   * @returns {Object} Processed frame data\\n   */\\n  const processFrame = (frameData, options = {}) => {\\n    const startTime = Date.now();\\n    let processedFrame;\\n    \\n    try {\\n      // Handle different input formats\\n      if (typeof frameData === 'string') {\\n        if (frameData.startsWith('data:image')) {\\n          processedFrame = decodeDataUrl(frameData);\\n        } else {\\n          throw new Error('Unsupported string frame format');\\n        }\\n      } else if (frameData instanceof ArrayBuffer || frameData instanceof Uint8Array) {\\n        processedFrame = decodeBinaryFrame(frameData, options);\\n      } else if (frameData && typeof frameData === 'object') {\\n        // Already processed frame data\\n        processedFrame = {\\n          data: frameData.data,\\n          format: frameData.format || 'unknown',\\n          size: frameData.size || (frameData.data ? frameData.data.length : 0),\\n          width: frameData.width,\\n          height: frameData.height,\\n          timestamp: frameData.timestamp || Date.now()\\n        };\\n      } else {\\n        throw new Error('Invalid frame data type');\\n      }\\n\\n      // Cache processing if enabled\\n      if (state.config.enableCaching && processedFrame.data) {\\n        const hash = generateFrameHash(processedFrame.data);\\n        \\n        if (state.frameCache.has(hash)) {\\n          state.stats.cacheHits++;\\n          const cached = state.frameCache.get(hash);\\n          processedFrame.cached = true;\\n          processedFrame.cacheHit = true;\\n          processedFrame = { ...processedFrame, ...cached.metadata };\\n        } else {\\n          state.stats.cacheMisses++;\\n          \\n          // Add to cache if not full\\n          if (state.frameCache.size < state.config.cacheSize) {\\n            state.frameCache.set(hash, {\\n              metadata: {\\n                format: processedFrame.format,\\n                size: processedFrame.size,\\n                processedAt: Date.now()\\n              }\\n            });\\n          }\\n        }\\n      }\\n\\n      // Update statistics\\n      state.stats.framesProcessed++;\\n      state.stats.bytesProcessed += processedFrame.size;\\n      \\n      const processingTime = Date.now() - startTime;\\n      state.stats.averageProcessingTime = \\n        (state.stats.averageProcessingTime * (state.stats.framesProcessed - 1) + processingTime) / \\n        state.stats.framesProcessed;\\n\\n      return processedFrame;\\n      \\n    } catch (error) {\\n      state.stats.errors++;\\n      console.error('Frame processing error:', error);\\n      throw error;\\n    }\\n  };\\n\\n  /**\\n   * Validate frame data\\n   * @param {Object} frameData - Frame data to validate\\n   * @returns {Object} Validation result\\n   */\\n  const validateFrame = (frameData) => {\\n    const issues = [];\\n    const warnings = [];\\n\\n    if (!frameData) {\\n      issues.push('Frame data is null or undefined');\\n      return { valid: false, issues, warnings };\\n    }\\n\\n    if (!frameData.data) {\\n      issues.push('Frame data missing data property');\\n    }\\n\\n    if (!frameData.size || frameData.size <= 0) {\\n      warnings.push('Frame size is zero or undefined');\\n    }\\n\\n    if (frameData.size > state.config.maxFrameSize) {\\n      issues.push(`Frame size ${frameData.size} exceeds maximum ${state.config.maxFrameSize}`);\\n    }\\n\\n    if (frameData.format && !state.config.supportedFormats.includes(frameData.format)) {\\n      warnings.push(`Frame format '${frameData.format}' may not be supported`);\\n    }\\n\\n    return {\\n      valid: issues.length === 0,\\n      issues,\\n      warnings\\n    };\\n  };\\n\\n  /**\\n   * Clear frame cache\\n   */\\n  const clearCache = () => {\\n    state.frameCache.clear();\\n    console.log('🧹 Frame cache cleared');\\n  };\\n\\n  /**\\n   * Get processing statistics\\n   * @returns {Object} Processing statistics\\n   */\\n  const getStatistics = () => {\\n    return {\\n      ...state.stats,\\n      cacheSize: state.frameCache.size,\\n      cacheHitRate: state.stats.cacheHits / Math.max(state.stats.cacheHits + state.stats.cacheMisses, 1),\\n      averageFrameSize: state.stats.bytesProcessed / Math.max(state.stats.framesProcessed, 1),\\n      timestamp: Date.now()\\n    };\\n  };\\n\\n  /**\\n   * Cleanup processor resources\\n   */\\n  const cleanup = () => {\\n    clearCache();\\n    \\n    // Reset statistics\\n    state.stats = {\\n      framesProcessed: 0,\\n      bytesProcessed: 0,\\n      cacheHits: 0,\\n      cacheMisses: 0,\\n      errors: 0,\\n      averageProcessingTime: 0\\n    };\\n    \\n    console.log('🧹 Frame processor cleanup completed');\\n  };\\n\\n  return {\\n    processFrame,\\n    validateFrame,\\n    clearCache,\\n    getStatistics,\\n    cleanup,\\n    \\n    // Direct decoders (for specialized use)\\n    decodeDataUrl,\\n    decodeBinaryFrame,\\n    \\n    // Configuration access\\n    getConfig: () => ({ ...state.config }),\\n    updateConfig: (updates) => {\\n      state.config = { ...state.config, ...updates };\\n    }\\n  };\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}},{\"ruleId\":\"no-process-exit\",\"replacedBy\":[\"n/no-process-exit\"],\"info\":{\"message\":\"Node.js rules were moved out of ESLint core.\",\"url\":\"https://eslint.org/docs/latest/use/migrating-to-7.0.0#deprecate-node-rules\",\"deprecatedSince\":\"7.0.0\",\"availableUntil\":null,\"replacedBy\":[{\"message\":\"eslint-plugin-n now maintains deprecated Node.js-related rules.\",\"plugin\":{\"name\":\"eslint-plugin-n\",\"url\":\"https://github.com/eslint-community/eslint-plugin-n\"},\"rule\":{\"name\":\"no-process-exit\",\"url\":\"https://github.com/eslint-community/eslint-plugin-n/tree/master/docs/rules/no-process-exit.md\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/services/api/websocket/index.js\",\"messages\":[],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}},{\"ruleId\":\"no-process-exit\",\"replacedBy\":[\"n/no-process-exit\"],\"info\":{\"message\":\"Node.js rules were moved out of ESLint core.\",\"url\":\"https://eslint.org/docs/latest/use/migrating-to-7.0.0#deprecate-node-rules\",\"deprecatedSince\":\"7.0.0\",\"availableUntil\":null,\"replacedBy\":[{\"message\":\"eslint-plugin-n now maintains deprecated Node.js-related rules.\",\"plugin\":{\"name\":\"eslint-plugin-n\",\"url\":\"https://github.com/eslint-community/eslint-plugin-n\"},\"rule\":{\"name\":\"no-process-exit\",\"url\":\"https://github.com/eslint-community/eslint-plugin-n/tree/master/docs/rules/no-process-exit.md\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/services/api/websocket/message-handlers.js\",\"messages\":[{\"ruleId\":\"max-lines-per-function\",\"severity\":1,\"message\":\"Arrow function has too many lines (208). Maximum allowed is 150.\",\"line\":11,\"column\":47,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"exceed\",\"endLine\":317,\"endColumn\":2},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'data' is defined but never used. Allowed unused args must match /^_/u.\",\"line\":128,\"column\":41,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":128,\"endColumn\":45,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"data\"},\"fix\":{\"range\":[3579,3585],\"text\":\"\"},\"desc\":\"Remove unused variable 'data'.\"}]},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'metadata' is assigned a value but never used. Allowed unused args must match /^_/u.\",\"line\":263,\"column\":33,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":263,\"endColumn\":41,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"metadata\"},\"fix\":{\"range\":[7501,7516],\"text\":\"\"},\"desc\":\"Remove unused variable 'metadata'.\"}]},{\"ruleId\":\"no-undef\",\"severity\":2,\"message\":\"'meta' is not defined.\",\"line\":264,\"column\":54,\"nodeType\":\"Identifier\",\"messageId\":\"undef\",\"endLine\":264,\"endColumn\":58},{\"ruleId\":\"no-undef\",\"severity\":2,\"message\":\"'data' is not defined.\",\"line\":264,\"column\":59,\"nodeType\":\"Identifier\",\"messageId\":\"undef\",\"endLine\":264,\"endColumn\":63}],\"suppressedMessages\":[],\"errorCount\":4,\"fatalErrorCount\":0,\"warningCount\":1,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * WebSocket Message Handlers\\n * Processes different types of WebSocket messages\\n */\\n\\n/**\\n * Create WebSocket message handler system\\n * @param {Object} dependencies - Required dependencies\\n * @returns {Object} Message handler instance\\n */\\nexport const createWebSocketMessageHandlers = (dependencies) => {\\n  const {\\n    sessionManager,\\n    orchestrator,\\n    initializeEmotionPipeline,\\n    decodeFrame\\n  } = dependencies;\\n\\n  /**\\n   * Process frame analysis message\\n   * @param {Object} session - WebSocket session\\n   * @param {Object} data - Message data\\n   */\\n  const handleFrameAnalysis = async (session, data) => {\\n    try {\\n      session.frameCount++;\\n      sessionManager.updateSessionActivity(session.id);\\n\\n      // Ensure emotion pipeline is loaded\\n      await initializeEmotionPipeline();\\n      \\n      const emotionPipeline = orchestrator.getPipeline('emotion-analysis');\\n      if (!emotionPipeline) {\\n        throw new Error('Emotion analysis pipeline not available');\\n      }\\n\\n      // Decode frame data\\n      const frameData = decodeFrame(data.frame || data.image);\\n      \\n      // Process frame through pipeline\\n      const result = await emotionPipeline.process(frameData);\\n      \\n      // Send result back to client\\n      const response = {\\n        type: 'frame_result',\\n        sessionId: session.id,\\n        frameId: data.frameId,\\n        data: result.data || result,\\n        timestamp: Date.now()\\n      };\\n\\n      session.ws.send(JSON.stringify(response));\\n      \\n    } catch (error) {\\n      console.error('Frame analysis error:', error);\\n      sessionManager.incrementSessionError(session.id);\\n      \\n      session.ws.send(JSON.stringify({\\n        type: 'error',\\n        sessionId: session.id,\\n        error: error.message,\\n        errorCode: 'FRAME_ANALYSIS_ERROR',\\n        timestamp: Date.now()\\n      }));\\n    }\\n  };\\n\\n  /**\\n   * Process configuration message\\n   * @param {Object} session - WebSocket session\\n   * @param {Object} data - Message data\\n   */\\n  const handleConfiguration = async (session, data) => {\\n    try {\\n      sessionManager.updateSessionActivity(session.id);\\n\\n      // Update session requirements\\n      session.requirements = { ...session.requirements, ...data.requirements };\\n      \\n      // Apply any session-specific configuration\\n      if (data.settings) {\\n        session.metadata.settings = { ...session.metadata.settings, ...data.settings };\\n      }\\n\\n      session.ws.send(JSON.stringify({\\n        type: 'configured',\\n        sessionId: session.id,\\n        requirements: session.requirements,\\n        settings: session.metadata.settings,\\n        timestamp: Date.now()\\n      }));\\n      \\n    } catch (error) {\\n      console.error('Configuration error:', error);\\n      sessionManager.incrementSessionError(session.id);\\n      \\n      session.ws.send(JSON.stringify({\\n        type: 'error',\\n        sessionId: session.id,\\n        error: error.message,\\n        errorCode: 'CONFIGURATION_ERROR',\\n        timestamp: Date.now()\\n      }));\\n    }\\n  };\\n\\n  /**\\n   * Process ping message (keepalive)\\n   * @param {Object} session - WebSocket session\\n   * @param {Object} data - Message data\\n   */\\n  const handlePing = (session, data) => {\\n    sessionManager.updateSessionActivity(session.id);\\n    \\n    session.ws.send(JSON.stringify({\\n      type: 'pong',\\n      sessionId: session.id,\\n      clientTimestamp: data.timestamp,\\n      serverTimestamp: Date.now()\\n    }));\\n  };\\n\\n  /**\\n   * Process status request message\\n   * @param {Object} session - WebSocket session\\n   * @param {Object} data - Message data\\n   */\\n  const handleStatusRequest = (session, data) => {\\n    sessionManager.updateSessionActivity(session.id);\\n    \\n    const stats = sessionManager.getStatistics();\\n    const pipelines = orchestrator.getRegisteredPipelines();\\n    \\n    session.ws.send(JSON.stringify({\\n      type: 'status',\\n      sessionId: session.id,\\n      server: {\\n        uptime: stats.uptime,\\n        activeConnections: stats.activeConnections,\\n        totalSessions: stats.totalSessions,\\n        pipelines: pipelines.map(p => ({\\n          name: p.name,\\n          type: p.type || 'unknown',\\n          status: p.getStatus ? p.getStatus() : 'active'\\n        }))\\n      },\\n      session: {\\n        id: session.id,\\n        frameCount: session.frameCount,\\n        messageCount: session.messageCount,\\n        errors: session.errors,\\n        age: Math.round((Date.now() - session.createdAt) / 1000)\\n      },\\n      timestamp: Date.now()\\n    }));\\n  };\\n\\n  /**\\n   * Process subscription message (for real-time updates)\\n   * @param {Object} session - WebSocket session\\n   * @param {Object} data - Message data\\n   */\\n  const handleSubscription = (session, data) => {\\n    sessionManager.updateSessionActivity(session.id);\\n    \\n    if (!session.metadata.subscriptions) {\\n      session.metadata.subscriptions = new Set();\\n    }\\n    \\n    const { action, topics } = data;\\n    const topicsArray = Array.isArray(topics) ? topics : [topics];\\n    \\n    if (action === 'subscribe') {\\n      topicsArray.forEach(topic => session.metadata.subscriptions.add(topic));\\n    } else if (action === 'unsubscribe') {\\n      topicsArray.forEach(topic => session.metadata.subscriptions.delete(topic));\\n    }\\n    \\n    session.ws.send(JSON.stringify({\\n      type: 'subscription_result',\\n      sessionId: session.id,\\n      action,\\n      topics: Array.from(session.metadata.subscriptions),\\n      timestamp: Date.now()\\n    }));\\n  };\\n\\n  /**\\n   * Main message router\\n   * @param {WebSocket} ws - WebSocket connection\\n   * @param {string} message - Raw message string\\n   */\\n  const handleMessage = async (ws, message) => {\\n    const session = sessionManager.getSessionByWebSocket(ws);\\n    if (!session) {\\n      console.warn('⚠️ Received message from unknown WebSocket session');\\n      return;\\n    }\\n\\n    // Prevent concurrent message processing per session\\n    if (session.isProcessing) {\\n      console.warn(`⚠️ Session ${session.id} is busy, dropping message`);\\n      return;\\n    }\\n\\n    sessionManager.setSessionProcessing(session.id, true);\\n\\n    try {\\n      const data = JSON.parse(message);\\n      \\n      // Route message based on type\\n      switch (data.type) {\\n        case 'frame':\\n          await handleFrameAnalysis(session, data);\\n          break;\\n          \\n        case 'configure':\\n          await handleConfiguration(session, data);\\n          break;\\n          \\n        case 'ping':\\n          handlePing(session, data);\\n          break;\\n          \\n        case 'status':\\n          handleStatusRequest(session, data);\\n          break;\\n          \\n        case 'subscribe':\\n        case 'unsubscribe':\\n          handleSubscription(session, data);\\n          break;\\n          \\n        default:\\n          throw new Error(`Unknown message type: ${data.type}`);\\n      }\\n      \\n    } catch (error) {\\n      console.error('Message handling error:', error);\\n      sessionManager.incrementSessionError(session.id);\\n      \\n      try {\\n        session.ws.send(JSON.stringify({\\n          type: 'error',\\n          sessionId: session.id,\\n          error: error.message,\\n          errorCode: 'MESSAGE_HANDLING_ERROR',\\n          timestamp: Date.now()\\n        }));\\n      } catch (sendError) {\\n        console.error('Failed to send error response:', sendError);\\n      }\\n    } finally {\\n      sessionManager.setSessionProcessing(session.id, false);\\n    }\\n  };\\n\\n  /**\\n   * Handle WebSocket connection open\\n   * @param {WebSocket} ws - WebSocket connection\\n   * @param {Object} metadata - Optional connection metadata\\n   */\\n  const handleConnection = (ws, metadata = {}) => {\\n    const session = sessionManager.createSession(ws, meta,data);\\n    return session;\\n  };\\n\\n  /**\\n   * Handle WebSocket connection close\\n   * @param {WebSocket} ws - WebSocket connection\\n   * @param {number} code - Close code\\n   * @param {string} reason - Close reason\\n   */\\n  const handleDisconnection = (ws, code, reason) => {\\n    const session = sessionManager.getSessionByWebSocket(ws);\\n    if (session) {\\n      console.log(`🔌 WebSocket disconnected: ${session.id} (${code}: ${reason})`);\\n      sessionManager.removeSession(session.id);\\n    }\\n  };\\n\\n  /**\\n   * Broadcast system notification to subscribed clients\\n   * @param {string} topic - Topic name\\n   * @param {Object} data - Notification data\\n   */\\n  const broadcastNotification = (topic, data) => {\\n    const message = {\\n      type: 'notification',\\n      topic,\\n      data,\\n      timestamp: Date.now()\\n    };\\n\\n    const filter = (session) => {\\n      return session.metadata.subscriptions && session.metadata.subscriptions.has(topic);\\n    };\\n\\n    return sessionManager.broadcast(message, filter);\\n  };\\n\\n  return {\\n    handleMessage,\\n    handleConnection,\\n    handleDisconnection,\\n    broadcastNotification,\\n    \\n    // Individual handlers (for testing)\\n    handlers: {\\n      frame: handleFrameAnalysis,\\n      configure: handleConfiguration,\\n      ping: handlePing,\\n      status: handleStatusRequest,\\n      subscription: handleSubscription\\n    }\\n  };\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}},{\"ruleId\":\"no-process-exit\",\"replacedBy\":[\"n/no-process-exit\"],\"info\":{\"message\":\"Node.js rules were moved out of ESLint core.\",\"url\":\"https://eslint.org/docs/latest/use/migrating-to-7.0.0#deprecate-node-rules\",\"deprecatedSince\":\"7.0.0\",\"availableUntil\":null,\"replacedBy\":[{\"message\":\"eslint-plugin-n now maintains deprecated Node.js-related rules.\",\"plugin\":{\"name\":\"eslint-plugin-n\",\"url\":\"https://github.com/eslint-community/eslint-plugin-n\"},\"rule\":{\"name\":\"no-process-exit\",\"url\":\"https://github.com/eslint-community/eslint-plugin-n/tree/master/docs/rules/no-process-exit.md\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/services/api/websocket/session-manager.js\",\"messages\":[{\"ruleId\":\"max-lines-per-function\",\"severity\":1,\"message\":\"Arrow function has too many lines (183). Maximum allowed is 150.\",\"line\":13,\"column\":46,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"exceed\",\"endLine\":293,\"endColumn\":2}],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":1,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * WebSocket Session Manager\\n * Handles WebSocket session lifecycle and state management\\n */\\n\\nimport { createAnalysisRequirements } from '../../../core/configuration/types.js';\\n\\n/**\\n * Create WebSocket session manager\\n * @param {Object} config - Configuration options\\n * @returns {Object} Session manager instance\\n */\\nexport const createWebSocketSessionManager = (config = {}) => {\\n  const state = {\\n    sessions: new Map(),\\n    activeConnections: 0,\\n    totalSessions: 0,\\n    config: {\\n      maxSessions: config.maxSessions || 100,\\n      sessionTimeout: config.sessionTimeout || 300000, // 5 minutes\\n      cleanupInterval: config.cleanupInterval || 60000, // 1 minute\\n      ...config\\n    }\\n  };\\n\\n  // Cleanup inactive sessions periodically\\n  const cleanupTimer = setInterval(() => {\\n    cleanupInactiveSessions();\\n  }, state.config.cleanupInterval);\\n\\n  /**\\n   * Generate secure session ID\\n   * @param {string} prefix - Optional prefix for session ID\\n   * @returns {string} Generated session ID\\n   */\\n  const generateSessionId = (prefix = 'ws') => {\\n    const timestamp = Date.now();\\n    const random = crypto.getRandomValues(new Uint8Array(8));\\n    const randomHex = Array.from(random, byte => byte.toString(16).padStart(2, '0')).join('');\\n    return `${prefix}_${timestamp}_${randomHex}`;\\n  };\\n\\n  /**\\n   * Create new WebSocket session\\n   * @param {WebSocket} ws - WebSocket connection\\n   * @param {Object} metadata - Optional session metadata\\n   * @returns {Object} Created session object\\n   */\\n  const createSession = (ws, metadata = {}) => {\\n    // Check session limits\\n    if (state.sessions.size >= state.config.maxSessions) {\\n      console.warn('⚠️ Maximum WebSocket sessions reached, rejecting new connection');\\n      ws.close(1013, 'Server overloaded');\\n      return null;\\n    }\\n\\n    const sessionId = generateSessionId();\\n    const session = {\\n      id: sessionId,\\n      ws,\\n      metadata,\\n      requirements: createAnalysisRequirements(),\\n      createdAt: Date.now(),\\n      lastActivity: Date.now(),\\n      isProcessing: false,\\n      frameCount: 0,\\n      messageCount: 0,\\n      errors: 0,\\n      status: 'active'\\n    };\\n\\n    state.sessions.set(sessionId, session);\\n    state.activeConnections++;\\n    state.totalSessions++;\\n\\n    console.log(`🔌 WebSocket session created: ${sessionId} (${state.activeConnections} active)`);\\n\\n    // Send welcome message\\n    try {\\n      ws.send(JSON.stringify({\\n        type: 'connected',\\n        sessionId,\\n        capabilities: ['frame_analysis', 'emotion_detection', 'media_streaming'],\\n        serverVersion: '2.0.0',\\n        timestamp: Date.now()\\n      }));\\n    } catch (error) {\\n      console.error('Failed to send welcome message:', error);\\n      removeSession(sessionId);\\n      return null;\\n    }\\n\\n    return session;\\n  };\\n\\n  /**\\n   * Remove WebSocket session\\n   * @param {string} sessionId - Session ID to remove\\n   * @returns {boolean} Success status\\n   */\\n  const removeSession = (sessionId) => {\\n    const session = state.sessions.get(sessionId);\\n    if (!session) return false;\\n\\n    state.sessions.delete(sessionId);\\n    state.activeConnections--;\\n\\n    console.log(`🔌 WebSocket session removed: ${sessionId} (${state.activeConnections} active)`);\\n    return true;\\n  };\\n\\n  /**\\n   * Get session by WebSocket connection\\n   * @param {WebSocket} ws - WebSocket connection\\n   * @returns {Object|null} Session object or null if not found\\n   */\\n  const getSessionByWebSocket = (ws) => {\\n    for (const session of state.sessions.values()) {\\n      if (session.ws === ws) {\\n        return session;\\n      }\\n    }\\n    return null;\\n  };\\n\\n  /**\\n   * Get session by ID\\n   * @param {string} sessionId - Session ID\\n   * @returns {Object|null} Session object or null if not found\\n   */\\n  const getSessionById = (sessionId) => {\\n    return state.sessions.get(sessionId) || null;\\n  };\\n\\n  /**\\n   * Update session activity timestamp\\n   * @param {string} sessionId - Session ID\\n   */\\n  const updateSessionActivity = (sessionId) => {\\n    const session = state.sessions.get(sessionId);\\n    if (session) {\\n      session.lastActivity = Date.now();\\n      session.messageCount++;\\n    }\\n  };\\n\\n  /**\\n   * Mark session as processing\\n   * @param {string} sessionId - Session ID\\n   * @param {boolean} processing - Processing state\\n   */\\n  const setSessionProcessing = (sessionId, processing) => {\\n    const session = state.sessions.get(sessionId);\\n    if (session) {\\n      session.isProcessing = processing;\\n    }\\n  };\\n\\n  /**\\n   * Increment session error count\\n   * @param {string} sessionId - Session ID\\n   */\\n  const incrementSessionError = (sessionId) => {\\n    const session = state.sessions.get(sessionId);\\n    if (session) {\\n      session.errors++;\\n      \\n      // Auto-disconnect sessions with too many errors\\n      if (session.errors >= 10) {\\n        console.warn(`🚨 Session ${sessionId} exceeded error limit, disconnecting`);\\n        session.ws.close(1011, 'Too many errors');\\n        removeSession(sessionId);\\n      }\\n    }\\n  };\\n\\n  /**\\n   * Clean up inactive sessions\\n   */\\n  const cleanupInactiveSessions = () => {\\n    const now = Date.now();\\n    const timeout = state.config.sessionTimeout;\\n    let cleanedUp = 0;\\n\\n    for (const [sessionId, session] of state.sessions.entries()) {\\n      if (now - session.lastActivity > timeout) {\\n        console.log(`🧹 Cleaning up inactive session: ${sessionId}`);\\n        session.ws.close(1000, 'Session timeout');\\n        removeSession(sessionId);\\n        cleanedUp++;\\n      }\\n    }\\n\\n    if (cleanedUp > 0) {\\n      console.log(`🧹 Cleaned up ${cleanedUp} inactive WebSocket sessions`);\\n    }\\n  };\\n\\n  /**\\n   * Broadcast message to all active sessions\\n   * @param {Object} message - Message to broadcast\\n   * @param {Function} filter - Optional filter function for sessions\\n   */\\n  const broadcast = (message, filter = null) => {\\n    const messageStr = JSON.stringify(message);\\n    let sent = 0;\\n\\n    for (const session of state.sessions.values()) {\\n      if (session.status === 'active' && (!filter || filter(session))) {\\n        try {\\n          session.ws.send(messageStr);\\n          sent++;\\n        } catch (error) {\\n          console.error(`Failed to send broadcast to ${session.id}:`, error);\\n          removeSession(session.id);\\n        }\\n      }\\n    }\\n\\n    console.log(`📡 Broadcasted message to ${sent} sessions`);\\n    return sent;\\n  };\\n\\n  /**\\n   * Get session statistics\\n   * @returns {Object} Session statistics\\n   */\\n  const getStatistics = () => {\\n    const sessions = Array.from(state.sessions.values());\\n    \\n    return {\\n      activeConnections: state.activeConnections,\\n      totalSessions: state.totalSessions,\\n      averageSessionAge: sessions.length > 0 \\n        ? Math.round(sessions.reduce((sum, s) => sum + (Date.now() - s.createdAt), 0) / sessions.length / 1000)\\n        : 0,\\n      totalMessages: sessions.reduce((sum, s) => sum + s.messageCount, 0),\\n      totalFrames: sessions.reduce((sum, s) => sum + s.frameCount, 0),\\n      totalErrors: sessions.reduce((sum, s) => sum + s.errors, 0),\\n      processingRate: sessions.filter(s => s.isProcessing).length / Math.max(sessions.length, 1),\\n      uptime: Math.round((Date.now() - (sessions[0]?.createdAt || Date.now())) / 1000),\\n      timestamp: Date.now()\\n    };\\n  };\\n\\n  /**\\n   * Close all sessions and cleanup\\n   */\\n  const cleanup = () => {\\n    console.log('🧹 Cleaning up WebSocket session manager...');\\n    \\n    // Clear cleanup timer\\n    if (cleanupTimer) {\\n      clearInterval(cleanupTimer);\\n    }\\n    \\n    // Close all active sessions\\n    for (const [sessionId, session] of state.sessions.entries()) {\\n      try {\\n        session.ws.close(1001, 'Server shutting down');\\n      } catch (error) {\\n        console.warn(`Error closing session ${sessionId}:`, error);\\n      }\\n    }\\n    \\n    state.sessions.clear();\\n    state.activeConnections = 0;\\n    \\n    console.log('✅ WebSocket session manager cleanup complete');\\n  };\\n\\n  return {\\n    // Session lifecycle\\n    createSession,\\n    removeSession,\\n    getSessionByWebSocket,\\n    getSessionById,\\n    \\n    // Session management\\n    updateSessionActivity,\\n    setSessionProcessing,\\n    incrementSessionError,\\n    \\n    // Utilities\\n    broadcast,\\n    getStatistics,\\n    cleanup,\\n    \\n    // State access\\n    getSessions: () => Array.from(state.sessions.values()),\\n    getActiveCount: () => state.activeConnections\\n  };\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}},{\"ruleId\":\"no-process-exit\",\"replacedBy\":[\"n/no-process-exit\"],\"info\":{\"message\":\"Node.js rules were moved out of ESLint core.\",\"url\":\"https://eslint.org/docs/latest/use/migrating-to-7.0.0#deprecate-node-rules\",\"deprecatedSince\":\"7.0.0\",\"availableUntil\":null,\"replacedBy\":[{\"message\":\"eslint-plugin-n now maintains deprecated Node.js-related rules.\",\"plugin\":{\"name\":\"eslint-plugin-n\",\"url\":\"https://github.com/eslint-community/eslint-plugin-n\"},\"rule\":{\"name\":\"no-process-exit\",\"url\":\"https://github.com/eslint-community/eslint-plugin-n/tree/master/docs/rules/no-process-exit.md\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/shared/utils/camera.js\",\"messages\":[{\"ruleId\":\"max-lines-per-function\",\"severity\":1,\"message\":\"Arrow function has too many lines (166). Maximum allowed is 150.\",\"line\":5,\"column\":36,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"exceed\",\"endLine\":223,\"endColumn\":2},{\"ruleId\":\"prefer-destructuring\",\"severity\":1,\"message\":\"Use array destructuring.\",\"line\":161,\"column\":11,\"nodeType\":\"VariableDeclarator\",\"messageId\":\"preferDestructuring\",\"endLine\":161,\"endColumn\":56},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'width' is defined but never used. Allowed unused args must match /^_/u.\",\"line\":229,\"column\":25,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":229,\"endColumn\":30,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"width\"},\"fix\":{\"range\":[5893,5900],\"text\":\"\"},\"desc\":\"Remove unused variable 'width'.\"}]},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'height' is defined but never used. Allowed unused args must match /^_/u.\",\"line\":229,\"column\":32,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":229,\"endColumn\":38,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"height\"},\"fix\":{\"range\":[5900,5908],\"text\":\"\"},\"desc\":\"Remove unused variable 'height'.\"}]},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":242,\"column\":31,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":242,\"endColumn\":32},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":242,\"column\":35,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":242,\"endColumn\":36},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":252,\"column\":24,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":252,\"endColumn\":25},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":252,\"column\":28,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":252,\"endColumn\":29},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":253,\"column\":24,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":253,\"endColumn\":25},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":253,\"column\":28,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":253,\"endColumn\":29},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":254,\"column\":32,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":254,\"endColumn\":33},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":254,\"column\":36,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":254,\"endColumn\":37},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":254,\"column\":36,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":254,\"endColumn\":37},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":254,\"column\":44,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":254,\"endColumn\":45},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":254,\"column\":48,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":254,\"endColumn\":49},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":254,\"column\":56,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":254,\"endColumn\":57},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'width' is defined but never used. Allowed unused args must match /^_/u.\",\"line\":259,\"column\":26,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":259,\"endColumn\":31,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"width\"},\"fix\":{\"range\":[6894,6901],\"text\":\"\"},\"desc\":\"Remove unused variable 'width'.\"}]},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'height' is defined but never used. Allowed unused args must match /^_/u.\",\"line\":259,\"column\":33,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":259,\"endColumn\":39,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"height\"},\"fix\":{\"range\":[6901,6909],\"text\":\"\"},\"desc\":\"Remove unused variable 'height'.\"}]},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":301,\"column\":27,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":301,\"endColumn\":28},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":301,\"column\":38,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":301,\"endColumn\":39},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":304,\"column\":31,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":304,\"endColumn\":32},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":304,\"column\":42,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":304,\"endColumn\":43},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":304,\"column\":48,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":304,\"endColumn\":49},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":304,\"column\":52,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":304,\"endColumn\":53},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":305,\"column\":31,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":305,\"endColumn\":32},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":305,\"column\":42,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":305,\"endColumn\":43},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":305,\"column\":48,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":305,\"endColumn\":49},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":305,\"column\":52,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":305,\"endColumn\":53},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":306,\"column\":31,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":306,\"endColumn\":32},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":306,\"column\":42,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":306,\"endColumn\":43},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":306,\"column\":48,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":306,\"endColumn\":49},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":306,\"column\":52,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":306,\"endColumn\":53},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":307,\"column\":31,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":307,\"endColumn\":32},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":307,\"column\":42,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":307,\"endColumn\":43},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":307,\"column\":48,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":307,\"endColumn\":49},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":307,\"column\":52,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":307,\"endColumn\":53},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":309,\"column\":26,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":309,\"endColumn\":27},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":309,\"column\":38,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":309,\"endColumn\":39},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":310,\"column\":29,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":310,\"endColumn\":30},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":310,\"column\":41,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":310,\"endColumn\":42},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":311,\"column\":37,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":311,\"endColumn\":38},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":311,\"column\":54,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":311,\"endColumn\":55}],\"suppressedMessages\":[],\"errorCount\":4,\"fatalErrorCount\":0,\"warningCount\":38,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Camera Management - Webcam access and frame processing utilities\\n */\\n\\nexport const createCameraManager = () => {\\n  const state = {\\n    stream: null,\\n    video: null,\\n    canvas: null,\\n    context: null,\\n    isInitialized: false,\\n    frameCallbacks: [],\\n    animationFrameId: null\\n  };\\n\\n  const initialize = async (constraints = {}) => {\\n    // Default camera constraints optimized for face detection\\n    const defaultConstraints = {\\n      video: {\\n        width: { ideal: 640, max: 1280 },\\n        height: { ideal: 480, max: 720 },\\n        frameRate: { ideal: 30, max: 60 },\\n        facingMode: 'user'\\n      },\\n      audio: false\\n    };\\n\\n    const finalConstraints = {\\n      ...defaultConstraints,\\n      ...constraints\\n    };\\n\\n    try {\\n      // Request camera access\\n      state.stream = await navigator.mediaDevices.getUserMedia(finalConstraints);\\n      \\n      // Create video element\\n      state.video = document.createElement('video');\\n      state.video.srcObject = state.stream;\\n      state.video.playsInline = true;\\n      state.video.muted = true;\\n      \\n      // Wait for video to be ready\\n      await new Promise((resolve, reject) => {\\n        state.video.onloadedmetadata = () => {\\n          console.log(`Video metadata loaded: ${state.video.videoWidth}x${state.video.videoHeight}`);\\n          state.video.play().then(() => {\\n            console.log('Video playing, readyState:', state.video.readyState);\\n            resolve();\\n          }).catch(reject);\\n        };\\n        state.video.onerror = reject;\\n      });\\n\\n      // Create canvas for frame extraction\\n      state.canvas = document.createElement('canvas');\\n      state.canvas.width = state.video.videoWidth || 640;\\n      state.canvas.height = state.video.videoHeight || 480;\\n      state.context = state.canvas.getContext('2d');\\n      \\n      if (!state.context) {\\n        throw new Error('Failed to get 2D canvas context for camera');\\n      }\\n\\n      state.isInitialized = true;\\n      console.log(`Camera initialized: ${state.canvas.width}x${state.canvas.height}`);\\n      \\n    } catch (error) {\\n      throw new Error(`Camera initialization failed: ${error.message}`);\\n    }\\n  };\\n\\n  const getFrame = () => {\\n    // Performance optimization: Remove expensive console logging\\n    // Debug logging can be enabled via environment flag if needed\\n    \\n    if (!state.isInitialized) {\\n      throw new Error('Camera not initialized');\\n    }\\n\\n    if (!state.context) {\\n      throw new Error('Canvas context is null - camera not properly initialized');\\n    }\\n\\n    if (!state.video || state.video.readyState < 2) {\\n      throw new Error(`Video not ready - readyState: ${  state.video ? state.video.readyState : 'null'}`);\\n    }\\n\\n    try {\\n      // Draw current video frame to canvas (optimized)\\n      state.context.drawImage(state.video, 0, 0, state.canvas.width, state.canvas.height);\\n      \\n      // Get image data\\n      const imageData = state.context.getImageData(0, 0, state.canvas.width, state.canvas.height);\\n      \\n      return {\\n        data: imageData.data,\\n        width: state.canvas.width,\\n        height: state.canvas.height,\\n        canvas: state.canvas\\n      };\\n    } catch (error) {\\n      console.error('Draw image failed:', error);\\n      throw new Error(`Failed to get frame: ${error.message}`);\\n    }\\n  };\\n\\n  const startFrameProcessing = () => {\\n    if (state.animationFrameId) {\\n      return; // Already running\\n    }\\n\\n    const processFrame = () => {\\n      if (state.isInitialized && state.frameCallbacks.length > 0) {\\n        const frame = getFrame();\\n        \\n        // Call all registered callbacks\\n        state.frameCallbacks.forEach(callback => {\\n          try {\\n            callback(frame);\\n          } catch (error) {\\n            console.error('Frame callback error:', error);\\n          }\\n        });\\n      }\\n      \\n      state.animationFrameId = requestAnimationFrame(processFrame);\\n    };\\n\\n    processFrame();\\n  };\\n\\n  const stopFrameProcessing = () => {\\n    if (state.animationFrameId) {\\n      cancelAnimationFrame(state.animationFrameId);\\n      state.animationFrameId = null;\\n    }\\n  };\\n\\n  const onFrame = (callback) => {\\n    state.frameCallbacks.push(callback);\\n    return () => {\\n      const index = state.frameCallbacks.indexOf(callback);\\n      if (index > -1) {\\n        state.frameCallbacks.splice(index, 1);\\n      }\\n    };\\n  };\\n\\n  const getVideoElement = () => {\\n    return state.video;\\n  };\\n\\n  const getCanvas = () => {\\n    return state.canvas;\\n  };\\n\\n  const getStreamInfo = () => {\\n    if (!state.stream) return null;\\n    \\n    const videoTrack = state.stream.getVideoTracks()[0];\\n    if (!videoTrack) return null;\\n    \\n    return {\\n      settings: videoTrack.getSettings(),\\n      capabilities: videoTrack.getCapabilities(),\\n      constraints: videoTrack.getConstraints()\\n    };\\n  };\\n\\n  const switchCamera = async (facingMode = 'user') => {\\n    if (!state.isInitialized) {\\n      throw new Error('Camera not initialized');\\n    }\\n\\n    // Stop current stream\\n    cleanup();\\n    \\n    // Initialize with new facing mode\\n    await initialize({\\n      video: { facingMode }\\n    });\\n  };\\n\\n  const cleanup = () => {\\n    // Stop frame processing\\n    stopFrameProcessing();\\n    \\n    // Stop video stream\\n    if (state.stream) {\\n      state.stream.getTracks().forEach(track => {\\n        track.stop();\\n      });\\n      state.stream = null;\\n    }\\n\\n    // Clean up video element\\n    if (state.video) {\\n      state.video.srcObject = null;\\n      state.video = null;\\n    }\\n\\n    // Clean up canvas\\n    state.canvas = null;\\n    state.context = null;\\n    \\n    state.isInitialized = false;\\n    state.frameCallbacks = [];\\n  };\\n\\n  return {\\n    initialize,\\n    getFrame,\\n    startFrameProcessing,\\n    stopFrameProcessing,\\n    onFrame,\\n    getVideoElement,\\n    getCanvas,\\n    getStreamInfo,\\n    switchCamera,\\n    cleanup\\n  };\\n};\\n\\n/**\\n * Frame processing utilities\\n */\\nexport const FrameProcessor = {\\n  rgbaToTexture: (data, width, height) => {\\n    // Convert RGBA Uint8ClampedArray to Float32Array for WebGL\\n    const floatData = new Float32Array(data.length);\\n    for (let i = 0; i < data.length; i++) {\\n      floatData[i] = data[i] / 255.0;\\n    }\\n    return floatData;\\n  },\\n\\n  extractChannel: (data, width, height, channel = 0) => {\\n    // Extract single channel from RGBA data\\n    const channelData = new Float32Array(width * height);\\n    for (let i = 0; i < width * height; i++) {\\n      channelData[i] = data[i * 4 + channel] / 255.0;\\n    }\\n    return channelData;\\n  },\\n\\n  rgbToGrayscale: (data, width, height) => {\\n    // Convert RGB to grayscale using luminance formula\\n    const grayscaleData = new Float32Array(width * height);\\n    for (let i = 0; i < width * height; i++) {\\n      const r = data[i * 4] / 255.0;\\n      const g = data[i * 4 + 1] / 255.0;\\n      const b = data[i * 4 + 2] / 255.0;\\n      grayscaleData[i] = 0.299 * r + 0.587 * g + 0.114 * b;\\n    }\\n    return grayscaleData;\\n  },\\n\\n  normalizeFrame: (data, width, height) => {\\n    // Normalize frame data to [0, 1] range\\n    const normalized = new Float32Array(data.length);\\n    let min = Infinity;\\n    let max = -Infinity;\\n    \\n    // Find min/max\\n    for (let i = 0; i < data.length; i++) {\\n      min = Math.min(min, data[i]);\\n      max = Math.max(max, data[i]);\\n    }\\n    \\n    // Normalize\\n    const range = max - min;\\n    if (range > 0) {\\n      for (let i = 0; i < data.length; i++) {\\n        normalized[i] = (data[i] - min) / range;\\n      }\\n    }\\n    \\n    return normalized;\\n  },\\n\\n  resizeFrame: (data, srcWidth, srcHeight, dstWidth, dstHeight) => {\\n    // Simple bilinear interpolation resize\\n    const resized = new Float32Array(dstWidth * dstHeight * 4);\\n    const xRatio = srcWidth / dstWidth;\\n    const yRatio = srcHeight / dstHeight;\\n    \\n    for (let y = 0; y < dstHeight; y++) {\\n      for (let x = 0; x < dstWidth; x++) {\\n        const srcX = x * xRatio;\\n        const srcY = y * yRatio;\\n        \\n        const x1 = Math.floor(srcX);\\n        const y1 = Math.floor(srcY);\\n        const x2 = Math.min(x1 + 1, srcWidth - 1);\\n        const y2 = Math.min(y1 + 1, srcHeight - 1);\\n        \\n        const dx = srcX - x1;\\n        const dy = srcY - y1;\\n        \\n        const dstIdx = (y * dstWidth + x) * 4;\\n        \\n        for (let c = 0; c < 4; c++) {\\n          const tl = data[(y1 * srcWidth + x1) * 4 + c];\\n          const tr = data[(y1 * srcWidth + x2) * 4 + c];\\n          const bl = data[(y2 * srcWidth + x1) * 4 + c];\\n          const br = data[(y2 * srcWidth + x2) * 4 + c];\\n          \\n          const top = tl + (tr - tl) * dx;\\n          const bottom = bl + (br - bl) * dx;\\n          resized[dstIdx + c] = top + (bottom - top) * dy;\\n        }\\n      }\\n    }\\n    \\n    return resized;\\n  }\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/shared/utils/canvas-utils.js\",\"messages\":[{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'type' is defined but never used. Allowed unused args must match /^_/u.\",\"line\":24,\"column\":20,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":24,\"endColumn\":24,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"type\"},\"fix\":{\"range\":[761,765],\"text\":\"\"},\"desc\":\"Remove unused variable 'type'.\"}]},{\"ruleId\":\"prefer-destructuring\",\"severity\":1,\"message\":\"Use array destructuring.\",\"line\":48,\"column\":15,\"nodeType\":\"VariableDeclarator\",\"messageId\":\"preferDestructuring\",\"endLine\":48,\"endColumn\":45},{\"ruleId\":\"no-undef\",\"severity\":2,\"message\":\"'atob' is not defined.\",\"line\":49,\"column\":24,\"nodeType\":\"Identifier\",\"messageId\":\"undef\",\"endLine\":49,\"endColumn\":28},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'error' is defined but never used.\",\"line\":148,\"column\":12,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":148,\"endColumn\":17},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'error' is defined but never used.\",\"line\":161,\"column\":12,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":161,\"endColumn\":17}],\"suppressedMessages\":[],\"errorCount\":4,\"fatalErrorCount\":0,\"warningCount\":1,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Canvas Utilities for Server-side and Client-side rendering\\n * Provides unified canvas creation for both browser and Node.js environments\\n */\\n\\n// Check environment\\nconst isNode = typeof window === 'undefined';\\nconst isBrowser = typeof window !== 'undefined';\\n\\nexport const createCanvas = (width = 640, height = 480) => {\\n  if (isBrowser) {\\n    // Browser environment\\n    const canvas = document.createElement('canvas');\\n    canvas.width = width;\\n    canvas.height = height;\\n    return canvas;\\n  } else {\\n    // Node.js environment - would need 'canvas' package in production\\n    // For now, return a mock canvas object\\n    console.warn('Server-side canvas creation - using mock implementation');\\n    return {\\n      width,\\n      height,\\n      getContext: (type) => ({\\n        // Mock 2D context\\n        fillRect: () => {},\\n        clearRect: () => {},\\n        drawImage: () => {},\\n        getImageData: () => new ImageData(width, height),\\n        putImageData: () => {},\\n        // Mock WebGL context  \\n        useProgram: () => {},\\n        bindTexture: () => {},\\n        drawArrays: () => {}\\n      })\\n    };\\n  }\\n};\\n\\nexport const canvasToBlob = (canvas, type = 'image/png', quality = 0.92) => {\\n  return new Promise((resolve, reject) => {\\n    if (canvas.toBlob) {\\n      canvas.toBlob(resolve, type, quality);\\n    } else {\\n      // Fallback for environments without toBlob\\n      try {\\n        const dataURL = canvas.toDataURL(type, quality);\\n        const base64 = dataURL.split(',')[1];\\n        const binary = atob(base64);\\n        const bytes = new Uint8Array(binary.length);\\n        for (let i = 0; i < binary.length; i++) {\\n          bytes[i] = binary.charCodeAt(i);\\n        }\\n        resolve(new Blob([bytes], { type }));\\n      } catch (error) {\\n        reject(error);\\n      }\\n    }\\n  });\\n};\\n\\nexport const canvasToDataURL = (canvas, type = 'image/png', quality = 0.92) => {\\n  if (canvas.toDataURL) {\\n    return canvas.toDataURL(type, quality);\\n  } else {\\n    // Mock implementation for server\\n    return `data:${type};base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVR42mNkYPhfDwAChwGA60e6kgAAAABJRU5ErkJggg==`;\\n  }\\n};\\n\\nexport const loadImageToCanvas = (src, canvas = null) => {\\n  return new Promise((resolve, reject) => {\\n    if (isBrowser) {\\n      const img = new Image();\\n      img.crossOrigin = 'anonymous';\\n      \\n      img.onload = () => {\\n        const targetCanvas = canvas || createCanvas(img.width, img.height);\\n        const ctx = targetCanvas.getContext('2d');\\n        \\n        targetCanvas.width = img.width;\\n        targetCanvas.height = img.height;\\n        ctx.drawImage(img, 0, 0);\\n        \\n        resolve(targetCanvas);\\n      };\\n      \\n      img.onerror = () => reject(new Error('Failed to load image'));\\n      img.src = src;\\n      \\n    } else {\\n      // Server-side image loading would require additional packages\\n      reject(new Error('Server-side image loading not implemented'));\\n    }\\n  });\\n};\\n\\nexport const resizeCanvas = (sourceCanvas, targetWidth, targetHeight, canvas = null) => {\\n  const targetCanvas = canvas || createCanvas(targetWidth, targetHeight);\\n  const ctx = targetCanvas.getContext('2d');\\n  \\n  targetCanvas.width = targetWidth;\\n  targetCanvas.height = targetHeight;\\n  \\n  // Use high-quality scaling\\n  ctx.imageSmoothingEnabled = true;\\n  ctx.imageSmoothingQuality = 'high';\\n  \\n  ctx.drawImage(sourceCanvas, 0, 0, targetWidth, targetHeight);\\n  \\n  return targetCanvas;\\n};\\n\\nexport const getImageDataFromCanvas = (canvas, x = 0, y = 0, width = null, height = null) => {\\n  const ctx = canvas.getContext('2d');\\n  const w = width || canvas.width;\\n  const h = height || canvas.height;\\n  \\n  try {\\n    return ctx.getImageData(x, y, w, h);\\n  } catch (error) {\\n    console.error('Failed to get image data:', error);\\n    return null;\\n  }\\n};\\n\\nexport const createImageDataFromArray = (data, width, height) => {\\n  if (isBrowser && ImageData) {\\n    return new ImageData(data, width, height);\\n  } else {\\n    // Mock ImageData for server\\n    return {\\n      data,\\n      width,\\n      height\\n    };\\n  }\\n};\\n\\n// Utility to check if WebGL is supported\\nexport const isWebGLSupported = () => {\\n  if (!isBrowser) return false;\\n  \\n  try {\\n    const canvas = createCanvas();\\n    const gl = canvas.getContext('webgl') || canvas.getContext('experimental-webgl');\\n    return !!gl;\\n  } catch (error) {\\n    return false;\\n  }\\n};\\n\\n// Utility to check if WebGL2 is supported\\nexport const isWebGL2Supported = () => {\\n  if (!isBrowser) return false;\\n  \\n  try {\\n    const canvas = createCanvas();\\n    const gl = canvas.getContext('webgl2');\\n    return !!gl;\\n  } catch (error) {\\n    return false;\\n  }\\n};\\n\\nexport const getCanvasInfo = (canvas) => ({\\n  width: canvas.width,\\n  height: canvas.height,\\n  hasWebGL: isWebGLSupported(),\\n  hasWebGL2: isWebGL2Supported(),\\n  environment: isNode ? 'node' : 'browser'\\n});\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/shared/utils/dependency-loader.js\",\"messages\":[],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/shared/utils/dependency-resolver.js\",\"messages\":[{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'loadScript' is defined but never used. Allowed unused vars must match /^_/u.\",\"line\":6,\"column\":10,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":6,\"endColumn\":20,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"loadScript\"},\"fix\":{\"range\":[116,127],\"text\":\"\"},\"desc\":\"Remove unused variable 'loadScript'.\"}]},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'options' is assigned a value but never used. Allowed unused args must match /^_/u.\",\"line\":82,\"column\":29,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":82,\"endColumn\":36,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"options\"},\"fix\":{\"range\":[2227,2239],\"text\":\"\"},\"desc\":\"Remove unused variable 'options'.\"}]}],\"suppressedMessages\":[],\"errorCount\":2,\"fatalErrorCount\":0,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Dependency Resolution Module\\n * Handles dependency loading with prerequisites and verification\\n */\\n\\nimport { loadScript, loadScripts } from './script-loader.js';\\n\\n// Load a dependency and its prerequisites\\nexport const loadDependency = async (dependencies, dependencyKey) => {\\n  const dependency = dependencies[dependencyKey];\\n  \\n  if (!dependency) {\\n    throw new Error(`Unknown dependency: ${dependencyKey}`);\\n  }\\n\\n  // Check if already available\\n  if (dependency.check()) {\\n    return true;\\n  }\\n\\n  // Check browser environment\\n  if (typeof window === 'undefined' || typeof document === 'undefined') {\\n    throw new Error(`Cannot load ${dependency.name} in non-browser environment`);\\n  }\\n\\n  try {\\n    // Load dependencies first\\n    if (dependency.dependencies) {\\n      for (const depKey of dependency.dependencies) {\\n        await loadDependency(dependencies, depKey);\\n      }\\n    }\\n\\n    // Load the main scripts\\n    await loadScripts(dependency.scripts);\\n    \\n    // Verify loading was successful\\n    let retries = 0;\\n    const maxRetries = 10;\\n    const checkInterval = 100; // ms\\n    \\n    while (!dependency.check() && retries < maxRetries) {\\n      await new Promise(resolve => setTimeout(resolve, checkInterval));\\n      retries++;\\n    }\\n\\n    if (!dependency.check()) {\\n      throw new Error(`${dependency.name} failed to initialize after loading`);\\n    }\\n\\n    console.log(`✅ ${dependency.name} loaded successfully`);\\n    return true;\\n\\n  } catch (error) {\\n    console.error(`❌ Failed to load ${dependency.name}:`, error);\\n    throw new Error(`Failed to load ${dependency.name}: ${error.message}`);\\n  }\\n};\\n\\n// Load multiple dependencies\\nexport const loadDependencies = async (dependencies, dependencyKeys) => {\\n  const results = new Map();\\n  \\n  for (const key of dependencyKeys) {\\n    try {\\n      await loadDependency(dependencies, key);\\n      results.set(key, { success: true });\\n    } catch (error) {\\n      results.set(key, { success: false, error: error.message });\\n    }\\n  }\\n  \\n  return results;\\n};\\n\\n// Initialization helper for pipelines\\nexport const createDependencyInitializer = (dependencies, dependencyKeys) => {\\n  let loaded = false;\\n  let loading = false;\\n  let error = null;\\n\\n  const initialize = async (options = {}) => {\\n    if (loaded) return true;\\n    if (loading) {\\n      // Wait for current loading to complete\\n      while (loading && !loaded && !error) {\\n        await new Promise(resolve => setTimeout(resolve, 100));\\n      }\\n      if (error) throw error;\\n      return loaded;\\n    }\\n\\n    loading = true;\\n    error = null;\\n\\n    try {\\n      const results = await loadDependencies(dependencies, dependencyKeys);\\n      \\n      // Check if all required dependencies loaded successfully\\n      for (const [key, result] of results.entries()) {\\n        if (!result.success) {\\n          throw new Error(`Failed to load ${key}: ${result.error}`);\\n        }\\n      }\\n\\n      loaded = true;\\n      loading = false;\\n      return true;\\n\\n    } catch (err) {\\n      error = err;\\n      loading = false;\\n      throw err;\\n    }\\n  };\\n\\n  const isInitialized = () => loaded;\\n  const getError = () => error;\\n  const isLoading = () => loading;\\n\\n  return { initialize, isInitialized, getError, isLoading };\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/shared/utils/enhanced-memory-pool.js\",\"messages\":[{\"ruleId\":\"max-lines-per-function\",\"severity\":1,\"message\":\"Arrow function has too many lines (177). Maximum allowed is 150.\",\"line\":51,\"column\":41,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"exceed\",\"endLine\":313,\"endColumn\":2}],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":1,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Enhanced Memory Pool Manager\\n * \\n * Provides intelligent object pooling and reuse for better memory management\\n * and garbage collection performance in intensive applications.\\n * \\n * Features:\\n * - Typed array pooling (Float32Array, Uint8Array, etc.)\\n * - Canvas and ImageData pooling for graphics operations\\n * - Generic object pooling with custom factories\\n * - Adaptive cleanup based on usage patterns\\n * - Memory pressure monitoring and response\\n * - Comprehensive usage statistics and metrics\\n * \\n * Performance Benefits:\\n * - Reduces garbage collection pressure by reusing objects\\n * - Eliminates frequent allocations/deallocations\\n * - Adaptive cleanup prevents memory bloat\\n * - Memory pressure monitoring prevents out-of-memory conditions\\n * \\n * @example\\n * ```javascript\\n * import { createEnhancedMemoryPool } from './enhanced-memory-pool.js';\\n * \\n * const memoryPool = createEnhancedMemoryPool({\\n *   maxPoolSize: 100,\\n *   adaptiveCleanup: true,\\n *   enableMetrics: true\\n * });\\n * \\n * memoryPool.initialize();\\n * \\n * // Use typed arrays\\n * const array = memoryPool.acquireFloat32Array(1024);\\n * // ... use array\\n * memoryPool.releaseArray(array);\\n * \\n * // Use custom objects\\n * const result = memoryPool.acquire('FaceResult', { faces: [] });\\n * // ... use result\\n * memoryPool.release(result);\\n * ```\\n */\\n\\nimport { createMemoryPoolConfig, createMemoryPoolState } from './memory-pool-config.js';\\nimport { createFactoryManager } from './memory-pool-factories.js';\\nimport { createArrayManager } from './memory-pool-arrays.js';\\nimport { createCleanupManager } from './memory-pool-cleanup.js';\\n\\n// Create enhanced memory pool manager factory\\nexport const createEnhancedMemoryPool = (config = {}) => {\\n  const poolConfig = createMemoryPoolConfig(config);\\n  const state = createMemoryPoolState(poolConfig);\\n  \\n  // Create managers\\n  const factoryManager = createFactoryManager(state);\\n  const arrayManager = createArrayManager(state, factoryManager);\\n  const cleanupManager = createCleanupManager(state);\\n\\n  // Initialize the memory pool\\n  const initialize = () => {\\n    console.log('🔧 Initializing enhanced memory pool...');\\n    \\n    // Register default factories\\n    factoryManager.registerDefaultFactories();\\n    \\n    // Start adaptive cleanup timer\\n    if (state.config.baseCleanupInterval > 0) {\\n      cleanupManager.startAdaptiveCleanup();\\n    }\\n    \\n    // Monitor memory pressure if available\\n    if (typeof performance !== 'undefined' && performance.memory) {\\n      setInterval(cleanupManager.checkMemoryPressure, 5000);\\n    }\\n    \\n    console.log('✅ Enhanced memory pool initialized');\\n    return true;\\n  };\\n\\n  // Acquire object from pool\\n  const acquire = (type, ...args) => {\\n    const key = args.length > 0 ? `${type}_${args.join('_')}` : type;\\n    const pool = state.pools.objects.get(key) || [];\\n    \\n    let obj;\\n    if (pool.length > 0) {\\n      obj = pool.pop();\\n      state.stats.reuseHits++;\\n    } else {\\n      // Create new object\\n      const factory = factoryManager.getFactory(type);\\n      if (!factory) {\\n        throw new Error(`No factory registered for type: ${type}`);\\n      }\\n      \\n      obj = factory(...args);\\n      state.stats.allocations++;\\n    }\\n    \\n    // Track object\\n    if (state.config.enableTracking) {\\n      state.activeObjects.add(obj);\\n      state.objectMetadata.set(obj, {\\n        type,\\n        args,\\n        acquiredAt: Date.now(),\\n        poolKey: key\\n      });\\n    }\\n    \\n    return obj;\\n  };\\n\\n  // Release object back to pool\\n  const release = (obj) => {\\n    if (!obj) return;\\n    \\n    const metadata = state.objectMetadata.get(obj);\\n    if (!metadata) {\\n      console.warn('Attempting to release untracked object');\\n      return;\\n    }\\n    \\n    const { poolKey } = metadata;\\n    const pool = state.pools.objects.get(poolKey) || [];\\n    \\n    // Check pool size limit\\n    if (pool.length < state.config.maxPoolSize) {\\n      pool.push(obj);\\n      \\n      if (!state.pools.objects.has(poolKey)) {\\n        state.pools.objects.set(poolKey, pool);\\n      }\\n      \\n      state.stats.deallocations++;\\n    }\\n    \\n    // Remove from tracking\\n    if (state.config.enableTracking) {\\n      state.activeObjects.delete(obj);\\n      state.objectMetadata.delete(obj);\\n    }\\n  };\\n\\n  // Acquire canvas element\\n  const acquireCanvas = (width, height) => {\\n    const key = `${width}x${height}`;\\n    const pool = state.pools.canvases.get(key) || [];\\n    \\n    let canvas;\\n    if (pool.length > 0) {\\n      canvas = pool.pop();\\n      state.stats.reuseHits++;\\n      \\n      // Reset canvas\\n      const ctx = canvas.getContext('2d');\\n      if (ctx) {\\n        ctx.clearRect(0, 0, canvas.width, canvas.height);\\n      }\\n    } else {\\n      // Create new canvas\\n      const factory = factoryManager.getFactory('Canvas');\\n      canvas = factory ? factory(width, height) : null;\\n      \\n      if (!canvas) {\\n        throw new Error('Canvas not available in this environment');\\n      }\\n      \\n      state.stats.allocations++;\\n    }\\n    \\n    // Track canvas\\n    if (state.config.enableTracking) {\\n      state.objectMetadata.set(canvas, {\\n        type: 'Canvas',\\n        width,\\n        height,\\n        acquiredAt: Date.now(),\\n        poolKey: key\\n      });\\n    }\\n    \\n    return canvas;\\n  };\\n\\n  // Release canvas back to pool\\n  const releaseCanvas = (canvas) => {\\n    if (!canvas) return;\\n    \\n    const metadata = state.objectMetadata.get(canvas);\\n    if (!metadata) {\\n      console.warn('Attempting to release untracked canvas');\\n      return;\\n    }\\n    \\n    const { poolKey } = metadata;\\n    const pool = state.pools.canvases.get(poolKey) || [];\\n    \\n    // Check pool size limit\\n    if (pool.length < state.config.maxPoolSize) {\\n      pool.push(canvas);\\n      \\n      if (!state.pools.canvases.has(poolKey)) {\\n        state.pools.canvases.set(poolKey, pool);\\n      }\\n      \\n      state.stats.deallocations++;\\n    }\\n    \\n    // Remove from tracking\\n    if (state.config.enableTracking) {\\n      state.objectMetadata.delete(canvas);\\n    }\\n  };\\n\\n  // Get comprehensive statistics\\n  const getStatistics = () => {\\n    // Update pool sizes in stats\\n    state.stats.poolSizes = {};\\n    \\n    for (const [type, pools] of Object.entries(state.pools)) {\\n      state.stats.poolSizes[type] = {};\\n      for (const [key, pool] of pools.entries()) {\\n        state.stats.poolSizes[type][key] = pool.length;\\n      }\\n    }\\n    \\n    return {\\n      ...state.stats,\\n      pools: { ...state.stats.poolSizes },\\n      cleanup: cleanupManager.getCleanupStats(),\\n      configuration: state.config,\\n      runtime: Date.now() - state.stats.created\\n    };\\n  };\\n\\n  // Update pool configuration\\n  const updateConfiguration = (newConfig) => {\\n    Object.assign(state.config, newConfig);\\n    console.log('🔧 Memory pool configuration updated');\\n  };\\n\\n  // Reset all pools and statistics\\n  const reset = () => {\\n    // Clear all pools\\n    for (const pools of Object.values(state.pools)) {\\n      pools.clear();\\n    }\\n    \\n    // Reset statistics\\n    state.stats.allocations = 0;\\n    state.stats.deallocations = 0;\\n    state.stats.reuseHits = 0;\\n    state.stats.memoryLeaks = 0;\\n    state.stats.poolSizes = {};\\n    state.stats.lastCleanup = Date.now();\\n    \\n    console.log('🧹 Memory pool reset completed');\\n  };\\n\\n  // Cleanup and destroy pool\\n  const cleanup = () => {\\n    cleanupManager.stopCleanup();\\n    \\n    // Clear all pools\\n    for (const pools of Object.values(state.pools)) {\\n      pools.clear();\\n    }\\n    \\n    // Clear factories\\n    state.factories.clear();\\n    \\n    console.log('🧹 Enhanced memory pool cleaned up');\\n  };\\n\\n  return {\\n    // Core functionality\\n    initialize,\\n    acquire,\\n    release,\\n    \\n    // Typed arrays\\n    acquireArray: arrayManager.acquireArray,\\n    releaseArray: arrayManager.releaseArray,\\n    acquireFloat32Array: arrayManager.acquireFloat32Array,\\n    acquireUint8Array: arrayManager.acquireUint8Array,\\n    \\n    // Canvas management\\n    acquireCanvas,\\n    releaseCanvas,\\n    \\n    // Factory management\\n    registerFactory: factoryManager.registerFactory,\\n    getRegisteredTypes: factoryManager.getRegisteredTypes,\\n    \\n    // Cleanup management\\n    cleanup: cleanupManager.cleanup,\\n    forceCleanup: cleanupManager.forceCleanup,\\n    \\n    // Information and statistics\\n    getStatistics,\\n    getArrayPoolStats: arrayManager.getArrayPoolStats,\\n    \\n    // Configuration and maintenance\\n    updateConfiguration,\\n    getConfiguration: () => ({ ...state.config }),\\n    reset,\\n    \\n    // Lifecycle\\n    cleanup\\n  };\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/shared/utils/error-handler.js\",\"messages\":[{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'errorHistory' is assigned a value but never used. Allowed unused vars must match /^_/u.\",\"line\":39,\"column\":7,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":39,\"endColumn\":19,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"errorHistory\"},\"fix\":{\"range\":[852,876],\"text\":\"\"},\"desc\":\"Remove unused variable 'errorHistory'.\"}]},{\"ruleId\":\"max-lines-per-function\",\"severity\":1,\"message\":\"Arrow function has too many lines (322). Maximum allowed is 150.\",\"line\":44,\"column\":35,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"exceed\",\"endLine\":457,\"endColumn\":2}],\"suppressedMessages\":[],\"errorCount\":1,\"fatalErrorCount\":0,\"warningCount\":1,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Comprehensive Error Handling System\\n * Provides standardized error handling, logging controls, and recovery mechanisms\\n */\\n\\n// Error severity levels\\nexport const ErrorSeverity = {\\n  FATAL: 'fatal',\\n  ERROR: 'error', \\n  WARNING: 'warning',\\n  INFO: 'info',\\n  DEBUG: 'debug'\\n};\\n\\n// Error categories for better classification\\nexport const ErrorCategory = {\\n  INITIALIZATION: 'initialization',\\n  WEBGL: 'webgl',\\n  CAMERA: 'camera',\\n  PROCESSING: 'processing',\\n  MEMORY: 'memory',\\n  PERFORMANCE: 'performance',\\n  NETWORK: 'network',\\n  VALIDATION: 'validation',\\n  PIPELINE_EXECUTION: 'pipeline_execution'\\n};\\n\\n// Global error handling configuration\\nlet errorConfig = {\\n  logLevel: ErrorSeverity.WARNING,\\n  enableConsole: true,\\n  enableCollection: false,\\n  maxErrorHistory: 100,\\n  onError: null,\\n  enableRecovery: true\\n};\\n\\n// Error history for debugging\\nconst errorHistory = [];\\n\\n/**\\n * Creates a comprehensive error handler system\\n */\\nexport const createErrorHandler = (config = {}) => {\\n  // Merge configuration\\n  errorConfig = { ...errorConfig, ...config };\\n  \\n  const state = {\\n    config: errorConfig,\\n    history: [],\\n    recoveryAttempts: new Map()\\n  };\\n\\n  // Severity level ordering for filtering\\n  const severityLevels = {\\n    [ErrorSeverity.DEBUG]: 0,\\n    [ErrorSeverity.INFO]: 1,\\n    [ErrorSeverity.WARNING]: 2,\\n    [ErrorSeverity.ERROR]: 3,\\n    [ErrorSeverity.FATAL]: 4\\n  };\\n\\n  const shouldLog = (severity) => {\\n    const configLevel = severityLevels[state.config.logLevel] || 2;\\n    const messagLevel = severityLevels[severity] || 2;\\n    return messagLevel >= configLevel;\\n  };\\n\\n  const createStandardError = (message, category, severity = ErrorSeverity.ERROR, context = {}) => {\\n    const timestamp = new Date().toISOString();\\n    const error = {\\n      id: `${category}_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`,\\n      message,\\n      category,\\n      severity,\\n      timestamp,\\n      context,\\n      stack: new Error().stack\\n    };\\n\\n    // Add to history if collection enabled\\n    if (state.config.enableCollection) {\\n      state.history.push(error);\\n      \\n      // Maintain history size limit\\n      if (state.history.length > state.config.maxErrorHistory) {\\n        state.history.shift();\\n      }\\n    }\\n\\n    return error;\\n  };\\n\\n  const logError = (error) => {\\n    if (!shouldLog(error.severity)) return;\\n\\n    const prefix = `[${error.severity.toUpperCase()}] [${error.category}]`;\\n    const message = `${prefix} ${error.message}`;\\n    \\n    if (state.config.enableConsole) {\\n      switch (error.severity) {\\n        case ErrorSeverity.FATAL:\\n        case ErrorSeverity.ERROR:\\n          console.error(message, error.context);\\n          break;\\n        case ErrorSeverity.WARNING:\\n          console.warn(message, error.context);\\n          break;\\n        case ErrorSeverity.INFO:\\n          console.info(message, error.context);\\n          break;\\n        case ErrorSeverity.DEBUG:\\n          console.debug(message, error.context);\\n          break;\\n      }\\n    }\\n\\n    // Call custom error handler\\n    if (state.config.onError) {\\n      try {\\n        state.config.onError(error);\\n      } catch (handlerError) {\\n        console.error('Error in custom error handler:', handlerError);\\n      }\\n    }\\n  };\\n\\n  const handleError = (message, category, severity = ErrorSeverity.ERROR, context = {}) => {\\n    const error = createStandardError(message, category, severity, context);\\n    logError(error);\\n    \\n    // Skip recovery for INFO level messages to avoid interference with initialization\\n    if (severity !== ErrorSeverity.FATAL && severity !== ErrorSeverity.INFO && state.config.enableRecovery) {\\n      attemptRecovery(error);\\n    }\\n    \\n    return error;\\n  };\\n\\n  const attemptRecovery = (error) => {\\n    const recoveryKey = `${error.category}_${error.message}`;\\n    const attempts = state.recoveryAttempts.get(recoveryKey) || 0;\\n    \\n    // Limit recovery attempts to prevent infinite loops\\n    if (attempts >= 3) {\\n      console.error(`Recovery failed after ${attempts} attempts: ${error.message}`, { originalError: error });\\n      return false;\\n    }\\n\\n    state.recoveryAttempts.set(recoveryKey, attempts + 1);\\n    \\n    // Category-specific recovery strategies\\n    switch (error.category) {\\n      case ErrorCategory.WEBGL:\\n        return recoverWebGL(error);\\n      case ErrorCategory.CAMERA:\\n        return recoverCamera(error);\\n      case ErrorCategory.MEMORY:\\n        return recoverMemory(error);\\n      default:\\n        return false;\\n    }\\n  };\\n\\n  const recoverWebGL = (error) => {\\n    handleError(\\n      'Attempting WebGL context recovery',\\n      ErrorCategory.WEBGL,\\n      ErrorSeverity.INFO,\\n      { originalError: error.id }\\n    );\\n    \\n    // WebGL context recovery implementation\\n    try {\\n      const canvas = error.context?.canvas || document.querySelector('canvas');\\n      if (!canvas) {\\n        handleError(\\n          'No canvas found for WebGL recovery',\\n          ErrorCategory.WEBGL,\\n          ErrorSeverity.ERROR\\n        );\\n        return false;\\n      }\\n\\n      // Check if context is lost\\n      const gl = canvas.getContext('webgl2') || canvas.getContext('webgl');\\n      if (!gl) {\\n        handleError(\\n          'Failed to get WebGL context during recovery',\\n          ErrorCategory.WEBGL,\\n          ErrorSeverity.ERROR\\n        );\\n        return false;\\n      }\\n\\n      // Check if context is actually lost\\n      if (gl.isContextLost && gl.isContextLost()) {\\n        handleError(\\n          'WebGL context is lost, waiting for restoration',\\n          ErrorCategory.WEBGL,\\n          ErrorSeverity.WARNING\\n        );\\n\\n        // Set up context restoration handler\\n        const handleContextRestored = () => {\\n          console.info('[INFO] [WEBGL] WebGL context restored successfully');\\n          \\n          // Trigger reinitialization if callback available\\n          if (error.context?.onContextRestored) {\\n            error.context.onContextRestored();\\n          }\\n          \\n          canvas.removeEventListener('webglcontextrestored', handleContextRestored);\\n        };\\n\\n        canvas.addEventListener('webglcontextrestored', handleContextRestored);\\n        return true; // Recovery attempt in progress\\n      }\\n\\n      // Context is not lost, try other recovery strategies\\n      \\n      // Clear any GL errors\\n      let glError;\\n      while ((glError = gl.getError()) !== gl.NO_ERROR) {\\n        console.warn(`[WARNING] [WEBGL] Clearing GL error during recovery: ${glError}`);\\n      }\\n\\n      // Test basic WebGL functionality\\n      const testTexture = gl.createTexture();\\n      if (!testTexture) {\\n        console.error('[ERROR] [WEBGL] WebGL recovery failed: cannot create test texture');\\n        return false;\\n      }\\n      \\n      gl.deleteTexture(testTexture);\\n      \\n      console.info('[INFO] [WEBGL] WebGL recovery successful');\\n      \\n      return true;\\n\\n    } catch (recoveryError) {\\n      console.error('[ERROR] [WEBGL] WebGL recovery failed with exception', { \\n        originalError: error.id,\\n        recoveryError: recoveryError.message,\\n        stack: recoveryError.stack\\n      });\\n      \\n      return false;\\n    }\\n  };\\n\\n  const recoverCamera = (error) => {\\n    handleError(\\n      'Attempting camera recovery',\\n      ErrorCategory.CAMERA, \\n      ErrorSeverity.INFO,\\n      { originalError: error.id }\\n    );\\n    \\n    // Camera recovery could involve re-initializing permissions\\n    return true;\\n  };\\n\\n  const recoverMemory = (error) => {\\n    handleError(\\n      'Attempting memory cleanup and recovery',\\n      ErrorCategory.MEMORY,\\n      ErrorSeverity.WARNING,\\n      { originalError: error.id }\\n    );\\n    \\n    // Memory recovery would trigger cleanup routines\\n    if (globalThis.gc) {\\n      globalThis.gc();\\n    }\\n    return true;\\n  };\\n\\n  // Validation helpers\\n  const validateRequired = (value, name, context = {}) => {\\n    if (value === null || value === undefined) {\\n      handleError(\\n        `Required parameter '${name}' is missing`,\\n        ErrorCategory.VALIDATION,\\n        ErrorSeverity.ERROR,\\n        { paramName: name, ...context }\\n      );\\n      return false;\\n    }\\n    return true;\\n  };\\n\\n  const validateType = (value, expectedType, name, context = {}) => {\\n    if (typeof value !== expectedType) {\\n      handleError(\\n        `Parameter '${name}' expected ${expectedType}, got ${typeof value}`,\\n        ErrorCategory.VALIDATION,\\n        ErrorSeverity.ERROR,\\n        { paramName: name, expectedType, actualType: typeof value, ...context }\\n      );\\n      return false;\\n    }\\n    return true;\\n  };\\n\\n  const validateRange = (value, min, max, name, context = {}) => {\\n    if (value < min || value > max) {\\n      handleError(\\n        `Parameter '${name}' must be between ${min} and ${max}, got ${value}`,\\n        ErrorCategory.VALIDATION,\\n        ErrorSeverity.ERROR,\\n        { paramName: name, value, min, max, ...context }\\n      );\\n      return false;\\n    }\\n    return true;\\n  };\\n\\n  // Performance monitoring\\n  const wrapFunction = (fn, name, category = ErrorCategory.PROCESSING) => {\\n    return function(...args) {\\n      const start = performance.now();\\n      \\n      try {\\n        const result = fn.apply(this, args);\\n        \\n        // Log performance if it's a Promise\\n        if (result && typeof result.then === 'function') {\\n          return result.catch(error => {\\n            handleError(\\n              `Async function '${name}' failed: ${error.message}`,\\n              category,\\n              ErrorSeverity.ERROR,\\n              { functionName: name, args: args.length, duration: performance.now() - start }\\n            );\\n            throw error;\\n          });\\n        }\\n        \\n        const duration = performance.now() - start;\\n        if (duration > 50) { // Log slow operations\\n          handleError(\\n            `Function '${name}' took ${duration.toFixed(2)}ms to execute`,\\n            ErrorCategory.PERFORMANCE,\\n            ErrorSeverity.WARNING,\\n            { functionName: name, duration, args: args.length }\\n          );\\n        }\\n        \\n        return result;\\n        \\n      } catch (error) {\\n        handleError(\\n          `Function '${name}' failed: ${error.message}`,\\n          category,\\n          ErrorSeverity.ERROR,\\n          { functionName: name, args: args.length, duration: performance.now() - start }\\n        );\\n        throw error;\\n      }\\n    };\\n  };\\n\\n  // Error boundary for async operations\\n  const safeAsync = async (operation, fallback = null) => {\\n    try {\\n      return await operation();\\n    } catch (error) {\\n      handleError(\\n        `Async operation failed: ${error.message}`,\\n        ErrorCategory.PROCESSING,\\n        ErrorSeverity.ERROR,\\n        { hasStack: !!error.stack }\\n      );\\n      return fallback;\\n    }\\n  };\\n\\n  // Configuration management\\n  const setLogLevel = (level) => {\\n    if (!Object.values(ErrorSeverity).includes(level)) {\\n      handleError(\\n        `Invalid log level: ${level}`,\\n        ErrorCategory.VALIDATION,\\n        ErrorSeverity.WARNING\\n      );\\n      return;\\n    }\\n    state.config.logLevel = level;\\n    handleError(\\n      `Log level changed to: ${level}`,\\n      ErrorCategory.INITIALIZATION,\\n      ErrorSeverity.INFO\\n    );\\n  };\\n\\n  const getErrorHistory = () => {\\n    return [...state.history];\\n  };\\n\\n  const clearErrorHistory = () => {\\n    state.history.length = 0;\\n    handleError(\\n      'Error history cleared',\\n      ErrorCategory.INITIALIZATION, \\n      ErrorSeverity.INFO\\n    );\\n  };\\n\\n  const getStatistics = () => {\\n    const stats = {\\n      total: state.history.length,\\n      bySeverity: {},\\n      byCategory: {},\\n      recentErrors: state.history.slice(-10)\\n    };\\n\\n    // Count by severity\\n    Object.values(ErrorSeverity).forEach(severity => {\\n      stats.bySeverity[severity] = state.history.filter(e => e.severity === severity).length;\\n    });\\n\\n    // Count by category  \\n    Object.values(ErrorCategory).forEach(category => {\\n      stats.byCategory[category] = state.history.filter(e => e.category === category).length;\\n    });\\n\\n    return stats;\\n  };\\n\\n  return {\\n    // Core error handling\\n    handleError,\\n    logError,\\n    \\n    // Validation helpers\\n    validateRequired,\\n    validateType, \\n    validateRange,\\n    \\n    // Performance monitoring\\n    wrapFunction,\\n    safeAsync,\\n    \\n    // Configuration\\n    setLogLevel,\\n    \\n    // History and statistics\\n    getErrorHistory,\\n    clearErrorHistory,\\n    getStatistics,\\n    \\n    // Constants\\n    ErrorSeverity,\\n    ErrorCategory\\n  };\\n};\\n\\n// Global error handler instance\\nexport const GlobalErrorHandler = createErrorHandler();\\n\\n// Convenience functions using global handler\\nexport const {handleError} = GlobalErrorHandler;\\nexport const {validateRequired} = GlobalErrorHandler;\\nexport const {validateType} = GlobalErrorHandler; \\nexport const {validateRange} = GlobalErrorHandler;\\nexport const {wrapFunction} = GlobalErrorHandler;\\nexport const {safeAsync} = GlobalErrorHandler;\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/shared/utils/html-utils.js\",\"messages\":[{\"ruleId\":\"no-script-url\",\"severity\":1,\"message\":\"Script URL is a form of eval.\",\"line\":81,\"column\":27,\"nodeType\":\"Literal\",\"messageId\":\"unexpectedScriptURL\",\"endLine\":81,\"endColumn\":40},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '||' and '&&'. Use parentheses to clarify the intended order of operations.\",\"line\":83,\"column\":38,\"nodeType\":\"LogicalExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":83,\"endColumn\":40},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '||' and '&&'. Use parentheses to clarify the intended order of operations.\",\"line\":84,\"column\":35,\"nodeType\":\"LogicalExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":84,\"endColumn\":37}],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":3,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * HTML Security Utilities\\n * Provides safe HTML escaping to prevent XSS attacks\\n */\\n\\n/**\\n * Escape HTML characters to prevent XSS\\n * @param {string} str - String to escape\\n * @returns {string} - HTML-escaped string\\n */\\nexport const escapeHtml = (str) => {\\n  if (typeof str !== 'string') {\\n    return String(str);\\n  }\\n  \\n  const htmlEscapeMap = {\\n    '&': '&amp;',\\n    '<': '&lt;',\\n    '>': '&gt;',\\n    '\\\"': '&quot;',\\n    \\\"'\\\": '&#39;',\\n    '/': '&#x2F;',\\n    '`': '&#x60;',\\n    '=': '&#x3D;'\\n  };\\n  \\n  return str.replace(/[&<>\\\"'`=\\\\/]/g, (char) => htmlEscapeMap[char]);\\n};\\n\\n/**\\n * Create text node safely (alternative to innerHTML)\\n * @param {string} text - Text content\\n * @returns {Text} - DOM text node\\n */\\nexport const createTextNode = (text) => {\\n  return document.createTextNode(String(text));\\n};\\n\\n/**\\n * Set text content safely without XSS risk\\n * @param {HTMLElement} element - Target element\\n * @param {string} text - Text to set\\n */\\nexport const setTextContent = (element, text) => {\\n  element.textContent = String(text);\\n};\\n\\n/**\\n * Create HTML element with safe text content\\n * @param {string} tagName - HTML tag name\\n * @param {string} textContent - Safe text content\\n * @param {Object} attributes - Element attributes\\n * @returns {HTMLElement} - Created element\\n */\\nexport const createElement = (tagName, textContent = '', attributes = {}) => {\\n  const element = document.createElement(tagName);\\n  \\n  if (textContent) {\\n    element.textContent = String(textContent);\\n  }\\n  \\n  for (const [key, value] of Object.entries(attributes)) {\\n    element.setAttribute(key, String(value));\\n  }\\n  \\n  return element;\\n};\\n\\n/**\\n * Validate and sanitize CSS values\\n * @param {Object} styles - CSS style object\\n * @returns {Object} - Sanitized styles\\n */\\nexport const sanitizeStyles = (styles) => {\\n  const safe = {};\\n  \\n  for (const [property, value] of Object.entries(styles)) {\\n    const strValue = String(value);\\n    \\n    // Block dangerous CSS patterns\\n    if (strValue.includes('javascript:') || \\n        strValue.includes('expression(') ||\\n        strValue.includes('@import') ||\\n        strValue.includes('url(') && !strValue.match(/^url\\\\(['\\\"]?[a-zA-Z0-9\\\\-_.\\\\/]+['\\\"]?\\\\)$/)) {\\n      continue; // Skip dangerous values\\n    }\\n    \\n    safe[property] = strValue;\\n  }\\n  \\n  return safe;\\n};\\n\\n/**\\n * Apply styles safely to element\\n * @param {HTMLElement} element - Target element\\n * @param {Object} styles - CSS styles to apply\\n */\\nexport const applyStyles = (element, styles) => {\\n  const safeStyles = sanitizeStyles(styles);\\n  \\n  for (const [property, value] of Object.entries(safeStyles)) {\\n    element.style[property] = value;\\n  }\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/shared/utils/index.js\",\"messages\":[],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/shared/utils/logger.js\",\"messages\":[],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/shared/utils/mediapipe-loader.js\",\"messages\":[],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/shared/utils/memory-pool-arrays.js\",\"messages\":[],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/shared/utils/memory-pool-cleanup.js\",\"messages\":[{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'type' is assigned a value but never used. Allowed unused vars must match /^_/u.\",\"line\":32,\"column\":17,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":32,\"endColumn\":21,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"type\"},\"fix\":{\"range\":[909,913],\"text\":\"\"},\"desc\":\"Remove unused variable 'type'.\"}]},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'key' is assigned a value but never used. Allowed unused vars must match /^_/u.\",\"line\":90,\"column\":17,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":90,\"endColumn\":20,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"key\"},\"fix\":{\"range\":[2704,2707],\"text\":\"\"},\"desc\":\"Remove unused variable 'key'.\"}]},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'key' is assigned a value but never used. Allowed unused vars must match /^_/u.\",\"line\":123,\"column\":19,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":123,\"endColumn\":22,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"key\"},\"fix\":{\"range\":[3909,3912],\"text\":\"\"},\"desc\":\"Remove unused variable 'key'.\"}]},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'type' is assigned a value but never used. Allowed unused vars must match /^_/u.\",\"line\":147,\"column\":17,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":147,\"endColumn\":21,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"type\"},\"fix\":{\"range\":[4552,4556],\"text\":\"\"},\"desc\":\"Remove unused variable 'type'.\"}]},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'key' is assigned a value but never used. Allowed unused vars must match /^_/u.\",\"line\":148,\"column\":19,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":148,\"endColumn\":22,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"key\"},\"fix\":{\"range\":[4617,4620],\"text\":\"\"},\"desc\":\"Remove unused variable 'key'.\"}]}],\"suppressedMessages\":[],\"errorCount\":5,\"fatalErrorCount\":0,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Adaptive cleanup and memory pressure management for memory pool\\n */\\n\\nexport const createCleanupManager = (state) => {\\n\\n  // Check memory pressure and trigger cleanup if needed\\n  const checkMemoryPressure = () => {\\n    if (typeof performance === 'undefined' || !performance.memory) {\\n      return;\\n    }\\n\\n    const memoryInfo = performance.memory;\\n    const usedMB = memoryInfo.usedJSHeapSize / (1024 * 1024);\\n    \\n    if (usedMB > state.config.maxMemoryPressureThreshold) {\\n      console.warn(`⚠️ High memory pressure detected: ${usedMB.toFixed(1)}MB`);\\n      forceCleanup();\\n    } else if (usedMB > state.config.memoryPressureThreshold) {\\n      cleanup();\\n    }\\n  };\\n\\n  // Adaptive cleanup based on pool usage patterns\\n  const adaptiveCleanup = () => {\\n    const now = Date.now();\\n    \\n    // Calculate current pool usage\\n    let totalPoolSize = 0;\\n    const totalActiveSize = 0;\\n    \\n    for (const [type, pools] of Object.entries(state.pools)) {\\n      for (const pool of pools.values()) {\\n        totalPoolSize += pool.length;\\n      }\\n    }\\n    \\n    // Update usage history\\n    state.adaptiveState.usageHistory.push({\\n      timestamp: now,\\n      totalPoolSize,\\n      activeObjects: state.activeObjects ? 0 : totalActiveSize // WeakSet size not available\\n    });\\n    \\n    // Keep only last 10 usage records\\n    if (state.adaptiveState.usageHistory.length > 10) {\\n      state.adaptiveState.usageHistory.shift();\\n    }\\n    \\n    // Calculate average pool usage\\n    const recentUsage = state.adaptiveState.usageHistory.slice(-5);\\n    state.adaptiveState.averagePoolUsage = recentUsage.reduce((sum, record) => \\n      sum + record.totalPoolSize, 0\\n    ) / recentUsage.length;\\n    \\n    // Adjust cleanup interval based on usage\\n    const highUsage = state.adaptiveState.averagePoolUsage > state.config.maxPoolSize * 0.7;\\n    const lowUsage = state.adaptiveState.averagePoolUsage < state.config.maxPoolSize * 0.3;\\n    \\n    if (highUsage) {\\n      // Increase cleanup frequency\\n      state.adaptiveState.currentInterval = Math.max(\\n        state.config.baseCleanupInterval * 0.5,\\n        1000\\n      );\\n    } else if (lowUsage) {\\n      // Decrease cleanup frequency\\n      state.adaptiveState.currentInterval = Math.min(\\n        state.config.baseCleanupInterval * 2,\\n        60000\\n      );\\n    }\\n    \\n    // Perform cleanup\\n    const cleaned = cleanup();\\n    \\n    // Update cleanup efficiency\\n    if (totalPoolSize > 0) {\\n      state.adaptiveState.cleanupEfficiency = cleaned / totalPoolSize;\\n    }\\n  };\\n\\n  // Standard cleanup routine\\n  const cleanup = () => {\\n    const now = Date.now();\\n    const maxAge = state.config.maxObjectAge;\\n    let totalCleaned = 0;\\n    \\n    // Clean arrays pool\\n    for (const [key, pool] of state.pools.arrays.entries()) {\\n      const originalSize = pool.length;\\n      \\n      // Remove old arrays (we can't track age of individual arrays without metadata)\\n      if (originalSize > state.config.maxPoolSize * 0.8) {\\n        const toRemove = Math.floor(originalSize * 0.3);\\n        pool.splice(0, toRemove);\\n        totalCleaned += toRemove;\\n      }\\n    }\\n    \\n    // Clean objects pool\\n    for (const [key, pool] of state.pools.objects.entries()) {\\n      const originalSize = pool.length;\\n      \\n      // Filter out objects that are too old or exceed pool size\\n      const filteredPool = pool.filter((obj, index) => {\\n        const metadata = state.objectMetadata.get(obj);\\n        if (!metadata) return index < state.config.maxPoolSize;\\n        \\n        const age = now - metadata.acquiredAt;\\n        return age < maxAge && index < state.config.maxPoolSize;\\n      });\\n      \\n      const cleaned = originalSize - filteredPool.length;\\n      if (cleaned > 0) {\\n        state.pools.objects.set(key, filteredPool);\\n        totalCleaned += cleaned;\\n      }\\n    }\\n    \\n    // Clean other pool types similarly\\n    ['buffers', 'canvases', 'contexts'].forEach(poolType => {\\n      for (const [key, pool] of state.pools[poolType].entries()) {\\n        const originalSize = pool.length;\\n        if (originalSize > state.config.maxPoolSize) {\\n          const toKeep = state.config.maxPoolSize;\\n          pool.splice(toKeep);\\n          totalCleaned += (originalSize - toKeep);\\n        }\\n      }\\n    });\\n    \\n    state.stats.lastCleanup = now;\\n    \\n    if (totalCleaned > 0) {\\n      console.log(`🧹 Memory pool cleanup: removed ${totalCleaned} objects`);\\n    }\\n    \\n    return totalCleaned;\\n  };\\n\\n  // Force aggressive cleanup\\n  const forceCleanup = () => {\\n    let totalCleaned = 0;\\n    \\n    // Aggressively reduce all pools\\n    for (const [type, pools] of Object.entries(state.pools)) {\\n      for (const [key, pool] of pools.entries()) {\\n        const originalSize = pool.length;\\n        const targetSize = Math.floor(state.config.maxPoolSize * 0.5);\\n        \\n        if (originalSize > targetSize) {\\n          pool.splice(targetSize);\\n          totalCleaned += (originalSize - targetSize);\\n        }\\n      }\\n    }\\n    \\n    console.log(`🔥 Force cleanup completed: removed ${totalCleaned} objects`);\\n    return totalCleaned;\\n  };\\n\\n  // Start adaptive cleanup timer\\n  const startAdaptiveCleanup = () => {\\n    if (state.cleanupTimer) {\\n      clearInterval(state.cleanupTimer);\\n    }\\n    \\n    const runCleanup = () => {\\n      if (state.config.adaptiveCleanup) {\\n        adaptiveCleanup();\\n      } else {\\n        cleanup();\\n      }\\n      \\n      // Schedule next cleanup with current interval\\n      state.cleanupTimer = setTimeout(runCleanup, state.adaptiveState.currentInterval);\\n    };\\n    \\n    // Start initial cleanup\\n    runCleanup();\\n  };\\n\\n  // Stop cleanup timer\\n  const stopCleanup = () => {\\n    if (state.cleanupTimer) {\\n      clearTimeout(state.cleanupTimer);\\n      state.cleanupTimer = null;\\n    }\\n  };\\n\\n  return {\\n    checkMemoryPressure,\\n    cleanup,\\n    forceCleanup,\\n    startAdaptiveCleanup,\\n    stopCleanup,\\n    getCleanupStats: () => ({\\n      lastCleanup: state.stats.lastCleanup,\\n      currentInterval: state.adaptiveState.currentInterval,\\n      cleanupEfficiency: state.adaptiveState.cleanupEfficiency,\\n      averagePoolUsage: state.adaptiveState.averagePoolUsage\\n    })\\n  };\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/shared/utils/memory-pool-config.js\",\"messages\":[],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/shared/utils/memory-pool-factories.js\",\"messages\":[{\"ruleId\":\"no-undef\",\"severity\":2,\"message\":\"'OffscreenCanvas' is not defined.\",\"line\":42,\"column\":13,\"nodeType\":\"Identifier\",\"messageId\":\"undef\",\"endLine\":42,\"endColumn\":28}],\"suppressedMessages\":[],\"errorCount\":1,\"fatalErrorCount\":0,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Object factory registration and management for memory pool\\n */\\n\\nexport const createFactoryManager = (state) => {\\n  \\n  // Register default object factories\\n  const registerDefaultFactories = () => {\\n    // Float32Array factory\\n    state.factories.set('Float32Array', (size) => new Float32Array(size));\\n    \\n    // Uint8Array factory\\n    state.factories.set('Uint8Array', (size) => new Uint8Array(size));\\n    \\n    // Canvas factory\\n    state.factories.set('Canvas', (width, height) => {\\n      if (typeof document !== 'undefined') {\\n        const canvas = document.createElement('canvas');\\n        canvas.width = width;\\n        canvas.height = height;\\n        return canvas;\\n      }\\n      return null;\\n    });\\n    \\n    // ImageData factory\\n    state.factories.set('ImageData', (width, height) => {\\n      if (typeof ImageData !== 'undefined') {\\n        return new ImageData(width, height);\\n      }\\n      // Fallback for Node.js or unsupported environments\\n      return {\\n        width,\\n        height,\\n        data: new Uint8ClampedArray(width * height * 4)\\n      };\\n    });\\n    \\n    // OffscreenCanvas factory (if available)\\n    if (typeof OffscreenCanvas !== 'undefined') {\\n      state.factories.set('OffscreenCanvas', (width, height) => \\n        new OffscreenCanvas(width, height)\\n      );\\n    }\\n    \\n    // Generic object factory\\n    state.factories.set('Object', (template) => ({ ...template }));\\n    \\n    // Buffer factory\\n    state.factories.set('ArrayBuffer', (size) => new ArrayBuffer(size));\\n  };\\n  \\n  // Register custom factory\\n  const registerFactory = (type, factory) => {\\n    if (typeof factory !== 'function') {\\n      throw new Error(`Factory for type '${type}' must be a function`);\\n    }\\n    \\n    state.factories.set(type, factory);\\n    console.log(`📦 Registered factory for type: ${type}`);\\n  };\\n  \\n  // Get factory for type\\n  const getFactory = (type) => {\\n    return state.factories.get(type);\\n  };\\n  \\n  // Get all registered factories\\n  const getRegisteredTypes = () => {\\n    return Array.from(state.factories.keys());\\n  };\\n  \\n  return {\\n    registerDefaultFactories,\\n    registerFactory,\\n    getFactory,\\n    getRegisteredTypes\\n  };\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/shared/utils/memory-pool-stats.js\",\"messages\":[{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'timeDelta' is assigned a value but never used. Allowed unused vars must match /^_/u.\",\"line\":70,\"column\":9,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":70,\"endColumn\":18,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"timeDelta\"},\"fix\":{\"range\":[1821,1874],\"text\":\"\"},\"desc\":\"Remove unused variable 'timeDelta'.\"}]}],\"suppressedMessages\":[],\"errorCount\":1,\"fatalErrorCount\":0,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Memory Pool Statistics and Monitoring\\n */\\n\\nexport const updatePoolStatistics = (stats, pools) => {\\n  // Update pool sizes\\n  stats.poolSizes = {};\\n  for (const [poolType, poolMap] of Object.entries(pools)) {\\n    stats.poolSizes[poolType] = {};\\n    for (const [key, pool] of poolMap) {\\n      stats.poolSizes[poolType][key] = pool.length;\\n    }\\n  }\\n};\\n\\nexport const recordAllocation = (stats) => {\\n  stats.allocations++;\\n};\\n\\nexport const recordDeallocation = (stats) => {\\n  stats.deallocations++;\\n};\\n\\nexport const recordReuseHit = (stats) => {\\n  stats.reuseHits++;\\n};\\n\\nexport const recordMemoryLeak = (stats) => {\\n  stats.memoryLeaks++;\\n};\\n\\nexport const calculateEfficiencyMetrics = (stats) => {\\n  const total = stats.allocations + stats.deallocations;\\n  const reuseRate = total > 0 ? stats.reuseHits / total : 0;\\n  const leakRate = stats.allocations > 0 ? stats.memoryLeaks / stats.allocations : 0;\\n  \\n  return {\\n    reuseRate: Math.round(reuseRate * 100) / 100,\\n    leakRate: Math.round(leakRate * 100) / 100,\\n    totalOperations: total,\\n    uptime: Date.now() - stats.created\\n  };\\n};\\n\\nexport const checkMemoryPressureLevel = (config) => {\\n  if (typeof performance === 'undefined' || !performance.memory) {\\n    return { level: 'unknown', usage: 0 };\\n  }\\n  \\n  const memoryInfo = performance.memory;\\n  const usedMB = memoryInfo.usedJSHeapSize / (1024 * 1024);\\n  \\n  let level = 'low';\\n  if (usedMB > config.maxMemoryPressureThreshold) {\\n    level = 'critical';\\n  } else if (usedMB > config.memoryPressureThreshold) {\\n    level = 'high';\\n  }\\n  \\n  return {\\n    level,\\n    usage: Math.round(usedMB),\\n    limit: memoryInfo.jsHeapSizeLimit / (1024 * 1024),\\n    total: memoryInfo.totalJSHeapSize / (1024 * 1024)\\n  };\\n};\\n\\nexport const updateAdaptiveState = (adaptiveState, cleanupEfficiency) => {\\n  const now = Date.now();\\n  const timeDelta = now - adaptiveState.lastUsageCheck;\\n  \\n  // Update cleanup efficiency\\n  adaptiveState.cleanupEfficiency = cleanupEfficiency;\\n  \\n  // Update usage history\\n  adaptiveState.usageHistory.push({\\n    timestamp: now,\\n    efficiency: cleanupEfficiency\\n  });\\n  \\n  // Keep only last 10 measurements\\n  if (adaptiveState.usageHistory.length > 10) {\\n    adaptiveState.usageHistory.shift();\\n  }\\n  \\n  // Calculate average efficiency\\n  const avgEfficiency = adaptiveState.usageHistory.reduce((sum, item) => sum + item.efficiency, 0) / adaptiveState.usageHistory.length;\\n  adaptiveState.averagePoolUsage = avgEfficiency;\\n  \\n  // Adjust cleanup interval based on efficiency\\n  if (avgEfficiency > 0.8) {\\n    // High efficiency - pools are being used well, cleanup less frequently\\n    adaptiveState.currentInterval = Math.min(adaptiveState.currentInterval * 1.2, 30000);\\n  } else if (avgEfficiency < 0.3) {\\n    // Low efficiency - pools are not being reused, cleanup more frequently\\n    adaptiveState.currentInterval = Math.max(adaptiveState.currentInterval * 0.8, 1000);\\n  }\\n  \\n  adaptiveState.lastUsageCheck = now;\\n};\\n\\nexport const getMemoryPoolSummary = (stats, pools, adaptiveState) => {\\n  const efficiency = calculateEfficiencyMetrics(stats);\\n  const memoryPressure = checkMemoryPressureLevel({ \\n    memoryPressureThreshold: 100, \\n    maxMemoryPressureThreshold: 150 \\n  });\\n  \\n  const totalPooledObjects = Object.values(pools).reduce((total, poolMap) => {\\n    return total + Array.from(poolMap.values()).reduce((sum, pool) => sum + pool.length, 0);\\n  }, 0);\\n  \\n  return {\\n    efficiency,\\n    memoryPressure,\\n    totalPooledObjects,\\n    adaptiveInterval: adaptiveState.currentInterval,\\n    averageEfficiency: adaptiveState.averagePoolUsage,\\n    stats: { ...stats },\\n    uptime: Date.now() - stats.created\\n  };\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/shared/utils/modules/analysis/audio/index.js\",\"messages\":[],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/shared/utils/modules/analysis/index.js\",\"messages\":[],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/shared/utils/modules/analysis/video/index.js\",\"messages\":[],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/shared/utils/modules/detection/index.js\",\"messages\":[],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/shared/utils/modules/detection/mediapipe/mediapipe-face-detector.js\",\"messages\":[{\"ruleId\":\"max-lines-per-function\",\"severity\":1,\"message\":\"Arrow function has too many lines (183). Maximum allowed is 150.\",\"line\":18,\"column\":44,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"exceed\",\"endLine\":275,\"endColumn\":2},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '/'. Use parentheses to clarify the intended order of operations.\",\"line\":137,\"column\":22,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":137,\"endColumn\":23},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '/'. Use parentheses to clarify the intended order of operations.\",\"line\":137,\"column\":34,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":137,\"endColumn\":35},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '/'. Use parentheses to clarify the intended order of operations.\",\"line\":138,\"column\":22,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":138,\"endColumn\":23},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '/'. Use parentheses to clarify the intended order of operations.\",\"line\":138,\"column\":35,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":138,\"endColumn\":36},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'landmarks' is assigned a value but never used. Allowed unused vars must match /^_/u.\",\"line\":151,\"column\":11,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":151,\"endColumn\":20,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"landmarks\"},\"fix\":{\"range\":[4733,4754],\"text\":\"\"},\"desc\":\"Remove unused variable 'landmarks'.\"}]},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":156,\"column\":20,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":156,\"endColumn\":21},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":156,\"column\":28,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":156,\"endColumn\":29},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":156,\"column\":46,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":156,\"endColumn\":47},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":156,\"column\":55,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":156,\"endColumn\":56},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":157,\"column\":20,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":157,\"endColumn\":21},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":157,\"column\":28,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":157,\"endColumn\":29},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":157,\"column\":46,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":157,\"endColumn\":47},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":157,\"column\":55,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":157,\"endColumn\":56},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":161,\"column\":20,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":161,\"endColumn\":21},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":161,\"column\":28,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":161,\"endColumn\":29},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":161,\"column\":47,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":161,\"endColumn\":48},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":161,\"column\":56,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":161,\"endColumn\":57},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":162,\"column\":20,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":162,\"endColumn\":21},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":162,\"column\":28,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":162,\"endColumn\":29},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":162,\"column\":47,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":162,\"endColumn\":48},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":162,\"column\":56,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":162,\"endColumn\":57},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":164,\"column\":20,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":164,\"endColumn\":21},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":164,\"column\":28,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":164,\"endColumn\":29},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":165,\"column\":20,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":165,\"endColumn\":21},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":165,\"column\":28,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":165,\"endColumn\":29},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '/'. Use parentheses to clarify the intended order of operations.\",\"line\":200,\"column\":48,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":200,\"endColumn\":49},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '/'. Use parentheses to clarify the intended order of operations.\",\"line\":200,\"column\":78,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":200,\"endColumn\":79},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '/'. Use parentheses to clarify the intended order of operations.\",\"line\":201,\"column\":48,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":201,\"endColumn\":49},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '/'. Use parentheses to clarify the intended order of operations.\",\"line\":201,\"column\":79,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":201,\"endColumn\":80}],\"suppressedMessages\":[],\"errorCount\":1,\"fatalErrorCount\":0,\"warningCount\":29,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * MediaPipe Face Detection - Lightweight Alternative to TensorFlow.js\\n * Provides face detection using MediaPipe's JavaScript API\\n * Synopticon face detection interface\\n */\\n\\nimport { checkFeatures, detectRuntime } from '../../../runtime-detector.js';\\n\\n// MediaPipe face detection configuration\\nconst createMediaPipeConfig = (config = {}) => ({\\n  model: config.model || 'short', // 'short' for close faces, 'full' for far faces\\n  minDetectionConfidence: config.minDetectionConfidence || 0.5,\\n  maxNumFaces: config.maxNumFaces || 10,\\n  ...config\\n});\\n\\n// MediaPipe face detector factory\\nexport const createMediaPipeFaceDetector = (config = {}) => {\\n  const detectorConfig = createMediaPipeConfig(config);\\n  const runtime = detectRuntime();\\n  const features = checkFeatures();\\n  \\n  const state = {\\n    detector: null,\\n    isInitialized: false,\\n    isLoading: false,\\n    runtime,\\n    features,\\n    config: detectorConfig\\n  };\\n\\n  // Initialize MediaPipe face detection\\n  const initialize = async () => {\\n    if (state.isInitialized) {\\n      return true;\\n    }\\n\\n    if (state.isLoading) {\\n      // Wait for existing initialization\\n      while (state.isLoading) {\\n        await new Promise(resolve => setTimeout(resolve, 100));\\n      }\\n      return state.isInitialized;\\n    }\\n\\n    state.isLoading = true;\\n\\n    try {\\n      if (features.isBrowser && typeof window !== 'undefined') {\\n        // Browser environment - use MediaPipe web\\n        await initializeBrowserDetection();\\n      } else {\\n        // Node.js environment - use fallback\\n        await initializeNodeDetection();\\n      }\\n\\n      state.isInitialized = true;\\n      return true;\\n\\n    } catch (error) {\\n      console.warn('MediaPipe face detection initialization failed:', error.message);\\n      // Initialize fallback detector\\n      await initializeFallbackDetection();\\n      state.isInitialized = true;\\n      return true;\\n    } finally {\\n      state.isLoading = false;\\n    }\\n  };\\n\\n  // Browser MediaPipe initialization\\n  const initializeBrowserDetection = async () => {\\n    // Try to load MediaPipe dynamically\\n    try {\\n      // Option 1: Try CDN MediaPipe\\n      if (!window.MediaPipe) {\\n        const script = document.createElement('script');\\n        script.src = 'https://cdn.jsdelivr.net/npm/@mediapipe/face_detection@0.4.1646425229/face_detection.js';\\n        document.head.appendChild(script);\\n        \\n        await new Promise((resolve, reject) => {\\n          script.onload = resolve;\\n          script.onerror = reject;\\n        });\\n      }\\n\\n      // Initialize MediaPipe face detection\\n      const { FaceDetection } = window.MediaPipe;\\n      state.detector = new FaceDetection({\\n        locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/face_detection@0.4.1646425229/${file}`\\n      });\\n\\n      state.detector.setOptions({\\n        model: state.config.model,\\n        minDetectionConfidence: state.config.minDetectionConfidence\\n      });\\n\\n      // Set up results callback\\n      state.detector.onResults((results) => {\\n        state.lastResults = results;\\n      });\\n\\n    } catch (error) {\\n      throw new Error(`Browser MediaPipe initialization failed: ${error.message}`);\\n    }\\n  };\\n\\n  // Node.js fallback initialization\\n  const initializeNodeDetection = async () => {\\n    // For Node.js, we'll use a lightweight face detection algorithm\\n    // This is a simplified implementation for server-side processing\\n    state.detector = createSimpleFaceDetector();\\n  };\\n\\n  // Fallback detection for when MediaPipe is unavailable\\n  const initializeFallbackDetection = async () => {\\n    console.warn('Using fallback face detection (reduced accuracy)');\\n    state.detector = createSimpleFaceDetector();\\n  };\\n\\n  // Simple face detector implementation (fallback)\\n  const createSimpleFaceDetector = () => ({\\n    detect: async (imageData) => {\\n      // Simple center-based face detection for fallback\\n      // This is a placeholder that assumes a face in the center region\\n      const width = imageData.width || 640;\\n      const height = imageData.height || 480;\\n      \\n      // Create a mock detection in center region\\n      const centerX = width / 2;\\n      const centerY = height / 2;\\n      const faceWidth = Math.min(width, height) * 0.3;\\n      const faceHeight = faceWidth * 1.2;\\n      \\n      return [{\\n        boundingBox: {\\n          x: centerX - faceWidth / 2,\\n          y: centerY - faceHeight / 2,\\n          width: faceWidth,\\n          height: faceHeight\\n        },\\n        landmarks: generateMockLandmarks(centerX, centerY, faceWidth, faceHeight),\\n        score: 0.8, // Mock confidence score\\n        keypoints: []\\n      }];\\n    }\\n  });\\n\\n  // Generate mock facial landmarks for fallback\\n  const generateMockLandmarks = (centerX, centerY, width, height) => {\\n    const landmarks = [];\\n    \\n    // Basic facial landmarks (simplified)\\n    const points = [\\n      // Eyes\\n      { x: centerX - width * 0.2, y: centerY - height * 0.1, name: 'leftEye' },\\n      { x: centerX + width * 0.2, y: centerY - height * 0.1, name: 'rightEye' },\\n      // Nose\\n      { x: centerX, y: centerY, name: 'nose' },\\n      // Mouth corners  \\n      { x: centerX - width * 0.15, y: centerY + height * 0.2, name: 'leftMouth' },\\n      { x: centerX + width * 0.15, y: centerY + height * 0.2, name: 'rightMouth' },\\n      // Face outline points\\n      { x: centerX - width * 0.4, y: centerY, name: 'leftCheek' },\\n      { x: centerX + width * 0.4, y: centerY, name: 'rightCheek' }\\n    ];\\n\\n    return points.map(point => ({\\n      x: point.x,\\n      y: point.y,\\n      name: point.name\\n    }));\\n  };\\n\\n  // Detect faces in image\\n  const detectFaces = async (imageData, options = {}) => {\\n    if (!state.isInitialized) {\\n      await initialize();\\n    }\\n\\n    try {\\n      if (state.detector && state.detector.detect) {\\n        // Use fallback detector\\n        return await state.detector.detect(imageData);\\n      } else if (state.detector && features.isBrowser) {\\n        // Use MediaPipe detector (browser)\\n        await state.detector.send({ image: imageData });\\n        \\n        // Wait for results (with timeout)\\n        const timeout = options.timeout || 5000;\\n        const start = Date.now();\\n        \\n        while (!state.lastResults && (Date.now() - start) < timeout) {\\n          await new Promise(resolve => setTimeout(resolve, 10));\\n        }\\n        \\n        if (state.lastResults && state.lastResults.detections) {\\n          const faces = state.lastResults.detections.map(detection => ({\\n            boundingBox: {\\n              x: detection.boundingBox.xCenter - detection.boundingBox.width / 2,\\n              y: detection.boundingBox.yCenter - detection.boundingBox.height / 2,\\n              width: detection.boundingBox.width,\\n              height: detection.boundingBox.height\\n            },\\n            landmarks: detection.landmarks || [],\\n            score: detection.score || 0.5,\\n            keypoints: detection.landmarks || []\\n          }));\\n          \\n          // Clear results for next detection\\n          state.lastResults = null;\\n          return faces;\\n        }\\n      }\\n      \\n      // Fallback to empty array if no detections\\n      return [];\\n\\n    } catch (error) {\\n      console.warn('Face detection failed:', error);\\n      return [];\\n    }\\n  };\\n\\n  // MediaPipe native implementation\\n\\n  // Get detector status\\n  const getStatus = () => ({\\n    initialized: state.isInitialized,\\n    loading: state.isLoading,\\n    runtime: state.runtime,\\n    detector: state.detector ? 'active' : 'none',\\n    backend: state.detector && state.detector.detect ? 'fallback' : 'mediapipe',\\n    config: state.config\\n  });\\n\\n  // Cleanup resources\\n  const cleanup = async () => {\\n    if (state.detector && state.detector.close) {\\n      await state.detector.close();\\n    }\\n    \\n    state.detector = null;\\n    state.isInitialized = false;\\n    state.isLoading = false;\\n    state.lastResults = null;\\n  };\\n\\n  // Update configuration\\n  const updateConfig = (newConfig) => {\\n    Object.assign(state.config, newConfig);\\n    \\n    if (state.detector && state.detector.setOptions) {\\n      state.detector.setOptions({\\n        model: state.config.model,\\n        minDetectionConfidence: state.config.minDetectionConfidence\\n      });\\n    }\\n  };\\n\\n  return {\\n    // Core detection methods\\n    initialize,\\n    detectFaces,\\n    \\n    // Configuration and status\\n    updateConfig,\\n    getStatus,\\n    cleanup,\\n    \\n    // Properties\\n    get isInitialized() { return state.isInitialized; },\\n    get config() { return { ...state.config }; }\\n  };\\n};\\n\\n// Export factory function for pipeline integration\\nexport const createFaceDetector = createMediaPipeFaceDetector;\\n\\n// Export default configuration\\nexport const defaultMediaPipeConfig = {\\n  model: 'short',\\n  minDetectionConfidence: 0.5,\\n  maxNumFaces: 10\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/shared/utils/modules/index.js\",\"messages\":[],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/shared/utils/object-pool.js\",\"messages\":[],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/shared/utils/performance-tester.js\",\"messages\":[{\"ruleId\":\"max-lines-per-function\",\"severity\":1,\"message\":\"Arrow function has too many lines (323). Maximum allowed is 150.\",\"line\":40,\"column\":40,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"exceed\",\"endLine\":453,\"endColumn\":2}],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":1,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Performance Testing Framework\\n * Comprehensive performance monitoring and benchmarking for face analysis engine\\n */\\n\\nimport { ErrorCategory, ErrorSeverity, createErrorHandler } from './error-handler.js';\\n\\n// Performance test categories\\nexport const TestCategory = {\\n  INITIALIZATION: 'initialization',\\n  DETECTION: 'detection',\\n  LANDMARK: 'landmark',\\n  WEBGL: 'webgl',\\n  MEMORY: 'memory',\\n  OVERALL: 'overall'\\n};\\n\\n// Performance thresholds (in milliseconds)\\nexport const PerformanceThresholds = {\\n  TARGET_FRAME_TIME: 16.67, // 60 FPS target\\n  WARNING_FRAME_TIME: 33.33, // 30 FPS warning\\n  CRITICAL_FRAME_TIME: 50.0, // 20 FPS critical\\n  \\n  TARGET_DETECTION_TIME: 10.0, // Sub-10ms detection target\\n  WARNING_DETECTION_TIME: 20.0,\\n  CRITICAL_DETECTION_TIME: 50.0,\\n  \\n  TARGET_LANDMARK_TIME: 5.0, // Sub-5ms landmark target\\n  WARNING_LANDMARK_TIME: 15.0,\\n  CRITICAL_LANDMARK_TIME: 30.0,\\n  \\n  TARGET_INITIALIZATION_TIME: 1000.0, // 1 second initialization\\n  WARNING_INITIALIZATION_TIME: 3000.0,\\n  CRITICAL_INITIALIZATION_TIME: 5000.0\\n};\\n\\n/**\\n * Creates a comprehensive performance testing system\\n */\\nexport const createPerformanceTester = (config = {}) => {\\n  const errorHandler = createErrorHandler({\\n    logLevel: ErrorSeverity.INFO,\\n    enableConsole: true,\\n    enableCollection: true\\n  });\\n\\n  const state = {\\n    config: {\\n      enableRealTime: true,\\n      enableBenchmarks: true,\\n      enableMemoryTracking: true,\\n      sampleSize: 100,\\n      warmupFrames: 10,\\n      ...config\\n    },\\n    \\n    // Performance metrics storage\\n    metrics: {\\n      frameTime: [],\\n      detectionTime: [],\\n      landmarkTime: [],\\n      initializationTime: [],\\n      memoryUsage: [],\\n      gpuMemory: []\\n    },\\n    \\n    // Real-time monitoring\\n    currentFrame: 0,\\n    startTime: null,\\n    lastFrameTime: null,\\n    \\n    // Benchmark results\\n    benchmarkResults: new Map(),\\n    \\n    // Memory tracking\\n    memoryBaseline: null,\\n    gcThreshold: 100 * 1024 * 1024, // 100MB\\n    \\n    isActive: false\\n  };\\n\\n  const start = () => {\\n    state.isActive = true;\\n    state.startTime = performance.now();\\n    state.currentFrame = 0;\\n    \\n    // Establish memory baseline\\n    if (state.config.enableMemoryTracking && performance.memory) {\\n      state.memoryBaseline = performance.memory.usedJSHeapSize;\\n    }\\n    \\n    errorHandler.handleError(\\n      'Performance monitoring started',\\n      ErrorCategory.PERFORMANCE,\\n      ErrorSeverity.INFO,\\n      { \\n        memoryBaseline: state.memoryBaseline,\\n        config: state.config\\n      }\\n    );\\n  };\\n\\n  const stop = () => {\\n    state.isActive = false;\\n    \\n    const totalTime = performance.now() - state.startTime;\\n    const avgFrameTime = state.metrics.frameTime.length > 0 \\n      ? state.metrics.frameTime.reduce((a, b) => a + b, 0) / state.metrics.frameTime.length\\n      : 0;\\n    \\n    errorHandler.handleError(\\n      `Performance monitoring stopped - Total: ${totalTime.toFixed(2)}ms, Avg Frame: ${avgFrameTime.toFixed(2)}ms`,\\n      ErrorCategory.PERFORMANCE,\\n      ErrorSeverity.INFO,\\n      { \\n        totalFrames: state.currentFrame,\\n        avgFrameTime,\\n        totalTime\\n      }\\n    );\\n  };\\n\\n  const recordFrameTime = (frameTime) => {\\n    if (!state.isActive) return;\\n    \\n    state.currentFrame++;\\n    \\n    // Skip warmup frames\\n    if (state.currentFrame <= state.config.warmupFrames) {\\n      return;\\n    }\\n    \\n    // Record frame time\\n    state.metrics.frameTime.push(frameTime);\\n    \\n    // Maintain sample size limit\\n    if (state.metrics.frameTime.length > state.config.sampleSize) {\\n      state.metrics.frameTime.shift();\\n    }\\n    \\n    // Check thresholds and warn if necessary\\n    if (frameTime > PerformanceThresholds.CRITICAL_FRAME_TIME) {\\n      errorHandler.handleError(\\n        `Critical frame time detected: ${frameTime.toFixed(2)}ms`,\\n        ErrorCategory.PERFORMANCE,\\n        ErrorSeverity.ERROR,\\n        { frameTime, frameNumber: state.currentFrame }\\n      );\\n    } else if (frameTime > PerformanceThresholds.WARNING_FRAME_TIME) {\\n      errorHandler.handleError(\\n        `Slow frame detected: ${frameTime.toFixed(2)}ms`,\\n        ErrorCategory.PERFORMANCE,\\n        ErrorSeverity.WARNING,\\n        { frameTime, frameNumber: state.currentFrame }\\n      );\\n    }\\n  };\\n\\n  const recordDetectionTime = (detectionTime) => {\\n    if (!state.isActive) return;\\n    \\n    state.metrics.detectionTime.push(detectionTime);\\n    \\n    if (state.metrics.detectionTime.length > state.config.sampleSize) {\\n      state.metrics.detectionTime.shift();\\n    }\\n    \\n    if (detectionTime > PerformanceThresholds.CRITICAL_DETECTION_TIME) {\\n      errorHandler.handleError(\\n        `Critical detection time: ${detectionTime.toFixed(2)}ms`,\\n        ErrorCategory.PERFORMANCE,\\n        ErrorSeverity.ERROR,\\n        { detectionTime }\\n      );\\n    } else if (detectionTime > PerformanceThresholds.WARNING_DETECTION_TIME) {\\n      errorHandler.handleError(\\n        `Slow detection: ${detectionTime.toFixed(2)}ms`,\\n        ErrorCategory.PERFORMANCE,\\n        ErrorSeverity.WARNING,\\n        { detectionTime }\\n      );\\n    }\\n  };\\n\\n  const recordLandmarkTime = (landmarkTime) => {\\n    if (!state.isActive) return;\\n    \\n    state.metrics.landmarkTime.push(landmarkTime);\\n    \\n    if (state.metrics.landmarkTime.length > state.config.sampleSize) {\\n      state.metrics.landmarkTime.shift();\\n    }\\n    \\n    if (landmarkTime > PerformanceThresholds.CRITICAL_LANDMARK_TIME) {\\n      errorHandler.handleError(\\n        `Critical landmark time: ${landmarkTime.toFixed(2)}ms`,\\n        ErrorCategory.PERFORMANCE,\\n        ErrorSeverity.ERROR,\\n        { landmarkTime }\\n      );\\n    }\\n  };\\n\\n  const recordInitializationTime = (initTime) => {\\n    state.metrics.initializationTime.push(initTime);\\n    \\n    if (initTime > PerformanceThresholds.CRITICAL_INITIALIZATION_TIME) {\\n      errorHandler.handleError(\\n        `Critical initialization time: ${initTime.toFixed(2)}ms`,\\n        ErrorCategory.PERFORMANCE,\\n        ErrorSeverity.ERROR,\\n        { initTime }\\n      );\\n    }\\n  };\\n\\n  const trackMemoryUsage = () => {\\n    if (!state.config.enableMemoryTracking || !performance.memory) {\\n      return null;\\n    }\\n    \\n    const memInfo = {\\n      used: performance.memory.usedJSHeapSize,\\n      total: performance.memory.totalJSHeapSize,\\n      limit: performance.memory.jsHeapSizeLimit,\\n      timestamp: performance.now()\\n    };\\n    \\n    state.metrics.memoryUsage.push(memInfo);\\n    \\n    // Check for memory leaks\\n    if (state.memoryBaseline && memInfo.used > state.memoryBaseline + state.gcThreshold) {\\n      errorHandler.handleError(\\n        `Memory usage increased significantly: ${((memInfo.used - state.memoryBaseline) / 1024 / 1024).toFixed(2)}MB`,\\n        ErrorCategory.MEMORY,\\n        ErrorSeverity.WARNING,\\n        { \\n          baseline: state.memoryBaseline,\\n          current: memInfo.used,\\n          increase: memInfo.used - state.memoryBaseline\\n        }\\n      );\\n    }\\n    \\n    // Warn if approaching memory limit\\n    if (memInfo.used > memInfo.limit * 0.8) {\\n      errorHandler.handleError(\\n        `Memory usage approaching limit: ${(memInfo.used / memInfo.limit * 100).toFixed(1)}%`,\\n        ErrorCategory.MEMORY,\\n        ErrorSeverity.WARNING,\\n        memInfo\\n      );\\n    }\\n    \\n    return memInfo;\\n  };\\n\\n  const runBenchmark = async (name, testFunction, iterations = 10) => {\\n    errorHandler.handleError(\\n      `Starting benchmark: ${name} (${iterations} iterations)`,\\n      ErrorCategory.PERFORMANCE,\\n      ErrorSeverity.INFO\\n    );\\n    \\n    const results = {\\n      name,\\n      iterations,\\n      times: [],\\n      memory: [],\\n      errors: 0,\\n      startTime: performance.now()\\n    };\\n    \\n    // Warmup run\\n    try {\\n      await testFunction();\\n    } catch (error) {\\n      errorHandler.handleError(\\n        `Benchmark warmup failed for ${name}: ${error.message}`,\\n        ErrorCategory.PERFORMANCE,\\n        ErrorSeverity.WARNING\\n      );\\n    }\\n    \\n    // Run benchmark iterations\\n    for (let i = 0; i < iterations; i++) {\\n      const memBefore = trackMemoryUsage();\\n      const startTime = performance.now();\\n      \\n      try {\\n        await testFunction();\\n        const duration = performance.now() - startTime;\\n        results.times.push(duration);\\n        \\n        const memAfter = trackMemoryUsage();\\n        if (memBefore && memAfter) {\\n          results.memory.push(memAfter.used - memBefore.used);\\n        }\\n        \\n      } catch (error) {\\n        results.errors++;\\n        errorHandler.handleError(\\n          `Benchmark iteration ${i + 1} failed for ${name}: ${error.message}`,\\n          ErrorCategory.PERFORMANCE,\\n          ErrorSeverity.WARNING\\n        );\\n      }\\n      \\n      // Small delay to prevent overwhelming the system\\n      await new Promise(resolve => setTimeout(resolve, 10));\\n    }\\n    \\n    results.totalTime = performance.now() - results.startTime;\\n    \\n    // Calculate statistics\\n    if (results.times.length > 0) {\\n      const sortedTimes = [...results.times].sort((a, b) => a - b);\\n      results.stats = {\\n        min: sortedTimes[0],\\n        max: sortedTimes[sortedTimes.length - 1],\\n        mean: results.times.reduce((a, b) => a + b, 0) / results.times.length,\\n        median: sortedTimes[Math.floor(sortedTimes.length / 2)],\\n        p95: sortedTimes[Math.floor(sortedTimes.length * 0.95)],\\n        p99: sortedTimes[Math.floor(sortedTimes.length * 0.99)]\\n      };\\n    }\\n    \\n    state.benchmarkResults.set(name, results);\\n    \\n    errorHandler.handleError(\\n      `Benchmark completed: ${name} - Mean: ${results.stats?.mean?.toFixed(2)}ms, Errors: ${results.errors}`,\\n      ErrorCategory.PERFORMANCE,\\n      ErrorSeverity.INFO,\\n      { benchmarkResults: results.stats }\\n    );\\n    \\n    return results;\\n  };\\n\\n  const getRealtimeStats = () => {\\n    if (state.metrics.frameTime.length === 0) {\\n      return null;\\n    }\\n    \\n    const recentFrames = state.metrics.frameTime.slice(-30); // Last 30 frames\\n    const recentDetections = state.metrics.detectionTime.slice(-30);\\n    const recentLandmarks = state.metrics.landmarkTime.slice(-30);\\n    \\n    const calculateStats = (arr) => {\\n      if (arr.length === 0) return null;\\n      const sorted = [...arr].sort((a, b) => a - b);\\n      return {\\n        min: sorted[0],\\n        max: sorted[sorted.length - 1],\\n        mean: arr.reduce((a, b) => a + b, 0) / arr.length,\\n        median: sorted[Math.floor(sorted.length / 2)]\\n      };\\n    };\\n    \\n    const memInfo = trackMemoryUsage();\\n    \\n    return {\\n      fps: recentFrames.length > 0 ? 1000 / (recentFrames.reduce((a, b) => a + b, 0) / recentFrames.length) : 0,\\n      frameTime: calculateStats(recentFrames),\\n      detectionTime: calculateStats(recentDetections),\\n      landmarkTime: calculateStats(recentLandmarks),\\n      memory: memInfo,\\n      frameCount: state.currentFrame,\\n      uptime: state.startTime ? performance.now() - state.startTime : 0\\n    };\\n  };\\n\\n  const generateReport = () => {\\n    const stats = getRealtimeStats();\\n    const benchmarks = Object.fromEntries(state.benchmarkResults);\\n    \\n    const report = {\\n      timestamp: new Date().toISOString(),\\n      runtime: stats?.uptime || 0,\\n      frameCount: state.currentFrame,\\n      \\n      performance: {\\n        realtime: stats,\\n        benchmarks,\\n        thresholds: PerformanceThresholds\\n      },\\n      \\n      compliance: {\\n        frameTimeTarget: stats?.frameTime?.mean ? stats.frameTime.mean <= PerformanceThresholds.TARGET_FRAME_TIME : null,\\n        detectionTimeTarget: stats?.detectionTime?.mean ? stats.detectionTime.mean <= PerformanceThresholds.TARGET_DETECTION_TIME : null,\\n        landmarkTimeTarget: stats?.landmarkTime?.mean ? stats.landmarkTime.mean <= PerformanceThresholds.TARGET_LANDMARK_TIME : null\\n      },\\n      \\n      memory: {\\n        baseline: state.memoryBaseline,\\n        current: stats?.memory,\\n        samples: state.metrics.memoryUsage.length\\n      },\\n      \\n      errors: errorHandler.getStatistics()\\n    };\\n    \\n    return report;\\n  };\\n\\n  const reset = () => {\\n    // Clear all metrics\\n    Object.keys(state.metrics).forEach(key => {\\n      state.metrics[key] = [];\\n    });\\n    \\n    // Clear benchmark results\\n    state.benchmarkResults.clear();\\n    \\n    // Reset counters\\n    state.currentFrame = 0;\\n    state.startTime = null;\\n    state.memoryBaseline = null;\\n    state.isActive = false;\\n    \\n    errorHandler.handleError(\\n      'Performance tester reset',\\n      ErrorCategory.PERFORMANCE,\\n      ErrorSeverity.INFO\\n    );\\n  };\\n\\n  return {\\n    // Control\\n    start,\\n    stop,\\n    reset,\\n    \\n    // Recording\\n    recordFrameTime,\\n    recordDetectionTime,\\n    recordLandmarkTime,\\n    recordInitializationTime,\\n    trackMemoryUsage,\\n    \\n    // Benchmarking\\n    runBenchmark,\\n    \\n    // Analysis\\n    getRealtimeStats,\\n    generateReport,\\n    \\n    // State access\\n    get isActive() { return state.isActive; },\\n    get frameCount() { return state.currentFrame; },\\n    get benchmarkResults() { return new Map(state.benchmarkResults); }\\n  };\\n};\\n\\n// Global performance tester instance\\nexport const GlobalPerformanceTester = createPerformanceTester();\\n\\n// Convenience functions\\nexport const {recordFrameTime} = GlobalPerformanceTester;\\nexport const {recordDetectionTime} = GlobalPerformanceTester;\\nexport const {recordLandmarkTime} = GlobalPerformanceTester;\\nexport const {getRealtimeStats} = GlobalPerformanceTester;\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/shared/utils/runtime-detector.js\",\"messages\":[{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'quality' is assigned a value but never used. Allowed unused args must match /^_/u.\",\"line\":74,\"column\":54,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":74,\"endColumn\":61,\"suggestions\":[{\"messageId\":\"removeVar\",\"data\":{\"varName\":\"quality\"},\"fix\":{\"range\":[2311,2324],\"text\":\"\"},\"desc\":\"Remove unused variable 'quality'.\"}]},{\"ruleId\":\"no-unused-vars\",\"severity\":2,\"message\":\"'error' is defined but never used.\",\"line\":83,\"column\":14,\"nodeType\":\"Identifier\",\"messageId\":\"unusedVar\",\"endLine\":83,\"endColumn\":19},{\"ruleId\":\"prefer-destructuring\",\"severity\":1,\"message\":\"Use array destructuring.\",\"line\":220,\"column\":13,\"nodeType\":\"VariableDeclarator\",\"messageId\":\"preferDestructuring\",\"endLine\":220,\"endColumn\":41}],\"suppressedMessages\":[],\"errorCount\":2,\"fatalErrorCount\":0,\"warningCount\":1,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Runtime Detection Utilities\\n * Detects current runtime environment and provides compatibility helpers\\n */\\n\\n// Detect runtime environment\\nexport const detectRuntime = () => {\\n  if (typeof window !== 'undefined' && typeof document !== 'undefined') {\\n    return 'browser';\\n  }\\n  \\n  if (typeof process !== 'undefined' && process.versions && process.versions.node) {\\n    return 'node';\\n  }\\n  \\n  if (typeof Bun !== 'undefined') {\\n    return 'bun';\\n  }\\n  \\n  if (typeof Deno !== 'undefined') {\\n    return 'deno';\\n  }\\n  \\n  return 'unknown';\\n};\\n\\n// Check specific feature availability\\nexport const checkFeatures = () => {\\n  const runtime = detectRuntime();\\n  \\n  return {\\n    runtime,\\n    isBrowser: runtime === 'browser',\\n    isNode: runtime === 'node' || runtime === 'bun',\\n    isServer: runtime !== 'browser',\\n    \\n    // Feature availability\\n    hasDOM: typeof document !== 'undefined',\\n    hasCanvas: typeof HTMLCanvasElement !== 'undefined',\\n    hasWebGL: typeof WebGLRenderingContext !== 'undefined',\\n    hasWorkers: typeof Worker !== 'undefined',\\n    hasNodeModules: typeof globalThis.require !== 'undefined' || typeof import.meta !== 'undefined',\\n    \\n    // API availability\\n    hasFetch: typeof fetch !== 'undefined',\\n    hasWebSocket: typeof WebSocket !== 'undefined',\\n    hasFileSystem: runtime === 'node' || runtime === 'bun',\\n    \\n    // Performance features\\n    hasGPU: typeof WebGLRenderingContext !== 'undefined',\\n    hasWASM: typeof WebAssembly !== 'undefined',\\n    hasSharedArrayBuffer: typeof SharedArrayBuffer !== 'undefined'\\n  };\\n};\\n\\n// Create appropriate canvas for environment (with optional canvas dependency)\\nexport const createUniversalCanvas = async (width = 640, height = 480) => {\\n  const features = checkFeatures();\\n  \\n  if (features.hasCanvas) {\\n    // Browser environment\\n    const canvas = document.createElement('canvas');\\n    canvas.width = width;\\n    canvas.height = height;\\n    return canvas;\\n  } else if (features.isNode) {\\n    // Node.js environment - optional canvas dependency\\n    try {\\n      // Try to load canvas dynamically (optional dependency)\\n      const { createCanvas, loadImage } = await import('canvas');\\n      const canvas = createCanvas(width, height);\\n      \\n      // Enhance with browser-compatible methods\\n      canvas.toBlob = (callback, type = 'image/png', quality = 1) => {\\n        const buffer = canvas.toBuffer(type.replace('image/', ''));\\n        const blob = new Blob([buffer], { type });\\n        callback(blob);\\n      };\\n      \\n      canvas.loadImage = loadImage;\\n      \\n      return canvas;\\n    } catch (error) {\\n      console.warn('⚠️ Optional canvas dependency not available, using lightweight fallback');\\n      // Enhanced fallback with better compatibility\\n      return createMockCanvas(width, height);\\n    }\\n  } else {\\n    // Unknown environment - return mock\\n    return createMockCanvas(width, height);\\n  }\\n};\\n\\n// Create mock canvas for testing/fallback\\nexport const createMockCanvas = (width = 640, height = 480) => {\\n  return {\\n    width,\\n    height,\\n    getContext: (type) => createMockContext(type),\\n    toDataURL: () => 'data:image/png;base64,mock',\\n    toBlob: (callback) => callback(new Blob(['mock'], { type: 'image/png' }))\\n  };\\n};\\n\\n// Create mock context for testing\\nconst createMockContext = (type) => {\\n  if (type === '2d') {\\n    return {\\n      canvas: { width: 640, height: 480 },\\n      fillStyle: '',\\n      strokeStyle: '',\\n      lineWidth: 1,\\n      fillRect: () => {},\\n      strokeRect: () => {},\\n      clearRect: () => {},\\n      beginPath: () => {},\\n      closePath: () => {},\\n      moveTo: () => {},\\n      lineTo: () => {},\\n      arc: () => {},\\n      fill: () => {},\\n      stroke: () => {},\\n      drawImage: () => {},\\n      getImageData: () => ({ data: new Uint8ClampedArray(640 * 480 * 4), width: 640, height: 480 }),\\n      putImageData: () => {},\\n      createImageData: (w, h) => ({ data: new Uint8ClampedArray(w * h * 4), width: w, height: h }),\\n      save: () => {},\\n      restore: () => {},\\n      scale: () => {},\\n      rotate: () => {},\\n      translate: () => {},\\n      transform: () => {},\\n      setTransform: () => {}\\n    };\\n  }\\n  \\n  if (type === 'webgl' || type === 'webgl2') {\\n    return null; // WebGL not available in Node\\n  }\\n  \\n  return null;\\n};\\n\\n// Load appropriate MediaPipe for environment\\nexport const loadMediaPipe = async () => {\\n  const features = checkFeatures();\\n  \\n  if (features.isBrowser) {\\n    // Browser: Use MediaPipe from CDN or local\\n    try {\\n      // Check if MediaPipe is already loaded globally\\n      if (typeof window !== 'undefined' && window.MediaPipeUtils) {\\n        return window.MediaPipeUtils;\\n      }\\n      \\n      // Try to load MediaPipe dynamically\\n      const script = document.createElement('script');\\n      script.src = 'https://cdn.jsdelivr.net/npm/@mediapipe/face_detection@0.4.1646425229/face_detection.js';\\n      document.head.appendChild(script);\\n      \\n      return new Promise((resolve, reject) => {\\n        script.onload = () => resolve(window.MediaPipeUtils || true);\\n        script.onerror = () => reject(new Error('Failed to load MediaPipe'));\\n      });\\n    } catch (error) {\\n      console.warn('Failed to load MediaPipe for browser:', error);\\n      return null;\\n    }\\n  } else {\\n    // Server: MediaPipe not needed for server-side analysis\\n    console.log('MediaPipe not required in server environment');\\n    return { serverMode: true };\\n  }\\n};\\n\\n// Convert various image formats to MediaPipe-compatible format\\nexport const imageToMediaPipe = async (input) => {\\n  const features = checkFeatures();\\n  \\n  // MediaPipe works directly with HTML elements and ImageData\\n  if (features.isBrowser) {\\n    // Return supported formats directly\\n    if (input instanceof HTMLImageElement || \\n        input instanceof HTMLCanvasElement || \\n        input instanceof HTMLVideoElement ||\\n        input instanceof ImageData) {\\n      return input;\\n    }\\n    \\n    // Convert other formats to canvas\\n    if (input instanceof Blob) {\\n      return new Promise((resolve, reject) => {\\n        const img = new Image();\\n        img.onload = () => {\\n          const canvas = document.createElement('canvas');\\n          canvas.width = img.width;\\n          canvas.height = img.height;\\n          const ctx = canvas.getContext('2d');\\n          ctx.drawImage(img, 0, 0);\\n          resolve(canvas);\\n        };\\n        img.onerror = reject;\\n        img.src = URL.createObjectURL(input);\\n      });\\n    }\\n  }\\n  \\n  // Server environment: Convert to compatible format\\n  if (features.isNode) {\\n    // For server-side, return image metadata for processing\\n    if (Buffer.isBuffer(input)) {\\n      return {\\n        type: 'buffer',\\n        data: input,\\n        serverMode: true\\n      };\\n    }\\n    \\n    if (typeof input === 'string' && input.startsWith('data:image')) {\\n      const base64 = input.split(',')[1];\\n      const buffer = Buffer.from(base64, 'base64');\\n      return {\\n        type: 'base64',\\n        data: buffer,\\n        serverMode: true\\n      };\\n    }\\n  }\\n  \\n  // Handle raw pixel data\\n  if (input.data && input.width && input.height) {\\n    return {\\n      type: 'imageData',\\n      width: input.width,\\n      height: input.height,\\n      data: input.data\\n    };\\n  }\\n  \\n  throw new Error('Unsupported image input format for MediaPipe');\\n};\\n\\n// Export runtime information\\nexport const getRuntimeInfo = () => {\\n  const features = checkFeatures();\\n  \\n  return {\\n    ...features,\\n    version: {\\n      node: features.isNode ? process.version : null,\\n      bun: typeof Bun !== 'undefined' ? Bun.version : null,\\n      browser: features.isBrowser ? navigator.userAgent : null\\n    },\\n    platform: features.isNode ? process.platform : 'browser',\\n    arch: features.isNode ? process.arch : null,\\n    memory: features.isNode ? process.memoryUsage() : null\\n  };\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/shared/utils/script-loader.js\",\"messages\":[{\"ruleId\":\"no-param-reassign\",\"severity\":1,\"message\":\"Assignment to function parameter 'scriptConfig'.\",\"line\":14,\"column\":5,\"nodeType\":\"Identifier\",\"messageId\":\"assignmentToFunctionParam\",\"endLine\":14,\"endColumn\":17}],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":1,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Script Loading Module  \\n * Handles individual script loading with SRI verification and fallback support\\n */\\n\\n// Script loading cache to prevent duplicate loads\\nconst loadingCache = new Map();\\nconst loadedScripts = new Set();\\n\\n// Load a single script with SRI verification and fallback support\\nexport const loadScript = (scriptConfig) => {\\n  // Handle string format\\n  if (typeof scriptConfig === 'string') {\\n    scriptConfig = { url: scriptConfig };\\n  }\\n  \\n  const { url, integrity, crossorigin, fallback } = scriptConfig;\\n  const cacheKey = url;\\n  \\n  if (loadedScripts.has(cacheKey)) {\\n    return Promise.resolve();\\n  }\\n\\n  if (loadingCache.has(cacheKey)) {\\n    return loadingCache.get(cacheKey);\\n  }\\n\\n  const promise = new Promise((resolve, reject) => {\\n    const loadScriptElement = (scriptUrl, isFirstAttempt = true) => {\\n      const script = document.createElement('script');\\n      script.src = scriptUrl;\\n      script.async = true;\\n      \\n      // Set security attributes if provided\\n      if (integrity && isFirstAttempt) {\\n        script.integrity = integrity;\\n      }\\n      if (crossorigin) {\\n        script.crossOrigin = crossorigin;\\n      }\\n      \\n      script.onload = () => {\\n        loadedScripts.add(cacheKey);\\n        console.log(`✅ Script loaded successfully: ${scriptUrl}`);\\n        resolve();\\n      };\\n      \\n      script.onerror = (error) => {\\n        console.warn(`❌ Failed to load script: ${scriptUrl}`, error);\\n        \\n        // Try fallback if available and this was the first attempt\\n        if (fallback && isFirstAttempt) {\\n          console.log(`🔄 Attempting fallback: ${fallback}`);\\n          loadScriptElement(fallback, false);\\n        } else {\\n          loadingCache.delete(cacheKey);\\n          reject(new Error(`Failed to load script: ${scriptUrl}${fallback ? ' (fallback also failed)' : ''}`));\\n        }\\n      };\\n      \\n      document.head.appendChild(script);\\n    };\\n    \\n    loadScriptElement(url, true);\\n  });\\n\\n  loadingCache.set(cacheKey, promise);\\n  return promise;\\n};\\n\\n// Load multiple scripts sequentially\\nexport const loadScripts = async (scriptConfigs) => {\\n  for (const scriptConfig of scriptConfigs) {\\n    await loadScript(scriptConfig);\\n  }\\n};\\n\\n// Get loading status\\nexport const getScriptStatus = (url) => {\\n  return {\\n    isLoaded: loadedScripts.has(url),\\n    isLoading: loadingCache.has(url)\\n  };\\n};\\n\\n// Clear caches (for testing/cleanup)\\nexport const clearScriptCache = () => {\\n  loadingCache.clear();\\n  loadedScripts.clear();\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/shared/utils/shaders/base-shaders.js\",\"messages\":[{\"ruleId\":\"func-style\",\"severity\":1,\"message\":\"Expected a function expression.\",\"line\":208,\"column\":8,\"nodeType\":\"FunctionDeclaration\",\"messageId\":\"expression\",\"endLine\":225,\"endColumn\":2}],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":1,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Base Shaders - Core vertex and fragment shaders for computer vision operations\\n */\\n\\n// Standard vertex shader for full-screen quad processing\\nexport const VERTEX_SHADER_FULLSCREEN = `#version 300 es\\nprecision highp float;\\n\\nin vec2 a_position;\\nin vec2 a_texCoord;\\n\\nout vec2 v_texCoord;\\n\\nvoid main() {\\n    gl_Position = vec4(a_position, 0.0, 1.0);\\n    v_texCoord = a_texCoord;\\n}`;\\n\\n// WebGL1 fallback vertex shader\\nexport const VERTEX_SHADER_FULLSCREEN_V1 = `\\nprecision highp float;\\n\\nattribute vec2 a_position;\\nattribute vec2 a_texCoord;\\n\\nvarying vec2 v_texCoord;\\n\\nvoid main() {\\n    gl_Position = vec4(a_position, 0.0, 1.0);\\n    v_texCoord = a_texCoord;\\n}`;\\n\\n// RGB to grayscale conversion shader\\nexport const FRAGMENT_SHADER_GRAYSCALE = `#version 300 es\\nprecision highp float;\\n\\nuniform sampler2D u_image;\\nin vec2 v_texCoord;\\nout vec4 fragColor;\\n\\nvoid main() {\\n    vec3 rgb = texture(u_image, v_texCoord).rgb;\\n    float gray = dot(rgb, vec3(0.299, 0.587, 0.114));\\n    fragColor = vec4(gray, gray, gray, 1.0);\\n}`;\\n\\nexport const FRAGMENT_SHADER_GRAYSCALE_V1 = `\\nprecision highp float;\\n\\nuniform sampler2D u_image;\\nvarying vec2 v_texCoord;\\n\\nvoid main() {\\n    vec3 rgb = texture2D(u_image, v_texCoord).rgb;\\n    float gray = dot(rgb, vec3(0.299, 0.587, 0.114));\\n    gl_FragColor = vec4(gray, gray, gray, 1.0);\\n}`;\\n\\n// Gaussian blur shader\\nexport const FRAGMENT_SHADER_BLUR = `#version 300 es\\nprecision highp float;\\n\\nuniform sampler2D u_image;\\nuniform vec2 u_resolution;\\nuniform float u_sigma;\\n\\nin vec2 v_texCoord;\\nout vec4 fragColor;\\n\\nvoid main() {\\n    vec2 texel = 1.0 / u_resolution;\\n    vec3 color = vec3(0.0);\\n    float weight = 0.0;\\n    \\n    int radius = int(u_sigma * 2.0);\\n    \\n    for (int x = -radius; x <= radius; x++) {\\n        for (int y = -radius; y <= radius; y++) {\\n            vec2 offset = vec2(float(x), float(y)) * texel;\\n            float distance = length(offset);\\n            float w = exp(-distance * distance / (2.0 * u_sigma * u_sigma));\\n            \\n            color += texture(u_image, v_texCoord + offset).rgb * w;\\n            weight += w;\\n        }\\n    }\\n    \\n    fragColor = vec4(color / weight, 1.0);\\n}`;\\n\\n// Sobel edge detection shader\\nexport const FRAGMENT_SHADER_SOBEL = `#version 300 es\\nprecision highp float;\\n\\nuniform sampler2D u_image;\\nuniform vec2 u_resolution;\\n\\nin vec2 v_texCoord;\\nout vec4 fragColor;\\n\\nvoid main() {\\n    vec2 texel = 1.0 / u_resolution;\\n    \\n    // Sample surrounding pixels\\n    float tl = texture(u_image, v_texCoord + texel * vec2(-1.0, -1.0)).r;\\n    float tm = texture(u_image, v_texCoord + texel * vec2( 0.0, -1.0)).r;\\n    float tr = texture(u_image, v_texCoord + texel * vec2( 1.0, -1.0)).r;\\n    float ml = texture(u_image, v_texCoord + texel * vec2(-1.0,  0.0)).r;\\n    float mm = texture(u_image, v_texCoord + texel * vec2( 0.0,  0.0)).r;\\n    float mr = texture(u_image, v_texCoord + texel * vec2( 1.0,  0.0)).r;\\n    float bl = texture(u_image, v_texCoord + texel * vec2(-1.0,  1.0)).r;\\n    float bm = texture(u_image, v_texCoord + texel * vec2( 0.0,  1.0)).r;\\n    float br = texture(u_image, v_texCoord + texel * vec2( 1.0,  1.0)).r;\\n    \\n    // Apply Sobel operators\\n    float sobelX = (tr + 2.0*mr + br) - (tl + 2.0*ml + bl);\\n    float sobelY = (bl + 2.0*bm + br) - (tl + 2.0*tm + tr);\\n    \\n    float magnitude = sqrt(sobelX*sobelX + sobelY*sobelY);\\n    fragColor = vec4(magnitude, magnitude, magnitude, 1.0);\\n}`;\\n\\n// Integral image computation shader (first pass - horizontal)\\nexport const FRAGMENT_SHADER_INTEGRAL_H = `#version 300 es\\nprecision highp float;\\n\\nuniform sampler2D u_image;\\nuniform vec2 u_resolution;\\n\\nin vec2 v_texCoord;\\nout vec4 fragColor;\\n\\nvoid main() {\\n    vec2 texel = vec2(1.0 / u_resolution.x, 0.0);\\n    float sum = 0.0;\\n    \\n    // Sum horizontally from left edge to current position\\n    for (int i = 0; i < int(u_resolution.x); i++) {\\n        vec2 sampleCoord = vec2(float(i) / u_resolution.x, v_texCoord.y);\\n        if (sampleCoord.x <= v_texCoord.x) {\\n            sum += texture(u_image, sampleCoord).r;\\n        }\\n    }\\n    \\n    fragColor = vec4(sum, sum, sum, 1.0);\\n}`;\\n\\n// Histogram equalization shader\\nexport const FRAGMENT_SHADER_HISTOGRAM_EQ = `#version 300 es\\nprecision highp float;\\n\\nuniform sampler2D u_image;\\nuniform sampler2D u_histogram;\\n\\nin vec2 v_texCoord;\\nout vec4 fragColor;\\n\\nvoid main() {\\n    vec3 color = texture(u_image, v_texCoord).rgb;\\n    float gray = dot(color, vec3(0.299, 0.587, 0.114));\\n    \\n    // Lookup equalized value from histogram texture\\n    float equalized = texture(u_histogram, vec2(gray, 0.5)).r;\\n    \\n    fragColor = vec4(equalized, equalized, equalized, 1.0);\\n}`;\\n\\n// Template matching correlation shader\\nexport const FRAGMENT_SHADER_TEMPLATE_MATCH = `#version 300 es\\nprecision highp float;\\n\\nuniform sampler2D u_image;\\nuniform sampler2D u_template;\\nuniform vec2 u_resolution;\\nuniform vec2 u_templateSize;\\n\\nin vec2 v_texCoord;\\nout vec4 fragColor;\\n\\nvoid main() {\\n    vec2 texel = 1.0 / u_resolution;\\n    vec2 templateTexel = 1.0 / u_templateSize;\\n    \\n    float correlation = 0.0;\\n    float normalization = 0.0;\\n    \\n    // Calculate normalized cross-correlation\\n    for (int x = 0; x < int(u_templateSize.x); x++) {\\n        for (int y = 0; y < int(u_templateSize.y); y++) {\\n            vec2 imageOffset = vec2(float(x), float(y)) * texel;\\n            vec2 templateCoord = vec2(float(x), float(y)) * templateTexel;\\n            \\n            float imageVal = texture(u_image, v_texCoord + imageOffset).r;\\n            float templateVal = texture(u_template, templateCoord).r;\\n            \\n            correlation += imageVal * templateVal;\\n            normalization += templateVal * templateVal;\\n        }\\n    }\\n    \\n    float score = correlation / sqrt(normalization);\\n    fragColor = vec4(score, score, score, 1.0);\\n}`;\\n\\n/**\\n * Shader compilation helper function\\n */\\nexport function getShaderSource(name, isWebGL2 = true) {\\n    const shaders = {\\n        vertex_fullscreen: isWebGL2 ? VERTEX_SHADER_FULLSCREEN : VERTEX_SHADER_FULLSCREEN_V1,\\n        fragment_grayscale: isWebGL2 ? FRAGMENT_SHADER_GRAYSCALE : FRAGMENT_SHADER_GRAYSCALE_V1,\\n        fragment_blur: FRAGMENT_SHADER_BLUR,\\n        fragment_sobel: FRAGMENT_SHADER_SOBEL,\\n        fragment_integral_h: FRAGMENT_SHADER_INTEGRAL_H,\\n        fragment_histogram_eq: FRAGMENT_SHADER_HISTOGRAM_EQ,\\n        fragment_template_match: FRAGMENT_SHADER_TEMPLATE_MATCH\\n    };\\n    \\n    const source = shaders[name];\\n    if (!source) {\\n        throw new Error(`Shader '${name}' not found`);\\n    }\\n    \\n    return source;\\n}\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/shared/utils/speech-analysis-config.js\",\"messages\":[],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/shared/utils/speech-analysis-events.js\",\"messages\":[],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/shared/utils/speech-analysis-metrics.js\",\"messages\":[{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":22,\"column\":33,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":22,\"endColumn\":34},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '*' and '+'. Use parentheses to clarify the intended order of operations.\",\"line\":22,\"column\":56,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":22,\"endColumn\":57}],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":2,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Performance metrics tracking for speech analysis pipeline\\n */\\n\\nexport const createMetricsTracker = () => {\\n  const metrics = {\\n    totalSessions: 0,\\n    totalTranscriptions: 0,\\n    totalAnalyses: 0,\\n    averageLatency: 0,\\n    successRate: 0,\\n    errorCount: 0,\\n    lastProcessingTime: 0\\n  };\\n\\n  // Update performance metrics\\n  const updateMetrics = (processingTime, success) => {\\n    const totalProcessed = metrics.totalTranscriptions + metrics.totalAnalyses;\\n    \\n    if (totalProcessed > 0) {\\n      metrics.averageLatency = \\n        (metrics.averageLatency * (totalProcessed - 1) + processingTime) / totalProcessed;\\n    }\\n    \\n    if (success) {\\n      const successfulOps = totalProcessed - metrics.errorCount;\\n      metrics.successRate = successfulOps / totalProcessed;\\n    }\\n\\n    metrics.lastProcessingTime = processingTime;\\n  };\\n\\n  // Increment transcription count\\n  const incrementTranscriptions = () => {\\n    metrics.totalTranscriptions++;\\n  };\\n\\n  // Increment analysis count\\n  const incrementAnalyses = () => {\\n    metrics.totalAnalyses++;\\n  };\\n\\n  // Increment error count\\n  const incrementErrors = () => {\\n    metrics.errorCount++;\\n  };\\n\\n  // Set total sessions\\n  const setTotalSessions = (count) => {\\n    metrics.totalSessions = count;\\n  };\\n\\n  // Get current metrics\\n  const getMetrics = () => ({ ...metrics });\\n\\n  // Get performance metrics with additional session data\\n  const getPerformanceMetrics = (isProcessing, activeSession, sessionData) => ({\\n    ...metrics,\\n    isProcessing,\\n    activeSession,\\n    sessionData: sessionData ? {\\n      startTime: sessionData.startTime,\\n      transcriptionCount: sessionData.transcriptions.length,\\n      analysisCount: sessionData.analyses.length\\n    } : null\\n  });\\n\\n  return {\\n    updateMetrics,\\n    incrementTranscriptions,\\n    incrementAnalyses,\\n    incrementErrors,\\n    setTotalSessions,\\n    getMetrics,\\n    getPerformanceMetrics\\n  };\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/shared/utils/speech-analysis-pipeline-client-server.js\",\"messages\":[{\"ruleId\":\"max-lines-per-function\",\"severity\":1,\"message\":\"Arrow function has too many lines (353). Maximum allowed is 150.\",\"line\":12,\"column\":45,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"exceed\",\"endLine\":488,\"endColumn\":2}],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":1,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Speech Analysis Pipeline - Client/Server Architecture\\n * Browser client handles Web Speech API, server handles analysis\\n * Following functional programming patterns with factory functions\\n */\\n\\nimport { createBrowserSpeechClient } from '../browser-speech-client.js';\\nimport { createPipelineEvents } from '../core/pipeline-events.js';\\nimport { createSpeechPipelineStatus } from '../core/types.js';\\n\\n// Create client-server speech analysis pipeline factory\\nexport const createSpeechAnalysisPipeline = (config = {}) => {\\n  const state = {\\n    speechClient: null,\\n    isInitialized: false,\\n    isListening: false,\\n    sessionId: null,\\n    \\n    // Configuration\\n    config: {\\n      serverUrl: config.serverUrl || (process.env.SPEECH_SERVER_URL || 'http://localhost:3000/api/analyze'),\\n      language: config.language || 'en-US',\\n      continuous: config.continuous !== false,\\n      interimResults: config.interimResults !== false,\\n      sendInterimResults: config.sendInterimResults || false,\\n      batchSize: config.batchSize || 5,\\n      batchTimeout: config.batchTimeout || 2000,\\n      autoReconnect: config.autoReconnect !== false,\\n      ...config\\n    },\\n    \\n    // Statistics\\n    stats: {\\n      transcriptCount: 0,\\n      analysisCount: 0,\\n      errorCount: 0,\\n      sessionStartTime: null,\\n      lastTranscriptTime: null,\\n      lastAnalysisTime: null\\n    }\\n  };\\n\\n  // Create event system\\n  const events = createPipelineEvents();\\n\\n  // Initialize pipeline\\n  const initialize = async (options = {}) => {\\n    if (state.isInitialized) {\\n      console.warn('Pipeline already initialized');\\n      return true;\\n    }\\n\\n    try {\\n      console.log('🚀 Initializing client-server speech analysis pipeline...');\\n      \\n      // Merge options with config\\n      const mergedConfig = { ...state.config, ...options };\\n      state.config = mergedConfig;\\n      \\n      // Create browser speech client\\n      state.speechClient = createBrowserSpeechClient({\\n        serverUrl: mergedConfig.serverUrl,\\n        language: mergedConfig.language,\\n        continuous: mergedConfig.continuous,\\n        interimResults: mergedConfig.interimResults,\\n        sendInterimResults: mergedConfig.sendInterimResults,\\n        batchSize: mergedConfig.batchSize,\\n        batchTimeout: mergedConfig.batchTimeout\\n      });\\n      \\n      // Initialize speech client\\n      state.speechClient.initialize();\\n      \\n      // Setup event forwarding\\n      setupEventForwarding();\\n      \\n      // Create new session\\n      state.sessionId = state.speechClient.getSessionId();\\n      \\n      state.isInitialized = true;\\n      \\n      // Emit ready event\\n      events.emit('ready', {\\n        pipeline: 'speech_analysis_client_server',\\n        sessionId: state.sessionId,\\n        config: mergedConfig\\n      });\\n      \\n      console.log('✅ Speech analysis pipeline initialized');\\n      console.log(`📝 Session ID: ${state.sessionId}`);\\n      console.log(`🌐 Server URL: ${mergedConfig.serverUrl}`);\\n      \\n      return true;\\n      \\n    } catch (error) {\\n      console.error('Pipeline initialization failed:', error);\\n      events.emit('error', {\\n        type: 'initialization_error',\\n        error: error.message\\n      });\\n      throw error;\\n    }\\n  };\\n\\n  // Setup event forwarding from speech client\\n  const setupEventForwarding = () => {\\n    // Forward transcripts\\n    state.speechClient.onTranscript((data) => {\\n      state.stats.transcriptCount++;\\n      state.stats.lastTranscriptTime = Date.now();\\n      \\n      events.emit('transcript', {\\n        text: data.text,\\n        confidence: data.confidence,\\n        isFinal: data.isFinal,\\n        timestamp: data.timestamp,\\n        sessionId: data.sessionId\\n      });\\n    });\\n    \\n    // Forward analysis results\\n    state.speechClient.onAnalysis((data) => {\\n      state.stats.analysisCount++;\\n      state.stats.lastAnalysisTime = Date.now();\\n      \\n      events.emit('analysis', {\\n        results: data.results,\\n        summary: data.summary,\\n        timestamp: data.timestamp,\\n        sessionId: data.sessionId\\n      });\\n      \\n      // Also emit individual analysis results\\n      if (data.results && Array.isArray(data.results)) {\\n        data.results.forEach(result => {\\n          if (result.analyses) {\\n            result.analyses.forEach(analysis => {\\n              events.emit('analysis_result', {\\n                prompt: analysis.prompt,\\n                result: analysis.result,\\n                confidence: analysis.confidence,\\n                timestamp: analysis.timestamp\\n              });\\n            });\\n          }\\n        });\\n      }\\n    });\\n    \\n    // Forward errors\\n    state.speechClient.onError((data) => {\\n      state.stats.errorCount++;\\n      \\n      events.emit('error', {\\n        type: data.type,\\n        error: data.error,\\n        timestamp: data.timestamp\\n      });\\n    });\\n    \\n    // Forward status changes\\n    state.speechClient.onStatusChange((data) => {\\n      state.isListening = data.isListening;\\n      \\n      events.emit('status_change', {\\n        isListening: data.isListening,\\n        timestamp: Date.now()\\n      });\\n      \\n      // Update stats\\n      if (data.isListening && !state.stats.sessionStartTime) {\\n        state.stats.sessionStartTime = Date.now();\\n      } else if (!data.isListening && state.stats.sessionStartTime) {\\n        const duration = Date.now() - state.stats.sessionStartTime;\\n        console.log(`📊 Session duration: ${Math.round(duration / 1000)}s`);\\n      }\\n    });\\n  };\\n\\n  // Start listening\\n  const startListening = async () => {\\n    if (!state.isInitialized) {\\n      throw new Error('Pipeline not initialized');\\n    }\\n    \\n    if (state.isListening) {\\n      console.warn('Already listening');\\n      return;\\n    }\\n    \\n    try {\\n      console.log('🎤 Starting speech recognition...');\\n      \\n      await state.speechClient.startListening();\\n      \\n      events.emit('listening_started', {\\n        sessionId: state.sessionId,\\n        timestamp: Date.now()\\n      });\\n      \\n    } catch (error) {\\n      console.error('Failed to start listening:', error);\\n      events.emit('error', {\\n        type: 'start_error',\\n        error: error.message\\n      });\\n      throw error;\\n    }\\n  };\\n\\n  // Stop listening\\n  const stopListening = () => {\\n    if (!state.isInitialized || !state.isListening) {\\n      return;\\n    }\\n    \\n    console.log('🛑 Stopping speech recognition...');\\n    \\n    state.speechClient.stopListening();\\n    \\n    events.emit('listening_stopped', {\\n      sessionId: state.sessionId,\\n      timestamp: Date.now()\\n    });\\n  };\\n\\n  // Send text manually\\n  const sendText = async (text, options = {}) => {\\n    if (!state.isInitialized) {\\n      throw new Error('Pipeline not initialized');\\n    }\\n    \\n    if (!text || !text.trim()) {\\n      throw new Error('No text provided');\\n    }\\n    \\n    try {\\n      const result = await state.speechClient.sendText(text, options);\\n      \\n      events.emit('manual_text', {\\n        text,\\n        result,\\n        timestamp: Date.now()\\n      });\\n      \\n      return result;\\n      \\n    } catch (error) {\\n      console.error('Failed to send text:', error);\\n      events.emit('error', {\\n        type: 'send_error',\\n        error: error.message\\n      });\\n      throw error;\\n    }\\n  };\\n\\n  // Get session data from server\\n  const getSessionData = async () => {\\n    if (!state.isInitialized) {\\n      throw new Error('Pipeline not initialized');\\n    }\\n    \\n    try {\\n      // Properly construct URL\\n      const baseUrl = new URL(state.config.serverUrl);\\n      const apiBase = `${baseUrl.protocol}//${baseUrl.host}/api`;\\n      const sessionUrl = `${apiBase}/session/${state.sessionId}`;\\n      \\n      const response = await fetch(sessionUrl);\\n      \\n      if (!response.ok) {\\n        throw new Error(`Server error: ${response.status}`);\\n      }\\n      \\n      const sessionData = await response.json();\\n      return sessionData;\\n      \\n    } catch (error) {\\n      console.error('Failed to get session data:', error);\\n      throw error;\\n    }\\n  };\\n\\n  // Update session metadata\\n  const updateSessionMetadata = async (meta,data) => {\\n    if (!state.isInitialized) {\\n      throw new Error('Pipeline not initialized');\\n    }\\n    \\n    try {\\n      // Properly construct URL\\n      const baseUrl = new URL(state.config.serverUrl);\\n      const apiBase = `${baseUrl.protocol}//${baseUrl.host}/api`;\\n      const metadataUrl = `${apiBase}/session/${state.sessionId}/metadata`;\\n      \\n      const response = await fetch(\\n        metadataUrl,\\n        {\\n          method: 'PATCH',\\n          headers: {\\n            'Content-Type': 'application/json'\\n          },\\n          body: JSON.stringify(meta,data)\\n        }\\n      );\\n      \\n      if (!response.ok) {\\n        throw new Error(`Server error: ${response.status}`);\\n      }\\n      \\n      const result = await response.json();\\n      return result;\\n      \\n    } catch (error) {\\n      console.error('Failed to update metadata:', error);\\n      throw error;\\n    }\\n  };\\n\\n  // End session\\n  const endSession = async () => {\\n    if (!state.isInitialized) {\\n      return;\\n    }\\n    \\n    // Stop listening if active\\n    if (state.isListening) {\\n      stopListening();\\n    }\\n    \\n    try {\\n      // Properly construct URL\\n      const baseUrl = new URL(state.config.serverUrl);\\n      const apiBase = `${baseUrl.protocol}//${baseUrl.host}/api`;\\n      const deleteUrl = `${apiBase}/session/${state.sessionId}`;\\n      \\n      const response = await fetch(\\n        deleteUrl,\\n        {\\n          method: 'DELETE'\\n        }\\n      );\\n      \\n      if (!response.ok) {\\n        console.warn(`Failed to end session on server: ${response.status}`);\\n      }\\n      \\n      events.emit('session_ended', {\\n        sessionId: state.sessionId,\\n        stats: getStatistics(),\\n        timestamp: Date.now()\\n      });\\n      \\n    } catch (error) {\\n      console.error('Failed to end session:', error);\\n    }\\n  };\\n\\n  // Start new session\\n  const startNewSession = () => {\\n    if (state.isListening) {\\n      stopListening();\\n    }\\n    \\n    state.sessionId = state.speechClient.newSession();\\n    state.stats = {\\n      transcriptCount: 0,\\n      analysisCount: 0,\\n      errorCount: 0,\\n      sessionStartTime: null,\\n      lastTranscriptTime: null,\\n      lastAnalysisTime: null\\n    };\\n    \\n    console.log(`📝 New session started: ${state.sessionId}`);\\n    \\n    events.emit('new_session', {\\n      sessionId: state.sessionId,\\n      timestamp: Date.now()\\n    });\\n    \\n    return state.sessionId;\\n  };\\n\\n  // Get pipeline status\\n  const getStatus = () => {\\n    return createSpeechPipelineStatus({\\n      isInitialized: state.isInitialized,\\n      isListening: state.isListening,\\n      sessionId: state.sessionId,\\n      serverUrl: state.config.serverUrl,\\n      stats: getStatistics()\\n    });\\n  };\\n\\n  // Get statistics\\n  const getStatistics = () => {\\n    const duration = state.stats.sessionStartTime \\n      ? Date.now() - state.stats.sessionStartTime \\n      : 0;\\n    \\n    return {\\n      ...state.stats,\\n      duration,\\n      transcriptsPerMinute: duration > 0 \\n        ? (state.stats.transcriptCount / (duration / 60000)).toFixed(2)\\n        : 0,\\n      analysesPerMinute: duration > 0\\n        ? (state.stats.analysisCount / (duration / 60000)).toFixed(2)\\n        : 0\\n    };\\n  };\\n\\n  // Update configuration\\n  const updateConfig = (newConfig) => {\\n    Object.assign(state.config, newConfig);\\n    \\n    if (state.speechClient) {\\n      state.speechClient.updateConfig(newConfig);\\n    }\\n    \\n    events.emit('config_updated', {\\n      config: state.config,\\n      timestamp: Date.now()\\n    });\\n  };\\n\\n  // Cleanup\\n  const cleanup = async () => {\\n    console.log('🧹 Cleaning up speech analysis pipeline...');\\n    \\n    // End session if active\\n    if (state.sessionId) {\\n      await endSession();\\n    }\\n    \\n    // Cleanup speech client\\n    if (state.speechClient) {\\n      state.speechClient.cleanup();\\n    }\\n    \\n    // Clear event listeners\\n    events.removeAllListeners();\\n    \\n    state.isInitialized = false;\\n    state.isListening = false;\\n    \\n    console.log('✅ Pipeline cleanup complete');\\n  };\\n\\n  return {\\n    // Core functionality\\n    initialize,\\n    startListening,\\n    stopListening,\\n    sendText,\\n    cleanup,\\n    \\n    // Session management\\n    getSessionData,\\n    updateSessionMetadata,\\n    endSession,\\n    startNewSession,\\n    getSessionId: () => state.sessionId,\\n    \\n    // Status and statistics\\n    getStatus,\\n    getStatistics,\\n    isInitialized: () => state.isInitialized,\\n    isListening: () => state.isListening,\\n    \\n    // Configuration\\n    updateConfig,\\n    getConfig: () => ({ ...state.config }),\\n    \\n    // Event handling\\n    on: events.on,\\n    off: events.off,\\n    once: events.once,\\n    \\n    // Direct event subscriptions\\n    onTranscript: (callback) => events.on('transcript', callback),\\n    onAnalysis: (callback) => events.on('analysis', callback),\\n    onError: (callback) => events.on('error', callback),\\n    onStatusChange: (callback) => events.on('status_change', callback)\\n  };\\n};\\n\\n// Export configuration\\nexport const PIPELINE_CONFIG = {\\n  name: 'Speech Analysis Client-Server',\\n  version: '1.0.0',\\n  architecture: 'client-server',\\n  capabilities: {\\n    webSpeechAPI: true,\\n    serverAnalysis: true,\\n    realtimeTranscription: true,\\n    batchProcessing: true,\\n    sessionManagement: true\\n  },\\n  requirements: {\\n    browser: ['Web Speech API support'],\\n    server: ['Analysis server running on configured URL']\\n  },\\n  defaultConfig: {\\n    serverUrl: process.env.SPEECH_SERVER_URL || 'http://localhost:3000/api/analyze',\\n    language: 'en-US',\\n    continuous: true,\\n    interimResults: true,\\n    sendInterimResults: false,\\n    batchSize: 5,\\n    batchTimeout: 2000\\n  }\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/shared/utils/speech-analysis-pipeline-hybrid.js\",\"messages\":[{\"ruleId\":\"max-lines-per-function\",\"severity\":1,\"message\":\"Arrow function has too many lines (213). Maximum allowed is 150.\",\"line\":22,\"column\":45,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"exceed\",\"endLine\":319,\"endColumn\":2}],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":1,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Speech Analysis Pipeline - Hybrid Implementation\\n * Integrates comprehensive speech analysis with the Synopticon architecture\\n * Following functional programming patterns with factory functions\\n */\\n\\nimport { createPipeline } from '../core/pipeline.js';\\nimport { checkFeatures, detectRuntime } from './runtime-detector.js';\\nimport { measureAsync } from '../core/performance-monitor.js';\\nimport { \\n  Capability, \\n  createPerformanceProfile,\\n  createSpeechAnalysisResult\\n} from '../core/types.js';\\nimport { createSpeechAnalysisAPI } from '../speech-analysis/index.js';\\nimport { createSpeechAnalysisConfig } from './speech-analysis-config.js';\\nimport { createSessionManager } from './speech-analysis-session.js';\\nimport { createMetricsTracker } from './speech-analysis-metrics.js';\\nimport { createEventManager } from './speech-analysis-events.js';\\n\\n// Main speech analysis pipeline factory\\nexport const createSpeechAnalysisPipeline = (config = {}) => {\\n  const pipelineConfig = createSpeechAnalysisConfig(config);\\n  \\n  const state = {\\n    runtime: detectRuntime(),\\n    features: checkFeatures(),\\n    speechAPI: null,\\n    isInitialized: false,\\n    isProcessing: false\\n  };\\n\\n  // Create components\\n  const eventManager = createEventManager();\\n  const metricsTracker = createMetricsTracker();\\n  let sessionManager = null; // Created after speechAPI is initialized\\n\\n  // Initialize the speech analysis pipeline\\n  const initialize = async (options = {}) => {\\n    if (state.isInitialized) {\\n      console.log('🎤 Speech analysis pipeline already initialized');\\n      return true;\\n    }\\n\\n    return await measureAsync(async () => {\\n      try {\\n        // Merge configuration\\n        const initConfig = { ...pipelineConfig, ...options };\\n        \\n        // Initialize speech analysis API\\n        state.speechAPI = createSpeechAnalysisAPI(initConfig);\\n        \\n        // Create session manager with speech API\\n        sessionManager = createSessionManager(state.speechAPI, eventManager.callbacks);\\n        \\n        // Setup event handlers\\n        eventManager.setupEventHandlers(state.speechAPI, sessionManager, metricsTracker);\\n        \\n        // Initialize the API\\n        await state.speechAPI.initialize(initConfig);\\n        \\n        state.isInitialized = true;\\n        console.log('✅ Speech analysis pipeline initialized');\\n        \\n        // Auto-start if requested\\n        if (pipelineConfig.autoStart) {\\n          await sessionManager.startSession();\\n        }\\n        \\n        return true;\\n        \\n      } catch (error) {\\n        console.error('❌ Speech analysis pipeline initialization failed:', error);\\n        throw new Error(`Speech analysis pipeline initialization failed: ${error.message}`);\\n      }\\n    }, 'speech_analysis_pipeline', 'initialize');\\n  };\\n\\n  // Process method - main pipeline interface\\n  const process = async (input = null, options = {}) => {\\n    if (!state.isInitialized) {\\n      throw new Error('Speech analysis pipeline not initialized');\\n    }\\n\\n    return await measureAsync(async () => {\\n      const startTime = performance.now();\\n      state.isProcessing = true;\\n\\n      try {\\n        // Handle different input types\\n        let result;\\n\\n        if (typeof input === 'string') {\\n          // Process text directly\\n          result = await state.speechAPI.processText(input, options);\\n          \\n        } else if (input && input.audio) {\\n          // Handle audio input (future enhancement)\\n          throw new Error('Audio input processing not yet implemented');\\n          \\n        } else if (input === null && sessionManager?.getActiveSession()) {\\n          // Get current session results\\n          result = await getCurrentSessionResults();\\n          \\n        } else {\\n          throw new Error('Invalid input: expected text string or null for session results');\\n        }\\n\\n        // Update metrics\\n        const processingTime = performance.now() - startTime;\\n        metricsTracker.updateMetrics(processingTime, true);\\n\\n        // Create standardized pipeline result\\n        const pipelineResult = createSpeechAnalysisResult({\\n          timestamp: Date.now(),\\n          source: 'speech_analysis_pipeline',\\n          ...(result || {}),\\n          metadata: {\\n            ...result?.metadata,\\n            processingTime,\\n            pipelineVersion: '1.0.0',\\n            backend: state.speechAPI?.getStatus()?.configuration?.llmBackend || 'unknown',\\n            sessionId: sessionManager?.getActiveSession()\\n          }\\n        });\\n\\n        return pipelineResult;\\n\\n      } catch (error) {\\n        const processingTime = performance.now() - startTime;\\n        metricsTracker.updateMetrics(processingTime, false);\\n        \\n        console.warn('Speech analysis processing failed:', error);\\n        \\n        // Return error result instead of throwing\\n        return createSpeechAnalysisResult({\\n          timestamp: Date.now(),\\n          source: 'speech_analysis_pipeline',\\n          text: typeof input === 'string' ? input : '',\\n          analyses: [],\\n          error: error.message,\\n          metadata: {\\n            processingTime,\\n            error: true,\\n            sessionId: sessionManager?.getActiveSession()\\n          }\\n        });\\n      } finally {\\n        state.isProcessing = false;\\n      }\\n    }, 'speech_analysis_pipeline', 'process');\\n  };\\n\\n  // Get current session results\\n  const getCurrentSessionResults = async () => {\\n    if (!sessionManager?.getActiveSession()) {\\n      return createSpeechAnalysisResult({\\n        timestamp: Date.now(),\\n        source: 'speech_analysis_pipeline',\\n        text: '',\\n        analyses: [],\\n        metadata: {\\n          error: 'No active session',\\n          sessionId: null\\n        }\\n      });\\n    }\\n\\n    const history = state.speechAPI.getAnalysisHistory();\\n    const status = state.speechAPI.getStatus();\\n\\n    return createSpeechAnalysisResult({\\n      timestamp: Date.now(),\\n      source: 'speech_analysis_pipeline',\\n      text: history?.chunks?.map(c => c.text).join(' ') || '',\\n      analyses: history?.chunks?.flatMap(c => c.analysisResults) || [],\\n      conversationContext: {\\n        summary: history?.summary || '',\\n        totalChunks: history?.totalChunks || 0,\\n        chunkIndex: history?.chunks?.length || 0\\n      },\\n      metadata: {\\n        sessionId: sessionManager.getActiveSession(),\\n        sessionActive: status.components?.streaming || false,\\n        totalWords: history?.totalWords || 0\\n      }\\n    });\\n  };\\n\\n  // Get pipeline health status\\n  const getHealthStatus = () => {\\n    const apiStatus = state.speechAPI?.getStatus();\\n    const isHealthy = state.isInitialized && \\n                     (apiStatus?.components?.recognition !== false) &&\\n                     (apiStatus?.components?.analysis !== false);\\n\\n    return {\\n      healthy: isHealthy,\\n      runtime: state.runtime.isBrowser ? 'browser' : 'node',\\n      backend: apiStatus?.configuration?.llmBackend || 'unknown',\\n      modelLoaded: apiStatus?.llm?.modelLoaded !== false,\\n      speechRecognition: apiStatus?.speechRecognition?.available !== false,\\n      activeSession: sessionManager?.getActiveSession(),\\n      lastProcessingTime: metricsTracker.getMetrics().lastProcessingTime,\\n      errorCount: metricsTracker.getMetrics().errorCount,\\n      successRate: metricsTracker.getMetrics().successRate\\n    };\\n  };\\n\\n  // Check if pipeline is initialized\\n  const isInitialized = () => state.isInitialized;\\n\\n  // Get performance metrics\\n  const getPerformanceMetrics = () => {\\n    if (!sessionManager) return metricsTracker.getMetrics();\\n    \\n    // Update metrics with session count\\n    metricsTracker.setTotalSessions(sessionManager.getTotalSessions());\\n    \\n    return metricsTracker.getPerformanceMetrics(\\n      state.isProcessing,\\n      sessionManager.getActiveSession(),\\n      sessionManager.getSessionData()\\n    );\\n  };\\n\\n  // Cleanup pipeline resources\\n  const cleanup = async () => {\\n    try {\\n      // Stop active session\\n      if (sessionManager?.getActiveSession()) {\\n        await sessionManager.stopSession();\\n      }\\n\\n      // Cleanup speech API\\n      if (state.speechAPI) {\\n        await state.speechAPI.cleanup();\\n        state.speechAPI = null;\\n      }\\n\\n      // Reset state\\n      state.isInitialized = false;\\n      state.isProcessing = false;\\n      sessionManager = null;\\n\\n      console.log('🧹 Speech analysis pipeline cleaned up');\\n\\n    } catch (error) {\\n      console.warn('Speech analysis pipeline cleanup error:', error);\\n    }\\n  };\\n\\n  // Create standard pipeline interface\\n  const basePipeline = createPipeline({\\n    // Standard pipeline interface\\n    name: 'speech-analysis-hybrid',\\n    capabilities: [\\n      Capability.SPEECH_RECOGNITION,\\n      Capability.SPEECH_ANALYSIS, \\n      Capability.CONVERSATION_CONTEXT,\\n      Capability.MULTI_PROMPT_ANALYSIS,\\n      Capability.REAL_TIME_TRANSCRIPTION\\n    ],\\n    \\n    // Core methods\\n    initialize,\\n    process,\\n    cleanup,\\n    getHealthStatus,\\n    isInitialized,\\n    getPerformanceMetrics,\\n\\n    // Performance profile\\n    performance: createPerformanceProfile({\\n      fps: 30,\\n      latency: '200-1000ms',\\n      modelSize: 'Variable (1-5GB)',\\n      cpuUsage: 'medium-high',\\n      memoryUsage: 'high',\\n      batteryImpact: 'high', // Due to continuous speech recognition and LLM processing\\n      networkUsage: 'low' // Local processing\\n    })\\n  });\\n\\n  // Extended interface for speech analysis specific features\\n  return {\\n    ...basePipeline,\\n    \\n    // Speech analysis specific methods\\n    startSession: () => sessionManager?.startSession(),\\n    stopSession: () => sessionManager?.stopSession(),\\n    getCurrentSessionResults,\\n    \\n    // Event handlers\\n    onTranscription: eventManager.onTranscription,\\n    onAnalysis: eventManager.onAnalysis,\\n    onSessionStart: eventManager.onSessionStart,\\n    onSessionEnd: eventManager.onSessionEnd,\\n    onError: eventManager.onError,\\n\\n    // Configuration access\\n    getConfiguration: () => ({ ...pipelineConfig }),\\n    updatePrompts: (prompts) => state.speechAPI?.updatePrompts(prompts),\\n    updateSystemPrompt: (prompt) => state.speechAPI?.updateSystemPrompt(prompt),\\n\\n    // Direct API access for advanced usage\\n    getSpeechAPI: () => state.speechAPI,\\n    \\n    // Session management\\n    getActiveSession: () => sessionManager?.getActiveSession(),\\n    getSessionHistory: () => state.speechAPI?.getAnalysisHistory(),\\n    clearSession: () => state.speechAPI?.clearSession(),\\n    generateSummary: () => state.speechAPI?.generateSummary(),\\n\\n    // Pipeline metadata\\n    version: '1.0.0',\\n    type: 'speech_analysis_hybrid'\\n  };\\n};\\n\\n// Factory function for pipeline registration\\nexport const createSpeechAnalysisPipelineFactory = () => ({\\n  name: 'speech-analysis-hybrid',\\n  description: 'Real-time speech recognition and multi-prompt analysis with conversation context',\\n  capabilities: [\\n    Capability.SPEECH_RECOGNITION,\\n    Capability.SPEECH_ANALYSIS, \\n    Capability.CONVERSATION_CONTEXT,\\n    Capability.MULTI_PROMPT_ANALYSIS,\\n    Capability.REAL_TIME_TRANSCRIPTION\\n  ],\\n  create: createSpeechAnalysisPipeline,\\n  requiresHardware: false, // Works with software fallbacks\\n  supportsRealtime: true,\\n  supportsBrowser: true,\\n  supportsNode: true, // With fallbacks\\n  pythonFree: true // No Python dependencies\\n});\\n\\n// Export configuration factory for external use\\nexport { createSpeechAnalysisConfig };\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/shared/utils/speech-analysis-session.js\",\"messages\":[],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/shared/utils/system-capabilities.js\",\"messages\":[],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/shared/utils/ui/loading-components.js\",\"messages\":[],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":0,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/shared/utils/url-utils.js\",\"messages\":[{\"ruleId\":\"no-script-url\",\"severity\":1,\"message\":\"Script URL is a form of eval.\",\"line\":104,\"column\":33,\"nodeType\":\"Literal\",\"messageId\":\"unexpectedScriptURL\",\"endLine\":104,\"endColumn\":46}],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":1,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * Secure URL Utilities\\n * Replaces deprecated url.parse() with WHATWG URL API\\n * Addresses CVE security concerns\\n */\\n\\n/**\\n * Secure URL parsing using WHATWG URL API\\n * @param {string} urlString - URL to parse\\n * @param {string} baseURL - Base URL for relative URLs (optional)\\n * @returns {Object} Parsed URL components\\n */\\nexport const parseURL = (urlString, baseURL = 'http://localhost') => {\\n  try {\\n    const url = new URL(urlString, baseURL);\\n    \\n    // Convert searchParams to query object (similar to url.parse behavior)\\n    const query = {};\\n    for (const [key, value] of url.searchParams.entries()) {\\n      if (query[key]) {\\n        // Handle multiple values for same key\\n        if (Array.isArray(query[key])) {\\n          query[key].push(value);\\n        } else {\\n          query[key] = [query[key], value];\\n        }\\n      } else {\\n        query[key] = value;\\n      }\\n    }\\n    \\n    return {\\n      pathname: url.pathname,\\n      query,\\n      search: url.search,\\n      searchParams: url.searchParams,\\n      hash: url.hash,\\n      hostname: url.hostname,\\n      port: url.port,\\n      protocol: url.protocol,\\n      href: url.href,\\n      origin: url.origin\\n    };\\n  } catch (error) {\\n    throw new Error(`Invalid URL: ${urlString} - ${error.message}`);\\n  }\\n};\\n\\n/**\\n * Parse request URL securely (for HTTP servers)\\n * @param {string} reqUrl - Request URL from req.url\\n * @param {boolean} parseQuery - Whether to parse query parameters\\n * @returns {Object} Parsed URL components\\n */\\nexport const parseRequestURL = (reqUrl, parseQuery = false) => {\\n  try {\\n    // Handle relative URLs from HTTP requests\\n    const url = new URL(reqUrl, 'http://localhost');\\n    \\n    const result = {\\n      pathname: url.pathname,\\n      search: url.search,\\n      hash: url.hash\\n    };\\n    \\n    if (parseQuery) {\\n      const query = {};\\n      for (const [key, value] of url.searchParams.entries()) {\\n        if (query[key]) {\\n          if (Array.isArray(query[key])) {\\n            query[key].push(value);\\n          } else {\\n            query[key] = [query[key], value];\\n          }\\n        } else {\\n          query[key] = value;\\n        }\\n      }\\n      result.query = query;\\n    }\\n    \\n    return result;\\n  } catch {\\n    // Fallback for malformed URLs\\n    return {\\n      pathname: reqUrl.split('?')[0],\\n      search: reqUrl.includes('?') ? reqUrl.substring(reqUrl.indexOf('?')) : '',\\n      query: parseQuery ? {} : undefined,\\n      hash: ''\\n    };\\n  }\\n};\\n\\n/**\\n * Validate URL to prevent injection attacks\\n * @param {string} urlString - URL to validate\\n * @returns {boolean} Whether URL is safe\\n */\\nexport const isValidURL = (urlString) => {\\n  try {\\n    const url = new URL(urlString);\\n    \\n    // Check for dangerous protocols\\n    const dangerousProtocols = ['javascript:', 'data:', 'vbscript:', 'file:'];\\n    if (dangerousProtocols.includes(url.protocol.toLowerCase())) {\\n      return false;\\n    }\\n    \\n    // Check for suspicious characters\\n    const suspiciousChars = ['<', '>', '\\\"', \\\"'\\\", '`'];\\n    if (suspiciousChars.some(char => url.href.includes(char))) {\\n      return false;\\n    }\\n    \\n    return true;\\n  } catch {\\n    return false;\\n  }\\n};\\n\\nexport default { parseURL, parseRequestURL, isValidURL };\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/shared/utils/url-validator.js\",\"messages\":[{\"ruleId\":\"max-lines-per-function\",\"severity\":1,\"message\":\"Arrow function has too many lines (158). Maximum allowed is 150.\",\"line\":8,\"column\":35,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"exceed\",\"endLine\":209,\"endColumn\":2}],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":1,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * URL Validator Utility\\n * Security-focused URL validation for API endpoints\\n * Following functional programming patterns with factory functions\\n */\\n\\n// Create URL validator factory\\nexport const createUrlValidator = (config = {}) => {\\n  const state = {\\n    allowedProtocols: config.allowedProtocols || ['http:', 'https:'],\\n    allowedHosts: config.allowedHosts || ['localhost', '127.0.0.1', '::1'],\\n    allowedPorts: config.allowedPorts || [3000, 3001, 8080, 8081, 11434],\\n    blockPrivateIPs: config.blockPrivateIPs !== false,\\n    blockLocalhost: config.blockLocalhost || false,\\n    maxUrlLength: config.maxUrlLength || 2048\\n  };\\n\\n  // Check if IP is private\\n  const isPrivateIP = (ip) => {\\n    const parts = ip.split('.');\\n    if (parts.length !== 4) return false;\\n    \\n    const first = parseInt(parts[0]);\\n    const second = parseInt(parts[1]);\\n    \\n    // Check for private IP ranges\\n    return (\\n      first === 10 || // 10.0.0.0 - 10.255.255.255\\n      (first === 172 && second >= 16 && second <= 31) || // 172.16.0.0 - 172.31.255.255\\n      (first === 192 && second === 168) || // 192.168.0.0 - 192.168.255.255\\n      first === 127 // 127.0.0.0 - 127.255.255.255 (loopback)\\n    );\\n  };\\n\\n  // Check if hostname is localhost variant\\n  const isLocalhost = (hostname) => {\\n    const localhostVariants = [\\n      'localhost',\\n      '127.0.0.1',\\n      '::1',\\n      '0.0.0.0',\\n      'local'\\n    ];\\n    \\n    return localhostVariants.includes(hostname.toLowerCase());\\n  };\\n\\n  // Validate URL\\n  const validate = (urlString) => {\\n    // Check URL length\\n    if (urlString.length > state.maxUrlLength) {\\n      return {\\n        valid: false,\\n        error: `URL exceeds maximum length of ${state.maxUrlLength} characters`\\n      };\\n    }\\n\\n    let url;\\n    try {\\n      url = new URL(urlString);\\n    } catch {\\n      return {\\n        valid: false,\\n        error: 'Invalid URL format'\\n      };\\n    }\\n\\n    // Check protocol\\n    if (!state.allowedProtocols.includes(url.protocol)) {\\n      return {\\n        valid: false,\\n        error: `Protocol '${url.protocol}' not allowed. Allowed: ${state.allowedProtocols.join(', ')}`\\n      };\\n    }\\n\\n    // Check for localhost if blocking is enabled\\n    if (state.blockLocalhost && isLocalhost(url.hostname)) {\\n      return {\\n        valid: false,\\n        error: 'Localhost URLs are not allowed'\\n      };\\n    }\\n\\n    // Check for private IPs if blocking is enabled\\n    if (state.blockPrivateIPs && isPrivateIP(url.hostname)) {\\n      return {\\n        valid: false,\\n        error: 'Private IP addresses are not allowed'\\n      };\\n    }\\n\\n    // Check allowed hosts\\n    if (state.allowedHosts.length > 0) {\\n      const isAllowedHost = state.allowedHosts.some(host => {\\n        if (host.startsWith('*.')) {\\n          // Wildcard subdomain matching\\n          const domain = host.slice(2);\\n          return url.hostname === domain || url.hostname.endsWith(`.${  domain}`);\\n        }\\n        return url.hostname === host;\\n      });\\n\\n      if (!isAllowedHost) {\\n        return {\\n          valid: false,\\n          error: `Host '${url.hostname}' not in allowed list`\\n        };\\n      }\\n    }\\n\\n    // Check port\\n    const port = url.port || (url.protocol === 'https:' ? 443 : 80);\\n    if (state.allowedPorts.length > 0 && !state.allowedPorts.includes(parseInt(port))) {\\n      return {\\n        valid: false,\\n        error: `Port ${port} not allowed. Allowed ports: ${state.allowedPorts.join(', ')}`\\n      };\\n    }\\n\\n    // Check for suspicious patterns (more refined)\\n    const suspiciousPatterns = [\\n      /\\\\.\\\\.[\\\\\\\\/]/,     // Path traversal attempts (more specific)\\n      /%00/,           // Null byte injection\\n      /<script/i,      // XSS attempts\\n      /javascript:/i,  // JavaScript protocol\\n      /data:/i,        // Data protocol\\n      /file:/i,        // File protocol\\n      /vbscript:/i,    // VBScript protocol\\n      /about:/i,       // About protocol\\n      /jar:/i,         // JAR protocol\\n      /%2e%2e/i,       // URL-encoded path traversal\\n      /\\\\x00-\\\\x1f/,     // Control characters\\n      /[\\\\u202e\\\\u202d]/  // Unicode direction override attacks\\n    ];\\n\\n    for (const pattern of suspiciousPatterns) {\\n      if (pattern.test(urlString)) {\\n        return {\\n          valid: false,\\n          error: 'URL contains suspicious patterns'\\n        };\\n      }\\n    }\\n\\n    return {\\n      valid: true,\\n      url: url.toString(),\\n      protocol: url.protocol,\\n      hostname: url.hostname,\\n      port,\\n      pathname: url.pathname\\n    };\\n  };\\n\\n  // Sanitize URL (remove dangerous parts)\\n  const sanitize = (urlString) => {\\n    const validation = validate(urlString);\\n    \\n    if (!validation.valid) {\\n      return null;\\n    }\\n\\n    try {\\n      const url = new URL(urlString);\\n      \\n      // Remove hash and search params for safety\\n      url.hash = '';\\n      url.search = '';\\n      \\n      // Normalize path\\n      url.pathname = url.pathname.replace(/\\\\/+/g, '/');\\n      \\n      return url.toString();\\n    } catch {\\n      return null;\\n    }\\n  };\\n\\n  // Update configuration\\n  const updateConfig = (newConfig) => {\\n    Object.assign(state, newConfig);\\n  };\\n\\n  // Add allowed host\\n  const addAllowedHost = (host) => {\\n    if (!state.allowedHosts.includes(host)) {\\n      state.allowedHosts.push(host);\\n    }\\n  };\\n\\n  // Remove allowed host\\n  const removeAllowedHost = (host) => {\\n    const index = state.allowedHosts.indexOf(host);\\n    if (index !== -1) {\\n      state.allowedHosts.splice(index, 1);\\n    }\\n  };\\n\\n  return {\\n    validate,\\n    sanitize,\\n    updateConfig,\\n    addAllowedHost,\\n    removeAllowedHost,\\n    getConfig: () => ({ ...state }),\\n    isPrivateIP,\\n    isLocalhost\\n  };\\n};\\n\\n// Create default validators for common use cases\\n\\n// Development validator (allows localhost and common dev patterns)\\nexport const createDevValidator = () => createUrlValidator({\\n  allowedHosts: ['localhost', '127.0.0.1', '::1', '*.local', '*.localhost'],\\n  allowedPorts: [3000, 3001, 3002, 8000, 8080, 8081, 8443, 5000, 5001, 9000, 11434, 80, 443],\\n  blockLocalhost: false,\\n  blockPrivateIPs: false,\\n  maxUrlLength: 4096 // More lenient for development\\n});\\n\\n// Production validator (strict)\\nexport const createProdValidator = () => createUrlValidator({\\n  allowedHosts: [], // Must be configured\\n  blockLocalhost: true,\\n  blockPrivateIPs: true,\\n  allowedProtocols: ['https:']\\n});\\n\\n// API validator (for backend services)\\nexport const createApiValidator = () => createUrlValidator({\\n  allowedHosts: ['localhost', '127.0.0.1', 'api.openai.com', 'api.anthropic.com'],\\n  allowedPorts: [3000, 3001, 8080, 11434, 443, 80],\\n  blockPrivateIPs: false,\\n  blockLocalhost: false\\n});\\n\\n// Export default configuration\\nexport const DEFAULT_VALIDATOR_CONFIG = {\\n  allowedProtocols: ['http:', 'https:'],\\n  allowedHosts: ['localhost', '127.0.0.1'],\\n  allowedPorts: [3000, 3001, 8080, 443, 80],\\n  blockPrivateIPs: false,\\n  blockLocalhost: false,\\n  maxUrlLength: 2048\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]},{\"filePath\":\"/Users/Michael.Hildebrandt@ife.no/Claude/synopticon-api/src/shared/utils/visualization/pose-3d.js\",\"messages\":[{\"ruleId\":\"max-lines-per-function\",\"severity\":1,\"message\":\"Arrow function has too many lines (222). Maximum allowed is 150.\",\"line\":170,\"column\":42,\"nodeType\":\"ArrowFunctionExpression\",\"messageId\":\"exceed\",\"endLine\":474,\"endColumn\":2},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":332,\"column\":14,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":332,\"endColumn\":15},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '+' and '*'. Use parentheses to clarify the intended order of operations.\",\"line\":332,\"column\":24,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":332,\"endColumn\":25},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '/'. Use parentheses to clarify the intended order of operations.\",\"line\":500,\"column\":37,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":500,\"endColumn\":38},{\"ruleId\":\"no-mixed-operators\",\"severity\":1,\"message\":\"Unexpected mix of '-' and '/'. Use parentheses to clarify the intended order of operations.\",\"line\":500,\"column\":52,\"nodeType\":\"BinaryExpression\",\"messageId\":\"unexpectedMixedOperator\",\"endLine\":500,\"endColumn\":53}],\"suppressedMessages\":[],\"errorCount\":0,\"fatalErrorCount\":0,\"warningCount\":5,\"fixableErrorCount\":0,\"fixableWarningCount\":0,\"source\":\"/**\\n * 3D Pose Visualization using Three.js\\n * Real-time 6DOF head pose rendering with face model\\n */\\n\\nimport { createLogger } from '../logger.js';\\n\\nconst logger = createLogger({ level: 2 });\\n\\n// 3D face model configuration\\nconst FACE_MODEL_CONFIG = {\\n  scale: 100,\\n  opacity: 0.8,\\n  wireframe: false,\\n  showAxes: true,\\n  axisLength: 150,\\n  colors: {\\n    face: 0x4a90e2,\\n    wireframe: 0x667eea,\\n    xAxis: 0xff0000,\\n    yAxis: 0x00ff00,\\n    zAxis: 0x0000ff\\n  }\\n};\\n\\n// Helper: Create Three.js scene components\\nconst initializeThreeJSComponents = (canvas) => {\\n  const scene = new THREE.Scene();\\n  scene.background = new THREE.Color(0x1a1a1a);\\n  \\n  const camera = new THREE.PerspectiveCamera(\\n    45, \\n    canvas.clientWidth / canvas.clientHeight, \\n    0.1, \\n    1000\\n  );\\n  camera.position.set(0, 0, 400);\\n  camera.lookAt(0, 0, 0);\\n\\n  const renderer = new THREE.WebGLRenderer({ \\n    canvas,\\n    antialias: true,\\n    alpha: true \\n  });\\n  renderer.setSize(canvas.clientWidth, canvas.clientHeight);\\n  renderer.setPixelRatio(Math.min(window.devicePixelRatio, 2));\\n  renderer.shadowMap.enabled = true;\\n  renderer.shadowMap.type = THREE.PCFSoftShadowMap;\\n\\n  return { scene, camera, renderer };\\n};\\n\\n// Helper: Add lighting to scene\\nconst addSceneLighting = (scene) => {\\n  // Ambient light\\n  const ambientLight = new THREE.AmbientLight(0x404040, 0.3);\\n  scene.add(ambientLight);\\n\\n  // Directional light\\n  const directionalLight = new THREE.DirectionalLight(0xffffff, 0.8);\\n  directionalLight.position.set(50, 50, 100);\\n  directionalLight.castShadow = true;\\n  scene.add(directionalLight);\\n\\n  // Point light\\n  const pointLight = new THREE.PointLight(0x4080ff, 0.4, 200);\\n  pointLight.position.set(-50, 30, 50);\\n  scene.add(pointLight);\\n};\\n\\n// Helper: Create main head geometry\\nconst createHeadGeometry = () => {\\n  const headGeometry = new THREE.SphereGeometry(\\n    FACE_MODEL_CONFIG.scale * 0.8, 32, 24, \\n    0, Math.PI * 2, 0, Math.PI * 0.7\\n  );\\n  const headMaterial = new THREE.MeshPhongMaterial({\\n    color: FACE_MODEL_CONFIG.colors.face,\\n    transparent: true,\\n    opacity: FACE_MODEL_CONFIG.opacity,\\n    wireframe: FACE_MODEL_CONFIG.wireframe,\\n    side: THREE.DoubleSide\\n  });\\n  const headMesh = new THREE.Mesh(headGeometry, headMaterial);\\n  headMesh.castShadow = true;\\n  headMesh.receiveShadow = true;\\n  return { headMesh, headGeometry };\\n};\\n\\n// Helper: Create facial features\\nconst createFacialFeatures = () => {\\n  const features = [];\\n\\n  // Nose\\n  const noseGeometry = new THREE.ConeGeometry(8, 25, 8);\\n  const noseMaterial = new THREE.MeshPhongMaterial({ \\n    color: FACE_MODEL_CONFIG.colors.face,\\n    transparent: true,\\n    opacity: FACE_MODEL_CONFIG.opacity * 0.9\\n  });\\n  const noseMesh = new THREE.Mesh(noseGeometry, noseMaterial);\\n  noseMesh.position.set(0, -10, 60);\\n  noseMesh.rotation.x = Math.PI;\\n  noseMesh.castShadow = true;\\n  features.push(noseMesh);\\n\\n  // Eyes\\n  const eyeGeometry = new THREE.SphereGeometry(12, 16, 12);\\n  const eyeMaterial = new THREE.MeshPhongMaterial({ \\n    color: 0x333333,\\n    transparent: true,\\n    opacity: 0.8\\n  });\\n\\n  const leftEye = new THREE.Mesh(eyeGeometry, eyeMaterial);\\n  leftEye.position.set(-25, 15, 50);\\n  leftEye.castShadow = true;\\n  features.push(leftEye);\\n\\n  const rightEye = new THREE.Mesh(eyeGeometry, eyeMaterial);\\n  rightEye.position.set(25, 15, 50);\\n  rightEye.castShadow = true;\\n  features.push(rightEye);\\n\\n  return features;\\n};\\n\\n// Helper: Create wireframe overlay\\nconst createWireframeOverlay = (headGeometry) => {\\n  if (!FACE_MODEL_CONFIG.wireframe) return null;\\n\\n  const wireframeGeometry = headGeometry.clone();\\n  const wireframeMaterial = new THREE.MeshBasicMaterial({\\n    color: FACE_MODEL_CONFIG.colors.wireframe,\\n    wireframe: true,\\n    transparent: true,\\n    opacity: 0.3\\n  });\\n  return new THREE.Mesh(wireframeGeometry, wireframeMaterial);\\n};\\n\\n// Helper: Create detailed 3D face geometry\\nconst createFaceGeometry = (scene) => {\\n  const faceModel = new THREE.Group();\\n\\n  // Main head\\n  const { headMesh, headGeometry } = createHeadGeometry();\\n  faceModel.add(headMesh);\\n\\n  // Facial features\\n  const features = createFacialFeatures();\\n  features.forEach(feature => faceModel.add(feature));\\n\\n  // Wireframe overlay\\n  const wireframeMesh = createWireframeOverlay(headGeometry);\\n  if (wireframeMesh) faceModel.add(wireframeMesh);\\n\\n  // Axes helper\\n  let axesHelper = null;\\n  if (FACE_MODEL_CONFIG.showAxes) {\\n    axesHelper = new THREE.AxesHelper(FACE_MODEL_CONFIG.axisLength);\\n    faceModel.add(axesHelper);\\n  }\\n\\n  scene.add(faceModel);\\n  return { faceModel, axesHelper };\\n};\\n\\n// Create 3D pose visualization\\nexport const createPose3DVisualization = (canvas) => {\\n  const state = {\\n    scene: null,\\n    camera: null,\\n    renderer: null,\\n    faceModel: null,\\n    axesHelper: null,\\n    animationId: null,\\n    currentPose: null,\\n    smoothedPose: null,\\n    smoothingFactor: 0.7,\\n    isInitialized: false\\n  };\\n\\n  // Initialize Three.js scene\\n  const initialize = () => {\\n    try {\\n      // Use helper functions to set up components\\n      const { scene, camera, renderer } = initializeThreeJSComponents(canvas);\\n      state.scene = scene;\\n      state.camera = camera;\\n      state.renderer = renderer;\\n\\n      // Add lighting\\n      addSceneLighting(state.scene);\\n\\n      // Create face model\\n      const { faceModel, axesHelper } = createFaceGeometry(state.scene);\\n      state.faceModel = faceModel;\\n      state.axesHelper = axesHelper;\\n\\n\\n      // Start render loop\\n      state.animationId = requestAnimationFrame(render);\\n      state.isInitialized = true;\\n\\n      logger.info('3D pose visualization initialized');\\n\\n    } catch (error) {\\n      logger.error('Failed to initialize 3D visualization:', error);\\n      throw error;\\n    }\\n  };\\n\\n\\n\\n  // Create coordinate axes helper\\n  const _createAxesHelper = () => {\\n    if (!FACE_MODEL_CONFIG.showAxes) return;\\n\\n    // Custom axes with labels\\n    const axesGroup = new THREE.Group();\\n\\n    // X-axis (Red)\\n    const xGeometry = new THREE.BufferGeometry().setFromPoints([\\n      new THREE.Vector3(0, 0, 0),\\n      new THREE.Vector3(FACE_MODEL_CONFIG.axisLength, 0, 0)\\n    ]);\\n    const xMaterial = new THREE.LineBasicMaterial({ color: FACE_MODEL_CONFIG.colors.xAxis });\\n    const xAxis = new THREE.Line(xGeometry, xMaterial);\\n    axesGroup.add(xAxis);\\n\\n    // Y-axis (Green)  \\n    const yGeometry = new THREE.BufferGeometry().setFromPoints([\\n      new THREE.Vector3(0, 0, 0),\\n      new THREE.Vector3(0, FACE_MODEL_CONFIG.axisLength, 0)\\n    ]);\\n    const yMaterial = new THREE.LineBasicMaterial({ color: FACE_MODEL_CONFIG.colors.yAxis });\\n    const yAxis = new THREE.Line(yGeometry, yMaterial);\\n    axesGroup.add(yAxis);\\n\\n    // Z-axis (Blue)\\n    const zGeometry = new THREE.BufferGeometry().setFromPoints([\\n      new THREE.Vector3(0, 0, 0),\\n      new THREE.Vector3(0, 0, FACE_MODEL_CONFIG.axisLength)\\n    ]);\\n    const zMaterial = new THREE.LineBasicMaterial({ color: FACE_MODEL_CONFIG.colors.zAxis });\\n    const zAxis = new THREE.Line(zGeometry, zMaterial);\\n    axesGroup.add(zAxis);\\n\\n    // Add arrow heads\\n    addArrowHead(axesGroup, FACE_MODEL_CONFIG.axisLength, 0, 0, FACE_MODEL_CONFIG.colors.xAxis);\\n    addArrowHead(axesGroup, 0, FACE_MODEL_CONFIG.axisLength, 0, FACE_MODEL_CONFIG.colors.yAxis);\\n    addArrowHead(axesGroup, 0, 0, FACE_MODEL_CONFIG.axisLength, FACE_MODEL_CONFIG.colors.zAxis);\\n\\n    state.axesHelper = axesGroup;\\n    state.scene.add(axesGroup);\\n  };\\n\\n  // Add arrow head to axis\\n  const addArrowHead = (group, x, y, z, color) => {\\n    const arrowGeometry = new THREE.ConeGeometry(5, 15, 8);\\n    const arrowMaterial = new THREE.MeshBasicMaterial({ color });\\n    const arrowMesh = new THREE.Mesh(arrowGeometry, arrowMaterial);\\n    \\n    arrowMesh.position.set(x, y, z);\\n    \\n    // Orient arrow head\\n    if (x > 0) arrowMesh.rotation.z = -Math.PI / 2; // X-axis\\n    else if (y > 0) arrowMesh.rotation.z = 0;       // Y-axis  \\n    else if (z > 0) arrowMesh.rotation.x = Math.PI / 2; // Z-axis\\n    \\n    group.add(arrowMesh);\\n  };\\n\\n  // Helper: Apply pose smoothing\\n  const applySmoothingToPose = (pose) => {\\n    if (state.smoothedPose) {\\n      const alpha = state.smoothingFactor;\\n      return {\\n        rotation: {\\n          yaw: lerp(state.smoothedPose.rotation.yaw, pose.rotation.yaw || 0, alpha),\\n          pitch: lerp(state.smoothedPose.rotation.pitch, pose.rotation.pitch || 0, alpha),\\n          roll: lerp(state.smoothedPose.rotation.roll, pose.rotation.roll || 0, alpha)\\n        },\\n        translation: {\\n          x: lerp(state.smoothedPose.translation?.x || 0, pose.translation?.x || 0, alpha),\\n          y: lerp(state.smoothedPose.translation?.y || 0, pose.translation?.y || 0, alpha),\\n          z: lerp(state.smoothedPose.translation?.z || 0, pose.translation?.z || 0, alpha)\\n        }\\n      };\\n    }\\n    return {\\n      rotation: { ...pose.rotation },\\n      translation: pose.translation ? { ...pose.translation } : { x: 0, y: 0, z: 0 }\\n    };\\n  };\\n\\n  // Helper: Apply pose to face model\\n  const applyPoseToFaceModel = (pose) => {\\n    // Apply rotation (convert coordinate systems)\\n    if (pose.rotation) {\\n      state.faceModel.rotation.x = -(pose.rotation.pitch || 0);\\n      state.faceModel.rotation.y = pose.rotation.yaw || 0;\\n      state.faceModel.rotation.z = -(pose.rotation.roll || 0);\\n    }\\n\\n    // Apply translation\\n    if (pose.translation) {\\n      state.faceModel.position.x = (pose.translation.x || 0) * 0.5;\\n      state.faceModel.position.y = -(pose.translation.y || 0) * 0.5;\\n      state.faceModel.position.z = (pose.translation.z || 0) * 0.5;\\n    }\\n\\n    // Update axes helper to match\\n    if (state.axesHelper) {\\n      state.axesHelper.rotation.copy(state.faceModel.rotation);\\n      state.axesHelper.position.copy(state.faceModel.position);\\n    }\\n  };\\n\\n  // Update pose visualization\\n  const updatePose = (pose) => {\\n    if (!state.isInitialized || !state.faceModel) return;\\n\\n    state.currentPose = pose;\\n    state.smoothedPose = applySmoothingToPose(pose);\\n    applyPoseToFaceModel(state.smoothedPose);\\n  };\\n\\n  // Linear interpolation helper\\n  const lerp = (a, b, alpha) => {\\n    return a + (b - a) * alpha;\\n  };\\n\\n  // Render loop\\n  const render = () => {\\n    if (!state.isInitialized) return;\\n\\n    try {\\n      // Auto-rotate scene slightly for better depth perception\\n      if (!state.currentPose) {\\n        state.camera.position.x = Math.sin(Date.now() * 0.001) * 50;\\n        state.camera.lookAt(0, 0, 0);\\n      }\\n\\n      state.renderer.render(state.scene, state.camera);\\n      state.animationId = requestAnimationFrame(render);\\n\\n    } catch (error) {\\n      logger.error('Render error:', error);\\n    }\\n  };\\n\\n  // Handle canvas resize\\n  const resize = () => {\\n    if (!state.isInitialized) return;\\n\\n    const width = canvas.clientWidth;\\n    const height = canvas.clientHeight;\\n\\n    state.camera.aspect = width / height;\\n    state.camera.updateProjectionMatrix();\\n    state.renderer.setSize(width, height);\\n  };\\n\\n  // Cleanup resources\\n  const cleanup = () => {\\n    if (state.animationId) {\\n      cancelAnimationFrame(state.animationId);\\n    }\\n\\n    if (state.renderer) {\\n      state.renderer.dispose();\\n    }\\n\\n    if (state.scene) {\\n      // Dispose of all geometries and materials\\n      state.scene.traverse((object) => {\\n        if (object.geometry) {\\n          object.geometry.dispose();\\n        }\\n        if (object.material) {\\n          if (Array.isArray(object.material)) {\\n            object.material.forEach(material => material.dispose());\\n          } else {\\n            object.material.dispose();\\n          }\\n        }\\n      });\\n    }\\n\\n    state.isInitialized = false;\\n    logger.info('3D pose visualization cleaned up');\\n  };\\n\\n  // Set visualization options\\n  const setOptions = (options = {}) => {\\n    if (options.smoothingFactor !== undefined) {\\n      state.smoothingFactor = Math.max(0, Math.min(1, options.smoothingFactor));\\n    }\\n\\n    if (options.showAxes !== undefined && state.axesHelper) {\\n      state.axesHelper.visible = options.showAxes;\\n    }\\n\\n    if (options.wireframe !== undefined && state.faceModel) {\\n      state.faceModel.traverse((child) => {\\n        if (child.material && child.material.wireframe !== undefined) {\\n          child.material.wireframe = options.wireframe;\\n        }\\n      });\\n    }\\n\\n    if (options.opacity !== undefined && state.faceModel) {\\n      state.faceModel.traverse((child) => {\\n        if (child.material && child.material.transparent) {\\n          child.material.opacity = options.opacity;\\n        }\\n      });\\n    }\\n  };\\n\\n  // Get current pose\\n  const getCurrentPose = () => {\\n    return state.currentPose;\\n  };\\n\\n  // Get smoothed pose\\n  const getSmoothedPose = () => {\\n    return state.smoothedPose;\\n  };\\n\\n  // Initialize and return public interface\\n  initialize();\\n\\n  // Setup resize observer with cleanup\\n  let resizeObserver = null;\\n  let resizeController = null;\\n  \\n  if (window.ResizeObserver) {\\n    resizeObserver = new ResizeObserver(resize);\\n    resizeObserver.observe(canvas);\\n  } else {\\n    resizeController = new AbortController();\\n    window.addEventListener('resize', resize, { signal: resizeController.signal });\\n  }\\n\\n  return {\\n    updatePose,\\n    setOptions,\\n    getCurrentPose,\\n    getSmoothedPose,\\n    resize,\\n    cleanup: () => {\\n      // Clean up event listeners\\n      if (resizeObserver) {\\n        resizeObserver.disconnect();\\n      }\\n      if (resizeController) {\\n        resizeController.abort();\\n      }\\n      cleanup();\\n    },\\n    \\n    // Advanced methods\\n    getScene: () => state.scene,\\n    getCamera: () => state.camera,\\n    getRenderer: () => state.renderer,\\n    getFaceModel: () => state.faceModel,\\n    \\n    // State queries\\n    isInitialized: () => state.isInitialized\\n  };\\n};\\n\\n// Create pose comparison visualization\\nexport const createPoseComparisonVisualization = (canvas, poses = []) => {\\n  const state = {\\n    scene: null,\\n    camera: null,\\n    renderer: null,\\n    faceModels: [],\\n    isInitialized: false\\n  };\\n\\n  const initialize = () => {\\n    // Similar to main visualization but with multiple face models\\n    state.scene = new THREE.Scene();\\n    state.scene.background = new THREE.Color(0x1a1a1a);\\n\\n    state.camera = new THREE.PerspectiveCamera(45, canvas.clientWidth / canvas.clientHeight, 0.1, 1000);\\n    state.camera.position.set(0, 0, 600);\\n\\n    state.renderer = new THREE.WebGLRenderer({ canvas, antialias: true });\\n    state.renderer.setSize(canvas.clientWidth, canvas.clientHeight);\\n\\n    // Create multiple face models for comparison\\n    poses.forEach((_, index) => {\\n      const faceModel = createComparisonFaceModel(index);\\n      faceModel.position.x = (index - poses.length / 2) * 200;\\n      state.faceModels.push(faceModel);\\n      state.scene.add(faceModel);\\n    });\\n\\n    state.isInitialized = true;\\n    render();\\n  };\\n\\n  const createComparisonFaceModel = (index) => {\\n    // Simplified face model for comparison\\n    const group = new THREE.Group();\\n    \\n    const geometry = new THREE.SphereGeometry(60, 16, 12);\\n    const material = new THREE.MeshBasicMaterial({\\n      color: [0xff0000, 0x00ff00, 0x0000ff, 0xffff00][index % 4],\\n      wireframe: true,\\n      opacity: 0.7,\\n      transparent: true\\n    });\\n    \\n    const mesh = new THREE.Mesh(geometry, material);\\n    group.add(mesh);\\n    \\n    return group;\\n  };\\n\\n  const updatePoses = (newPoses) => {\\n    newPoses.forEach((pose, index) => {\\n      if (state.faceModels[index] && pose) {\\n        state.faceModels[index].rotation.x = -(pose.rotation?.pitch || 0);\\n        state.faceModels[index].rotation.y = pose.rotation?.yaw || 0;\\n        state.faceModels[index].rotation.z = -(pose.rotation?.roll || 0);\\n      }\\n    });\\n  };\\n\\n  const render = () => {\\n    if (state.isInitialized) {\\n      state.renderer.render(state.scene, state.camera);\\n      requestAnimationFrame(render);\\n    }\\n  };\\n\\n  initialize();\\n\\n  return {\\n    updatePoses,\\n    cleanup: () => { state.isInitialized = false; }\\n  };\\n};\\n\\n// Export utilities\\nexport const pose3DUtils = {\\n  convertPoseToThreeJS: (pose) => ({\\n    rotation: {\\n      x: -(pose.rotation?.pitch || 0),\\n      y: pose.rotation?.yaw || 0,\\n      z: -(pose.rotation?.roll || 0)\\n    },\\n    position: {\\n      x: (pose.translation?.x || 0) * 0.5,\\n      y: -(pose.translation?.y || 0) * 0.5,\\n      z: (pose.translation?.z || 0) * 0.5\\n    }\\n  }),\\n\\n  createCustomFaceModel: (geometry, material) => {\\n    return new THREE.Mesh(geometry, material);\\n  },\\n\\n  addLandmarkVisualization: (scene, landmarks, color = 0x00ff00) => {\\n    const group = new THREE.Group();\\n    \\n    landmarks.forEach(point => {\\n      const geometry = new THREE.SphereGeometry(2, 8, 6);\\n      const material = new THREE.MeshBasicMaterial({ color });\\n      const sphere = new THREE.Mesh(geometry, material);\\n      \\n      sphere.position.set(point.x, point.y, point.z);\\n      group.add(sphere);\\n    });\\n    \\n    scene.add(group);\\n    return group;\\n  }\\n};\",\"usedDeprecatedRules\":[{\"ruleId\":\"max-len\",\"replacedBy\":[\"@stylistic/max-len\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"max-len\",\"url\":\"https://eslint.style/rules/max-len\"}}]}},{\"ruleId\":\"no-mixed-operators\",\"replacedBy\":[\"@stylistic/no-mixed-operators\"],\"info\":{\"message\":\"Formatting rules are being moved out of ESLint core.\",\"url\":\"https://eslint.org/blog/2023/10/deprecating-formatting-rules/\",\"deprecatedSince\":\"8.53.0\",\"availableUntil\":\"10.0.0\",\"replacedBy\":[{\"message\":\"ESLint Stylistic now maintains deprecated stylistic core rules.\",\"url\":\"https://eslint.style/guide/migration\",\"plugin\":{\"name\":\"@stylistic/eslint-plugin\",\"url\":\"https://eslint.style\"},\"rule\":{\"name\":\"no-mixed-operators\",\"url\":\"https://eslint.style/rules/no-mixed-operators\"}}]}}]}]\n",
      "errors": "",
      "summary": "267 errors, 1083 warnings",
      "weight": 0.4,
      "critical": true
    },
    {
      "name": "TypeScript Check",
      "passed": false,
      "exitCode": 2,
      "duration": 429,
      "output": "src/core/state/streams.js(356,34): error TS1109: Expression expected.\nsrc/core/state/streams.js(356,43): error TS1005: ',' expected.\nsrc/core/state/streams.js(361,34): error TS1109: Expression expected.\nsrc/core/state/streams.js(361,43): error TS1005: ',' expected.\nsrc/core/state/streams.js(366,35): error TS1109: Expression expected.\nsrc/core/state/streams.js(366,44): error TS1005: ',' expected.\nsrc/core/state/streams.js(373,40): error TS1109: Expression expected.\nsrc/core/state/streams.js(373,49): error TS1005: ',' expected.\nsrc/core/state/streams.js(374,9): error TS1005: ':' expected.\nsrc/core/state/streams.js(387,4): error TS1005: ',' expected.\nsrc/core/state/streams.js(389,9): error TS1005: ':' expected.\nsrc/core/state/streams.js(389,51): error TS1005: ',' expected.\nsrc/core/state/streams.js(392,22): error TS1005: ',' expected.\nsrc/core/state/streams.js(392,47): error TS1005: ',' expected.\nsrc/core/state/streams.js(392,49): error TS1005: ';' expected.\nsrc/core/state/streams.js(442,1): error TS1128: Declaration or statement expected.\nsrc/core/state/streams.js(442,2): error TS1128: Declaration or statement expected.\nsrc/features/face-detection/age-estimation-pipeline.js(7,3): error TS8006: 'import...type' declarations can only be used in TypeScript files.\nsrc/features/face-detection/age-estimation-pipeline.js(8,3): error TS8006: 'import...type' declarations can only be used in TypeScript files.\nsrc/features/face-detection/age-estimation-pipeline.js(9,3): error TS8006: 'import...type' declarations can only be used in TypeScript files.\nsrc/features/face-detection/age-estimation-pipeline.js(10,3): error TS8006: 'import...type' declarations can only be used in TypeScript files.\nsrc/features/face-detection/age-estimation-pipeline.js(22,1): error TS8006: 'export type' declarations can only be used in TypeScript files.\nsrc/features/media-streaming/media-streaming-pipeline.js(69,5): error TS1128: Declaration or statement expected.\nsrc/features/media-streaming/media-streaming-pipeline.js(69,6): error TS1128: Declaration or statement expected.\nsrc/features/media-streaming/media-streaming-pipeline.js(70,3): error TS1128: Declaration or statement expected.\nsrc/features/media-streaming/media-streaming-pipeline.js(578,1): error TS1128: Declaration or statement expected.\nsrc/features/speech-analysis/context-manager.js(10,3): error TS8006: 'import...type' declarations can only be used in TypeScript files.\nsrc/features/speech-analysis/context-manager.js(11,3): error TS8006: 'import...type' declarations can only be used in TypeScript files.\nsrc/features/speech-analysis/context-manager.js(12,3): error TS8006: 'import...type' declarations can only be used in TypeScript files.\nsrc/features/speech-analysis/context-manager.js(13,3): error TS8006: 'import...type' declarations can only be used in TypeScript files.\nsrc/features/speech-analysis/context-manager.js(14,3): error TS8006: 'import...type' declarations can only be used in TypeScript files.\nsrc/features/speech-analysis/context-manager.js(15,3): error TS8006: 'import...type' declarations can only be used in TypeScript files.\nsrc/features/speech-analysis/context-manager.js(29,1): error TS8006: 'export type' declarations can only be used in TypeScript files.\nsrc/features/speech-analysis/streaming.js(361,45): error TS1135: Argument expression expected.\nsrc/features/speech-analysis/streaming.js(361,54): error TS1005: ',' expected.\nsrc/features/speech-analysis/streaming.js(377,6): error TS1128: Declaration or statement expected.\nsrc/features/speech-analysis/streaming.js(379,46): error TS1109: Expression expected.\nsrc/features/speech-analysis/streaming.js(379,55): error TS1005: ',' expected.\nsrc/features/speech-analysis/streaming.js(381,14): error TS1005: ',' expected.\nsrc/features/speech-analysis/streaming.js(381,56): error TS1005: ',' expected.\nsrc/features/speech-analysis/streaming.js(404,3): error TS1128: Declaration or statement expected.\nsrc/features/speech-analysis/streaming.js(586,1): error TS1128: Declaration or statement expected.\n",
      "errors": "",
      "summary": "No type errors",
      "weight": 0.3,
      "critical": true
    },
    {
      "name": "Knip Dead Code",
      "passed": false,
      "exitCode": 1,
      "duration": 896,
      "output": "{\"files\":[\".eslintrc-custom.js\",\".eslintrc-performance.js\",\"test-phase2-conversion.ts\",\"examples/shared/component-integration.js\",\"examples/shared/demo-integration-example.js\",\"examples/shared/error-boundaries.js\",\"examples/shared/lifecycle-bulk-operations.js\",\"examples/shared/lifecycle-helpers.js\",\"examples/shared/lifecycle-manager.js\",\"examples/shared/lifecycle-operations.js\",\"examples/shared/state-helpers.js\",\"examples/shared/state-manager.js\",\"examples/shared/state-operations.js\",\"examples/tutorials/simple-neon-app.js\",\"src/core/index.ts\",\"src/core/configuration/config-validator.ts\",\"src/core/configuration/validation-helpers.ts\",\"src/core/configuration/validation-types.ts\",\"src/core/distribution/index-bun.ts\",\"src/core/engine/face-analysis-engine.js\",\"src/core/engine/image-operations.ts\",\"src/core/engine/image-processor-types.ts\",\"src/core/engine/webgl-engine.js\",\"src/core/engine/webgl-lazy-loader.js\",\"src/core/integration/module-interface.js\",\"src/core/integration/module-interface.ts\",\"src/core/integration/transport.js\",\"src/core/orchestration/plugin-loader.js\",\"src/core/orchestration/registry-operations.js\",\"src/core/orchestration/registry.js\",\"src/core/orchestration/sync-metrics.js\",\"src/core/performance/adaptive-batching.js\",\"src/core/performance/memory-optimization.js\",\"src/core/performance/performance-metrics.js\",\"src/core/performance/resource-pool-config.ts\",\"src/core/performance/resource-pool.ts\",\"src/core/pipeline/analysis-pipeline.js\",\"src/core/pipeline/pipeline-composer.js\",\"src/core/pipeline/pipeline-events.js\",\"src/core/pipeline/pipeline-results.ts\",\"src/features/multi-device/device-manager.js\",\"src/features/multi-device/event-system.js\",\"src/features/multi-device/multi-device-coordinator.js\",\"src/features/multi-device/network-monitor.js\",\"src/features/multi-device/stream-manager.js\",\"src/features/speech-analysis/context-modular.ts\",\"src/services/api/monitoring.ts\",\"src/services/api/openapi-modular.ts\",\"src/services/api/openapi-spec-modular.ts\",\"src/services/api/openapi-spec.ts\",\"src/shared/utils/camera.js\",\"src/shared/utils/canvas-utils.js\",\"src/shared/utils/error-handler.d.ts\",\"src/shared/utils/index.js\",\"src/shared/utils/memory-pool-stats.js\",\"src/shared/utils/performance-tester.js\",\"src/shared/utils/speech-analysis-config.js\",\"src/shared/utils/speech-analysis-events.js\",\"src/shared/utils/speech-analysis-metrics.js\",\"src/shared/utils/speech-analysis-pipeline-client-server.js\",\"src/shared/utils/speech-analysis-pipeline-hybrid.js\",\"src/shared/utils/speech-analysis-session.js\",\"src/core/configuration/types/analysis-types.ts\",\"src/core/configuration/types/capability-types.ts\",\"src/core/configuration/types/core-types.ts\",\"src/core/configuration/types/factory-functions.ts\",\"src/core/configuration/types/geometry-types.ts\",\"src/core/configuration/types/index.ts\",\"src/core/configuration/types/performance-types.ts\",\"src/core/configuration/types/pipeline-types.ts\",\"src/core/configuration/types/sensor-types.ts\",\"src/core/configuration/types/type-guards.ts\",\"src/core/distribution/config/config-manager.ts\",\"src/core/distribution/configs/distribution-presets.ts\",\"src/core/distribution/mqtt/index.ts\",\"src/core/engine/image-processing/image-processor.js\",\"src/core/engine/processors/color-processor.js\",\"src/core/engine/processors/crop-processor.js\",\"src/core/engine/processors/filter-processor.js\",\"src/core/engine/processors/resize-processor.js\",\"src/core/orchestration/aligners/buffer-aligner.js\",\"src/core/orchestration/aligners/event-aligner.js\",\"src/core/orchestration/aligners/hardware-aligner.js\",\"src/core/orchestration/aligners/software-aligner.js\",\"src/core/orchestration/synchronization/sync-engine.js\",\"src/core/pipeline/composers/adaptive-composer.ts\",\"src/core/pipeline/composers/base-composer.ts\",\"src/core/pipeline/composers/cascading-composer.ts\",\"src/core/pipeline/composers/conditional-composer.ts\",\"src/core/pipeline/composers/index.ts\",\"src/core/pipeline/composers/parallel-composer.ts\",\"src/core/pipeline/composers/sequential-composer.ts\",\"src/features/eye-tracking/common/calibration.js\",\"src/features/speech-analysis/audio/agc-config.js\",\"src/features/speech-analysis/audio/agc-processor.js\",\"src/features/speech-analysis/audio/analysis-processor.js\",\"src/features/speech-analysis/audio/audio-preprocessing-pipeline.js\",\"src/features/speech-analysis/audio/audio-quality-metrics.js\",\"src/features/speech-analysis/audio/callback-notifier.js\",\"src/features/speech-analysis/audio/emotion-classifier.js\",\"src/features/speech-analysis/audio/emotion-config.js\",\"src/features/speech-analysis/audio/emotion-detection.js\",\"src/features/speech-analysis/audio/emotion-processor.js\",\"src/features/speech-analysis/audio/emotion-stats.js\",\"src/features/speech-analysis/audio/feature-extractor.js\",\"src/features/speech-analysis/audio/noise-reduction-config.js\",\"src/features/speech-analysis/audio/noise-reduction-fft.js\",\"src/features/speech-analysis/audio/noise-reduction-spectral.js\",\"src/features/speech-analysis/audio/noise-reduction-window.js\",\"src/features/speech-analysis/audio/preprocessing-config.js\",\"src/features/speech-analysis/audio/preprocessing-modules.js\",\"src/features/speech-analysis/audio/preprocessing-quality.js\",\"src/features/speech-analysis/audio/processing-chain.js\",\"src/features/speech-analysis/audio/prosodic-analyzer.js\",\"src/features/speech-analysis/audio/quality-analyzer-config.js\",\"src/features/speech-analysis/audio/quality-analyzer-config.ts\",\"src/features/speech-analysis/audio/quality-analyzer-core.js\",\"src/features/speech-analysis/audio/quality-analyzer-stats.js\",\"src/features/speech-analysis/audio/realtime-audio-analyzer.js\",\"src/features/speech-analysis/audio/speaker-diarization.js\",\"src/features/speech-analysis/audio/speaking-pace-analysis.js\",\"src/features/speech-analysis/audio/vad-config.js\",\"src/features/speech-analysis/audio/vad-consensus.js\",\"src/features/speech-analysis/audio/vad-smoothing.js\",\"src/features/speech-analysis/audio/vad-stats.js\",\"src/features/speech-analysis/audio/voice-activity-detection.js\",\"src/features/speech-analysis/context/context-aggregator.ts\",\"src/features/speech-analysis/context/context-manager-factory.ts\",\"src/features/speech-analysis/context/conversation-context.ts\",\"src/features/speech-analysis/context/engine-integrations.ts\",\"src/features/speech-analysis/context/speaker-context.ts\",\"src/features/speech-analysis/context/temporal-context.ts\",\"src/services/api/middleware/index.ts\",\"src/services/api/openapi/base-spec.ts\",\"src/services/api/openapi/index.ts\",\"src/services/api/paths/analysis-paths.ts\",\"src/services/api/paths/media-paths.ts\",\"src/services/api/paths/system-paths.ts\",\"src/services/api/routes/media.ts\",\"src/services/api/routes/system.ts\",\"src/services/api/schemas/analysis-schemas.ts\",\"src/services/api/schemas/common-schemas.ts\",\"src/services/api/schemas/media-schemas.ts\",\"src/services/api/schemas/system-schemas.ts\",\"src/services/api/types/media-types.ts\",\"src/services/api/types/system-types.ts\",\"src/shared/utils/modules/index.js\",\"src/shared/utils/shaders/base-shaders.js\",\"src/shared/utils/visualization/pose-3d.js\",\"src/core/distribution/config/validators/field-validators.ts\",\"src/core/distribution/config/validators/http-validator.ts\",\"src/core/distribution/config/validators/mqtt-validator.ts\",\"src/core/distribution/config/validators/sse-validator.ts\",\"src/core/distribution/config/validators/udp-validator.ts\",\"src/core/distribution/config/validators/validator-types.ts\",\"src/core/distribution/config/validators/websocket-validator.ts\",\"src/core/engine/image-processing/cache/processing-cache.js\",\"src/core/engine/image-processing/operations/color-operations.js\",\"src/core/engine/image-processing/operations/crop-operations.js\",\"src/core/engine/image-processing/operations/filter-operations.js\",\"src/core/engine/image-processing/operations/resize-operations.js\",\"src/core/orchestration/synchronization/aligners/buffer-aligner.js\",\"src/core/orchestration/synchronization/aligners/event-aligner.js\",\"src/core/orchestration/synchronization/aligners/hardware-aligner.js\",\"src/core/orchestration/synchronization/aligners/software-aligner.js\",\"src/core/orchestration/synchronization/metrics/sync-metrics.js\",\"src/core/orchestration/synchronization/strategies/sync-strategies.js\",\"src/features/eye-tracking/devices/neon/index.js\",\"src/features/eye-tracking/devices/webcam/index.js\",\"src/features/speech-analysis/audio/diarization/diarization-manager.js\",\"src/features/speech-analysis/audio/diarization/speaker-change-detection.js\",\"src/features/speech-analysis/audio/diarization/voice-fingerprinting.js\",\"src/features/speech-analysis/audio/pace/fluency-analyzer.js\",\"src/features/speech-analysis/audio/pace/pace-analysis-manager.js\",\"src/features/speech-analysis/audio/pace/speaking-rate-analyzer.js\",\"src/features/speech-analysis/audio/speaker-diarization/base-speaker-analyzer.ts\",\"src/services/api/openapi/components/common-responses.ts\",\"src/services/api/openapi/components/security-schemes.ts\",\"src/services/api/openapi/paths/analysis.ts\",\"src/services/api/openapi/paths/distribution-paths.ts\",\"src/services/api/openapi/paths/distribution.ts\",\"src/services/api/openapi/paths/face-detection-paths.ts\",\"src/services/api/openapi/paths/index.ts\",\"src/services/api/openapi/paths/system-paths.ts\",\"src/services/api/openapi/paths/system.ts\",\"src/services/api/openapi/schemas/common.ts\",\"src/services/api/openapi/schemas/distribution-schemas.ts\",\"src/services/api/openapi/schemas/distribution.ts\",\"src/services/api/openapi/schemas/face-analysis.ts\",\"src/services/api/openapi/schemas/face-detection-schemas.ts\",\"src/services/api/openapi/schemas/index.ts\",\"src/services/api/openapi/schemas/media-streaming.ts\",\"src/services/api/openapi/schemas/system-schemas.ts\",\"src/shared/utils/modules/analysis/index.js\",\"src/shared/utils/modules/detection/index.js\",\"src/shared/utils/modules/analysis/audio/index.js\",\"src/shared/utils/modules/analysis/video/index.js\",\"src/shared/utils/modules/detection/mediapipe/mediapipe-face-detector.js\"],\"issues\":[{\"file\":\"package.json\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[{\"name\":\"concurrently\"}],\"unresolved\":[],\"exports\":[],\"types\":[],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/services/mcp/config/mcp-config.ts\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[{\"name\":\"DEFAULT_MCP_CONFIG\",\"line\":37,\"col\":14,\"pos\":959},{\"name\":\"MCP_PORTS\",\"line\":48,\"col\":14,\"pos\":1164},{\"name\":\"SUPPORTED_CLIENTS\",\"line\":55,\"col\":14,\"pos\":1363}],\"types\":[{\"name\":\"MCPClientConfig\",\"line\":26,\"col\":18,\"pos\":610}],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/services/mcp/tools/system-tools.ts\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[{\"name\":\"systemTools\",\"line\":132,\"col\":14,\"pos\":3750}],\"types\":[],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/services/mcp/tools/face-tools.ts\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[{\"name\":\"faceTools\",\"line\":171,\"col\":14,\"pos\":4663}],\"types\":[],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/services/mcp/tools/emotion-tools.ts\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[{\"name\":\"stopEmotionAnalysisTool\",\"line\":112,\"col\":14,\"pos\":3575},{\"name\":\"emotionTools\",\"line\":198,\"col\":14,\"pos\":6165}],\"types\":[],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/services/mcp/tools/media-tools.ts\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[{\"name\":\"stopMediaStreamTool\",\"line\":115,\"col\":14,\"pos\":3090},{\"name\":\"mediaTools\",\"line\":185,\"col\":14,\"pos\":5056}],\"types\":[],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/shared/utils/url-utils.js\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[{\"name\":\"parseURL\",\"line\":13,\"col\":14,\"pos\":341},{\"name\":\"isValidURL\",\"line\":99,\"col\":14,\"pos\":2598},{\"name\":\"default\",\"line\":121,\"col\":8,\"pos\":3143}],\"types\":[],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/core/orchestration/orchestrator.ts\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[{\"name\":\"createCircuitBreaker\",\"line\":90,\"col\":14,\"pos\":2985}],\"types\":[{\"name\":\"CircuitBreaker\",\"line\":33,\"col\":18,\"pos\":1130},{\"name\":\"OrchestratorConfig\",\"line\":49,\"col\":18,\"pos\":1675},{\"name\":\"Orchestrator\",\"line\":516,\"col\":13,\"pos\":16657}],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/core/orchestration/strategies.ts\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[{\"name\":\"createStrategy\",\"line\":69,\"col\":14,\"pos\":1939},{\"name\":\"createPerformanceFirstStrategy\",\"line\":82,\"col\":14,\"pos\":2373},{\"name\":\"createAccuracyFirstStrategy\",\"line\":114,\"col\":14,\"pos\":3726},{\"name\":\"createBatteryOptimizedStrategy\",\"line\":175,\"col\":14,\"pos\":5778},{\"name\":\"createHybridStrategy\",\"line\":223,\"col\":14,\"pos\":7496},{\"name\":\"createAdaptiveStrategy\",\"line\":321,\"col\":14,\"pos\":10803},{\"name\":\"STRATEGIES\",\"line\":455,\"col\":14,\"pos\":15587}],\"types\":[{\"name\":\"Strategy\",\"line\":20,\"col\":18,\"pos\":582},{\"name\":\"PerformanceRecord\",\"line\":38,\"col\":18,\"pos\":1137},{\"name\":\"StrategyConfig\",\"line\":45,\"col\":18,\"pos\":1295},{\"name\":\"StrategyRegistry\",\"line\":409,\"col\":18,\"pos\":13957},{\"name\":\"StrategyName\",\"line\":464,\"col\":13,\"pos\":15814}],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/core/configuration/types.ts\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[{\"name\":\"createPipelineConfig\",\"line\":444,\"col\":14,\"pos\":12167},{\"name\":\"createAudioResult\",\"line\":467,\"col\":14,\"pos\":12754},{\"name\":\"createMotionResult\",\"line\":481,\"col\":14,\"pos\":13031},{\"name\":\"createSensorResult\",\"line\":488,\"col\":14,\"pos\":13237},{\"name\":\"createSimulatorResult\",\"line\":496,\"col\":14,\"pos\":13414},{\"name\":\"isErrorResult\",\"line\":504,\"col\":14,\"pos\":13609},{\"name\":\"isFaceResult\",\"line\":508,\"col\":14,\"pos\":13790},{\"name\":\"isAnalysisResult\",\"line\":512,\"col\":14,\"pos\":13948},{\"name\":\"createAnalysisPipelineResult\",\"line\":573,\"col\":14,\"pos\":15401}],\"types\":[{\"name\":\"UsageLevel\",\"line\":30,\"col\":13,\"pos\":1048},{\"name\":\"HealthStatusType\",\"line\":31,\"col\":13,\"pos\":1100},{\"name\":\"Point2D\",\"line\":63,\"col\":18,\"pos\":1996},{\"name\":\"Point3D\",\"line\":68,\"col\":18,\"pos\":2070},{\"name\":\"BoundingBox\",\"line\":74,\"col\":18,\"pos\":2166},{\"name\":\"Pose3DOF\",\"line\":83,\"col\":18,\"pos\":2354},{\"name\":\"Pose6DOF\",\"line\":91,\"col\":18,\"pos\":2521},{\"name\":\"FaceDetection\",\"line\":104,\"col\":18,\"pos\":2846},{\"name\":\"EyeResult\",\"line\":113,\"col\":18,\"pos\":3102},{\"name\":\"EmotionResult\",\"line\":122,\"col\":18,\"pos\":3350},{\"name\":\"AgeResult\",\"line\":130,\"col\":18,\"pos\":3605},{\"name\":\"GenderResult\",\"line\":139,\"col\":18,\"pos\":3782},{\"name\":\"FaceResult\",\"line\":146,\"col\":18,\"pos\":3961},{\"name\":\"BaseAnalysisResult\",\"line\":166,\"col\":18,\"pos\":4492},{\"name\":\"FaceAnalysisData\",\"line\":181,\"col\":18,\"pos\":5138},{\"name\":\"SpeechAnalysisResult\",\"line\":198,\"col\":18,\"pos\":5592},{\"name\":\"SpeechEvent\",\"line\":217,\"col\":18,\"pos\":6068},{\"name\":\"StreamCapabilityType\",\"line\":274,\"col\":13,\"pos\":7813},{\"name\":\"AudioResult\",\"line\":277,\"col\":18,\"pos\":7937},{\"name\":\"MotionResult\",\"line\":289,\"col\":18,\"pos\":8208},{\"name\":\"SensorResult\",\"line\":301,\"col\":18,\"pos\":8494},{\"name\":\"SimulatorResult\",\"line\":309,\"col\":18,\"pos\":8691},{\"name\":\"GazeSemanticsConfig\",\"line\":518,\"col\":18,\"pos\":14187},{\"name\":\"GazeSemantics\",\"line\":529,\"col\":18,\"pos\":14392},{\"name\":\"AnalysisPipelineMetadata\",\"line\":553,\"col\":18,\"pos\":15024},{\"name\":\"AnalysisPipelineResult\",\"line\":563,\"col\":18,\"pos\":15209},{\"name\":\"AnalysisPromptResult\",\"line\":590,\"col\":18,\"pos\":15872},{\"name\":\"EyeState\",\"line\":615,\"col\":18,\"pos\":16416},{\"name\":\"GazeData\",\"line\":639,\"col\":18,\"pos\":17039},{\"name\":\"EyeTrackingResult\",\"line\":670,\"col\":18,\"pos\":17738},{\"name\":\"DeviceStatus\",\"line\":705,\"col\":18,\"pos\":18579},{\"name\":\"CalibrationResult\",\"line\":727,\"col\":18,\"pos\":19168}],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/features/emotion-analysis/emotion-analysis-pipeline.js\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[{\"name\":\"EMOTION_LABELS\",\"line\":325,\"col\":9,\"pos\":10085}],\"types\":[],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/core/distribution/index.ts\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[{\"name\":\"createDistributionManager\",\"line\":7,\"col\":9,\"pos\":171},{\"name\":\"createDistributionConfigManager\",\"line\":8,\"col\":9,\"pos\":268},{\"name\":\"createBaseDistributor\",\"line\":9,\"col\":9,\"pos\":384},{\"name\":\"DistributorCapabilities\",\"line\":9,\"col\":54,\"pos\":429},{\"name\":\"createHttpDistributor\",\"line\":12,\"col\":9,\"pos\":529},{\"name\":\"createWebSocketDistributor\",\"line\":13,\"col\":9,\"pos\":627},{\"name\":\"createMqttDistributor\",\"line\":14,\"col\":9,\"pos\":740},{\"name\":\"createUdpDistributor\",\"line\":15,\"col\":9,\"pos\":846},{\"name\":\"createSseDistributor\",\"line\":16,\"col\":9,\"pos\":941},{\"name\":\"createMediaWebSocketDistributor\",\"line\":19,\"col\":9,\"pos\":1074},{\"name\":\"createHttpDistributorBun\",\"line\":23,\"col\":27,\"pos\":1262},{\"name\":\"createWebSocketDistributorBun\",\"line\":27,\"col\":32,\"pos\":1407},{\"name\":\"createQuickDistribution\",\"line\":42,\"col\":14,\"pos\":1845}],\"types\":[{\"name\":\"DistributionManager\",\"line\":7,\"col\":41,\"pos\":203},{\"name\":\"DistributionConfigManager\",\"line\":8,\"col\":47,\"pos\":306},{\"name\":\"BaseDistributor\",\"line\":9,\"col\":37,\"pos\":412},{\"name\":\"HttpDistributor\",\"line\":12,\"col\":37,\"pos\":557},{\"name\":\"WebSocketDistributor\",\"line\":13,\"col\":42,\"pos\":660},{\"name\":\"MqttDistributor\",\"line\":14,\"col\":37,\"pos\":768},{\"name\":\"UdpDistributor\",\"line\":15,\"col\":36,\"pos\":873},{\"name\":\"SseDistributor\",\"line\":16,\"col\":36,\"pos\":968},{\"name\":\"MediaWebSocketDistributor\",\"line\":19,\"col\":47,\"pos\":1112},{\"name\":\"BunHttpDistributor\",\"line\":24,\"col\":7,\"pos\":1296},{\"name\":\"BunWebSocketDistributor\",\"line\":28,\"col\":7,\"pos\":1446},{\"name\":\"DistributionManagerConfig\",\"line\":57,\"col\":14,\"pos\":2401},{\"name\":\"DistributionResponse\",\"line\":59,\"col\":29,\"pos\":2460},{\"name\":\"DistributionResult\",\"line\":60,\"col\":24,\"pos\":2484},{\"name\":\"HealthCheckResult\",\"line\":61,\"col\":22,\"pos\":2506},{\"name\":\"DistributorEvents\",\"line\":67,\"col\":27,\"pos\":2637},{\"name\":\"DistributorHealth\",\"line\":68,\"col\":21,\"pos\":2658},{\"name\":\"DistributorStats\",\"line\":69,\"col\":21,\"pos\":2679},{\"name\":\"SendOptions\",\"line\":70,\"col\":20,\"pos\":2699},{\"name\":\"EventCallback\",\"line\":71,\"col\":15,\"pos\":2714},{\"name\":\"HttpDistributorConfig\",\"line\":75,\"col\":14,\"pos\":2777},{\"name\":\"HttpSendResult\",\"line\":77,\"col\":25,\"pos\":2835},{\"name\":\"HttpBroadcastResult\",\"line\":78,\"col\":18,\"pos\":2853},{\"name\":\"WebSocketDistributorConfig\",\"line\":82,\"col\":14,\"pos\":2935},{\"name\":\"WebSocketSendResult\",\"line\":84,\"col\":30,\"pos\":3003},{\"name\":\"ClientInfo\",\"line\":85,\"col\":23,\"pos\":3026},{\"name\":\"WebSocketHealth\",\"line\":86,\"col\":14,\"pos\":3040},{\"name\":\"MqttDistributorConfig\",\"line\":90,\"col\":14,\"pos\":3123},{\"name\":\"MqttSendResult\",\"line\":92,\"col\":25,\"pos\":3181},{\"name\":\"MqttBroadcastResult\",\"line\":93,\"col\":18,\"pos\":3199},{\"name\":\"MqttHealth\",\"line\":94,\"col\":23,\"pos\":3222},{\"name\":\"UdpDistributorConfig\",\"line\":98,\"col\":14,\"pos\":3303},{\"name\":\"UdpSendResult\",\"line\":100,\"col\":24,\"pos\":3359},{\"name\":\"UdpTarget\",\"line\":101,\"col\":17,\"pos\":3376},{\"name\":\"UdpHealth\",\"line\":102,\"col\":13,\"pos\":3389},{\"name\":\"SseDistributorConfig\",\"line\":106,\"col\":14,\"pos\":3460},{\"name\":\"SseSendResult\",\"line\":108,\"col\":24,\"pos\":3516},{\"name\":\"SseClientInfo\",\"line\":109,\"col\":17,\"pos\":3533},{\"name\":\"SseHealth\",\"line\":110,\"col\":17,\"pos\":3550},{\"name\":\"MediaWebSocketDistributorConfig\",\"line\":114,\"col\":14,\"pos\":3621},{\"name\":\"StreamConfig\",\"line\":116,\"col\":35,\"pos\":3700},{\"name\":\"StreamInfo\",\"line\":117,\"col\":16,\"pos\":3716},{\"name\":\"MediaMessage\",\"line\":118,\"col\":14,\"pos\":3730},{\"name\":\"FrameMetadata\",\"line\":119,\"col\":16,\"pos\":3746},{\"name\":\"StreamingStats\",\"line\":120,\"col\":17,\"pos\":3763}],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/services/api/media-streaming-api.js\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[{\"name\":\"createMediaStreamingAPI\",\"line\":24,\"col\":14,\"pos\":1117}],\"types\":[],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/features/media-streaming/multi-device-coordinator.js\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[{\"name\":\"createMultiDeviceCoordinator\",\"line\":15,\"col\":14,\"pos\":497}],\"types\":[],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/features/eye-tracking/index.js\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[{\"name\":\"createEyeTrackingAPI\",\"line\":27,\"col\":14,\"pos\":1141},{\"name\":\"createDeviceDiscovery\",\"line\":186,\"col\":9,\"pos\":6089},{\"name\":\"createEyeTrackerDevice\",\"line\":187,\"col\":25,\"pos\":6114},{\"name\":\"createGazeProcessor\",\"line\":188,\"col\":26,\"pos\":6140},{\"name\":\"createEyeTrackingStreaming\",\"line\":189,\"col\":23,\"pos\":6163},{\"name\":\"createEyeTrackingSystem\",\"line\":190,\"col\":30,\"pos\":6193}],\"types\":[],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/features/face-detection/mediapipe-pipeline.js\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[{\"name\":\"createMediaPipePipeline\",\"line\":599,\"col\":14,\"pos\":19762},{\"name\":\"createMediaPipeIrisPipeline\",\"line\":604,\"col\":14,\"pos\":19912}],\"types\":[],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/features/face-detection/age-estimation-pipeline.js\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[{\"name\":\"AgeUtils\",\"line\":19,\"col\":9,\"pos\":378},{\"name\":\"createDefaultAgeConfiguration\",\"line\":30,\"col\":9,\"pos\":568},{\"name\":\"DEFAULT_AGE_RANGES\",\"line\":31,\"col\":33,\"pos\":601}],\"types\":[{\"name\":\"BaseAgeDetector\",\"line\":22,\"col\":14,\"pos\":446},{\"name\":\"AgeDetectorConfiguration\",\"line\":23,\"col\":19,\"pos\":465},{\"name\":\"AgeResult\",\"line\":24,\"col\":28,\"pos\":493},{\"name\":\"GenderResult\",\"line\":25,\"col\":13,\"pos\":506}],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/shared/utils/dependency-loader.js\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[{\"name\":\"isDependencyAvailableLocal\",\"line\":66,\"col\":14,\"pos\":2678},{\"name\":\"loadDependencyLocal\",\"line\":69,\"col\":14,\"pos\":2795},{\"name\":\"loadDependenciesLocal\",\"line\":72,\"col\":14,\"pos\":2904},{\"name\":\"getDependencyInfoLocal\",\"line\":75,\"col\":14,\"pos\":3018},{\"name\":\"checkSystemCapabilitiesLocal\",\"line\":78,\"col\":14,\"pos\":3126},{\"name\":\"createMediaPipeLoaderLocal\",\"line\":81,\"col\":14,\"pos\":3218},{\"name\":\"createDependencyInitializerLocal\",\"line\":84,\"col\":14,\"pos\":3306},{\"name\":\"loadDependency\",\"line\":90,\"col\":25,\"pos\":3568},{\"name\":\"loadDependencies\",\"line\":91,\"col\":27,\"pos\":3611},{\"name\":\"getDependencyInfo\",\"line\":92,\"col\":28,\"pos\":3657},{\"name\":\"createDependencyInitializer\",\"line\":95,\"col\":38,\"pos\":3828}],\"types\":[],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/core/pipeline/composition/composition-engine.ts\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[{\"name\":\"ExecutionStrategy\",\"line\":27,\"col\":14,\"pos\":1099}],\"types\":[],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/core/resources/resource-manager.ts\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[{\"name\":\"setGlobalResourceManager\",\"line\":451,\"col\":14,\"pos\":12907}],\"types\":[{\"name\":\"ResourceManagerConfig\",\"line\":13,\"col\":18,\"pos\":585},{\"name\":\"ResourceManager\",\"line\":62,\"col\":18,\"pos\":1662},{\"name\":\"ResourceSystemStatus\",\"line\":93,\"col\":18,\"pos\":2609}],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/browser-speech-client.js\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[{\"name\":\"DEFAULT_CLIENT_CONFIG\",\"line\":431,\"col\":14,\"pos\":11861}],\"types\":[],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/server-analysis-endpoint.js\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[{\"name\":\"createServerAnalysisEndpoint\",\"line\":184,\"col\":14,\"pos\":5912},{\"name\":\"DEFAULT_SERVER_CONFIG\",\"line\":268,\"col\":14,\"pos\":8647}],\"types\":[],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/shared/utils/url-validator.js\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[{\"name\":\"createProdValidator\",\"line\":223,\"col\":14,\"pos\":6103},{\"name\":\"createApiValidator\",\"line\":231,\"col\":14,\"pos\":6332},{\"name\":\"DEFAULT_VALIDATOR_CONFIG\",\"line\":239,\"col\":14,\"pos\":6615}],\"types\":[],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/index.js\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[{\"name\":\"createOrchestrator\",\"line\":13,\"col\":9,\"pos\":509},{\"name\":\"createLazyPipelineRegistry\",\"line\":16,\"col\":9,\"pos\":595},{\"name\":\"createLoadingStateManager\",\"line\":17,\"col\":9,\"pos\":683},{\"name\":\"LoadingStates\",\"line\":17,\"col\":36,\"pos\":710},{\"name\":\"ProgressStages\",\"line\":17,\"col\":51,\"pos\":725},{\"name\":\"createPipelinePreloader\",\"line\":18,\"col\":9,\"pos\":797},{\"name\":\"PreloadingStrategies\",\"line\":18,\"col\":34,\"pos\":822},{\"name\":\"UsageContexts\",\"line\":18,\"col\":56,\"pos\":844},{\"name\":\"createPipelineFactory\",\"line\":26,\"col\":14,\"pos\":1115},{\"name\":\"createPipeline\",\"line\":124,\"col\":9,\"pos\":4220},{\"name\":\"Capability\",\"line\":126,\"col\":22,\"pos\":4305},{\"name\":\"createPerformanceProfile\",\"line\":126,\"col\":34,\"pos\":4317},{\"name\":\"createFaceResult\",\"line\":127,\"col\":28,\"pos\":4346},{\"name\":\"createAnalysisResult\",\"line\":128,\"col\":20,\"pos\":4367},{\"name\":\"createPose3DOF\",\"line\":129,\"col\":24,\"pos\":4392},{\"name\":\"createPose6DOF\",\"line\":130,\"col\":18,\"pos\":4410},{\"name\":\"detectRuntime\",\"line\":135,\"col\":9,\"pos\":4498},{\"name\":\"checkFeatures\",\"line\":136,\"col\":17,\"pos\":4516},{\"name\":\"createUniversalCanvas\",\"line\":137,\"col\":17,\"pos\":4534},{\"name\":\"loadMediaPipe\",\"line\":138,\"col\":25,\"pos\":4560},{\"name\":\"imageToMediaPipe\",\"line\":139,\"col\":17,\"pos\":4577},{\"name\":\"getRuntimeInfo\",\"line\":140,\"col\":20,\"pos\":4597},{\"name\":\"createPerformanceMonitor\",\"line\":145,\"col\":9,\"pos\":4702},{\"name\":\"getGlobalMonitor\",\"line\":146,\"col\":28,\"pos\":4731},{\"name\":\"measureAsync\",\"line\":147,\"col\":20,\"pos\":4751},{\"name\":\"createFaceAnalysisServer\",\"line\":152,\"col\":9,\"pos\":4850},{\"name\":\"createSpeechAnalysisAPI\",\"line\":155,\"col\":9,\"pos\":4957},{\"name\":\"createSpeechRecognition\",\"line\":155,\"col\":34,\"pos\":4982},{\"name\":\"createLLMClient\",\"line\":155,\"col\":59,\"pos\":5007},{\"name\":\"VERSION\",\"line\":158,\"col\":14,\"pos\":5107},{\"name\":\"BUILD\",\"line\":159,\"col\":14,\"pos\":5178}],\"types\":[],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/services/mcp/utils/validation.ts\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[{\"name\":\"withValidation\",\"line\":141,\"col\":14,\"pos\":3688}],\"types\":[{\"name\":\"ValidationRule\",\"line\":8,\"col\":18,\"pos\":172},{\"name\":\"ValidationResult\",\"line\":22,\"col\":18,\"pos\":495}],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/core/performance/resource-pool.js\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[{\"name\":\"getWebGLResourcePool\",\"line\":82,\"col\":14,\"pos\":2970},{\"name\":\"setGlobalResourcePool\",\"line\":122,\"col\":14,\"pos\":4155}],\"types\":[],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/shared/utils/error-handler.ts\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[{\"name\":\"GlobalErrorHandler\",\"line\":369,\"col\":14,\"pos\":11905},{\"name\":\"handleError\",\"line\":372,\"col\":16,\"pos\":12010},{\"name\":\"validateRequired\",\"line\":373,\"col\":16,\"pos\":12061},{\"name\":\"validateType\",\"line\":374,\"col\":16,\"pos\":12117},{\"name\":\"validateRange\",\"line\":375,\"col\":16,\"pos\":12170},{\"name\":\"wrapFunction\",\"line\":376,\"col\":16,\"pos\":12223},{\"name\":\"safeAsync\",\"line\":377,\"col\":16,\"pos\":12275}],\"types\":[{\"name\":\"ErrorSeverity\",\"line\":7,\"col\":13,\"pos\":173},{\"name\":\"ErrorCategory\",\"line\":16,\"col\":13,\"pos\":347},{\"name\":\"StandardError\",\"line\":28,\"col\":18,\"pos\":620},{\"name\":\"ErrorHandlerConfig\",\"line\":39,\"col\":18,\"pos\":849},{\"name\":\"ErrorStatistics\",\"line\":49,\"col\":18,\"pos\":1114}],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/shared/utils/url-utils.d.ts\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[{\"name\":\"parseRequestURL\",\"line\":12,\"col\":17,\"pos\":182},{\"name\":\"validateURL\",\"line\":13,\"col\":17,\"pos\":261},{\"name\":\"normalizeURL\",\"line\":14,\"col\":17,\"pos\":312}],\"types\":[{\"name\":\"ParsedURL\",\"line\":5,\"col\":18,\"pos\":64}],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/core/pipeline/lazy-pipeline-registry.ts\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[{\"name\":\"createLazyPipelineRegistry\",\"line\":63,\"col\":14,\"pos\":2689}],\"types\":[],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/core/state/loading-state-manager.js\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[{\"name\":\"LoadingStates\",\"line\":52,\"col\":14,\"pos\":1805},{\"name\":\"ProgressStages\",\"line\":63,\"col\":14,\"pos\":2032}],\"types\":[],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/core/pipeline/pipeline-preloader.js\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[{\"name\":\"createPipelinePreloader\",\"line\":60,\"col\":14,\"pos\":2070},{\"name\":\"PreloadingStrategies\",\"line\":268,\"col\":9,\"pos\":7933},{\"name\":\"UsageContexts\",\"line\":268,\"col\":31,\"pos\":7955}],\"types\":[],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/shared/utils/ui/loading-components.js\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[{\"name\":\"createLoadingSpinner\",\"line\":13,\"col\":14,\"pos\":323},{\"name\":\"createProgressBar\",\"line\":112,\"col\":14,\"pos\":2989},{\"name\":\"createPipelineLoadingCard\",\"line\":206,\"col\":14,\"pos\":5876},{\"name\":\"createLoadingOverlay\",\"line\":314,\"col\":14,\"pos\":9257},{\"name\":\"createLoadingToast\",\"line\":412,\"col\":14,\"pos\":11982}],\"types\":[],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/core/pipeline/pipeline.ts\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[{\"name\":\"validatePipelineConfig\",\"line\":242,\"col\":14,\"pos\":6792}],\"types\":[],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/shared/utils/runtime-detector.js\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[{\"name\":\"createMockCanvas\",\"line\":95,\"col\":14,\"pos\":2936},{\"name\":\"getRuntimeInfo\",\"line\":244,\"col\":14,\"pos\":7293}],\"types\":[],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/core/performance/performance-monitor.js\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[{\"name\":\"createPerformanceMonitor\",\"line\":11,\"col\":14,\"pos\":269},{\"name\":\"getGlobalMonitor\",\"line\":327,\"col\":14,\"pos\":9938},{\"name\":\"measureAsync\",\"line\":336,\"col\":14,\"pos\":10167}],\"types\":[],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/services/api/server.ts\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[{\"name\":\"createFaceAnalysisServer\",\"line\":189,\"col\":14,\"pos\":6229}],\"types\":[{\"name\":\"ServerConfig\",\"line\":20,\"col\":18,\"pos\":868},{\"name\":\"RouteHandler\",\"line\":43,\"col\":13,\"pos\":1528},{\"name\":\"Router\",\"line\":46,\"col\":18,\"pos\":1641},{\"name\":\"ServerInstance\",\"line\":52,\"col\":18,\"pos\":1822},{\"name\":\"DistributionStream\",\"line\":63,\"col\":18,\"pos\":2067},{\"name\":\"DistributionClient\",\"line\":72,\"col\":18,\"pos\":2246}],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/features/speech-analysis/index.js\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[{\"name\":\"validatePrompts\",\"line\":25,\"col\":9,\"pos\":744},{\"name\":\"suggestPrompts\",\"line\":27,\"col\":19,\"pos\":778},{\"name\":\"analyzeContext\",\"line\":28,\"col\":18,\"pos\":796},{\"name\":\"CONTEXT_STRATEGIES\",\"line\":29,\"col\":18,\"pos\":814},{\"name\":\"DEFAULT_STREAM_CONFIG\",\"line\":30,\"col\":22,\"pos\":836},{\"name\":\"createSpeechRecognition\",\"line\":35,\"col\":9,\"pos\":906},{\"name\":\"createLLMClient\",\"line\":36,\"col\":27,\"pos\":933},{\"name\":\"createSpeechRecognitionResult\",\"line\":41,\"col\":9,\"pos\":1003},{\"name\":\"createSpeechAnalysisResult\",\"line\":42,\"col\":33,\"pos\":1036},{\"name\":\"createConversationContext\",\"line\":43,\"col\":30,\"pos\":1066},{\"name\":\"createLLMConfig\",\"line\":44,\"col\":29,\"pos\":1095},{\"name\":\"createSpeechPipelineStatus\",\"line\":45,\"col\":19,\"pos\":1114},{\"name\":\"createSpeechEvent\",\"line\":46,\"col\":30,\"pos\":1144},{\"name\":\"createSpeechAnalysis\",\"line\":53,\"col\":14,\"pos\":1291}],\"types\":[],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/shared/utils/logger.js\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[{\"name\":\"LogLevel\",\"line\":7,\"col\":14,\"pos\":124},{\"name\":\"logger\",\"line\":73,\"col\":14,\"pos\":1797}],\"types\":[],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/features/speech-analysis/analysis-engine.js\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[{\"name\":\"validatePrompt\",\"line\":405,\"col\":14,\"pos\":12356}],\"types\":[],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/features/speech-analysis/context-manager.js\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[{\"name\":\"ContextStrategy\",\"line\":24,\"col\":22,\"pos\":596}],\"types\":[{\"name\":\"ContextManagerConfiguration\",\"line\":29,\"col\":14,\"pos\":673},{\"name\":\"ConversationContext\",\"line\":30,\"col\":31,\"pos\":704},{\"name\":\"ContextChunk\",\"line\":31,\"col\":23,\"pos\":727},{\"name\":\"SemanticSearchResult\",\"line\":32,\"col\":16,\"pos\":743},{\"name\":\"TopicExtractionResult\",\"line\":33,\"col\":24,\"pos\":767},{\"name\":\"TopicEvolutionResult\",\"line\":34,\"col\":25,\"pos\":792}],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/features/speech-analysis/conversation-analytics.js\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[{\"name\":\"createConversationMetrics\",\"line\":19,\"col\":14,\"pos\":638}],\"types\":[],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/shared/utils/error-handler.js\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[{\"name\":\"createErrorHandler\",\"line\":44,\"col\":14,\"pos\":947},{\"name\":\"GlobalErrorHandler\",\"line\":460,\"col\":14,\"pos\":12379},{\"name\":\"validateRequired\",\"line\":464,\"col\":15,\"pos\":12532},{\"name\":\"validateType\",\"line\":465,\"col\":15,\"pos\":12586},{\"name\":\"validateRange\",\"line\":466,\"col\":15,\"pos\":12637},{\"name\":\"wrapFunction\",\"line\":467,\"col\":15,\"pos\":12688},{\"name\":\"safeAsync\",\"line\":468,\"col\":15,\"pos\":12738}],\"types\":[],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/core/configuration/validation-helpers.js\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[{\"name\":\"DANGEROUS_PATTERNS\",\"line\":40,\"col\":14,\"pos\":825},{\"name\":\"validateNoEval\",\"line\":108,\"col\":14,\"pos\":2774},{\"name\":\"validateNoProtoPollution\",\"line\":115,\"col\":14,\"pos\":2993},{\"name\":\"validateSafePath\",\"line\":127,\"col\":14,\"pos\":3325},{\"name\":\"validateSanitizedString\",\"line\":142,\"col\":14,\"pos\":3851},{\"name\":\"validateTrustedUrl\",\"line\":153,\"col\":14,\"pos\":4149}],\"types\":[],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/core/configuration/config-validator.js\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[{\"name\":\"CommonSchemas\",\"line\":194,\"col\":14,\"pos\":6011},{\"name\":\"createPipelineValidator\",\"line\":279,\"col\":14,\"pos\":8044},{\"name\":\"createServerValidator\",\"line\":286,\"col\":14,\"pos\":8208},{\"name\":\"createDependencyValidator\",\"line\":293,\"col\":14,\"pos\":8368}],\"types\":[],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/shared/utils/logger.ts\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[{\"name\":\"logger\",\"line\":89,\"col\":14,\"pos\":2435}],\"types\":[{\"name\":\"LogLevel\",\"line\":7,\"col\":13,\"pos\":144},{\"name\":\"LoggerConfig\",\"line\":15,\"col\":18,\"pos\":258},{\"name\":\"Logger\",\"line\":23,\"col\":18,\"pos\":415}],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/core/distribution/distribution-config-manager.ts\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[{\"name\":\"CONFIG_TEMPLATES\",\"line\":132,\"col\":14,\"pos\":3586},{\"name\":\"createDistributionConfigManager\",\"line\":246,\"col\":14,\"pos\":6593}],\"types\":[{\"name\":\"HttpDistributorConfig\",\"line\":11,\"col\":18,\"pos\":288},{\"name\":\"WebSocketDistributorConfig\",\"line\":20,\"col\":18,\"pos\":493},{\"name\":\"MqttDistributorConfig\",\"line\":29,\"col\":18,\"pos\":680},{\"name\":\"UdpDistributorConfig\",\"line\":39,\"col\":18,\"pos\":876},{\"name\":\"SseDistributorConfig\",\"line\":46,\"col\":18,\"pos\":1026},{\"name\":\"DistributorConfig\",\"line\":53,\"col\":13,\"pos\":1177},{\"name\":\"ConfigTemplate\",\"line\":61,\"col\":18,\"pos\":1386},{\"name\":\"SessionConfig\",\"line\":70,\"col\":18,\"pos\":1624},{\"name\":\"ValidationResult\",\"line\":79,\"col\":18,\"pos\":1878},{\"name\":\"SessionValidationResult\",\"line\":85,\"col\":18,\"pos\":1977},{\"name\":\"RuntimeInfo\",\"line\":90,\"col\":18,\"pos\":2149},{\"name\":\"DistributionConfigManager\",\"line\":99,\"col\":18,\"pos\":2413}],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/core/distribution/distributors/http-distributor-bun.ts\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[{\"name\":\"createHttpDistributor\",\"line\":85,\"col\":14,\"pos\":2113}],\"types\":[{\"name\":\"BunHttpDistributorConfig\",\"line\":12,\"col\":18,\"pos\":358},{\"name\":\"BunHttpDistributorStats\",\"line\":25,\"col\":18,\"pos\":630},{\"name\":\"BunHttpDistributorStatus\",\"line\":35,\"col\":18,\"pos\":890},{\"name\":\"DataPayload\",\"line\":48,\"col\":18,\"pos\":1189},{\"name\":\"BunHttpDistributor\",\"line\":55,\"col\":18,\"pos\":1315}],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/core/distribution/distributors/websocket-distributor-bun.ts\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[{\"name\":\"createWebSocketDistributor\",\"line\":64,\"col\":14,\"pos\":1644}],\"types\":[{\"name\":\"BunWebSocketDistributorConfig\",\"line\":12,\"col\":18,\"pos\":330},{\"name\":\"BunWebSocketDistributorStats\",\"line\":20,\"col\":18,\"pos\":509},{\"name\":\"BunWebSocketDistributorStatus\",\"line\":28,\"col\":18,\"pos\":704},{\"name\":\"WebSocketDataPayload\",\"line\":38,\"col\":18,\"pos\":968},{\"name\":\"BunWebSocketDistributor\",\"line\":45,\"col\":18,\"pos\":1108}],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/core/engine/image-processor.js\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[{\"name\":\"IMAGE_FORMATS\",\"line\":595,\"col\":9,\"pos\":18867},{\"name\":\"INTERPOLATION_METHODS\",\"line\":595,\"col\":24,\"pos\":18882}],\"types\":[],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/core/integration/mediapipe-commons.js\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[{\"name\":\"CANONICAL_FACE_MODEL_3D\",\"line\":85,\"col\":14,\"pos\":2474},{\"name\":\"DEFAULT_CAMERA_MATRIX\",\"line\":114,\"col\":14,\"pos\":3623},{\"name\":\"normalizeLandmarks\",\"line\":270,\"col\":14,\"pos\":8680},{\"name\":\"createMediaPipeProcessor\",\"line\":326,\"col\":14,\"pos\":10051},{\"name\":\"default\",\"line\":458,\"col\":8,\"pos\":14124}],\"types\":[],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/core/integration/transport.ts\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[{\"name\":\"createUdpTransport\",\"line\":459,\"col\":14,\"pos\":13779},{\"name\":\"createTransportFactory\",\"line\":510,\"col\":14,\"pos\":15305},{\"name\":\"transportFactory\",\"line\":540,\"col\":14,\"pos\":16212}],\"types\":[],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/core/state/streams.js\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[{\"name\":\"createStreamFactory\",\"line\":323,\"col\":14,\"pos\":8213}],\"types\":[],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/core/orchestration/synchronization.js\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[{\"name\":\"SynchronizationStrategy\",\"line\":10,\"col\":14,\"pos\":281},{\"name\":\"createSyncMetrics\",\"line\":18,\"col\":14,\"pos\":521},{\"name\":\"createTemporalAligner\",\"line\":37,\"col\":14,\"pos\":1311},{\"name\":\"createMultiStreamCoordinator\",\"line\":519,\"col\":14,\"pos\":14777}],\"types\":[],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/core/performance/resource-pool-canvas.js\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[{\"name\":\"createMockCanvas\",\"line\":8,\"col\":14,\"pos\":209}],\"types\":[],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/features/eye-tracking/devices/webcam/pipeline.js\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[{\"name\":\"estimateScreenGazePoint\",\"line\":248,\"col\":14,\"pos\":8691},{\"name\":\"createEyeTrackingFilter\",\"line\":288,\"col\":14,\"pos\":10013},{\"name\":\"createIrisTrackingPipeline\",\"line\":394,\"col\":14,\"pos\":13703}],\"types\":[],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/features/eye-tracking/devices/neon/pipeline.js\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[{\"name\":\"createEyeTrackingPipeline\",\"line\":16,\"col\":14,\"pos\":849},{\"name\":\"createEyeTrackingPipelineFactory\",\"line\":408,\"col\":14,\"pos\":12492}],\"types\":[],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/core/pipeline/pipeline-config.js\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[{\"name\":\"getDefaultConfig\",\"line\":264,\"col\":14,\"pos\":8708},{\"name\":\"updateConfig\",\"line\":274,\"col\":14,\"pos\":9005},{\"name\":\"areConfigsCompatible\",\"line\":291,\"col\":14,\"pos\":9503},{\"name\":\"getConfigSchema\",\"line\":311,\"col\":14,\"pos\":10148},{\"name\":\"createInternalPipelineConfig\",\"line\":332,\"col\":14,\"pos\":10817},{\"name\":\"SUPPORTED_PIPELINE_TYPES\",\"line\":337,\"col\":14,\"pos\":11034},{\"name\":\"BASE_CONFIG\",\"line\":340,\"col\":9,\"pos\":11157},{\"name\":\"TYPE_SPECIFIC_CONFIGS\",\"line\":340,\"col\":22,\"pos\":11170},{\"name\":\"VALIDATION_RULES\",\"line\":340,\"col\":45,\"pos\":11193}],\"types\":[],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/features/eye-tracking/devices/neon/discovery.js\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[{\"name\":\"createDiscoveryFactory\",\"line\":267,\"col\":14,\"pos\":7472}],\"types\":[],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/features/face-detection/age-estimation/index.ts\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[{\"name\":\"createAgeEstimationPipeline\",\"line\":65,\"col\":14,\"pos\":1780}],\"types\":[{\"name\":\"AgeEstimationPipeline\",\"line\":47,\"col\":18,\"pos\":1348},{\"name\":\"FaceRegionData\",\"line\":474,\"col\":7,\"pos\":14150},{\"name\":\"FeatureExtractionEngine\",\"line\":475,\"col\":7,\"pos\":14173},{\"name\":\"AgeCalculationEngine\",\"line\":476,\"col\":7,\"pos\":14205},{\"name\":\"SmoothingFilter\",\"line\":477,\"col\":7,\"pos\":14234}],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/features/media-streaming/device-discovery-pipeline.js\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[{\"name\":\"createDeviceDiscoverySystem\",\"line\":379,\"col\":14,\"pos\":11816},{\"name\":\"discoverDevices\",\"line\":394,\"col\":14,\"pos\":12198}],\"types\":[],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/features/media-streaming/quality-controller.js\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[{\"name\":\"QUALITY_PROFILES\",\"line\":10,\"col\":14,\"pos\":250}],\"types\":[],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/features/media-streaming/pipeline-state.js\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[{\"name\":\"resetPipelineStats\",\"line\":35,\"col\":14,\"pos\":778},{\"name\":\"updateFrameStats\",\"line\":44,\"col\":14,\"pos\":1029}],\"types\":[],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/features/media-streaming/media-streaming-pipeline.js\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[{\"name\":\"createMultiDeviceStreaming\",\"line\":586,\"col\":14,\"pos\":17281}],\"types\":[],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/features/speech-analysis/audio-quality.js\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[{\"name\":\"createAudioQualityMetrics\",\"line\":11,\"col\":14,\"pos\":362}],\"types\":[],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/features/speech-analysis/context/index.ts\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[{\"name\":\"createContextManager\",\"line\":89,\"col\":14,\"pos\":2768}],\"types\":[{\"name\":\"ContextManagerState\",\"line\":54,\"col\":18,\"pos\":1328},{\"name\":\"ExtendedContextManager\",\"line\":67,\"col\":18,\"pos\":1728},{\"name\":\"BaseContextManager\",\"line\":662,\"col\":7,\"pos\":18597},{\"name\":\"ContextMetrics\",\"line\":666,\"col\":7,\"pos\":18709},{\"name\":\"ContextEvent\",\"line\":667,\"col\":7,\"pos\":18732},{\"name\":\"ContextEventCallback\",\"line\":668,\"col\":7,\"pos\":18753},{\"name\":\"ContextEventSubscription\",\"line\":669,\"col\":7,\"pos\":18782},{\"name\":\"TopicCluster\",\"line\":673,\"col\":7,\"pos\":18885}],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/features/speech-analysis/core/index.ts\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[{\"name\":\"createSpeechAnalysisAPI\",\"line\":95,\"col\":14,\"pos\":3089}],\"types\":[{\"name\":\"SpeechAnalysisAPI\",\"line\":36,\"col\":18,\"pos\":888},{\"name\":\"SpeechAnalysisConfiguration\",\"line\":400,\"col\":14,\"pos\":12574},{\"name\":\"EventManager\",\"line\":401,\"col\":31,\"pos\":12606},{\"name\":\"EventSubscription\",\"line\":402,\"col\":16,\"pos\":12622},{\"name\":\"ComponentFactory\",\"line\":403,\"col\":21,\"pos\":12643}],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/features/speech-analysis/llm-backends.js\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[{\"name\":\"createMockBackend\",\"line\":8,\"col\":14,\"pos\":165},{\"name\":\"createWebLLMBackend\",\"line\":51,\"col\":14,\"pos\":1766},{\"name\":\"createTransformersJSBackend\",\"line\":105,\"col\":14,\"pos\":3365}],\"types\":[],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/shared/utils/script-loader.js\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[{\"name\":\"getScriptStatus\",\"line\":79,\"col\":14,\"pos\":2234},{\"name\":\"clearScriptCache\",\"line\":87,\"col\":14,\"pos\":2409}],\"types\":[],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/shared/utils/html-utils.js\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[{\"name\":\"createTextNode\",\"line\":35,\"col\":14,\"pos\":726},{\"name\":\"setTextContent\",\"line\":44,\"col\":14,\"pos\":959},{\"name\":\"createElement\",\"line\":55,\"col\":14,\"pos\":1295},{\"name\":\"sanitizeStyles\",\"line\":74,\"col\":14,\"pos\":1766},{\"name\":\"applyStyles\",\"line\":99,\"col\":14,\"pos\":2443}],\"types\":[],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/features/face-detection/age-estimation/base-age-detector.ts\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[{\"name\":\"validateFacialFeatures\",\"line\":129,\"col\":14,\"pos\":3927},{\"name\":\"validateGenderFeatures\",\"line\":147,\"col\":14,\"pos\":4469}],\"types\":[],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/features/speech-analysis/core/configuration-manager.ts\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[{\"name\":\"createDefaultConfiguration\",\"line\":76,\"col\":14,\"pos\":2078},{\"name\":\"mergeConfiguration\",\"line\":144,\"col\":14,\"pos\":4419},{\"name\":\"validateConfiguration\",\"line\":164,\"col\":14,\"pos\":5210}],\"types\":[{\"name\":\"LLMConfiguration\",\"line\":23,\"col\":18,\"pos\":734},{\"name\":\"AnalysisConfiguration\",\"line\":32,\"col\":18,\"pos\":977},{\"name\":\"ContextConfiguration\",\"line\":39,\"col\":18,\"pos\":1159},{\"name\":\"StreamConfiguration\",\"line\":46,\"col\":18,\"pos\":1329}],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/services/mcp/config/tool-registry.ts\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[],\"types\":[{\"name\":\"ToolDefinition\",\"line\":6,\"col\":18,\"pos\":106},{\"name\":\"ToolCategory\",\"line\":23,\"col\":18,\"pos\":492}],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/services/mcp/client/http-client.ts\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[],\"types\":[{\"name\":\"HTTPClientConfig\",\"line\":11,\"col\":18,\"pos\":320},{\"name\":\"APIResponse\",\"line\":19,\"col\":18,\"pos\":483},{\"name\":\"SynopticonCapabilities\",\"line\":26,\"col\":18,\"pos\":601},{\"name\":\"AnalysisStatus\",\"line\":35,\"col\":18,\"pos\":802}],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/services/mcp/utils/logger.ts\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[],\"types\":[{\"name\":\"LogEntry\",\"line\":13,\"col\":18,\"pos\":170}],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/core/pipeline/composition/composers/conditional-composer.ts\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[],\"types\":[{\"name\":\"ConditionalPipeline\",\"line\":15,\"col\":18,\"pos\":404},{\"name\":\"ConditionalBranch\",\"line\":29,\"col\":18,\"pos\":839},{\"name\":\"ConditionalContext\",\"line\":38,\"col\":18,\"pos\":1100},{\"name\":\"ConditionalComposition\",\"line\":47,\"col\":18,\"pos\":1317},{\"name\":\"ConditionalComposerConfig\",\"line\":61,\"col\":18,\"pos\":1728}],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/services/mcp/tools/base-tool.ts\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[],\"types\":[{\"name\":\"MCPToolDefinition\",\"line\":12,\"col\":18,\"pos\":359},{\"name\":\"MCPToolResult\",\"line\":22,\"col\":18,\"pos\":546},{\"name\":\"MCPToolHandler\",\"line\":30,\"col\":13,\"pos\":659}],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/core/distribution/distributors/mqtt-distributor-builtin.ts\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[],\"types\":[{\"name\":\"SendOptions\",\"line\":17,\"col\":18,\"pos\":539},{\"name\":\"EventCallback\",\"line\":24,\"col\":13,\"pos\":642},{\"name\":\"MqttDistributorConfig\",\"line\":31,\"col\":18,\"pos\":790},{\"name\":\"MqttSendResult\",\"line\":51,\"col\":18,\"pos\":1177},{\"name\":\"MqttBroadcastResult\",\"line\":63,\"col\":18,\"pos\":1365},{\"name\":\"MqttHealth\",\"line\":77,\"col\":18,\"pos\":1643}],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/core/pipeline/composition/composers/sequential-composer.ts\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[],\"types\":[{\"name\":\"SequentialPipeline\",\"line\":15,\"col\":18,\"pos\":393},{\"name\":\"SequentialComposition\",\"line\":27,\"col\":18,\"pos\":755},{\"name\":\"SequentialComposerConfig\",\"line\":40,\"col\":18,\"pos\":1122}],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/core/pipeline/composition/composers/parallel-composer.ts\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[],\"types\":[{\"name\":\"ParallelPipeline\",\"line\":15,\"col\":18,\"pos\":415},{\"name\":\"ParallelContext\",\"line\":30,\"col\":18,\"pos\":936},{\"name\":\"ParallelComposition\",\"line\":39,\"col\":18,\"pos\":1168},{\"name\":\"ParallelComposerConfig\",\"line\":55,\"col\":18,\"pos\":1822}],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/core/pipeline/composition/metrics/composition-metrics.ts\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[],\"types\":[{\"name\":\"CompositionMetrics\",\"line\":6,\"col\":18,\"pos\":134},{\"name\":\"MetricsSummary\",\"line\":21,\"col\":18,\"pos\":501}],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/core/pipeline/composition/registry/composition-registry.ts\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[],\"types\":[{\"name\":\"CompositionTemplate\",\"line\":8,\"col\":18,\"pos\":192},{\"name\":\"RegistryStats\",\"line\":25,\"col\":18,\"pos\":533},{\"name\":\"RegistrySearchOptions\",\"line\":33,\"col\":18,\"pos\":826}],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/core/resources/managers/memory-manager.ts\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[],\"types\":[{\"name\":\"MemoryManagerConfig\",\"line\":8,\"col\":18,\"pos\":182},{\"name\":\"MemoryStats\",\"line\":15,\"col\":18,\"pos\":346},{\"name\":\"MemoryAllocation\",\"line\":25,\"col\":18,\"pos\":524}],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/core/resources/managers/cache-manager.ts\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[],\"types\":[{\"name\":\"CacheManagerConfig\",\"line\":8,\"col\":18,\"pos\":174},{\"name\":\"CacheEntry\",\"line\":15,\"col\":18,\"pos\":313},{\"name\":\"CacheStats\",\"line\":27,\"col\":18,\"pos\":533}],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/core/resources/managers/lifecycle-manager.ts\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[],\"types\":[{\"name\":\"LifecycleManagerConfig\",\"line\":10,\"col\":18,\"pos\":309},{\"name\":\"TrackedResource\",\"line\":17,\"col\":18,\"pos\":472},{\"name\":\"LifecycleStats\",\"line\":30,\"col\":18,\"pos\":736}],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/core/resources/registry/resource-registry.ts\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[],\"types\":[{\"name\":\"ResourceRegistryConfig\",\"line\":6,\"col\":18,\"pos\":130},{\"name\":\"ResourceRegistration\",\"line\":12,\"col\":18,\"pos\":263},{\"name\":\"ResourceType\",\"line\":23,\"col\":18,\"pos\":467},{\"name\":\"RegistryStats\",\"line\":32,\"col\":18,\"pos\":750}],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/core/resources/metrics/resource-metrics.ts\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[],\"types\":[{\"name\":\"ResourceMetricsConfig\",\"line\":12,\"col\":18,\"pos\":498},{\"name\":\"MetricsSnapshot\",\"line\":19,\"col\":18,\"pos\":669},{\"name\":\"PerformanceProfile\",\"line\":58,\"col\":18,\"pos\":1458},{\"name\":\"ResourceAlert\",\"line\":68,\"col\":18,\"pos\":1632}],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/core/distribution/base-distributor.ts\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[],\"types\":[{\"name\":\"DistributorHealthStatus\",\"line\":28,\"col\":13,\"pos\":675},{\"name\":\"DistributorConfig\",\"line\":31,\"col\":18,\"pos\":827},{\"name\":\"DistributorStats\",\"line\":47,\"col\":18,\"pos\":1162}],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/core/distribution/distribution-manager.ts\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[],\"types\":[{\"name\":\"DistributionResult\",\"line\":16,\"col\":18,\"pos\":344},{\"name\":\"HealthCheckResult\",\"line\":36,\"col\":18,\"pos\":715},{\"name\":\"EventRoute\",\"line\":47,\"col\":18,\"pos\":922},{\"name\":\"DistributionManagerConfig\",\"line\":53,\"col\":18,\"pos\":1051},{\"name\":\"DistributionStats\",\"line\":61,\"col\":18,\"pos\":1246}],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/core/distribution/distributors/http-distributor.ts\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[],\"types\":[{\"name\":\"HttpDistributorConfig\",\"line\":17,\"col\":18,\"pos\":397},{\"name\":\"HttpRequestOptions\",\"line\":30,\"col\":18,\"pos\":702},{\"name\":\"HttpResponse\",\"line\":40,\"col\":18,\"pos\":926},{\"name\":\"HttpSendResult\",\"line\":48,\"col\":18,\"pos\":1079},{\"name\":\"HttpBroadcastResult\",\"line\":58,\"col\":18,\"pos\":1263}],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/core/distribution/distributors/websocket-distributor.ts\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[],\"types\":[{\"name\":\"WebSocketDistributorConfig\",\"line\":19,\"col\":18,\"pos\":472},{\"name\":\"ClientInfo\",\"line\":31,\"col\":18,\"pos\":730},{\"name\":\"WebSocketMessage\",\"line\":41,\"col\":18,\"pos\":940},{\"name\":\"WebSocketSendResult\",\"line\":50,\"col\":18,\"pos\":1144},{\"name\":\"ClientSummary\",\"line\":62,\"col\":18,\"pos\":1366},{\"name\":\"SubscriptionSummary\",\"line\":70,\"col\":18,\"pos\":1524},{\"name\":\"WebSocketHealth\",\"line\":76,\"col\":18,\"pos\":1654}],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/core/distribution/distributors/udp-distributor.ts\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[],\"types\":[{\"name\":\"UdpTarget\",\"line\":17,\"col\":18,\"pos\":389},{\"name\":\"UdpDistributorConfig\",\"line\":23,\"col\":18,\"pos\":493},{\"name\":\"UdpSendOptions\",\"line\":35,\"col\":18,\"pos\":729},{\"name\":\"UdpSendResult\",\"line\":40,\"col\":18,\"pos\":840},{\"name\":\"UdpHealth\",\"line\":57,\"col\":18,\"pos\":1168}],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/core/distribution/distributors/sse-distributor.ts\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[],\"types\":[{\"name\":\"SseDistributorConfig\",\"line\":18,\"col\":18,\"pos\":439},{\"name\":\"SseClientInfo\",\"line\":31,\"col\":18,\"pos\":719},{\"name\":\"SseSendOptions\",\"line\":42,\"col\":18,\"pos\":977},{\"name\":\"SseSendResult\",\"line\":47,\"col\":18,\"pos\":1087},{\"name\":\"SseClientSummary\",\"line\":59,\"col\":18,\"pos\":1286},{\"name\":\"SseSubscriptionSummary\",\"line\":67,\"col\":18,\"pos\":1447},{\"name\":\"SseHealth\",\"line\":73,\"col\":18,\"pos\":1574}],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/core/distribution/distribution-session-manager.ts\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[],\"types\":[{\"name\":\"DistributorFactory\",\"line\":19,\"col\":18,\"pos\":947},{\"name\":\"DistributorData\",\"line\":23,\"col\":18,\"pos\":1022},{\"name\":\"SessionConfig\",\"line\":29,\"col\":18,\"pos\":1136},{\"name\":\"Session\",\"line\":40,\"col\":18,\"pos\":1421},{\"name\":\"SessionStatus\",\"line\":51,\"col\":18,\"pos\":1735},{\"name\":\"SessionSummary\",\"line\":62,\"col\":18,\"pos\":1952},{\"name\":\"DistributionSessionManager\",\"line\":70,\"col\":18,\"pos\":2104}],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/core/distribution/distributors/media-websocket-distributor.ts\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[],\"types\":[{\"name\":\"StreamConfig\",\"line\":14,\"col\":18,\"pos\":522},{\"name\":\"StreamInfo\",\"line\":21,\"col\":18,\"pos\":698},{\"name\":\"ClientSubscription\",\"line\":32,\"col\":18,\"pos\":967},{\"name\":\"MediaMessageHeader\",\"line\":41,\"col\":18,\"pos\":1135},{\"name\":\"MediaMessagePayload\",\"line\":50,\"col\":18,\"pos\":1311},{\"name\":\"MediaMessage\",\"line\":60,\"col\":18,\"pos\":1522},{\"name\":\"FrameMetadata\",\"line\":66,\"col\":18,\"pos\":1647},{\"name\":\"SubscriptionOptions\",\"line\":75,\"col\":18,\"pos\":1815},{\"name\":\"QualityProfile\",\"line\":81,\"col\":18,\"pos\":1928},{\"name\":\"StreamingStats\",\"line\":87,\"col\":18,\"pos\":2036},{\"name\":\"StreamInfoSummary\",\"line\":99,\"col\":18,\"pos\":2308},{\"name\":\"MediaWebSocketDistributorConfig\",\"line\":109,\"col\":18,\"pos\":2525},{\"name\":\"MediaWebSocketDistributor\",\"line\":121,\"col\":18,\"pos\":2802}],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/core/integration/transport-types.ts\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[],\"types\":[{\"name\":\"ConnectionStatus\",\"line\":10,\"col\":13,\"pos\":257},{\"name\":\"TransportEvent\",\"line\":13,\"col\":13,\"pos\":396},{\"name\":\"BaseTransportConfig\",\"line\":16,\"col\":18,\"pos\":511},{\"name\":\"WebSocketData\",\"line\":68,\"col\":18,\"pos\":1769},{\"name\":\"Transport\",\"line\":192,\"col\":13,\"pos\":5523},{\"name\":\"TransportConfig\",\"line\":195,\"col\":13,\"pos\":5637},{\"name\":\"CalibrationPoint\",\"line\":207,\"col\":18,\"pos\":5959},{\"name\":\"CalibrationData\",\"line\":213,\"col\":18,\"pos\":6045},{\"name\":\"DeviceStatus\",\"line\":221,\"col\":18,\"pos\":6255},{\"name\":\"RecordingInfo\",\"line\":231,\"col\":18,\"pos\":6443}],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/core/performance/parallel-initializer.ts\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[],\"types\":[{\"name\":\"ParallelInitializerConfig\",\"line\":28,\"col\":18,\"pos\":904},{\"name\":\"InitializationResult\",\"line\":36,\"col\":18,\"pos\":1139},{\"name\":\"FailedInitialization\",\"line\":43,\"col\":18,\"pos\":1353}],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/core/pipeline/pipeline-types.ts\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[],\"types\":[{\"name\":\"PipelineModule\",\"line\":10,\"col\":18,\"pos\":261},{\"name\":\"LoadingState\",\"line\":42,\"col\":13,\"pos\":1022},{\"name\":\"FailedLoadInfo\",\"line\":57,\"col\":18,\"pos\":1373}],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/services/api/middleware/middleware-types.ts\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[],\"types\":[{\"name\":\"MiddlewareType\",\"line\":7,\"col\":13,\"pos\":146},{\"name\":\"HttpMethod\",\"line\":10,\"col\":13,\"pos\":270},{\"name\":\"RequestHandler\",\"line\":13,\"col\":13,\"pos\":387},{\"name\":\"MiddlewareHandler\",\"line\":14,\"col\":13,\"pos\":484},{\"name\":\"CORSConfig\",\"line\":17,\"col\":18,\"pos\":618},{\"name\":\"RateLimitConfig\",\"line\":30,\"col\":18,\"pos\":940},{\"name\":\"ErrorHandlerConfig\",\"line\":44,\"col\":18,\"pos\":1359},{\"name\":\"AuthConfig\",\"line\":54,\"col\":18,\"pos\":1655},{\"name\":\"LoggingConfig\",\"line\":65,\"col\":18,\"pos\":1965},{\"name\":\"CORSStatistics\",\"line\":86,\"col\":18,\"pos\":2481},{\"name\":\"RateLimitStatistics\",\"line\":95,\"col\":18,\"pos\":2714},{\"name\":\"ErrorHandlerStatistics\",\"line\":105,\"col\":18,\"pos\":2962},{\"name\":\"AuthStatistics\",\"line\":113,\"col\":18,\"pos\":3164},{\"name\":\"LoggingStatistics\",\"line\":121,\"col\":18,\"pos\":3342},{\"name\":\"MiddlewareStatistics\",\"line\":130,\"col\":18,\"pos\":3537},{\"name\":\"ComponentHealth\",\"line\":140,\"col\":18,\"pos\":3800},{\"name\":\"MiddlewareHealth\",\"line\":148,\"col\":18,\"pos\":3981},{\"name\":\"RateLimitClient\",\"line\":162,\"col\":18,\"pos\":4333},{\"name\":\"RouteRateLimit\",\"line\":172,\"col\":18,\"pos\":4523},{\"name\":\"ErrorContext\",\"line\":179,\"col\":18,\"pos\":4653},{\"name\":\"MiddlewareError\",\"line\":192,\"col\":18,\"pos\":4887},{\"name\":\"CORSMiddleware\",\"line\":200,\"col\":18,\"pos\":5042},{\"name\":\"RateLimitMiddleware\",\"line\":210,\"col\":18,\"pos\":5378},{\"name\":\"ErrorHandlerMiddleware\",\"line\":222,\"col\":18,\"pos\":5869},{\"name\":\"AuthMiddleware\",\"line\":231,\"col\":18,\"pos\":6262},{\"name\":\"LoggingMiddleware\",\"line\":241,\"col\":18,\"pos\":6614},{\"name\":\"CORSMiddlewareFactory\",\"line\":282,\"col\":13,\"pos\":8148},{\"name\":\"RateLimitMiddlewareFactory\",\"line\":283,\"col\":13,\"pos\":8225},{\"name\":\"ErrorHandlerMiddlewareFactory\",\"line\":284,\"col\":13,\"pos\":8317},{\"name\":\"AuthMiddlewareFactory\",\"line\":285,\"col\":13,\"pos\":8418},{\"name\":\"LoggingMiddlewareFactory\",\"line\":286,\"col\":13,\"pos\":8495},{\"name\":\"MiddlewareSystemFactory\",\"line\":287,\"col\":13,\"pos\":8581},{\"name\":\"MiddlewarePipeline\",\"line\":290,\"col\":18,\"pos\":8703},{\"name\":\"RequestContext\",\"line\":299,\"col\":18,\"pos\":9016},{\"name\":\"ResponseContext\",\"line\":313,\"col\":18,\"pos\":9340},{\"name\":\"MiddlewareResult\",\"line\":323,\"col\":18,\"pos\":9532}],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/core/pipeline/composition/composers/cascading-composer.ts\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[],\"types\":[{\"name\":\"CascadingPipeline\",\"line\":15,\"col\":18,\"pos\":419},{\"name\":\"CascadingLayer\",\"line\":38,\"col\":18,\"pos\":1007},{\"name\":\"CascadingContext\",\"line\":48,\"col\":18,\"pos\":1275},{\"name\":\"CascadingComposition\",\"line\":58,\"col\":18,\"pos\":1648},{\"name\":\"CascadingComposerConfig\",\"line\":72,\"col\":18,\"pos\":2115}],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/core/pipeline/composition/composers/adaptive-composer.ts\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[],\"types\":[{\"name\":\"AdaptivePipeline\",\"line\":15,\"col\":18,\"pos\":425},{\"name\":\"AdaptationRule\",\"line\":34,\"col\":18,\"pos\":932},{\"name\":\"AdaptiveContext\",\"line\":50,\"col\":18,\"pos\":1444},{\"name\":\"AdaptiveComposition\",\"line\":75,\"col\":18,\"pos\":2037},{\"name\":\"AdaptiveComposerConfig\",\"line\":91,\"col\":18,\"pos\":2490}],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/core/pipeline/composition/scheduling/execution-scheduler.ts\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[],\"types\":[{\"name\":\"ScheduledExecution\",\"line\":8,\"col\":18,\"pos\":260},{\"name\":\"ScheduleOptions\",\"line\":23,\"col\":18,\"pos\":632},{\"name\":\"SchedulerStats\",\"line\":32,\"col\":18,\"pos\":808},{\"name\":\"ExecutionSchedulerConfig\",\"line\":45,\"col\":18,\"pos\":1077}],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/features/face-detection/age-estimation/smoothing-filter.ts\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[],\"types\":[{\"name\":\"SmoothingFilterConfiguration\",\"line\":8,\"col\":18,\"pos\":217},{\"name\":\"SmoothingState\",\"line\":15,\"col\":18,\"pos\":419}],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/features/speech-analysis/context/context-summarization-engine.ts\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[],\"types\":[{\"name\":\"SummaryMetrics\",\"line\":26,\"col\":18,\"pos\":723}],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/features/speech-analysis/context/semantic-search-engine.ts\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[],\"types\":[{\"name\":\"SemanticSimilarity\",\"line\":12,\"col\":18,\"pos\":265},{\"name\":\"SearchResult\",\"line\":17,\"col\":18,\"pos\":371}],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/features/speech-analysis/context/topic-modeling-engine.ts\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[],\"types\":[{\"name\":\"TopicChunk\",\"line\":17,\"col\":18,\"pos\":433},{\"name\":\"TopicEvolutionWindow\",\"line\":30,\"col\":18,\"pos\":737}],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/features/speech-analysis/core/component-factory.ts\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[],\"types\":[{\"name\":\"ComponentState\",\"line\":17,\"col\":18,\"pos\":589},{\"name\":\"ComponentInitializationResult\",\"line\":25,\"col\":18,\"pos\":760}],\"enumMembers\":{},\"duplicates\":[]},{\"file\":\"src/features/speech-analysis/core/event-manager.ts\",\"dependencies\":[],\"devDependencies\":[],\"optionalPeerDependencies\":[],\"unlisted\":[],\"binaries\":[],\"unresolved\":[],\"exports\":[],\"types\":[{\"name\":\"EventCallback\",\"line\":6,\"col\":13,\"pos\":133},{\"name\":\"SpeechAnalysisEvents\",\"line\":12,\"col\":18,\"pos\":255},{\"name\":\"EventType\",\"line\":22,\"col\":13,\"pos\":904}],\"enumMembers\":{},\"duplicates\":[]}]}\n",
      "errors": "",
      "summary": "198 unused files detected",
      "weight": 0.2,
      "critical": false
    },
    {
      "name": "Test Suite",
      "passed": false,
      "exitCode": 1,
      "duration": 3,
      "output": "",
      "errors": "error: unrecognized reporter format: 'json'. Currently, only 'junit' is supported\n",
      "summary": "Test output parsing failed",
      "weight": 0.1,
      "critical": true
    }
  ],
  "metrics": {
    "totalFiles": 0,
    "lintErrors": 267,
    "lintWarnings": 1083,
    "typeErrors": 0,
    "unusedFiles": 198,
    "testsPassed": 0,
    "testsFailed": 0
  },
  "recommendations": [
    {
      "type": "error",
      "message": "Fix 267 ESLint errors",
      "command": "bun run lint:fix"
    },
    {
      "type": "warning",
      "message": "Address 1083 ESLint warnings",
      "command": "bun run lint:fix"
    },
    {
      "type": "info",
      "message": "Consider removing 198 unused files",
      "command": "bun run knip:check"
    }
  ]
}