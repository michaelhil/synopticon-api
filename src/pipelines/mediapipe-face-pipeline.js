/**
 * MediaPipe Face Detection Pipeline - Lightweight Alternative
 * Replaces BlazeFace/TensorFlow.js with MediaPipe for 99% size reduction
 * Compatible with existing Synopticon pipeline architecture
 */

import { createPipeline } from '../core/pipeline.js';
import { detectRuntime, checkFeatures } from '../utils/runtime-detector.js';
import { measureAsync } from '../core/performance-monitor.js';
import { 
  Capability, 
  createPerformanceProfile, 
  createFaceDetectionResult 
} from '../core/types.js';
import { createMediaPipeFaceDetector } from '../modules/detection/mediapipe/mediapipe-face-detector.js';

// Pipeline configuration factory
const createMediaPipeFaceConfig = (config = {}) => ({
  // MediaPipe specific settings
  model: config.model || 'short', // 'short' for close range, 'full' for long range
  minDetectionConfidence: config.minDetectionConfidence || 0.5,
  maxNumFaces: config.maxNumFaces || 10,
  
  // Processing options
  enableLandmarks: config.enableLandmarks !== false,
  enableKeypoints: config.enableKeypoints !== false,
  
  // Performance settings
  targetFPS: config.targetFPS || 30,
  processEveryNthFrame: config.processEveryNthFrame || 1,
  
  // Fallback options
  useFallback: config.useFallback === true,
  fallbackTimeout: config.fallbackTimeout || 5000,
  
  ...config
});

// Main MediaPipe face detection pipeline factory
export const createMediaPipeFacePipeline = (config = {}) => {
  const pipelineConfig = createMediaPipeFaceConfig(config);
  
  const state = {
    runtime: detectRuntime(),
    features: checkFeatures(),
    detector: null,
    isInitialized: false,
    isProcessing: false,
    
    // Performance metrics
    metrics: {
      totalDetections: 0,
      successfulDetections: 0,
      averageLatency: 0,
      averageConfidence: 0,
      frameProcessingRate: 0,
      lastProcessingTime: 0
    },
    
    // Frame processing
    frameCount: 0,
    lastFrameTime: 0
  };

  // Initialize MediaPipe face detection pipeline
  const initialize = async (options = {}) => {
    if (state.isInitialized) {
      return true;
    }

    return await measureAsync(async () => {
      try {
        const initConfig = { ...pipelineConfig, ...options };
        
        // Create MediaPipe face detector
        state.detector = createMediaPipeFaceDetector(initConfig);
        
        // Initialize the detector
        await state.detector.initialize();
        
        state.isInitialized = true;
        console.log('âœ… MediaPipe face pipeline initialized');
        
        return true;
        
      } catch (error) {
        console.error('âŒ MediaPipe face pipeline initialization failed:', error);
        throw new Error(`MediaPipe face pipeline initialization failed: ${error.message}`);
      }
    }, 'mediapipe_face_pipeline', 'initialize');
  };

  // Process image/video frame for face detection
  const process = async (input, options = {}) => {
    if (!state.isInitialized) {
      throw new Error('MediaPipe face pipeline not initialized');
    }

    return await measureAsync(async () => {
      const startTime = performance.now();
      state.isProcessing = true;
      state.frameCount++;

      try {
        // Handle different input types
        let imageData;
        
        if (input instanceof HTMLCanvasElement) {
          imageData = input;
        } else if (input instanceof HTMLImageElement) {
          imageData = input;
        } else if (input instanceof HTMLVideoElement) {
          imageData = input;
        } else if (input.data && input.width && input.height) {
          // ImageData object
          imageData = input;
        } else {
          throw new Error('Invalid input format. Expected Canvas, Image, Video, or ImageData');
        }

        // Skip frame processing if configured
        if (state.frameCount % pipelineConfig.processEveryNthFrame !== 0) {
          return createFaceDetectionResult({
            timestamp: Date.now(),
            source: 'mediapipe_face_pipeline',
            faces: [],
            skipped: true,
            metadata: {
              frameCount: state.frameCount,
              skippedFrame: true
            }
          });
        }

        // Perform face detection
        const faces = await state.detector.detectFaces(imageData, {
          timeout: pipelineConfig.fallbackTimeout,
          ...options
        });

        // Calculate processing metrics
        const processingTime = performance.now() - startTime;
        updateMetrics(processingTime, faces);

        // Create standardized result
        const result = createFaceDetectionResult({
          timestamp: Date.now(),
          source: 'mediapipe_face_pipeline',
          faces: faces.map(face => ({
            ...face,
            // Ensure compatibility with existing face detection format
            box: face.boundingBox,
            landmarks: face.landmarks || [],
            confidence: face.score
          })),
          metadata: {
            processingTime,
            frameCount: state.frameCount,
            backend: 'mediapipe',
            detectorStatus: state.detector.getStatus(),
            performance: {
              fps: calculateFPS(processingTime),
              latency: processingTime,
              facesDetected: faces.length
            }
          }
        });

        return result;

      } catch (error) {
        const processingTime = performance.now() - startTime;
        updateMetrics(processingTime, [], false);
        
        console.warn('MediaPipe face detection failed:', error);
        
        // Return error result instead of throwing
        return createFaceDetectionResult({
          timestamp: Date.now(),
          source: 'mediapipe_face_pipeline',
          faces: [],
          error: error.message,
          metadata: {
            processingTime,
            frameCount: state.frameCount,
            error: true
          }
        });
        
      } finally {
        state.isProcessing = false;
        state.metrics.lastProcessingTime = performance.now() - startTime;
      }
    }, 'mediapipe_face_pipeline', 'process');
  };

  // Update performance metrics
  const updateMetrics = (processingTime, faces, success = true) => {
    state.metrics.totalDetections++;
    
    if (success) {
      state.metrics.successfulDetections++;
      
      // Update average latency
      const total = state.metrics.totalDetections;
      state.metrics.averageLatency = 
        (state.metrics.averageLatency * (total - 1) + processingTime) / total;
      
      // Update average confidence
      if (faces.length > 0) {
        const avgConfidence = faces.reduce((sum, face) => sum + face.score, 0) / faces.length;
        state.metrics.averageConfidence = 
          (state.metrics.averageConfidence * (total - 1) + avgConfidence) / total;
      }
    }
    
    // Update processing rate
    const now = performance.now();
    if (state.lastFrameTime > 0) {
      const timeDiff = now - state.lastFrameTime;
      const fps = 1000 / timeDiff;
      state.metrics.frameProcessingRate = 
        (state.metrics.frameProcessingRate * 0.9) + (fps * 0.1); // Moving average
    }
    state.lastFrameTime = now;
  };

  // Calculate effective FPS
  const calculateFPS = (processingTime) => {
    return Math.min(1000 / processingTime, pipelineConfig.targetFPS);
  };

  // Get pipeline health status
  const getHealthStatus = () => {
    const detectorStatus = state.detector?.getStatus();
    const isHealthy = state.isInitialized && 
                     detectorStatus?.initialized &&
                     state.metrics.successfulDetections > 0;

    return {
      healthy: isHealthy,
      runtime: state.runtime,
      backend: 'mediapipe',
      detector: detectorStatus || {},
      performance: {
        averageLatency: state.metrics.averageLatency,
        frameRate: state.metrics.frameProcessingRate,
        successRate: state.metrics.totalDetections > 0 ? 
          state.metrics.successfulDetections / state.metrics.totalDetections : 0
      },
      lastProcessingTime: state.metrics.lastProcessingTime
    };
  };

  // Check if pipeline is initialized
  const isInitialized = () => state.isInitialized;

  // Get performance metrics
  const getPerformanceMetrics = () => ({
    ...state.metrics,
    isProcessing: state.isProcessing,
    frameCount: state.frameCount,
    effectiveFPS: state.metrics.frameProcessingRate,
    targetFPS: pipelineConfig.targetFPS
  });

  // Update pipeline configuration
  const updateConfig = (newConfig) => {
    Object.assign(pipelineConfig, newConfig);
    
    if (state.detector && state.detector.updateConfig) {
      state.detector.updateConfig(newConfig);
    }
  };

  // Cleanup pipeline resources
  const cleanup = async () => {
    try {
      if (state.detector) {
        await state.detector.cleanup();
        state.detector = null;
      }

      // Reset state
      state.isInitialized = false;
      state.isProcessing = false;
      state.frameCount = 0;
      state.lastFrameTime = 0;

      console.log('ðŸ§¹ MediaPipe face pipeline cleaned up');

    } catch (error) {
      console.warn('MediaPipe face pipeline cleanup error:', error);
    }
  };

  // Create standard pipeline interface
  const basePipeline = createPipeline({
    name: 'mediapipe-face',
    capabilities: [
      Capability.FACE_DETECTION,
      Capability.FACE_LANDMARKS,
      Capability.REAL_TIME_PROCESSING
    ],
    
    // Core methods
    initialize,
    process,
    cleanup,
    getHealthStatus,
    isInitialized,
    getPerformanceMetrics,

    // Performance profile (much better than TensorFlow.js)
    performance: createPerformanceProfile({
      fps: 60, // Higher FPS due to lighter weight
      latency: '5-50ms', // Much lower latency
      modelSize: '5MB', // 99% reduction from 635MB
      cpuUsage: 'low', // Lower CPU usage
      memoryUsage: 'low', // Lower memory usage
      batteryImpact: 'low', // Better battery life
      networkUsage: 'low'
    })
  });

  // Extended interface for MediaPipe-specific features
  return {
    ...basePipeline,
    
    // MediaPipe specific methods
    updateConfig,
    getDetector: () => state.detector,
    
    // Configuration access
    getConfiguration: () => ({ ...pipelineConfig }),
    
    // Statistics
    getStats: () => ({
      ...state.metrics,
      frameCount: state.frameCount,
      skippedFrames: Math.floor(state.frameCount * (1 - 1/pipelineConfig.processEveryNthFrame))
    }),

    // Pipeline metadata
    version: '1.0.0',
    type: 'mediapipe_face_detection',
    backend: 'mediapipe'
  };
};

// Factory function for pipeline registration
export const createMediaPipeFacePipelineFactory = () => ({
  name: 'mediapipe-face',
  description: 'Lightweight MediaPipe face detection (replaces TensorFlow.js)',
  capabilities: [
    Capability.FACE_DETECTION,
    Capability.FACE_LANDMARKS, 
    Capability.REAL_TIME_PROCESSING
  ],
  create: createMediaPipeFacePipeline,
  requiresHardware: false,
  supportsRealtime: true,
  supportsBrowser: true,
  supportsNode: true,
  lightweight: true, // New flag for lightweight pipelines
  replaces: ['blazeface-hybrid'], // Indicates what this replaces
  sizeReduction: '99%' // Marketing info
});

// Export configuration factory for external use
export { createMediaPipeFaceConfig };