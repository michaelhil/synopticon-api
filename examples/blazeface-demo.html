<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Synopticon API - BlazeFace Demo</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 0;
            padding: 20px;
            background: #1a1a1a;
            color: #fff;
        }
        
        .container {
            max-width: 1200px;
            margin: 0 auto;
        }
        
        .demo-section {
            display: flex;
            gap: 20px;
            margin-bottom: 30px;
        }
        
        .video-container {
            position: relative;
        }
        
        .canvas-3d-container {
            position: relative;
            margin-left: 20px;
        }
        
        #canvas-3d {
            border: 2px solid #333;
            border-radius: 8px;
            background: #000;
        }
        
        .canvas-3d-controls {
            position: absolute;
            top: 10px;
            left: 10px;
            background: rgba(0, 0, 0, 0.7);
            padding: 8px 12px;
            border-radius: 5px;
            color: #fff;
            font-size: 12px;
        }
        
        .canvas-3d-title {
            font-weight: bold;
            color: #4CAF50;
            margin-bottom: 4px;
        }
        
        .canvas-3d-info {
            color: #bbb;
            font-family: monospace;
        }
        
        .calibrate-button {
            background: #4CAF50;
            color: white;
            border: none;
            padding: 6px 12px;
            border-radius: 4px;
            cursor: pointer;
            font-size: 11px;
            margin-top: 8px;
            transition: background 0.2s;
            display: block;
        }
        
        .calibrate-button:hover {
            background: #45a049;
        }
        
        .calibrate-button:active {
            background: #3d8b40;
            transform: translateY(1px);
        }
        
        #video {
            border: 2px solid #333;
            border-radius: 8px;
        }
        
        #canvas {
            border: 2px solid #333;
            border-radius: 8px;
        }
        
        #overlay {
            position: absolute;
            top: 0;
            left: 0;
            pointer-events: none;
            border: 2px solid transparent;
        }
        
        .controls {
            margin: 20px 0;
        }
        
        button {
            padding: 10px 20px;
            margin: 5px;
            border: none;
            border-radius: 5px;
            background: #4CAF50;
            color: white;
            cursor: pointer;
            font-size: 16px;
        }
        
        button:disabled {
            background: #666;
            cursor: not-allowed;
        }
        
        button.danger {
            background: #f44336;
        }
        
        .help-button {
            background: #2196F3 !important;
            border-radius: 50% !important;
            width: 40px !important;
            height: 40px !important;
            font-size: 18px !important;
            font-weight: bold !important;
            padding: 0 !important;
            margin-left: 15px !important;
        }
        
        .canvas-toggles {
            display: flex;
            gap: 20px;
            margin-top: 15px;
            align-items: center;
        }
        
        .toggle-switch {
            position: relative;
            display: flex;
            align-items: center;
            cursor: pointer;
            user-select: none;
        }
        
        .toggle-switch input {
            opacity: 0;
            width: 0;
            height: 0;
        }
        
        .toggle-slider {
            position: relative;
            width: 50px;
            height: 24px;
            background: #666;
            border-radius: 24px;
            transition: 0.3s;
            margin-right: 10px;
        }
        
        .toggle-slider:before {
            position: absolute;
            content: "";
            height: 18px;
            width: 18px;
            left: 3px;
            bottom: 3px;
            background: white;
            border-radius: 50%;
            transition: 0.3s;
        }
        
        .toggle-switch input:checked + .toggle-slider {
            background: #4CAF50;
        }
        
        .toggle-switch input:checked + .toggle-slider:before {
            transform: translateX(26px);
        }
        
        .toggle-label {
            color: #fff;
            font-size: 14px;
            font-weight: 500;
        }
        
        .status {
            background: #333;
            padding: 15px;
            border-radius: 8px;
            margin: 20px 0;
        }
        
        .metrics {
            background: #333;
            padding: 15px;
            border-radius: 8px;
            margin: 20px 0;
        }
        
        .metrics-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(150px, 1fr));
            gap: 15px;
            margin-top: 10px;
        }
        
        .metric-card {
            background: #444;
            padding: 12px;
            border-radius: 6px;
            text-align: center;
            border-left: 4px solid #4CAF50;
        }
        
        .metric-label {
            font-size: 12px;
            color: #bbb;
            margin-bottom: 5px;
            font-weight: 500;
        }
        
        .metric-value {
            font-size: 18px;
            font-weight: bold;
            color: #fff;
            font-family: monospace;
        }
        
        .debug {
            background: #222;
            padding: 15px;
            border-radius: 8px;
            font-family: monospace;
            font-size: 14px;
            max-height: 300px;
            overflow-y: auto;
            margin: 20px 0;
        }
        
        .modal {
            display: none;
            position: fixed;
            z-index: 1000;
            left: 0;
            top: 0;
            width: 100%;
            height: 100%;
            background-color: rgba(0,0,0,0.7);
            backdrop-filter: blur(3px);
        }
        
        .modal-content {
            background-color: #333;
            margin: 5% auto;
            padding: 0;
            border-radius: 10px;
            width: 80%;
            max-width: 800px;
            max-height: 85vh;
            overflow-y: auto;
            color: #fff;
            box-shadow: 0 4px 20px rgba(0,0,0,0.5);
        }
        
        .modal-header {
            background: #444;
            padding: 20px;
            border-radius: 10px 10px 0 0;
            display: flex;
            justify-content: space-between;
            align-items: center;
        }
        
        .modal-header h2 {
            margin: 0;
            color: #4CAF50;
        }
        
        .close {
            color: #aaa;
            font-size: 28px;
            font-weight: bold;
            cursor: pointer;
            padding: 5px 10px;
            border-radius: 5px;
            transition: all 0.2s;
        }
        
        .close:hover {
            color: #fff;
            background: #f44336;
        }
        
        .modal-body {
            padding: 30px;
            line-height: 1.6;
        }
        
        .modal-body h3 {
            color: #4CAF50;
            margin-top: 30px;
            margin-bottom: 15px;
        }
        
        .modal-body h3:first-child {
            margin-top: 0;
        }
        
        .modal-body ul, .modal-body ol {
            padding-left: 25px;
        }
        
        .modal-body li {
            margin-bottom: 8px;
        }
        
        .modal-body strong {
            color: #4CAF50;
        }
        
        .tech-note {
            background: #2c2c2c;
            border-left: 4px solid #2196F3;
            padding: 15px;
            margin: 20px 0;
            border-radius: 5px;
            font-style: italic;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Synopticon API - BlazeFace Pipeline</h1>
        <p><em>synopticon-api: an open-source platform for real-time multi-modal behavioral analysis and sensor synchronization</em></p>
        
        <div class="demo-section">
            <div class="video-container">
                <video id="video" width="640" height="480" autoplay muted></video>
                <canvas id="overlay" width="640" height="480"></canvas>
            </div>
            <div class="canvas-3d-container">
                <canvas id="canvas-3d" width="640" height="480"></canvas>
                <div class="canvas-3d-controls">
                    <div class="canvas-3d-title">3D Face Analysis</div>
                    <div class="canvas-3d-info" id="canvas-3d-info">Initializing...</div>
                    <button id="calibrate-btn" class="calibrate-button">Calibrate</button>
                </div>
            </div>
        </div>
        
        <div class="controls">
            <button id="toggle-btn">Start Camera & Detection</button>
            <button id="help-btn" class="help-button">?</button>
            <div class="canvas-toggles">
                <label class="toggle-switch">
                    <input type="checkbox" id="toggle-2d" checked>
                    <span class="toggle-slider"></span>
                    <span class="toggle-label">2D Overlay</span>
                </label>
                <label class="toggle-switch">
                    <input type="checkbox" id="toggle-3d" checked>
                    <span class="toggle-slider"></span>
                    <span class="toggle-label">3D Visualization</span>
                </label>
            </div>
        </div>
        
        <div class="status">
            <h3>Status</h3>
            <div id="status-content">Initializing...</div>
        </div>
        
        <div class="metrics">
            <h3>Real-time Metrics</h3>
            <div class="metrics-grid">
                <div class="metric-card">
                    <div class="metric-label">Processing Time</div>
                    <div id="processing-time" class="metric-value"> 0.0ms</div>
                </div>
                <div class="metric-card">
                    <div class="metric-label">Current FPS</div>
                    <div id="current-fps" class="metric-value"> 0.0</div>
                </div>
                <div class="metric-card">
                    <div class="metric-label">Average FPS</div>
                    <div id="average-fps" class="metric-value"> 0.0</div>
                </div>
                <div class="metric-card">
                    <div class="metric-label">Faces Detected</div>
                    <div id="face-count" class="metric-value">0</div>
                </div>
                <div class="metric-card">
                    <div class="metric-label">Avg Confidence</div>
                    <div id="avg-confidence" class="metric-value"> 0.0%</div>
                </div>
                <div class="metric-card">
                    <div class="metric-label">Landmarks Found</div>
                    <div id="landmarks-count" class="metric-value">0/0</div>
                </div>
            </div>
        </div>
        
        <div class="debug">
            <h3>Debug Log</h3>
            <div id="debug-content"></div>
        </div>
    </div>
    
    <!-- Help Modal -->
    <div id="help-modal" class="modal">
        <div class="modal-content">
            <div class="modal-header">
                <h2>How Face Detection Works</h2>
                <span class="close">&times;</span>
            </div>
            <div class="modal-body">
                <h3>ðŸŽ¯ What You're Seeing</h3>
                <p>This demo uses <strong>computer vision</strong> to detect and analyze human faces in real-time. The green boxes show detected faces, red dots mark facial landmarks, and the metrics track performance.</p>
                
                <h3>ðŸ§  BlazeFace: The AI Model</h3>
                <p><strong>BlazeFace</strong> is Google's lightweight neural network designed for mobile and web applications. It's optimized for speed while maintaining accuracy:</p>
                <ul>
                    <li><strong>Ultra-fast</strong>: Processes frames in 5-15ms (vs 25-50ms for alternatives)</li>
                    <li><strong>Compact</strong>: Only 150KB model size (15x smaller than competitors)</li>
                    <li><strong>Accurate</strong>: 94-97% detection rate on standard faces</li>
                    <li><strong>Web-native</strong>: Runs entirely in your browser using TensorFlow.js</li>
                </ul>
                
                <h3>ðŸ“Š Processing Pipeline</h3>
                <p>Each video frame goes through these steps:</p>
                <ol>
                    <li><strong>Frame Capture</strong>: Your camera provides 30 frames per second</li>
                    <li><strong>Preprocessing</strong>: Frame resized to 128x128 pixels for AI model</li>
                    <li><strong>Neural Network</strong>: BlazeFace analyzes the image for face patterns</li>
                    <li><strong>Post-processing</strong>: Results scaled back to original video size</li>
                    <li><strong>Visualization</strong>: Boxes and landmarks drawn as overlay</li>
                </ol>
                
                <h3>ðŸŽ¯ Facial Landmarks Explained</h3>
                <p><strong>Landmarks</strong> are specific anatomical points on faces that the AI identifies:</p>
                <ul>
                    <li><strong>Eyes</strong>: Left and right eye centers (2 points)</li>
                    <li><strong>Nose</strong>: Nose tip (1 point)</li>
                    <li><strong>Mouth</strong>: Left corner, center, right corner (3 points)</li>
                </ul>
                <p>These 6 landmark points enable applications like head pose estimation, face alignment, and emotion recognition.</p>
                
                <h3>âš¡ Performance Metrics</h3>
                <ul>
                    <li><strong>Processing Time</strong>: How long each frame takes to analyze</li>
                    <li><strong>FPS (Frames Per Second)</strong>: Speed of processing (higher = smoother)</li>
                    <li><strong>Confidence</strong>: AI's certainty that detected regions are actually faces</li>
                    <li><strong>Landmarks</strong>: Number of facial points successfully identified</li>
                </ul>
                
                <h3>ðŸ”’ Privacy & Security</h3>
                <p><strong>Your privacy is protected</strong>:</p>
                <ul>
                    <li>All processing happens <strong>locally in your browser</strong></li>
                    <li><strong>No video data</strong> is sent to any server</li>
                    <li><strong>No images are stored</strong> - each frame is processed and discarded</li>
                    <li>Camera access requires <strong>explicit permission</strong></li>
                </ul>
                
                <h3>ðŸš€ Real-world Applications</h3>
                <p>Face detection technology powers:</p>
                <ul>
                    <li><strong>Video Calling</strong>: Auto-focus, background blur, lighting adjustment</li>
                    <li><strong>Photography</strong>: Auto-focus on faces, smile detection</li>
                    <li><strong>Security</strong>: Access control, surveillance systems</li>
                    <li><strong>Entertainment</strong>: AR filters, face swapping, emotion recognition</li>
                    <li><strong>Accessibility</strong>: Eye-gaze control, facial expression interfaces</li>
                </ul>
                
                <div class="tech-note">
                    <strong>ðŸ’¡ Tech Note:</strong> This demo runs entirely on your device's GPU using WebGL, making it fast and private. The AI model was trained on millions of diverse faces to work across different ethnicities, ages, and lighting conditions.
                </div>
            </div>
        </div>
    </div>

    <script type="module">
        import * as tf from '@tensorflow/tfjs';
        import * as blazeface from '@tensorflow-models/blazeface';
        import * as THREE from 'https://unpkg.com/three@0.157.0/build/three.module.js';

        let model = null;
        let video = null;
        let overlayCanvas = null;
        let overlayCtx = null;
        let animationFrame = null;
        let stream = null;
        let isDetecting = false;
        
        // Metrics tracking with circular buffers for performance
        let frameCount = 0;
        let startTime = null;
        let lastFrameTime = null;
        
        // Circular buffers for better performance (no push/shift)
        const HISTORY_SIZE = 30;
        let fpsHistory = new Float32Array(HISTORY_SIZE);
        let processingTimes = new Float32Array(HISTORY_SIZE);
        let fpsIndex = 0;
        let processingIndex = 0;
        let fpsCount = 0;
        let processingCount = 0;
        
        // Display state for threshold-based updates
        let displayState = {
            processingTime: 0,
            currentFPS: 0,
            averageFPS: 0,
            faceCount: 0,
            avgConfidence: 0,
            landmarksCount: '0/0'
        };
        
        // Cached DOM elements for performance
        let metricElements = null;
        
        // Performance optimization: disable debug logging in production
        const DEBUG_MODE = true; // Set to false for production
        
        // Pre-compiled formatters for better performance
        const formatters = {
            ms: (val) => `${val.toFixed(1).padStart(4, ' ')}ms`,
            fps: (val) => val.toFixed(1).padStart(4, ' '),
            percent: (val) => `${val.toFixed(1).padStart(4, ' ')}%`,
            count: (val) => val.toString()
        };
        
        // Object pool for face detection results to reduce GC pressure
        const objectPool = {
            faces: [],
            maxPoolSize: 20,
            
            getFace() {
                return this.faces.pop() || {
                    id: 0,
                    bbox: [0, 0, 0, 0],
                    confidence: 0,
                    landmarks: []
                };
            },
            
            releaseFace(face) {
                if (this.faces.length < this.maxPoolSize) {
                    // Reset face object for reuse
                    face.id = 0;
                    face.bbox.fill(0);
                    face.confidence = 0;
                    face.landmarks.length = 0;
                    this.faces.push(face);
                }
            },
            
            releaseFaces(facesArray) {
                facesArray.forEach(face => this.releaseFace(face));
            }
        };

        const debugLog = (message) => {
            if (!DEBUG_MODE) return; // Skip debug operations in production
            
            console.log(message);
            const debugContent = document.getElementById('debug-content');
            debugContent.innerHTML += `[${new Date().toLocaleTimeString()}] ${message}<br>`;
            debugContent.scrollTop = debugContent.scrollHeight;
        };

        const setStatus = (message) => {
            document.getElementById('status-content').textContent = message;
            debugLog(`STATUS: ${message}`);
        };
        
        // Helper functions for smooth metric updates
        const shouldUpdateValue = (currentValue, newValue, threshold = 0.5) => {
            return Math.abs(currentValue - newValue) >= threshold;
        };
        
        const updateDisplayIfChanged = (elementId, currentValue, newValue, formatter = null) => {
            if (currentValue !== newValue) {
                const displayValue = formatter ? formatter(newValue) : newValue;
                // Use cached element reference instead of getElementById
                metricElements[elementId].textContent = displayValue;
                return newValue;
            }
            return currentValue;
        };
        
        const updateMetrics = (faces, processingTime) => {
            // Use circular buffer for processing times (no push/shift)
            processingTimes[processingIndex] = processingTime;
            processingIndex = (processingIndex + 1) % HISTORY_SIZE;
            processingCount = Math.min(processingCount + 1, HISTORY_SIZE);
            
            // Calculate FPS with circular buffer
            const now = performance.now();
            if (!startTime) startTime = now;
            if (lastFrameTime) {
                const currentFPS = 1000 / (now - lastFrameTime);
                fpsHistory[fpsIndex] = currentFPS;
                fpsIndex = (fpsIndex + 1) % HISTORY_SIZE;
                fpsCount = Math.min(fpsCount + 1, HISTORY_SIZE);
            }
            lastFrameTime = now;
            frameCount++;
            
            // Only update display if values change significantly (threshold-based updates)
            
            // Processing Time - update if change > 1ms
            if (shouldUpdateValue(displayState.processingTime, processingTime, 1.0)) {
                displayState.processingTime = updateDisplayIfChanged(
                    'processing-time', 
                    displayState.processingTime, 
                    processingTime,
                    formatters.ms
                );
            }
            
            // Current FPS - update if change > 1.0 FPS
            if (fpsCount > 0) {
                const currentFPS = fpsHistory[(fpsIndex - 1 + HISTORY_SIZE) % HISTORY_SIZE];
                if (shouldUpdateValue(displayState.currentFPS, currentFPS, 1.0)) {
                    displayState.currentFPS = updateDisplayIfChanged(
                        'current-fps',
                        displayState.currentFPS,
                        currentFPS,
                        formatters.fps
                    );
                }
            }
            
            // Average FPS - update if change > 0.5 FPS (optimized average calculation)
            if (fpsCount > 5) {
                let sum = 0;
                for (let i = 0; i < fpsCount; i++) {
                    sum += fpsHistory[i];
                }
                const avgFPS = sum / fpsCount;
                if (shouldUpdateValue(displayState.averageFPS, avgFPS, 0.5)) {
                    displayState.averageFPS = updateDisplayIfChanged(
                        'average-fps',
                        displayState.averageFPS,
                        avgFPS,
                        formatters.fps
                    );
                }
            }
            
            // Face Count - always update (discrete values)
            displayState.faceCount = updateDisplayIfChanged(
                'face-count',
                displayState.faceCount,
                faces.length,
                formatters.count
            );
            
            // Average Confidence - update if change > 2%
            if (faces.length > 0) {
                const avgConfidence = (faces.reduce((sum, face) => sum + face.confidence, 0) / faces.length) * 100;
                if (shouldUpdateValue(displayState.avgConfidence, avgConfidence, 2.0)) {
                    displayState.avgConfidence = updateDisplayIfChanged(
                        'avg-confidence',
                        displayState.avgConfidence,
                        avgConfidence,
                        formatters.percent
                    );
                }
            } else {
                displayState.avgConfidence = updateDisplayIfChanged(
                    'avg-confidence',
                    displayState.avgConfidence,
                    0,
                    (val) => `${formatFixed(val, 1, 4)}%`
                );
            }
            
            // Landmarks Count - always update (discrete values)
            const totalLandmarks = faces.reduce((sum, face) => sum + (face.landmarks ? face.landmarks.length : 0), 0);
            const expectedLandmarks = faces.length * 6;
            const landmarksText = `${totalLandmarks}/${expectedLandmarks}`;
            displayState.landmarksCount = updateDisplayIfChanged(
                'landmarks-count',
                displayState.landmarksCount,
                landmarksText
            );
        };
        
        const resetMetrics = () => {
            frameCount = 0;
            startTime = null;
            lastFrameTime = null;
            
            // Reset circular buffers
            fpsHistory.fill(0);
            processingTimes.fill(0);
            fpsIndex = 0;
            processingIndex = 0;
            fpsCount = 0;
            processingCount = 0;
            
            // Reset display state
            displayState = {
                processingTime: 0,
                currentFPS: 0,
                averageFPS: 0,
                faceCount: 0,
                avgConfidence: 0,
                landmarksCount: '0/0'
            };
            
            // Reset display with fixed formatting using cached elements
            if (metricElements) {
                metricElements['processing-time'].textContent = ' 0.0ms';
                metricElements['current-fps'].textContent = ' 0.0';
                metricElements['average-fps'].textContent = ' 0.0';
                metricElements['face-count'].textContent = '0';
                metricElements['avg-confidence'].textContent = ' 0.0%';
                metricElements['landmarks-count'].textContent = '0/0';
            }
        };

        const initializeElements = () => {
            debugLog('Initializing DOM elements...');
            
            video = document.getElementById('video');
            overlayCanvas = document.getElementById('overlay');
            
            overlayCtx = overlayCanvas.getContext('2d');
            
            // Cache metric DOM elements for performance
            metricElements = {
                'processing-time': document.getElementById('processing-time'),
                'current-fps': document.getElementById('current-fps'),
                'average-fps': document.getElementById('average-fps'),
                'face-count': document.getElementById('face-count'),
                'avg-confidence': document.getElementById('avg-confidence'),
                'landmarks-count': document.getElementById('landmarks-count')
            };
            
            debugLog(`Video element: ${!!video}`);
            debugLog(`Overlay element: ${!!overlayCanvas}`);
            debugLog(`2D context: ${!!overlayCtx}`);
            debugLog(`Cached ${Object.keys(metricElements).length} metric elements`);
        };

        const initializeBlazeFace = async () => {
            try {
                setStatus('Loading BlazeFace model...');
                debugLog('Setting TensorFlow.js backend...');
                
                // Set backend to WebGL if available
                await tf.setBackend('webgl');
                debugLog(`TensorFlow.js backend: ${tf.getBackend()}`);
                
                debugLog('Loading BlazeFace model...');
                model = await blazeface.load({
                    inputWidth: 128,
                    inputHeight: 128,
                    maxFaces: 5,
                    iouThreshold: 0.3,
                    scoreThreshold: 0.75
                });
                
                debugLog('âœ… BlazeFace model loaded successfully');
                setStatus('BlazeFace model loaded successfully');
                return true;
                
            } catch (error) {
                debugLog(`âŒ BlazeFace initialization failed: ${error.message}`);
                setStatus('BlazeFace initialization failed');
                throw error;
            }
        };

        const initializeCamera = async () => {
            try {
                setStatus('Requesting camera access...');
                debugLog('Requesting camera stream...');
                
                stream = await navigator.mediaDevices.getUserMedia({
                    video: {
                        width: 640,
                        height: 480,
                        facingMode: 'user'
                    }
                });
                
                video.srcObject = stream;
                
                return new Promise((resolve) => {
                    video.onloadedmetadata = () => {
                        debugLog('âœ… Camera initialized successfully');
                        setStatus('Camera ready');
                        resolve();
                    };
                });
                
            } catch (error) {
                debugLog(`âŒ Camera initialization failed: ${error.message}`);
                setStatus('Camera access denied');
                throw error;
            }
        };

        const detectFaces = async () => {
            if (!model || !video.readyState) return [];
            
            try {
                const predictions = await model.estimateFaces(video, false);
                
                // Use object pool to reduce garbage collection
                const faces = [];
                for (let i = 0; i < predictions.length; i++) {
                    const prediction = predictions[i];
                    const face = objectPool.getFace();
                    
                    face.id = i;
                    if (prediction.topLeft) {
                        face.bbox[0] = prediction.topLeft[0];
                        face.bbox[1] = prediction.topLeft[1];
                        face.bbox[2] = prediction.bottomRight[0] - prediction.topLeft[0];
                        face.bbox[3] = prediction.bottomRight[1] - prediction.topLeft[1];
                    } else {
                        face.bbox[0] = prediction.bbox?.[0] || 0;
                        face.bbox[1] = prediction.bbox?.[1] || 0;
                        face.bbox[2] = prediction.bbox?.[2] || 0;
                        face.bbox[3] = prediction.bbox?.[3] || 0;
                    }
                    face.confidence = prediction.probability ? prediction.probability[0] : 0.9;
                    face.landmarks = prediction.landmarks || [];
                    
                    faces.push(face);
                }
                
                return faces;
            } catch (error) {
                debugLog(`Face detection error: ${error.message}`);
                return [];
            }
        };


        const drawDetections = (faces) => {
            if (!overlayCtx) return;
            
            // Clear overlay
            overlayCtx.clearRect(0, 0, overlayCanvas.width, overlayCanvas.height);
            
            if (faces.length === 0) return; // Early return for performance
            
            // Batch canvas state changes for performance
            overlayCtx.save();
            
            // Draw all bounding boxes first (minimize state changes)
            overlayCtx.strokeStyle = '#00ff00';
            overlayCtx.lineWidth = 2;
            overlayCtx.beginPath();
            faces.forEach((face) => {
                const [x, y, width, height] = face.bbox;
                overlayCtx.rect(x, y, width, height);
            });
            overlayCtx.stroke();
            
            // Draw all text labels (batch font operations)
            overlayCtx.font = '16px Arial';
            overlayCtx.fillStyle = '#00ff00';
            faces.forEach((face, index) => {
                const [x, y] = face.bbox;
                overlayCtx.fillText(
                    `Face ${index + 1} (${(face.confidence * 100).toFixed(1)}%)`,
                    x, y - 5
                );
            });
            
            // Draw all landmarks (batch fill operations)
            overlayCtx.fillStyle = '#ff0000';
            faces.forEach((face) => {
                if (face.landmarks && face.landmarks.length > 0) {
                    face.landmarks.forEach(landmark => {
                        overlayCtx.fillRect(landmark[0] - 2, landmark[1] - 2, 4, 4);
                    });
                }
            });
            
            overlayCtx.restore();
        };

        const processFrame = async () => {
            // Early returns for performance
            if (!animationFrame) return; // Stop immediately if detection stopped
            if (!model || !video.readyState) {
                requestAnimationFrame(processFrame);
                return;
            }
            
            const startTime = performance.now();
            
            try {
                // Detect faces
                const faces = await detectFaces();
                
                // Draw detections (only if 2D overlay is enabled)
                if (show2DOverlay) {
                    drawDetections(faces);
                }
                
                // Update 3D visualization
                update3DVisualization(faces);
                
                const processingTime = performance.now() - startTime;
                
                // Update metrics
                updateMetrics(faces, processingTime);
                
                // Update status
                if (faces.length > 0) {
                    setStatus(`Detected ${faces.length} face(s) - ${processingTime.toFixed(1)}ms`);
                } else {
                    setStatus(`No faces detected - ${processingTime.toFixed(1)}ms`);
                }
                
                // Release pooled objects to reduce GC pressure
                objectPool.releaseFaces(faces);
                
            } catch (error) {
                debugLog(`Frame processing error: ${error.message}`);
            }
            
            if (animationFrame) {
                requestAnimationFrame(processFrame);
            }
        };

        const toggleDetection = async () => {
            const btn = document.getElementById('toggle-btn');
            
            if (!isDetecting) {
                try {
                    btn.disabled = true;
                    resetMetrics();
                    await initializeCamera();
                    animationFrame = true;
                    processFrame();
                    
                    isDetecting = true;
                    btn.textContent = 'Stop Detection';
                    btn.className = 'danger';
                    btn.disabled = false;
                    
                    debugLog('ðŸŽ¥ Detection started');
                    
                } catch (error) {
                    debugLog(`âŒ Failed to start detection: ${error.message}`);
                    setStatus('Failed to start camera');
                    btn.disabled = false;
                }
            } else {
                animationFrame = null;
                
                if (stream) {
                    stream.getTracks().forEach(track => track.stop());
                    stream = null;
                }
                
                if (overlayCtx) {
                    overlayCtx.clearRect(0, 0, overlayCanvas.width, overlayCanvas.height);
                }
                
                isDetecting = false;
                btn.textContent = 'Start Camera & Detection';
                btn.className = '';
                
                setStatus('Detection stopped');
                debugLog('ðŸ›‘ Detection stopped');
            }
        };


        // 3D System Setup
        let scene3D, camera3D, renderer3D, faceGroup, orientationArrow, wireframeHead;
        let canvas3DEnabled = false;
        let show2DOverlay = true;
        
        // Pose smoothing and tracking stability
        let smoothedPose = { yaw: 0, pitch: 0, roll: 0 };
        let lastValidPose = { yaw: 0, pitch: 0, roll: 0 };
        let lastRawAngles = { yaw: 0, pitch: 0, roll: 0 }; // Track raw angles for continuity
        let calibrationOffset = { yaw: 0, pitch: 0, roll: 0 }; // Calibration offsets
        let poseHistory = [];
        const smoothingFactor = 0.15; // More aggressive smoothing
        const historyLength = 5; // Number of frames to average
        
        // Helper function to maintain angle continuity
        const unwrapAngle = (newAngle, lastAngle) => {
            const diff = newAngle - lastAngle;
            if (Math.abs(diff) > Math.PI) {
                if (diff > Math.PI) {
                    return newAngle - 2 * Math.PI;
                } else {
                    return newAngle + 2 * Math.PI;
                }
            }
            return newAngle;
        };
        
        // Calibration function to reset head to neutral position
        let autoCalibrationDone = false;
        
        const calibrate3DHead = (isAutoCalibration = false) => {
            if (lastValidPose) {
                // Use the last valid pose for calibration - much simpler
                calibrationOffset = {
                    yaw: lastValidPose.yaw + calibrationOffset.yaw, // Add to existing offset
                    pitch: lastValidPose.pitch + calibrationOffset.pitch,
                    roll: lastValidPose.roll + calibrationOffset.roll
                };
                
                // Reset smoothed pose to neutral
                smoothedPose = { yaw: 0, pitch: 0, roll: 0 };
                
                // Immediately set head to neutral position
                wireframeHead.rotation.set(0, 0, 0); // Simple neutral position
                
                if (isAutoCalibration) {
                    autoCalibrationDone = true;
                    debugLog('ðŸŽ¯ Auto-calibrated 3D head to neutral position');
                } else {
                    debugLog('ðŸŽ¯ Manual calibration - 3D head reset to neutral position');
                }
                debugLog(`Calibration offsets: yaw=${calibrationOffset.yaw.toFixed(3)}, pitch=${calibrationOffset.pitch.toFixed(3)}, roll=${calibrationOffset.roll.toFixed(3)}`);
                
                // Update info display
                const info3D = document.getElementById('canvas-3d-info');
                if (info3D) {
                    info3D.innerHTML = isAutoCalibration ? 'Auto-calibrated!<br>Head reset to neutral' : 'Calibrated!<br>Head reset to neutral';
                    setTimeout(() => {
                        if (info3D.innerHTML.includes('calibrated')) {
                            info3D.innerHTML = 'Yaw: 0.0Â°<br>Pitch: 0.0Â°<br>Roll: 0.0Â°';
                        }
                    }, 1000);
                }
                return true;
            }
            return false;
        };
        
        const initialize3DSystem = () => {
            debugLog('ðŸŽ¯ Initializing 3D System...');
            
            const canvas3D = document.getElementById('canvas-3d');
            const info3D = document.getElementById('canvas-3d-info');
            
            // Create Three.js scene
            scene3D = new THREE.Scene();
            scene3D.background = new THREE.Color(0x1a1a1a);
            
            // Create camera
            camera3D = new THREE.PerspectiveCamera(75, canvas3D.width / canvas3D.height, 0.1, 1000);
            camera3D.position.set(0, 0, 300);
            
            // Create renderer
            renderer3D = new THREE.WebGLRenderer({ canvas: canvas3D, antialias: true });
            renderer3D.setSize(canvas3D.width, canvas3D.height);
            renderer3D.shadowMap.enabled = true;
            renderer3D.shadowMap.type = THREE.PCFSoftShadowMap;
            
            // Add lights
            const ambientLight = new THREE.AmbientLight(0x404040, 0.4);
            scene3D.add(ambientLight);
            
            const directionalLight = new THREE.DirectionalLight(0xffffff, 0.8);
            directionalLight.position.set(100, 100, 100);
            directionalLight.castShadow = true;
            scene3D.add(directionalLight);
            
            // Create face group to hold all face-related 3D objects
            faceGroup = new THREE.Group();
            scene3D.add(faceGroup);
            
            // Create orientation arrow - made bigger
            const arrowGeometry = new THREE.ConeGeometry(12, 60, 8);
            const arrowMaterial = new THREE.MeshPhongMaterial({ color: 0x00ff00 });
            orientationArrow = new THREE.Mesh(arrowGeometry, arrowMaterial);
            orientationArrow.rotation.x = -Math.PI / 2; // Point forward
            faceGroup.add(orientationArrow);
            
            // Create proper 3D head model using basic geometry
            const headGroup = new THREE.Group();
            
            // Main head - egg shape (ellipsoid) - made bigger
            const headGeometry = new THREE.SphereGeometry(60, 16, 12);
            headGeometry.scale(0.9, 1.2, 0.8); // Make it head-shaped
            const headMaterial = new THREE.MeshPhongMaterial({ 
                color: 0xffdbac,
                transparent: true,
                opacity: 0.8
            });
            const head = new THREE.Mesh(headGeometry, headMaterial);
            headGroup.add(head);
            
            // Face plane for better orientation reference - made bigger
            const faceGeometry = new THREE.PlaneGeometry(80, 100);
            const faceMaterial = new THREE.MeshPhongMaterial({ 
                color: 0x00aaff,
                wireframe: true,
                transparent: true,
                opacity: 0.3,
                side: THREE.DoubleSide
            });
            const face = new THREE.Mesh(faceGeometry, faceMaterial);
            face.position.set(0, 0, 48); // Position at front of head
            headGroup.add(face);
            
            // Eyes (positioned correctly - above nose) - made bigger
            const eyeGeometry = new THREE.SphereGeometry(6, 8, 8);
            const eyeMaterial = new THREE.MeshPhongMaterial({ color: 0x333333 });
            
            const leftEye = new THREE.Mesh(eyeGeometry, eyeMaterial);
            leftEye.position.set(-18, 12, 48); // Left eye - above nose, on face
            headGroup.add(leftEye);
            
            const rightEye = new THREE.Mesh(eyeGeometry, eyeMaterial);
            rightEye.position.set(18, 12, 48); // Right eye - above nose, on face
            headGroup.add(rightEye);
            
            // Nose (positioned below eyes, pointing forward) - made bigger
            const noseGeometry = new THREE.ConeGeometry(4, 18, 6);
            const noseMaterial = new THREE.MeshPhongMaterial({ 
                color: 0xffdbac,
                transparent: true,
                opacity: 0.9
            });
            const nose = new THREE.Mesh(noseGeometry, noseMaterial);
            nose.position.set(0, -3, 57); // Below eyes, protruding forward
            nose.rotation.x = Math.PI / 2; // Point forward along Z-axis
            headGroup.add(nose);
            
            // Mouth - made bigger (positioned below nose) - fixed orientation
            const mouthGeometry = new THREE.BoxGeometry(24, 4, 8); // Horizontal box instead of cylinder
            const mouthMaterial = new THREE.MeshPhongMaterial({ color: 0x8B0000 });
            const mouth = new THREE.Mesh(mouthGeometry, mouthMaterial);
            mouth.position.set(0, -18, 45); // Below nose
            // No rotation needed - box is naturally horizontal
            headGroup.add(mouth);
            
            // No base rotation - build head correctly from the start
            
            wireframeHead = headGroup;
            faceGroup.add(wireframeHead);
            
            // Add coordinate axes for reference
            const axesHelper = new THREE.AxesHelper(80);
            faceGroup.add(axesHelper);
            
            info3D.textContent = '3D System Ready';
            debugLog('âœ… 3D System initialized');
            
            // Start render loop
            render3D();
        };
        
        const render3D = () => {
            requestAnimationFrame(render3D);
            
            if (canvas3DEnabled && renderer3D) {
                renderer3D.render(scene3D, camera3D);
            }
        };
        
        const calculateFacePose = (landmarks, faceBox) => {
            // Get key facial landmarks (BlazeFace returns 6 landmarks)
            const rightEye = landmarks[0];    // Right eye center
            const leftEye = landmarks[1];     // Left eye center  
            const noseTip = landmarks[2];     // Nose tip
            const mouth = landmarks[3];       // Mouth center
            
            // Calculate face center (between eyes)
            const eyeCenterX = (leftEye[0] + rightEye[0]) / 2;
            const eyeCenterY = (leftEye[1] + rightEye[1]) / 2;
            
            // Eye distance for normalization and stability check
            const eyeDistance = Math.sqrt(
                Math.pow(rightEye[0] - leftEye[0], 2) + 
                Math.pow(rightEye[1] - leftEye[1], 2)
            );
            
            // Stability check - reject poses with very small eye distance
            if (eyeDistance < 20) {
                return lastValidPose;
            }
            
            // Simple, clean angle calculations
            
            // Roll (head tilt) - angle between eyes with continuity
            let roll = Math.atan2(rightEye[1] - leftEye[1], rightEye[0] - leftEye[0]);
            
            // Simple roll continuity - prevent sudden jumps
            if (lastValidPose && lastValidPose.roll !== undefined) {
                const rollDiff = roll - (lastValidPose.roll + calibrationOffset.roll);
                // If the change is more than 90 degrees, it's likely a flip
                if (Math.abs(rollDiff) > Math.PI / 2) {
                    // Adjust by Ï€ to maintain continuity
                    if (rollDiff > Math.PI / 2) {
                        roll -= Math.PI;
                    } else {
                        roll += Math.PI;
                    }
                }
            }
            
            // Yaw (left-right turn) - nose position relative to eye center
            const noseOffsetX = (noseTip[0] - eyeCenterX) / eyeDistance;
            // Clamp to prevent extreme values, multiply for sensitivity
            const yaw = Math.asin(Math.max(-1, Math.min(1, noseOffsetX))) * 1.5;
            
            // Pitch (up-down nod) - back to landmark-based but with better logic
            // Use the vertical positioning of nose and mouth relative to eyes
            const noseY = noseTip[1];
            const mouthY = mouth[1];
            const eyeY = eyeCenterY;
            
            // Calculate relative positions (normalized by eye distance)
            const noseToEyeRatio = (noseY - eyeY) / eyeDistance;
            const mouthToEyeRatio = (mouthY - eyeY) / eyeDistance;
            
            // In neutral position: nose slightly below eyes (~0.1), mouth well below (~0.8)
            // When head tilts up: both ratios decrease (features appear higher relative to eyes)
            // When head tilts down: both ratios increase (features appear lower relative to eyes)
            const expectedNoseRatio = 0.1;
            const expectedMouthRatio = 0.8;
            
            const nosePitchIndicator = (noseToEyeRatio - expectedNoseRatio) * 5.0;
            const mouthPitchIndicator = (mouthToEyeRatio - expectedMouthRatio) * 3.0;
            
            // Combine indicators (mouth is more reliable for large pitch changes)
            const pitch = -(nosePitchIndicator * 0.4 + mouthPitchIndicator * 0.6);
            
            debugLog(`Pitch debug: nose=${noseToEyeRatio.toFixed(3)}, mouth=${mouthToEyeRatio.toFixed(3)}, pitch=${pitch.toFixed(3)}`);
            
            // Apply calibration offsets
            const calibratedPose = {
                yaw: yaw - calibrationOffset.yaw,
                pitch: pitch - calibrationOffset.pitch, 
                roll: roll - calibrationOffset.roll,
                center: [eyeCenterX, eyeCenterY],
                eyeDistance: eyeDistance
            };
            
            // Store as last valid pose
            lastValidPose = calibratedPose;
            return calibratedPose;
        };
        
        const smoothPose = (currentPose, targetPose) => {
            // Simple exponential smoothing - no complex history or flip detection
            return {
                yaw: currentPose.yaw + (targetPose.yaw - currentPose.yaw) * (1 - smoothingFactor),
                pitch: currentPose.pitch + (targetPose.pitch - currentPose.pitch) * (1 - smoothingFactor),
                roll: currentPose.roll + (targetPose.roll - currentPose.roll) * (1 - smoothingFactor)
            };
        };
        
        const update3DVisualization = (faces) => {
            if (!canvas3DEnabled || !faceGroup) return;
            
            const info3D = document.getElementById('canvas-3d-info');
            
            if (faces.length > 0) {
                const face = faces[0]; // Use first detected face
                const landmarks = face.landmarks;
                const pose = calculateFacePose(landmarks, face.bbox);
                
                // Auto-calibration: trigger after stable tracking for 60 frames (~2 seconds at 30fps)
                frameCount++;
                if (!autoCalibrationDone && frameCount > 60) {
                    if (calibrate3DHead(true)) {
                        debugLog(`ðŸŽ¯ Auto-calibration triggered at frame ${frameCount}`);
                    }
                }
                
                // Apply smoothing to reduce jitter
                smoothedPose = smoothPose(smoothedPose, pose);
                
                // Update wireframe head orientation - simple, direct mapping
                wireframeHead.rotation.set(smoothedPose.pitch, smoothedPose.yaw, smoothedPose.roll);
                
                // Update orientation arrow
                orientationArrow.rotation.set(smoothedPose.pitch - Math.PI/2, smoothedPose.yaw, smoothedPose.roll);
                orientationArrow.position.set(0, 0, 45); // Position arrow in front of bigger head
                
                // Update info display
                info3D.innerHTML = `
                    Yaw: ${(smoothedPose.yaw * 180 / Math.PI).toFixed(1)}Â°<br>
                    Pitch: ${(smoothedPose.pitch * 180 / Math.PI).toFixed(1)}Â°<br>
                    Roll: ${(smoothedPose.roll * 180 / Math.PI).toFixed(1)}Â°
                `;
                
                // Make face elements visible
                faceGroup.children.forEach(child => {
                    if (child !== wireframeHead && child !== orientationArrow) return;
                    child.visible = true;
                });
                
            } else {
                // No faces detected - gradually return to neutral position
                smoothedPose = smoothPose(smoothedPose, { yaw: 0, pitch: 0, roll: 0 });
                wireframeHead.rotation.set(smoothedPose.pitch, smoothedPose.yaw, smoothedPose.roll);
                
                info3D.textContent = 'No face detected';
                
                // Hide arrow but keep head visible
                orientationArrow.visible = false;
                wireframeHead.visible = true;
            }
        };
        
        const toggle3DCanvas = () => {
            canvas3DEnabled = !canvas3DEnabled;
            const container = document.querySelector('.canvas-3d-container');
            const toggleCheckbox = document.getElementById('toggle-3d');
            
            if (canvas3DEnabled) {
                container.style.display = 'block';
                toggleCheckbox.checked = true;
                if (!scene3D) {
                    initialize3DSystem();
                }
                debugLog('ðŸŽ¯ 3D Canvas enabled');
            } else {
                container.style.display = 'none';
                toggleCheckbox.checked = false;
                debugLog('ðŸŽ¯ 3D Canvas disabled');
            }
        };
        
        const toggle2DOverlay = () => {
            show2DOverlay = !show2DOverlay;
            const overlayCanvas = document.getElementById('overlay');
            const toggleCheckbox = document.getElementById('toggle-2d');
            
            if (show2DOverlay) {
                overlayCanvas.style.display = 'block';
                toggleCheckbox.checked = true;
                debugLog('ðŸŽ¯ 2D Overlay enabled');
            } else {
                overlayCanvas.style.display = 'none';
                toggleCheckbox.checked = false;
                debugLog('ðŸŽ¯ 2D Overlay disabled');
            }
        };

        // Initialize everything when page loads
        window.addEventListener('load', async () => {
            debugLog('ðŸš€ Initializing BlazeFace Demo...');
            
            // Quick element check
            const requiredElements = ['toggle-btn', 'toggle-2d', 'toggle-3d', 'video', 'overlay'];
            let missingElements = [];
            for (const id of requiredElements) {
                const element = document.getElementById(id);
                debugLog(`Element check - ${id}: ${!!element}`);
                if (!element) {
                    debugLog(`âŒ CRITICAL: Element ${id} not found!`);
                    missingElements.push(id);
                }
            }
            
            if (missingElements.length > 0) {
                const errorMsg = `Missing elements: ${missingElements.join(', ')}`;
                debugLog(`âŒ FATAL: ${errorMsg}`);
                setStatus(`Initialization failed: ${errorMsg}`);
                return;
            }
            
            try {
                debugLog('ðŸ”§ Starting initialization...');
                initializeElements();
                debugLog('âœ… Elements initialized');
                
                await initializeBlazeFace();
                debugLog('âœ… BlazeFace initialized');
                
                // Set up event listeners
                debugLog('ðŸ”§ Setting up event listeners...');
                document.getElementById('toggle-btn').onclick = toggleDetection;
                document.getElementById('toggle-2d').onchange = toggle2DOverlay;
                document.getElementById('toggle-3d').onchange = toggle3DCanvas;
                debugLog('âœ… Basic event listeners set up');
                
                // Set up calibrate button if it exists (non-critical)
                try {
                    const calibrateBtn = document.getElementById('calibrate-btn');
                    if (calibrateBtn) {
                        calibrateBtn.onclick = () => calibrate3DHead(false);
                        debugLog('âœ… Calibrate button event listener set up');
                    } else {
                        debugLog('âš ï¸ Calibrate button not found (this is OK)');
                    }
                } catch (e) {
                    debugLog('âš ï¸ Calibrate button setup failed (non-critical)');
                }
                
                // Initialize toggle states based on checkbox state
                debugLog('ðŸ”§ Setting up toggle states...');
                const toggle2DCheckbox = document.getElementById('toggle-2d');
                const toggle3DCheckbox = document.getElementById('toggle-3d');
                
                if (!toggle2DCheckbox || !toggle3DCheckbox) {
                    debugLog('âŒ Toggle checkboxes not found!');
                    debugLog(`2D checkbox: ${!!toggle2DCheckbox}, 3D checkbox: ${!!toggle3DCheckbox}`);
                }
                
                show2DOverlay = toggle2DCheckbox ? toggle2DCheckbox.checked : true;
                canvas3DEnabled = toggle3DCheckbox ? toggle3DCheckbox.checked : true;
                debugLog(`Toggle states: 2D=${show2DOverlay}, 3D=${canvas3DEnabled}`);
                
                // Initialize 3D system if enabled
                if (canvas3DEnabled) {
                    try {
                        debugLog('ðŸ”§ Initializing 3D system...');
                        initialize3DSystem();
                        debugLog('âœ… 3D system initialized');
                        // Auto-calibration will happen automatically once tracking is stable
                    } catch (e) {
                        debugLog(`âŒ 3D system initialization failed: ${e.message}`);
                        canvas3DEnabled = false; // Disable 3D to continue with 2D only
                    }
                }
                
                // Set initial canvas visibility
                debugLog('ðŸ”§ Setting canvas visibility...');
                const overlayCanvas = document.getElementById('overlay');
                const canvas3DContainer = document.querySelector('.canvas-3d-container');
                
                if (overlayCanvas) {
                    overlayCanvas.style.display = show2DOverlay ? 'block' : 'none';
                    debugLog(`âœ… 2D overlay set to ${show2DOverlay ? 'visible' : 'hidden'}`);
                }
                
                if (canvas3DContainer) {
                    canvas3DContainer.style.display = canvas3DEnabled ? 'block' : 'none';
                    debugLog(`âœ… 3D container set to ${canvas3DEnabled ? 'visible' : 'hidden'}`);
                }
                
                // Help modal functionality
                const modal = document.getElementById('help-modal');
                const helpBtn = document.getElementById('help-btn');
                const closeBtn = document.querySelector('.close');
                
                helpBtn.onclick = () => {
                    modal.style.display = 'block';
                    document.body.style.overflow = 'hidden'; // Prevent background scrolling
                };
                
                closeBtn.onclick = () => {
                    modal.style.display = 'none';
                    document.body.style.overflow = 'auto';
                };
                
                // Close modal when clicking outside
                window.onclick = (event) => {
                    if (event.target === modal) {
                        modal.style.display = 'none';
                        document.body.style.overflow = 'auto';
                    }
                };
                
                debugLog('âœ… Demo initialized successfully');
                setStatus('Ready to start detection');
                
                // Auto-start detection
                debugLog('ðŸš€ Auto-starting detection...');
                setTimeout(() => toggleDetection(), 500); // Small delay to ensure UI is ready
                
            } catch (error) {
                debugLog(`âŒ Initialization failed: ${error.message}`);
                setStatus('Initialization failed');
            }
        });
    </script>
</body>
</html>