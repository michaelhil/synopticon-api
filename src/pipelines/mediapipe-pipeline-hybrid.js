/**
 * Hybrid MediaPipe Face Mesh Pipeline Implementation
 * Works in both browser and Node.js environments with graceful fallback
 */

import { createPipeline } from '../core/pipeline.js';
import { 
  Capability,
  createPerformanceProfile,
  createFaceResult,
  createPose6DOF,
  createAnalysisResult
} from '../core/types.js';
import { 
  detectRuntime, 
  checkFeatures,
  createUniversalCanvas,
  loadTensorFlow,
  imageToTensor
} from '../utils/runtime-detector.js';
import { createMediaPipeLoader } from '../utils/dependency-loader.js';

// MediaPipe configuration
const createMediaPipeConfig = (config = {}) => ({
  maxNumFaces: config.maxNumFaces || 1,
  refineLandmarks: config.refineLandmarks !== false,
  minDetectionConfidence: config.minDetectionConfidence || 0.5,
  minTrackingConfidence: config.minTrackingConfidence || 0.5,
  modelComplexity: config.modelComplexity || 1,
  ...config
});

// Convert MediaPipe landmarks to standard format
const mediaPipeToFaceResult = (faceLandmarks, index = 0) => {
  if (!faceLandmarks || faceLandmarks.length === 0) {
    return null;
  }

  // Calculate bounding box from landmarks
  let minX = Infinity, minY = Infinity, maxX = -Infinity, maxY = -Infinity;
  faceLandmarks.forEach(pt => {
    minX = Math.min(minX, pt.x);
    minY = Math.min(minY, pt.y);
    maxX = Math.max(maxX, pt.x);
    maxY = Math.max(maxY, pt.y);
  });

  const bbox = {
    x: minX,
    y: minY,
    width: maxX - minX,
    height: maxY - minY
  };

  // Extract key landmarks for pose estimation
  const noseTip = faceLandmarks[1];
  const leftEye = faceLandmarks[33];
  const rightEye = faceLandmarks[263];
  const leftMouth = faceLandmarks[61];
  const rightMouth = faceLandmarks[291];
  const chin = faceLandmarks[152];

  // Estimate 6DOF pose (simplified)
  const pose6DOF = createPose6DOF({
    yaw: 0, // Would need proper calculation
    pitch: 0,
    roll: 0,
    x: noseTip?.x || 0,
    y: noseTip?.y || 0,
    z: noseTip?.z || 0,
    confidence: 0.8
  });

  // Convert landmarks to standard format
  const landmarks = faceLandmarks.map((pt, idx) => ({
    x: pt.x,
    y: pt.y,
    z: pt.z || 0,
    confidence: pt.visibility || 0.9,
    name: `landmark_${idx}`
  }));

  return createFaceResult({
    id: `face_${index}_${Date.now()}`,
    boundingBox: bbox,
    confidence: 0.9,
    landmarks,
    pose: null, // Use 6DOF instead
    pose6DOF,
    expression: null, // Would need separate model
    eyes: {
      left: { 
        position: leftEye ? { x: leftEye.x, y: leftEye.y } : null,
        openness: 1.0 
      },
      right: { 
        position: rightEye ? { x: rightEye.x, y: rightEye.y } : null,
        openness: 1.0 
      }
    },
    quality: {
      brightness: 1.0,
      sharpness: 0.9,
      occlusion: 0
    }
  });
};

// Advanced Node.js fallback with TensorFlow.js-based detection
const createAdvancedNodeFallback = async () => {
  let tf = null;
  let blazefaceModel = null;
  
  try {
    tf = await loadTensorFlow();
    if (tf) {
      // Try to load a simple face detection model
      const blazeface = await import('@tensorflow-models/blazeface');
      blazefaceModel = await blazeface.load();
      console.log('âœ… Advanced Node.js fallback with BlazeFace initialized');
    }
  } catch (error) {
    console.warn('âš ï¸ Advanced fallback failed, using basic detection:', error.message);
  }
  
  return {
    process: async (input) => {
      const startTime = Date.now();
      
      // If we have TensorFlow.js and BlazeFace, use real detection
      if (tf && blazefaceModel) {
        try {
          const inputTensor = await imageToTensor(input, tf);
          const predictions = await blazefaceModel.estimateFaces(inputTensor, false);
          inputTensor.dispose();
          
          const faces = predictions.map((prediction, index) => {
            const { topLeft, bottomRight, landmarks, probability } = prediction;
            
            // Generate 468 landmarks estimate from BlazeFace's 6 landmarks
            const estimatedLandmarks = generateLandmarkEstimate(landmarks);
            
            return createFaceResult({
              id: `advanced_face_${index}`,
              boundingBox: {
                x: topLeft[0],
                y: topLeft[1],
                width: bottomRight[0] - topLeft[0],
                height: bottomRight[1] - topLeft[1]
              },
              confidence: probability[0],
              landmarks: estimatedLandmarks,
              pose6DOF: estimatePose6DOF(landmarks, topLeft, bottomRight)
            });
          });
          
          return createAnalysisResult({
            faces,
            metadata: {
              processingTime: Date.now() - startTime,
              frameTimestamp: Date.now(),
              pipelineName: 'mediapipe-advanced-fallback',
              backend: 'tensorflow-blazeface',
              runtime: 'node',
              fallbackReason: 'mediapipe-unavailable'
            }
          });
        } catch (error) {
          console.warn('Advanced fallback processing failed:', error);
        }
      }
      
      // Basic geometric fallback if advanced detection fails
      return createAnalysisResult({
        faces: [{
          ...createFaceResult({
            id: 'geometric_face_0',
            boundingBox: { x: 160, y: 120, width: 320, height: 240 }, // Center region
            confidence: 0.3,
            landmarks: generateBasicLandmarks(),
            pose6DOF: createPose6DOF({ 
              yaw: 0, pitch: 0, roll: 0, 
              x: 320, y: 240, z: 0, 
              confidence: 0.3 
            })
          })
        }],
        metadata: {
          processingTime: Date.now() - startTime,
          frameTimestamp: Date.now(),
          pipelineName: 'mediapipe-basic-fallback',
          backend: 'geometric',
          runtime: 'node',
          fallbackReason: 'no-models-available'
        }
      });
    }
  };
};

// Generate landmark estimate from BlazeFace landmarks
const generateLandmarkEstimate = (blazeLandmarks) => {
  if (!blazeLandmarks || blazeLandmarks.length < 6) {
    return generateBasicLandmarks();
  }
  
  // Use BlazeFace landmarks to estimate MediaPipe-style 468 landmarks
  const [rightEye, leftEye, nose, mouth, rightEar, leftEar] = blazeLandmarks;
  const landmarks = [];
  
  // Generate key facial landmarks based on BlazeFace points
  // This is a simplified estimation - real MediaPipe has 468 points
  for (let i = 0; i < 468; i++) {
    let x, y, z = 0;
    
    if (i < 17) { // Face contour
      const progress = i / 16;
      x = rightEar[0] + (leftEar[0] - rightEar[0]) * progress;
      y = rightEar[1] + (leftEar[1] - rightEar[1]) * progress * 0.5;
    } else if (i < 27) { // Right eyebrow
      x = rightEye[0] + (i - 17) * 5;
      y = rightEye[1] - 10;
    } else if (i < 36) { // Left eyebrow  
      x = leftEye[0] - (i - 27) * 5;
      y = leftEye[1] - 10;
    } else if (i < 48) { // Eyes
      x = i < 42 ? rightEye[0] : leftEye[0];
      y = i < 42 ? rightEye[1] : leftEye[1];
    } else if (i < 68) { // Mouth
      x = mouth[0] + (i - 48) * 3 - 30;
      y = mouth[1] + Math.sin((i - 48) / 10) * 5;
    } else { // Additional face points
      x = nose[0] + Math.random() * 40 - 20;
      y = nose[1] + Math.random() * 40 - 20;
    }
    
    landmarks.push({
      x: x || 0,
      y: y || 0, 
      z,
      confidence: 0.7,
      name: `landmark_${i}`
    });
  }
  
  return landmarks;
};

// Generate basic landmarks when no face detection available
const generateBasicLandmarks = () => {
  const landmarks = [];
  const centerX = 320, centerY = 240;
  
  // Create a basic face landmark set
  for (let i = 0; i < 468; i++) {
    landmarks.push({
      x: centerX + Math.sin(i / 10) * 50,
      y: centerY + Math.cos(i / 10) * 50,
      z: 0,
      confidence: 0.3,
      name: `basic_landmark_${i}`
    });
  }
  
  return landmarks;
};

// Estimate 6DOF pose from face landmarks
const estimatePose6DOF = (landmarks, topLeft, bottomRight) => {
  if (!landmarks || landmarks.length < 6) {
    return createPose6DOF({ confidence: 0.3 });
  }
  
  const [rightEye, leftEye, nose] = landmarks;
  const faceWidth = bottomRight[0] - topLeft[0];
  const faceHeight = bottomRight[1] - topLeft[1];
  
  // Estimate yaw from eye positions
  const eyeDistance = Math.abs(leftEye[0] - rightEye[0]);
  const expectedEyeDistance = faceWidth * 0.3;
  const yaw = (eyeDistance - expectedEyeDistance) / expectedEyeDistance * 30;
  
  // Estimate pitch from nose position  
  const noseY = nose[1] - topLeft[1];
  const expectedNoseY = faceHeight * 0.5;
  const pitch = (noseY - expectedNoseY) / faceHeight * 20;
  
  // Estimate roll from eye line
  const eyeAngle = Math.atan2(leftEye[1] - rightEye[1], leftEye[0] - rightEye[0]);
  const roll = eyeAngle * (180 / Math.PI);
  
  return createPose6DOF({
    yaw: Math.max(-45, Math.min(45, yaw)),
    pitch: Math.max(-30, Math.min(30, pitch)), 
    roll: Math.max(-30, Math.min(30, roll)),
    x: (topLeft[0] + bottomRight[0]) / 2,
    y: (topLeft[1] + bottomRight[1]) / 2,
    z: 0,
    confidence: 0.6
  });
};

// Legacy simple fallback for backward compatibility
const createNodeFallback = () => createAdvancedNodeFallback();

// Create hybrid MediaPipe pipeline
export const createHybridMediaPipePipeline = (config = {}) => {
  const state = {
    faceMesh: null,
    runtime: detectRuntime(),
    features: checkFeatures(),
    config: createMediaPipeConfig(config),
    isInitialized: false,
    fallback: null
  };

  const initialize = async () => {
    try {
      console.log(`ðŸ”„ Initializing MediaPipe pipeline for ${state.runtime} environment...`);
      
      if (state.features.isBrowser) {
        // Browser: Load MediaPipe
        try {
          const loader = createMediaPipeLoader();
          await loader.load();
          const deps = { FaceMesh: window.FaceMesh };
          
          if (!deps.FaceMesh) {
            throw new Error('MediaPipe FaceMesh not available');
          }

          state.faceMesh = new deps.FaceMesh({
            locateFile: (file) => {
              return `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`;
            }
          });

          state.faceMesh.setOptions({
            maxNumFaces: state.config.maxNumFaces,
            refineLandmarks: state.config.refineLandmarks,
            minDetectionConfidence: state.config.minDetectionConfidence,
            minTrackingConfidence: state.config.minTrackingConfidence
          });

          state.faceMesh.onResults((results) => {
            state.lastResults = results;
          });

          console.log('âœ… MediaPipe Face Mesh initialized for browser');
        } catch (error) {
          console.warn('MediaPipe initialization failed, using fallback:', error);
          state.fallback = await createAdvancedNodeFallback();
        }
      } else {
        // Node.js: Use advanced fallback
        console.log('ðŸ“¦ Using advanced fallback implementation for Node.js environment');
        state.fallback = await createAdvancedNodeFallback();
      }
      
      state.isInitialized = true;
      return true;
    } catch (error) {
      console.error('âŒ MediaPipe initialization failed:', error);
      // Use advanced fallback
      state.fallback = await createAdvancedNodeFallback();
      state.isInitialized = true;
      return true;
    }
  };

  const process = async (input) => {
    if (!state.isInitialized) {
      await initialize();
    }

    try {
      const startTime = Date.now();
      
      // Use fallback if MediaPipe not available
      if (state.fallback) {
        return state.fallback.process(input);
      }

      // Browser processing with MediaPipe
      if (state.faceMesh) {
        // Process input through MediaPipe
        await state.faceMesh.send({ image: input });
        
        // Wait for results (with timeout)
        const results = await new Promise((resolve) => {
          const timeout = setTimeout(() => resolve(null), 1000);
          const checkResults = setInterval(() => {
            if (state.lastResults) {
              clearTimeout(timeout);
              clearInterval(checkResults);
              const res = state.lastResults;
              state.lastResults = null;
              resolve(res);
            }
          }, 10);
        });

        if (!results || !results.multiFaceLandmarks) {
          return createAnalysisResult({
            faces: [],
            metadata: {
              processingTime: Date.now() - startTime,
              frameTimestamp: Date.now(),
              pipelineName: 'mediapipe-hybrid',
              backend: 'mediapipe'
            }
          });
        }

        // Convert MediaPipe results to standard format
        const faces = results.multiFaceLandmarks.map((landmarks, idx) => 
          mediaPipeToFaceResult(landmarks, idx)
        ).filter(face => face !== null);

        return createAnalysisResult({
          faces,
          metadata: {
            processingTime: Date.now() - startTime,
            frameTimestamp: Date.now(),
            pipelineName: 'mediapipe-hybrid',
            backend: 'mediapipe',
            runtime: state.runtime
          }
        });
      }

      // Should not reach here
      throw new Error('No processing method available');
      
    } catch (error) {
      console.error('MediaPipe processing error:', error);
      
      // Return empty result on error
      return createAnalysisResult({
        faces: [],
        metadata: {
          processingTime: 0,
          error: error.message,
          pipelineName: 'mediapipe-hybrid',
          runtime: state.runtime
        }
      });
    }
  };

  const cleanup = () => {
    if (state.faceMesh && typeof state.faceMesh.close === 'function') {
      state.faceMesh.close();
    }
    state.faceMesh = null;
    state.fallback = null;
    state.isInitialized = false;
    console.log('ðŸ§¹ MediaPipe pipeline cleaned up');
  };

  return createPipeline({
    name: 'mediapipe-hybrid',
    capabilities: [
      Capability.FACE_DETECTION,
      Capability.POSE_ESTIMATION_6DOF,
      Capability.LANDMARK_DETECTION,
      Capability.EYE_TRACKING
    ],
    performance: createPerformanceProfile({
      fps: 30,
      latency: '30-50ms',
      modelSize: '11MB',
      cpuUsage: state.features.isBrowser ? 'medium' : 'low',
      memoryUsage: 'medium'
    }),
    initialize,
    process,
    cleanup,
    getConfig: () => state.config,
    updateConfig: (updates) => {
      state.config = { ...state.config, ...updates };
      if (state.faceMesh) {
        state.faceMesh.setOptions(state.config);
      }
    },
    isInitialized: () => state.isInitialized,
    getHealthStatus: () => ({
      healthy: state.isInitialized,
      runtime: state.runtime,
      backend: state.faceMesh ? 'mediapipe' : 'fallback',
      modelLoaded: !!state.faceMesh || !!state.fallback
    })
  });
};

// Export as main factory
export const createMediaPipeFaceMeshPipeline = createHybridMediaPipePipeline;