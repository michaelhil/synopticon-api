<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ONNX Emotion Analysis Demo - Real-Time CNN Recognition</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            color: #333;
        }

        .header {
            background: rgba(255, 255, 255, 0.95);
            padding: 20px;
            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1);
            text-align: center;
        }

        .header h1 {
            font-size: 32px;
            margin-bottom: 10px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
        }

        .header .subtitle {
            color: #666;
            font-size: 16px;
            margin-bottom: 15px;
        }

        .status-bar {
            display: flex;
            justify-content: center;
            gap: 20px;
            flex-wrap: wrap;
        }

        .status-item {
            padding: 8px 16px;
            border-radius: 20px;
            font-size: 14px;
            font-weight: 500;
            display: flex;
            align-items: center;
            gap: 8px;
        }

        .status-loading { background: #ffeaa7; color: #d63031; }
        .status-ready { background: #00b894; color: white; }
        .status-error { background: #e74c3c; color: white; }

        .main-container {
            display: flex;
            gap: 20px;
            padding: 20px;
            max-width: 1800px;
            margin: 0 auto;
            min-height: calc(100vh - 120px);
        }

        .video-section {
            flex: 2;
            background: rgba(255, 255, 255, 0.95);
            border-radius: 15px;
            padding: 20px;
            box-shadow: 0 4px 20px rgba(0, 0, 0, 0.1);
        }

        .controls {
            display: flex;
            justify-content: center;
            gap: 15px;
            margin-bottom: 20px;
            flex-wrap: wrap;
        }

        .btn {
            padding: 12px 24px;
            border: none;
            border-radius: 8px;
            font-size: 14px;
            font-weight: 600;
            cursor: pointer;
            transition: all 0.3s ease;
            display: flex;
            align-items: center;
            gap: 8px;
        }

        .btn-primary {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
        }

        .btn-secondary {
            background: #f8f9fa;
            color: #495057;
            border: 2px solid #dee2e6;
        }

        .btn:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
        }

        .btn:disabled {
            opacity: 0.6;
            cursor: not-allowed;
            transform: none;
        }

        .video-container {
            position: relative;
            background: #000;
            border-radius: 10px;
            overflow: hidden;
            margin-bottom: 20px;
        }

        #videoElement {
            width: 100%;
            height: 400px;
            object-fit: cover;
        }

        .video-overlay {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            pointer-events: none;
        }

        .analysis-section {
            flex: 1;
            background: rgba(255, 255, 255, 0.95);
            border-radius: 15px;
            padding: 20px;
            box-shadow: 0 4px 20px rgba(0, 0, 0, 0.1);
            display: flex;
            flex-direction: column;
            gap: 20px;
        }

        .section-title {
            font-size: 20px;
            font-weight: 600;
            color: #495057;
            margin-bottom: 15px;
            display: flex;
            align-items: center;
            gap: 10px;
        }

        .emotion-display {
            text-align: center;
            padding: 20px;
            background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
            border-radius: 10px;
            border: 2px solid #dee2e6;
        }

        .dominant-emotion {
            font-size: 36px;
            font-weight: 700;
            margin-bottom: 10px;
            text-transform: capitalize;
        }

        .confidence {
            font-size: 18px;
            color: #6c757d;
            font-weight: 500;
        }

        .emotion-bars {
            display: flex;
            flex-direction: column;
            gap: 8px;
        }

        .emotion-bar {
            display: flex;
            align-items: center;
            gap: 10px;
            padding: 8px;
            background: #f8f9fa;
            border-radius: 6px;
        }

        .emotion-label {
            width: 80px;
            font-size: 14px;
            font-weight: 500;
            color: #495057;
            text-transform: capitalize;
        }

        .emotion-progress {
            flex: 1;
            height: 8px;
            background: #e9ecef;
            border-radius: 4px;
            overflow: hidden;
        }

        .emotion-fill {
            height: 100%;
            border-radius: 4px;
            transition: width 0.3s ease;
        }

        .emotion-value {
            width: 45px;
            text-align: right;
            font-size: 12px;
            color: #6c757d;
            font-weight: 500;
        }

        .valence-arousal {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 15px;
        }

        .dimension {
            text-align: center;
            padding: 15px;
            background: #f8f9fa;
            border-radius: 8px;
            border: 1px solid #e9ecef;
        }

        .dimension-label {
            font-size: 14px;
            color: #6c757d;
            margin-bottom: 8px;
        }

        .dimension-value {
            font-size: 24px;
            font-weight: 700;
            color: #495057;
        }

        .stats {
            font-size: 13px;
            color: #6c757d;
            background: #f8f9fa;
            padding: 15px;
            border-radius: 8px;
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 10px;
        }

        .stat-item {
            display: flex;
            justify-content: space-between;
        }

        .performance-metrics {
            background: #e8f5e8;
            border: 1px solid #28a745;
            border-radius: 8px;
            padding: 15px;
        }

        .metric {
            display: flex;
            justify-content: space-between;
            margin-bottom: 8px;
            font-size: 14px;
        }

        .metric:last-child {
            margin-bottom: 0;
            font-weight: 600;
            border-top: 1px solid #28a745;
            padding-top: 8px;
        }

        .emotion-colors {
            --angry: #e74c3c;
            --disgusted: #8e44ad;
            --fearful: #e67e22;
            --happy: #f1c40f;
            --sad: #3498db;
            --surprised: #1abc9c;
            --neutral: #95a5a6;
        }

        @media (max-width: 1200px) {
            .main-container {
                flex-direction: column;
            }
            
            .analysis-section {
                flex: none;
            }
        }

        @media (max-width: 768px) {
            .main-container {
                padding: 10px;
                gap: 10px;
            }
            
            .controls {
                gap: 10px;
            }
            
            .btn {
                padding: 10px 16px;
                font-size: 13px;
            }
            
            #videoElement {
                height: 300px;
            }
        }

        .loading-spinner {
            display: inline-block;
            width: 16px;
            height: 16px;
            border: 2px solid #f3f3f3;
            border-top: 2px solid #667eea;
            border-radius: 50%;
            animation: spin 1s linear infinite;
        }

        @keyframes spin {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }

        .feature-badge {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 4px 8px;
            border-radius: 12px;
            font-size: 10px;
            font-weight: 600;
            text-transform: uppercase;
            letter-spacing: 0.5px;
        }
    </style>
</head>
<body>
    <div class="header">
        <h1>üß† ONNX Emotion Analysis Demo</h1>
        <div class="subtitle">Real-Time CNN-Based Emotion Recognition with MediaPipe Integration</div>
        <div class="status-bar">
            <div id="statusPipeline" class="status-item status-loading">
                <span class="loading-spinner"></span>
                Initializing Pipeline...
            </div>
            <div id="statusONNX" class="status-item status-loading">
                <span class="loading-spinner"></span>
                Loading ONNX Model...
            </div>
            <div id="statusWebcam" class="status-item status-loading">
                <span class="loading-spinner"></span>
                Webcam Ready
            </div>
        </div>
    </div>

    <div class="main-container">
        <div class="video-section">
            <div class="controls">
                <button id="startBtn" class="btn btn-primary" disabled>
                    <span>üìπ</span> Start Analysis
                </button>
                <button id="stopBtn" class="btn btn-secondary" disabled>
                    <span>‚èπÔ∏è</span> Stop
                </button>
                <button id="screenshotBtn" class="btn btn-secondary" disabled>
                    <span>üì∏</span> Capture
                </button>
                <label for="fileInput" class="btn btn-secondary">
                    <span>üìÅ</span> Upload Image
                    <input type="file" id="fileInput" accept="image/*" style="display: none;">
                </label>
            </div>

            <div class="video-container">
                <video id="videoElement" autoplay muted playsinline></video>
                <canvas id="overlayCanvas" class="video-overlay"></canvas>
            </div>

            <div class="performance-metrics">
                <div class="section-title">
                    <span>‚ö°</span> Performance Metrics
                    <span class="feature-badge">Real-Time</span>
                </div>
                <div class="metric">
                    <span>Face Detection:</span>
                    <span id="faceDetectionTime">--ms</span>
                </div>
                <div class="metric">
                    <span>Emotion Analysis:</span>
                    <span id="emotionAnalysisTime">--ms</span>
                </div>
                <div class="metric">
                    <span>Processing FPS:</span>
                    <span id="processingFPS">--</span>
                </div>
                <div class="metric">
                    <span>Total Pipeline:</span>
                    <span id="totalProcessingTime">--ms</span>
                </div>
            </div>
        </div>

        <div class="analysis-section">
            <div>
                <div class="section-title">
                    <span>üòä</span> Dominant Emotion
                    <span class="feature-badge">ONNX CNN</span>
                </div>
                <div class="emotion-display">
                    <div id="dominantEmotion" class="dominant-emotion">Neutral</div>
                    <div id="emotionConfidence" class="confidence">50% Confidence</div>
                </div>
            </div>

            <div>
                <div class="section-title">
                    <span>üìä</span> All Emotions
                </div>
                <div id="emotionBars" class="emotion-bars">
                    <!-- Emotion bars will be generated here -->
                </div>
            </div>

            <div>
                <div class="section-title">
                    <span>üéØ</span> Emotional Dimensions
                </div>
                <div class="valence-arousal">
                    <div class="dimension">
                        <div class="dimension-label">Valence</div>
                        <div id="valenceValue" class="dimension-value">0.0</div>
                    </div>
                    <div class="dimension">
                        <div class="dimension-label">Arousal</div>
                        <div id="arousalValue" class="dimension-value">0.0</div>
                    </div>
                </div>
            </div>

            <div class="stats">
                <div class="stat-item">
                    <span>Model:</span>
                    <span id="modelType">Loading...</span>
                </div>
                <div class="stat-item">
                    <span>Runtime:</span>
                    <span id="runtime">Browser</span>
                </div>
                <div class="stat-item">
                    <span>Execution:</span>
                    <span id="executionProvider">WebGL</span>
                </div>
                <div class="stat-item">
                    <span>Faces:</span>
                    <span id="faceCount">0</span>
                </div>
            </div>
        </div>
    </div>

    <!-- Load ONNX Runtime for emotion analysis -->
    <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web@1.18.0/dist/ort.min.js"></script>
    
    <script type="module">
        // Import the emotion analysis pipeline
        import { createEmotionAnalysisPipeline } from '../../src/features/emotion-analysis/emotion-analysis-pipeline.js';
        import { createMediaPipeFacePipeline } from '../../src/features/face-detection/mediapipe-face-pipeline.js';

        // Demo application state
        const state = {
            emotionPipeline: null,
            facePipeline: null,
            isInitialized: false,
            isRunning: false,
            stream: null,
            animationFrame: null,
            stats: {
                frameCount: 0,
                lastFPS: 0,
                fpsStartTime: Date.now()
            }
        };

        // Emotion colors for visualization
        const emotionColors = {
            angry: '#e74c3c',
            disgusted: '#8e44ad', 
            fearful: '#e67e22',
            happy: '#f1c40f',
            sad: '#3498db',
            surprised: '#1abc9c',
            neutral: '#95a5a6'
        };

        // Initialize the demo
        async function initializeDemo() {
            try {
                updateStatus('statusPipeline', 'loading', 'Initializing Pipeline...');
                updateStatus('statusONNX', 'loading', 'Loading ONNX Model...');

                // Create emotion analysis pipeline with ONNX model
                state.emotionPipeline = createEmotionAnalysisPipeline({
                    smoothingFactor: 0.3,
                    confidenceThreshold: 0.5,
                    enableValenceArousal: true,
                    executionProvider: 'webgl'
                });

                // Create face detection pipeline  
                state.facePipeline = createMediaPipeFacePipeline({
                    maxFaces: 1,
                    minDetectionConfidence: 0.6
                });

                // Initialize pipelines
                await Promise.all([
                    state.emotionPipeline.initialize(),
                    state.facePipeline.initialize()
                ]);

                // Initialize webcam
                await initializeWebcam();

                // Setup UI
                setupEmotionBars();
                updateModelInfo();
                
                state.isInitialized = true;
                
                updateStatus('statusPipeline', 'ready', 'Pipeline Ready');
                updateStatus('statusONNX', 'ready', 'ONNX Model Loaded');
                updateStatus('statusWebcam', 'ready', 'Webcam Ready');
                
                document.getElementById('startBtn').disabled = false;
                
                console.log('‚úÖ Demo initialized successfully');

            } catch (error) {
                console.error('‚ùå Demo initialization failed:', error);
                updateStatus('statusPipeline', 'error', 'Initialization Failed');
                updateStatus('statusONNX', 'error', error.message);
            }
        }

        // Initialize webcam
        async function initializeWebcam() {
            try {
                state.stream = await navigator.mediaDevices.getUserMedia({
                    video: { 
                        width: { ideal: 640 },
                        height: { ideal: 480 },
                        facingMode: 'user'
                    },
                    audio: false
                });

                const video = document.getElementById('videoElement');
                video.srcObject = state.stream;
                
                return new Promise((resolve) => {
                    video.onloadedmetadata = () => {
                        video.play();
                        setupCanvas();
                        resolve();
                    };
                });
            } catch (error) {
                throw new Error(`Webcam initialization failed: ${error.message}`);
            }
        }

        // Setup canvas overlay for face detection visualization
        function setupCanvas() {
            const video = document.getElementById('videoElement');
            const canvas = document.getElementById('overlayCanvas');
            canvas.width = video.videoWidth || 640;
            canvas.height = video.videoHeight || 480;
        }

        // Setup emotion bars in the UI
        function setupEmotionBars() {
            const emotions = ['angry', 'disgusted', 'fearful', 'happy', 'sad', 'surprised', 'neutral'];
            const container = document.getElementById('emotionBars');
            
            container.innerHTML = emotions.map(emotion => `
                <div class="emotion-bar">
                    <div class="emotion-label">${emotion}</div>
                    <div class="emotion-progress">
                        <div class="emotion-fill" id="emotion-${emotion}" style="width: 0%; background-color: ${emotionColors[emotion]};"></div>
                    </div>
                    <div class="emotion-value" id="value-${emotion}">0%</div>
                </div>
            `).join('');
        }

        // Update model information display
        function updateModelInfo() {
            if (state.emotionPipeline) {
                const info = state.emotionPipeline.getInfo ? state.emotionPipeline.getInfo() : {};
                const status = state.emotionPipeline.getStatus ? state.emotionPipeline.getStatus() : {};
                
                document.getElementById('modelType').textContent = 'ONNX CNN';
                document.getElementById('runtime').textContent = 'Browser';
                document.getElementById('executionProvider').textContent = 'WebGL';
            }
        }

        // Start emotion analysis
        async function startAnalysis() {
            if (!state.isInitialized || state.isRunning) return;
            
            state.isRunning = true;
            state.stats.fpsStartTime = Date.now();
            state.stats.frameCount = 0;
            
            document.getElementById('startBtn').disabled = true;
            document.getElementById('stopBtn').disabled = false;
            document.getElementById('screenshotBtn').disabled = false;
            
            processVideoFrame();
        }

        // Stop emotion analysis
        function stopAnalysis() {
            if (!state.isRunning) return;
            
            state.isRunning = false;
            
            if (state.animationFrame) {
                cancelAnimationFrame(state.animationFrame);
                state.animationFrame = null;
            }
            
            document.getElementById('startBtn').disabled = false;
            document.getElementById('stopBtn').disabled = true;
            document.getElementById('screenshotBtn').disabled = true;
            
            clearCanvas();
        }

        // Process video frame for emotion analysis
        async function processVideoFrame() {
            if (!state.isRunning) return;

            const video = document.getElementById('videoElement');
            if (video.readyState !== video.HAVE_ENOUGH_DATA) {
                state.animationFrame = requestAnimationFrame(processVideoFrame);
                return;
            }

            try {
                const startTime = performance.now();
                
                // Create image data from video
                const canvas = document.createElement('canvas');
                canvas.width = video.videoWidth;
                canvas.height = video.videoHeight;
                const ctx = canvas.getContext('2d');
                ctx.drawImage(video, 0, 0);
                const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);

                // Run face detection
                const faceStartTime = performance.now();
                const faceResults = await state.facePipeline.process(imageData);
                const faceTime = performance.now() - faceStartTime;

                // Run emotion analysis
                const emotionStartTime = performance.now();
                const emotionResults = await state.emotionPipeline.process(imageData);
                const emotionTime = performance.now() - emotionStartTime;

                const totalTime = performance.now() - startTime;

                // Update UI with results
                updateEmotionDisplay(emotionResults);
                updatePerformanceMetrics(faceTime, emotionTime, totalTime);
                drawFaceOverlay(faceResults.faces);

                // Update FPS
                state.stats.frameCount++;
                const now = Date.now();
                if (now - state.stats.fpsStartTime >= 1000) {
                    state.stats.lastFPS = state.stats.frameCount;
                    state.stats.frameCount = 0;
                    state.stats.fpsStartTime = now;
                }

            } catch (error) {
                console.error('Frame processing error:', error);
            }

            state.animationFrame = requestAnimationFrame(processVideoFrame);
        }

        // Update emotion display
        function updateEmotionDisplay(results) {
            if (!results.faces || results.faces.length === 0) {
                document.getElementById('faceCount').textContent = '0';
                return;
            }

            const face = results.faces[0];
            const emotion = face.emotion;

            // Update dominant emotion
            document.getElementById('dominantEmotion').textContent = emotion.emotion || 'neutral';
            document.getElementById('dominantEmotion').style.color = emotionColors[emotion.emotion] || emotionColors.neutral;
            document.getElementById('emotionConfidence').textContent = `${Math.round((emotion.confidence || 0) * 100)}% Confidence`;

            // Update emotion bars
            const emotions = ['angry', 'disgusted', 'fearful', 'happy', 'sad', 'surprised', 'neutral'];
            emotions.forEach(emotionName => {
                const probability = emotion.probabilities?.[emotionName] || 0;
                const percentage = Math.round(probability * 100);
                
                document.getElementById(`emotion-${emotionName}`).style.width = `${percentage}%`;
                document.getElementById(`value-${emotionName}`).textContent = `${percentage}%`;
            });

            // Update valence/arousal
            if (emotion.valence !== undefined && emotion.arousal !== undefined) {
                document.getElementById('valenceValue').textContent = emotion.valence.toFixed(1);
                document.getElementById('arousalValue').textContent = emotion.arousal.toFixed(1);
            }

            document.getElementById('faceCount').textContent = results.faces.length;
        }

        // Update performance metrics
        function updatePerformanceMetrics(faceTime, emotionTime, totalTime) {
            document.getElementById('faceDetectionTime').textContent = `${faceTime.toFixed(1)}ms`;
            document.getElementById('emotionAnalysisTime').textContent = `${emotionTime.toFixed(1)}ms`;
            document.getElementById('totalProcessingTime').textContent = `${totalTime.toFixed(1)}ms`;
            document.getElementById('processingFPS').textContent = state.stats.lastFPS;
        }

        // Draw face detection overlay
        function drawFaceOverlay(faces) {
            const canvas = document.getElementById('overlayCanvas');
            const ctx = canvas.getContext('2d');
            
            // Clear canvas
            ctx.clearRect(0, 0, canvas.width, canvas.height);
            
            if (!faces || faces.length === 0) return;

            // Draw face bounding boxes
            ctx.strokeStyle = '#00ff00';
            ctx.lineWidth = 2;
            ctx.font = '16px Arial';
            ctx.fillStyle = '#00ff00';

            faces.forEach(face => {
                const bbox = face.bbox;
                if (bbox && bbox.length === 4) {
                    const [x, y, width, height] = bbox;
                    
                    // Draw bounding box
                    ctx.strokeRect(x, y, width, height);
                    
                    // Draw emotion label
                    if (face.emotion) {
                        const label = `${face.emotion.emotion} (${Math.round(face.emotion.confidence * 100)}%)`;
                        ctx.fillText(label, x, y - 5);
                    }
                }
            });
        }

        // Clear canvas overlay
        function clearCanvas() {
            const canvas = document.getElementById('overlayCanvas');
            const ctx = canvas.getContext('2d');
            ctx.clearRect(0, 0, canvas.width, canvas.height);
        }

        // Update status indicators
        function updateStatus(elementId, status, text) {
            const element = document.getElementById(elementId);
            element.className = `status-item status-${status}`;
            
            let icon = '';
            switch (status) {
                case 'loading':
                    icon = '<span class="loading-spinner"></span>';
                    break;
                case 'ready':
                    icon = '‚úÖ';
                    break;
                case 'error':
                    icon = '‚ùå';
                    break;
            }
            
            element.innerHTML = `${icon} ${text}`;
        }

        // Handle file upload
        function handleFileUpload(event) {
            const file = event.target.files[0];
            if (!file) return;

            const reader = new FileReader();
            reader.onload = async (e) => {
                const img = new Image();
                img.onload = async () => {
                    // Stop current analysis
                    stopAnalysis();
                    
                    // Draw image to video canvas
                    const video = document.getElementById('videoElement');
                    const canvas = document.createElement('canvas');
                    canvas.width = img.width;
                    canvas.height = img.height;
                    const ctx = canvas.getContext('2d');
                    ctx.drawImage(img, 0, 0);
                    
                    // Create image data
                    const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
                    
                    // Process single image
                    try {
                        const faceResults = await state.facePipeline.process(imageData);
                        const emotionResults = await state.emotionPipeline.process(imageData);
                        
                        updateEmotionDisplay(emotionResults);
                        drawFaceOverlay(faceResults.faces);
                    } catch (error) {
                        console.error('Image processing error:', error);
                    }
                };
                img.src = e.target.result;
            };
            reader.readAsDataURL(file);
        }

        // Capture screenshot
        function captureScreenshot() {
            const video = document.getElementById('videoElement');
            const canvas = document.createElement('canvas');
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;
            const ctx = canvas.getContext('2d');
            ctx.drawImage(video, 0, 0);
            
            // Download screenshot
            const link = document.createElement('a');
            link.download = `emotion-analysis-${Date.now()}.png`;
            link.href = canvas.toDataURL();
            link.click();
        }

        // Event listeners
        document.getElementById('startBtn').addEventListener('click', startAnalysis);
        document.getElementById('stopBtn').addEventListener('click', stopAnalysis);
        document.getElementById('screenshotBtn').addEventListener('click', captureScreenshot);
        document.getElementById('fileInput').addEventListener('change', handleFileUpload);

        // Cleanup on page unload
        window.addEventListener('beforeunload', () => {
            stopAnalysis();
            if (state.stream) {
                state.stream.getTracks().forEach(track => track.stop());
            }
        });

        // Initialize demo on load
        initializeDemo();
    </script>
</body>
</html>